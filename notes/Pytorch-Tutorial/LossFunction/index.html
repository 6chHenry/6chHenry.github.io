<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="6ch. 的个人网站"><meta name=author content=6ch.><link href=https://6chHenry.github.io/notes/Pytorch-Tutorial/LossFunction/ rel=canonical><link href=../../Latex/ rel=prev><link href=../Einsum/ rel=next><link rel=icon href=../../../img/avatar1.jpg><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.17"><title>Loss Function - 6ch's Website</title><link rel=stylesheet href=../../../assets/stylesheets/main.7e37652d.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M64%20480c-35.3%200-64-28.7-64-64V96c0-35.3%2028.7-64%2064-64h320c35.3%200%2064%2028.7%2064%2064v213.5c0%2017-6.7%2033.3-18.7%2045.3L322.7%20461.3c-12%2012-28.3%2018.7-45.3%2018.7zm325.5-176H296c-13.3%200-24%2010.7-24%2024v93.5z%22/%3E%3C/svg%3E');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M384%20512H96c-53%200-96-43-96-96V96C0%2043%2043%200%2096%200h304c26.5%200%2048%2021.5%2048%2048v288c0%2020.9-13.4%2038.7-32%2045.3V448c17.7%200%2032%2014.3%2032%2032s-14.3%2032-32%2032zM96%20384c-17.7%200-32%2014.3-32%2032s14.3%2032%2032%2032h256v-64zm32-232c0%2013.3%2010.7%2024%2024%2024h176c13.3%200%2024-10.7%2024-24s-10.7-24-24-24H152c-13.3%200-24%2010.7-24%2024m24%2072c-13.3%200-24%2010.7-24%2024s10.7%2024%2024%2024h176c13.3%200%2024-10.7%2024-24s-10.7-24-24-24z%22/%3E%3C/svg%3E');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M256%20512a256%20256%200%201%200%200-512%20256%20256%200%201%200%200%20512m-32-352a32%2032%200%201%201%2064%200%2032%2032%200%201%201-64%200m-8%2064h48c13.3%200%2024%2010.7%2024%2024v88h8c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-80c-13.3%200-24-10.7-24-24s10.7-24%2024-24h24v-64h-24c-13.3%200-24-10.7-24-24s10.7-24%2024-24%22/%3E%3C/svg%3E');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M461.2%2018.9C472.7%2024%20480%2035.4%20480%2048v416c0%2012.6-7.3%2024-18.8%2029.1s-24.8%203.2-34.3-5.1l-46.6-40.7c-43.6-38.1-98.7-60.3-156.4-63V480c0%2017.7-14.3%2032-32%2032h-32c-17.7%200-32-14.3-32-32v-96C57.3%20384%200%20326.7%200%20256s57.3-128%20128-128h84.5c61.8-.2%20121.4-22.7%20167.9-63.3L427%2024c9.4-8.3%2022.9-10.2%2034.3-5.1zM224%20320v.2c70.3%202.7%20137.8%2028.5%20192%2073.4V118.3c-54.2%2044.9-121.7%2070.7-192%2073.4z%22/%3E%3C/svg%3E');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M434.8%2070.1c14.3%2010.4%2017.5%2030.4%207.1%2044.7l-256%20352c-5.5%207.6-14%2012.3-23.4%2013.1s-18.5-2.7-25.1-9.3l-128-128c-12.5-12.5-12.5-32.8%200-45.3s32.8-12.5%2045.3%200l101.5%20101.5%20234-321.7c10.4-14.3%2030.4-17.5%2044.7-7.1z%22/%3E%3C/svg%3E');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M256%20512a256%20256%200%201%200%200-512%20256%20256%200%201%200%200%20512m0-336c-17.7%200-32%2014.3-32%2032%200%2013.3-10.7%2024-24%2024s-24-10.7-24-24c0-44.2%2035.8-80%2080-80s80%2035.8%2080%2080c0%2047.2-36%2067.2-56%2074.5v3.8c0%2013.3-10.7%2024-24%2024s-24-10.7-24-24v-8.1c0-20.5%2014.8-35.2%2030.1-40.2%206.4-2.1%2013.2-5.5%2018.2-10.3%204.3-4.2%207.7-10%207.7-19.6%200-17.7-14.3-32-32-32zm-32%20192a32%2032%200%201%201%2064%200%2032%2032%200%201%201-64%200%22/%3E%3C/svg%3E');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M256%200c14.7%200%2028.2%208.1%2035.2%2021l216%20400c6.7%2012.4%206.4%2027.4-.8%2039.5S486.1%20480%20472%20480H40c-14.1%200-27.1-7.4-34.4-19.5s-7.5-27.1-.8-39.5l216-400c7-12.9%2020.5-21%2035.2-21m0%20168c-13.3%200-24%2010.7-24%2024v112c0%2013.3%2010.7%2024%2024%2024s24-10.7%2024-24V192c0-13.3-10.7-24-24-24m26.7%20216a26.7%2026.7%200%201%200-53.3%200%2026.7%2026.7%200%201%200%2053.3%200%22/%3E%3C/svg%3E');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20576%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M480-16c6.9%200%2013%204.4%2015.2%2010.9l13.5%2040.4%2040.4%2013.5C555.6%2051%20560%2057.1%20560%2064s-4.4%2013-10.9%2015.2l-40.4%2013.5-13.5%2040.4c-2.2%206.5-8.3%2010.9-15.2%2010.9s-13-4.4-15.2-10.9l-13.5-40.4-40.4-13.5C404.4%2077%20400%2070.9%20400%2064s4.4-13%2010.9-15.2l40.4-13.5%2013.5-40.4C467-11.6%20473.1-16%20480-16M321.4%2097.4c12.5-12.5%2032.8-12.5%2045.3%200l80%2080c12.5%2012.5%2012.5%2032.8%200%2045.3l-10.9%2010.9c7.9%2022%2012.2%2045.7%2012.2%2070.5%200%20114.9-93.1%20208-208%20208S32%20418.9%2032%20304%20125.1%2096%20240%2096c24.7%200%2048.5%204.3%2070.5%2012.3zM144%20304c0-53%2043-96%2096-96%2013.3%200%2024-10.7%2024-24s-10.7-24-24-24c-79.5%200-144%2064.5-144%20144%200%2013.3%2010.7%2024%2024%2024s24-10.7%2024-24%22/%3E%3C/svg%3E');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M416%20427.4c58.5-44%2096-111.6%2096-187.4C512%20107.5%20397.4%200%20256%200S0%20107.5%200%20240c0%2075.8%2037.5%20143.4%2096%20187.4V464c0%2026.5%2021.5%2048%2048%2048h32v-40c0-13.3%2010.7-24%2024-24s24%2010.7%2024%2024v40h64v-40c0-13.3%2010.7-24%2024-24s24%2010.7%2024%2024v40h32c26.5%200%2048-21.5%2048-48zM96%20256a64%2064%200%201%201%20128%200%2064%2064%200%201%201-128%200m256-64a64%2064%200%201%201%200%20128%2064%2064%200%201%201%200-128%22/%3E%3C/svg%3E');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20640%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M352%200c0-17.7-14.3-32-32-32s-32%2014.3-32%2032v64h-96c-53%200-96%2043-96%2096v224c0%2053%2043%2096%2096%2096h256c53%200%2096-43%2096-96V160c0-53-43-96-96-96h-96zM160%20368c0-13.3%2010.7-24%2024-24h32c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-32c-13.3%200-24-10.7-24-24m120%200c0-13.3%2010.7-24%2024-24h32c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-32c-13.3%200-24-10.7-24-24m120%200c0-13.3%2010.7-24%2024-24h32c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-32c-13.3%200-24-10.7-24-24M224%20176a48%2048%200%201%201%200%2096%2048%2048%200%201%201%200-96m144%2048a48%2048%200%201%201%2096%200%2048%2048%200%201%201-96%200m-304%200c0-17.7-14.3-32-32-32S0%20206.3%200%20224v96c0%2017.7%2014.3%2032%2032%2032s32-14.3%2032-32zm544-32c-17.7%200-32%2014.3-32%2032v96c0%2017.7%2014.3%2032%2032%2032s32-14.3%2032-32v-96c0-17.7-14.3-32-32-32%22/%3E%3C/svg%3E');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M288%200H128c-17.7%200-32%2014.3-32%2032s14.3%2032%2032%2032v151.5L7.5%20426.3C2.6%20435%200%20444.7%200%20454.7%200%20486.4%2025.6%20512%2057.3%20512h333.4c31.6%200%2057.3-25.6%2057.3-57.3%200-10-2.6-19.8-7.5-28.4L320%20215.5V64c17.7%200%2032-14.3%2032-32S337.7%200%20320%200zm-96%20215.5V64h64v151.5c0%2011.1%202.9%2022.1%208.4%2031.8L306%20320H142l41.6-72.7c5.5-9.7%208.4-20.6%208.4-31.8%22/%3E%3C/svg%3E');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M0%20216C0%20149.7%2053.7%2096%20120%2096h8c17.7%200%2032%2014.3%2032%2032s-14.3%2032-32%2032h-8c-30.9%200-56%2025.1-56%2056v8h64c35.3%200%2064%2028.7%2064%2064v64c0%2035.3-28.7%2064-64%2064H64c-35.3%200-64-28.7-64-64zm256%200c0-66.3%2053.7-120%20120-120h8c17.7%200%2032%2014.3%2032%2032s-14.3%2032-32%2032h-8c-30.9%200-56%2025.1-56%2056v8h64c35.3%200%2064%2028.7%2064%2064v64c0%2035.3-28.7%2064-64%2064h-64c-35.3%200-64-28.7-64-64z%22/%3E%3C/svg%3E');}</style><style>:root{--md-annotation-icon:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2024%2024%22%3E%3Cpath%20d%3D%22M22%2012a10%2010%200%200%201-10%2010A10%2010%200%200%201%202%2012%2010%2010%200%200%201%2012%202a10%2010%200%200%201%2010%2010M6%2013h8l-3.5%203.5%201.42%201.42L17.84%2012l-5.92-5.92L10.5%207.5%2014%2011H6z%22/%3E%3C/svg%3E');}</style><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=JetBrains+Mono:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"JetBrains Mono";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../css/custom.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=../../../css/card.css><link rel=stylesheet href=../../../css/flink.css><link rel=stylesheet href=../../../css/tasklist.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><link href=../../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style><script src=../../../assets/javascripts/glightbox.min.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#loss-function class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="6ch's Website" class="md-header__button md-logo" aria-label="6ch's Website" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> 6ch's Website </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Loss Function </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=indigo aria-label="light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="dark mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 256 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/6chHenry/6chHenry.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> 6ch.'s Site </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"/></svg> 主页 </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"/></svg> 笔记 </a> </li> <li class=md-tabs__item> <a href=../../../diaries/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M224 24c0-13.3 10.7-24 24-24 145.8 0 264 118.2 264 264 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-119.3-96.7-216-216-216-13.3 0-24-10.7-24-24M80 96c26.5 0 48 21.5 48 48v224c0 26.5 21.5 48 48 48s48-21.5 48-48-21.5-48-48-48c-8.8 0-16-7.2-16-16v-64c0-8.8 7.2-16 16-16 79.5 0 144 64.5 144 144s-64.5 144-144 144S32 447.5 32 368V144c0-26.5 21.5-48 48-48m168 0c92.8 0 168 75.2 168 168 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-66.3-53.7-120-120-120-13.3 0-24-10.7-24-24s10.7-24 24-24"/></svg> 日记 </a> </li> <li class=md-tabs__item> <a href=../../../summary/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1zM5 8v11h14V8zm2 2h10v2H7z"/></svg> 总结 </a> </li> <li class=md-tabs__item> <a href=../../../websites/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.78 3.653a3.936 3.936 0 1 1 5.567 5.567l-3.627 3.627a3.936 3.936 0 0 1-5.88-.353.75.75 0 0 0-1.18.928 5.436 5.436 0 0 0 8.12.486l3.628-3.628a5.436 5.436 0 1 0-7.688-7.688l-3 3a.75.75 0 0 0 1.06 1.061z"/><path d="M7.28 11.153a3.936 3.936 0 0 1 5.88.353.75.75 0 0 0 1.18-.928 5.436 5.436 0 0 0-8.12-.486L2.592 13.72a5.436 5.436 0 1 0 7.688 7.688l3-3a.75.75 0 1 0-1.06-1.06l-3 3a3.936 3.936 0 0 1-5.567-5.568z"/></svg> 网站 </a> </li> <li class=md-tabs__item> <a href=../../../projects/ class=md-tabs__link> 项目 </a> </li> <li class=md-tabs__item> <a href=../../../about/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-90.6-190.1c20.4 28 53.4 46.1 90.6 46.1s70.2-18.1 90.6-46.1c7.8-10.7 22.8-13.1 33.5-5.3s13.1 22.8 5.3 33.5C356.3 390 309.2 416 256 416s-100.3-26-129.4-65.9c-7.8-10.7-5.4-25.7 5.3-33.5s25.7-5.4 33.5 5.3M144 208a32 32 0 1 1 64 0 32 32 0 1 1-64 0m164 8c0 11-9 20-20 20s-20-9-20-20c0-33.1 26.9-60 60-60h16c33.1 0 60 26.9 60 60 0 11-9 20-20 20s-20-9-20-20-9-20-20-20h-16c-11 0-20 9-20 20"/></svg> 关于我 </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="6ch's Website" class="md-nav__button md-logo" aria-label="6ch's Website" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"/></svg> </a> 6ch's Website </label> <div class=md-nav__source> <a href=https://github.com/6chHenry/6chHenry.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> 6ch.'s Site </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"/></svg> <span class=md-ellipsis> 主页 </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"/></svg> <span class=md-ellipsis> 笔记 </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> 笔记 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex=0> <span class=md-ellipsis> EECS 498(Deep Learning for Computer Vision) </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> EECS 498(Deep Learning for Computer Vision) </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../EECS498/Linear%20Classifiers/ class=md-nav__link> <span class=md-ellipsis> Linear Classifiers </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/Optimization/ class=md-nav__link> <span class=md-ellipsis> Optimization </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/A1/ class=md-nav__link> <span class=md-ellipsis> 第一次作业(pytorch & KNN) </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/Neural%20Network/ class=md-nav__link> <span class=md-ellipsis> Neural Network </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/Back%20Propagation/ class=md-nav__link> <span class=md-ellipsis> Back Propagation </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/Derivative%20of%20Matrix/ class=md-nav__link> <span class=md-ellipsis> 矩阵求导 </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/A2/ class=md-nav__link> <span class=md-ellipsis> 第二次作业(Linear Classifiers) </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/2-layer-network/ class=md-nav__link> <span class=md-ellipsis> 第二次作业(Two Layer Net) </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/CNN/ class=md-nav__link> <span class=md-ellipsis> CNN </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/CNNArchiture/ class=md-nav__link> <span class=md-ellipsis> CNNArchitecture </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/TrainingNN/ class=md-nav__link> <span class=md-ellipsis> TrainingNN </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3> <label class=md-nav__link for=__nav_2_3 id=__nav_2_3_label tabindex=0> <span class=md-ellipsis> 概率统计（荣誉）(MATH1207H) </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> 概率统计（荣誉）(MATH1207H) </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Probability/%E8%AE%A8%E8%AE%BA2/ class=md-nav__link> <span class=md-ellipsis> 第二次讨论 </span> </a> </li> <li class=md-nav__item> <a href=../../Probability/%E8%AE%A8%E8%AE%BA3/ class=md-nav__link> <span class=md-ellipsis> 第三次讨论 </span> </a> </li> <li class=md-nav__item> <a href=../../Probability/%E8%AE%A8%E8%AE%BA4/ class=md-nav__link> <span class=md-ellipsis> 第四次讨论 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_4> <label class=md-nav__link for=__nav_2_4 id=__nav_2_4_label tabindex=0> <span class=md-ellipsis> 数据结构（荣誉）(CS0501H) </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_4> <span class="md-nav__icon md-icon"></span> 数据结构（荣誉）(CS0501H) </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../CS0501H/%E9%93%BE%E8%A1%A8/ class=md-nav__link> <span class=md-ellipsis> 线性表 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_5> <label class=md-nav__link for=__nav_2_5 id=__nav_2_5_label tabindex=0> <span class=md-ellipsis> 从零构建GPT(Karpathy) </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_5_label aria-expanded=false> <label class=md-nav__title for=__nav_2_5> <span class="md-nav__icon md-icon"></span> 从零构建GPT(Karpathy) </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../GPT/micrograd/ class=md-nav__link> <span class=md-ellipsis> Micrograd </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/makemore/ class=md-nav__link> <span class=md-ellipsis> Makemore(First Status) </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/makemoreMLP/ class=md-nav__link> <span class=md-ellipsis> Makemore(MLP) </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/makemoreActivation/ class=md-nav__link> <span class=md-ellipsis> Makemore(Activation) </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/makemoreNinja/ class=md-nav__link> <span class=md-ellipsis> Makemore(Become a Backprop Ninja) </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/makemoreComnet/ class=md-nav__link> <span class=md-ellipsis> Makemore(Convolution Layer) </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/ShakespeareGPT/ class=md-nav__link> <span class=md-ellipsis> ShakespeareGPT </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/Attention%20is%20All%20You%20Need/ class=md-nav__link> <span class=md-ellipsis> Attention is All You Need </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/diveintogpt/ class=md-nav__link> <span class=md-ellipsis> Dive into GPT </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_6> <label class=md-nav__link for=__nav_2_6 id=__nav_2_6_label tabindex=0> <span class=md-ellipsis> Python进阶教程 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_6_label aria-expanded=false> <label class=md-nav__title for=__nav_2_6> <span class="md-nav__icon md-icon"></span> Python进阶教程 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Python-Tutorial/For-Loop/ class=md-nav__link> <span class=md-ellipsis> 减少For-Loop </span> </a> </li> <li class=md-nav__item> <a href=../../Python-Tutorial/Pyplot/ class=md-nav__link> <span class=md-ellipsis> Matplotlib </span> </a> </li> <li class=md-nav__item> <a href=../../Python-Tutorial/pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class=md-nav__item> <a href=../../Python-Tutorial/Tensorboard/ class=md-nav__link> <span class=md-ellipsis> Tensorboard </span> </a> </li> <li class=md-nav__item> <a href=../../Python-Tutorial/Logging/ class=md-nav__link> <span class=md-ellipsis> Logging </span> </a> </li> <li class=md-nav__item> <a href=../../Python-Tutorial/WhatIsPickle/ class=md-nav__link> <span class=md-ellipsis> Pickle </span> </a> </li> <li class=md-nav__item> <a href=../../Python-Tutorial/LearnRegex/ class=md-nav__link> <span class=md-ellipsis> Regex </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_7> <label class=md-nav__link for=__nav_2_7 id=__nav_2_7_label tabindex=0> <span class=md-ellipsis> 科研笔记 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_7_label aria-expanded=false> <label class=md-nav__title for=__nav_2_7> <span class="md-nav__icon md-icon"></span> 科研笔记 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_7_1> <label class=md-nav__link for=__nav_2_7_1 id=__nav_2_7_1_label tabindex=0> <span class=md-ellipsis> OCL </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_7_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_7_1> <span class="md-nav__icon md-icon"></span> OCL </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Research/OCL/OCL/ class=md-nav__link> <span class=md-ellipsis> OCL </span> </a> </li> <li class=md-nav__item> <a href=../../Research/OCL/CosineSimilarity/ class=md-nav__link> <span class=md-ellipsis> 余弦相似度 </span> </a> </li> <li class=md-nav__item> <a href=../../Research/OCL/mAP/ class=md-nav__link> <span class=md-ellipsis> mAP </span> </a> </li> <li class=md-nav__item> <a href=../../Research/OCL/tSNE/ class=md-nav__link> <span class=md-ellipsis> tSNE </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../Research/CausalDiscovery/Causal_Structure_Distributions/ class=md-nav__link> <span class=md-ellipsis> Causal Structure Distributions </span> </a> </li> <li class=md-nav__item> <a href=../../Research/Llava/ class=md-nav__link> <span class=md-ellipsis> Llava </span> </a> </li> <li class=md-nav__item> <a href=../../Research/CELLO/ class=md-nav__link> <span class=md-ellipsis> CELLO </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../SeveralQ/ class=md-nav__link> <span class=md-ellipsis> 一些问题 </span> </a> </li> <li class=md-nav__item> <a href=../../Latex/ class=md-nav__link> <span class=md-ellipsis> Latex基本教程 </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_10 checked> <label class=md-nav__link for=__nav_2_10 id=__nav_2_10_label tabindex=0> <span class=md-ellipsis> Pytorch进阶教程 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_10_label aria-expanded=true> <label class=md-nav__title for=__nav_2_10> <span class="md-nav__icon md-icon"></span> Pytorch进阶教程 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Loss Function </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Loss Function </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#positivebceloss class=md-nav__link> <span class=md-ellipsis> PositiveBCELoss </span> </a> </li> <li class=md-nav__item> <a href=#l1-loss-mean-absolute-error-mae class=md-nav__link> <span class=md-ellipsis> L1 Loss (Mean Absolute Error - MAE) </span> </a> <nav class=md-nav aria-label="L1 Loss (Mean Absolute Error - MAE)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#negative-log-likelihood-loss-nll-loss class=md-nav__link> <span class=md-ellipsis> Negative Log Likelihood Loss (NLL Loss) </span> </a> <nav class=md-nav aria-label="Negative Log Likelihood Loss (NLL Loss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_6 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#poisson-negative-log-likelihood-loss-poissonnllloss class=md-nav__link> <span class=md-ellipsis> Poisson Negative Log Likelihood Loss (PoissonNLLLoss) </span> </a> <nav class=md-nav aria-label="Poisson Negative Log Likelihood Loss (PoissonNLLLoss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_7 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_8 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#gaussian-negative-log-likelihood-loss-gaussiannllloss class=md-nav__link> <span class=md-ellipsis> Gaussian Negative Log Likelihood Loss (GaussianNLLLoss) </span> </a> <nav class=md-nav aria-label="Gaussian Negative Log Likelihood Loss (GaussianNLLLoss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_10 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_11 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_12 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#kullback-leibler-divergence-loss-kldivloss class=md-nav__link> <span class=md-ellipsis> Kullback-Leibler Divergence Loss (KLDivLoss) </span> </a> <nav class=md-nav aria-label="Kullback-Leibler Divergence Loss (KLDivLoss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_13 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_14 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_15 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#mean-squared-error-loss-mseloss class=md-nav__link> <span class=md-ellipsis> Mean Squared Error Loss (MSELoss) </span> </a> <nav class=md-nav aria-label="Mean Squared Error Loss (MSELoss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_16 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_17 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_18 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#binary-cross-entropy-loss-bceloss class=md-nav__link> <span class=md-ellipsis> Binary Cross Entropy Loss (BCELoss) </span> </a> <nav class=md-nav aria-label="Binary Cross Entropy Loss (BCELoss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_19 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_20 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_21 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#binary-cross-entropy-with-logits-loss-bcewithlogitsloss class=md-nav__link> <span class=md-ellipsis> Binary Cross Entropy with Logits Loss (BCEWithLogitsLoss) </span> </a> <nav class=md-nav aria-label="Binary Cross Entropy with Logits Loss (BCEWithLogitsLoss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_22 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_23 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_24 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#hinge-embedding-loss class=md-nav__link> <span class=md-ellipsis> Hinge Embedding Loss </span> </a> <nav class=md-nav aria-label="Hinge Embedding Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_25 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_26 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_27 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#multi-label-margin-loss class=md-nav__link> <span class=md-ellipsis> Multi Label Margin Loss </span> </a> <nav class=md-nav aria-label="Multi Label Margin Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_28 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_29 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_30 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#smooth-l1-loss class=md-nav__link> <span class=md-ellipsis> Smooth L1 Loss </span> </a> <nav class=md-nav aria-label="Smooth L1 Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_31 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_32 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_33 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#huber-loss class=md-nav__link> <span class=md-ellipsis> Huber Loss </span> </a> <nav class=md-nav aria-label="Huber Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_34 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_35 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_36 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#soft-margin-loss class=md-nav__link> <span class=md-ellipsis> Soft Margin Loss </span> </a> <nav class=md-nav aria-label="Soft Margin Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_37 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_38 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_39 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#cross-entropy-loss class=md-nav__link> <span class=md-ellipsis> Cross Entropy Loss </span> </a> <nav class=md-nav aria-label="Cross Entropy Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_40 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_41 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_42 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#multi-label-soft-margin-loss class=md-nav__link> <span class=md-ellipsis> Multi Label Soft Margin Loss </span> </a> <nav class=md-nav aria-label="Multi Label Soft Margin Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_43 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_44 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_45 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#cosine-embedding-loss class=md-nav__link> <span class=md-ellipsis> Cosine Embedding Loss </span> </a> <nav class=md-nav aria-label="Cosine Embedding Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_46 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_47 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_48 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#margin-ranking-loss class=md-nav__link> <span class=md-ellipsis> Margin Ranking Loss </span> </a> <nav class=md-nav aria-label="Margin Ranking Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_49 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_50 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_51 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#multi-margin-loss class=md-nav__link> <span class=md-ellipsis> Multi Margin Loss </span> </a> <nav class=md-nav aria-label="Multi Margin Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_52 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_53 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_54 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#triplet-margin-loss class=md-nav__link> <span class=md-ellipsis> Triplet Margin Loss </span> </a> <nav class=md-nav aria-label="Triplet Margin Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_55 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_56 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_57 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#triplet-margin-with-distance-loss class=md-nav__link> <span class=md-ellipsis> Triplet Margin with Distance Loss </span> </a> <nav class=md-nav aria-label="Triplet Margin with Distance Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_58 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_59 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_60 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#connectionist-temporal-classification-loss-ctcloss class=md-nav__link> <span class=md-ellipsis> Connectionist Temporal Classification Loss (CTCLoss) </span> </a> <nav class=md-nav aria-label="Connectionist Temporal Classification Loss (CTCLoss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_61 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_62 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_63 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../Einsum/ class=md-nav__link> <span class=md-ellipsis> Einsum </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../../../diaries/ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M224 24c0-13.3 10.7-24 24-24 145.8 0 264 118.2 264 264 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-119.3-96.7-216-216-216-13.3 0-24-10.7-24-24M80 96c26.5 0 48 21.5 48 48v224c0 26.5 21.5 48 48 48s48-21.5 48-48-21.5-48-48-48c-8.8 0-16-7.2-16-16v-64c0-8.8 7.2-16 16-16 79.5 0 144 64.5 144 144s-64.5 144-144 144S32 447.5 32 368V144c0-26.5 21.5-48 48-48m168 0c92.8 0 168 75.2 168 168 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-66.3-53.7-120-120-120-13.3 0-24-10.7-24-24s10.7-24 24-24"/></svg> <span class=md-ellipsis> 日记 </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> 日记 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> 2025年 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> 2025年 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../diaries/2025/Aug/ class=md-nav__link> <span class=md-ellipsis> 8月 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <div class="md-nav__link md-nav__container"> <a href=../../../summary/ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1zM5 8v11h14V8zm2 2h10v2H7z"/></svg> <span class=md-ellipsis> 总结 </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> 总结 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex=0> <span class=md-ellipsis> 影评 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> 影评 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../summary/Movies/3%20Idiots/ class=md-nav__link> <span class=md-ellipsis> 3 Idiots </span> </a> </li> <li class=md-nav__item> <a href=../../../summary/Movies/Hachi/ class=md-nav__link> <span class=md-ellipsis> Hachi </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_3> <label class=md-nav__link for=__nav_4_3 id=__nav_4_3_label tabindex=0> <span class=md-ellipsis> 音乐 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_3_label aria-expanded=false> <label class=md-nav__title for=__nav_4_3> <span class="md-nav__icon md-icon"></span> 音乐 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../summary/Music/%E5%AD%A4%E5%84%BF%E4%BB%94/ class=md-nav__link> <span class=md-ellipsis> 孤儿仔 --Eason Chan </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../summary/%E9%AB%98%E4%B8%AD%E5%9B%9E%E5%BF%86%E5%BD%95/ class=md-nav__link> <span class=md-ellipsis> 我的高中 </span> </a> </li> <li class=md-nav__item> <a href=../../../summary/%E7%9D%A1%E7%9C%A0%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7/ class=md-nav__link> <span class=md-ellipsis> 睡眠 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <div class="md-nav__link md-nav__container"> <a href=../../../websites/ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.78 3.653a3.936 3.936 0 1 1 5.567 5.567l-3.627 3.627a3.936 3.936 0 0 1-5.88-.353.75.75 0 0 0-1.18.928 5.436 5.436 0 0 0 8.12.486l3.628-3.628a5.436 5.436 0 1 0-7.688-7.688l-3 3a.75.75 0 0 0 1.06 1.061z"/><path d="M7.28 11.153a3.936 3.936 0 0 1 5.88.353.75.75 0 0 0 1.18-.928 5.436 5.436 0 0 0-8.12-.486L2.592 13.72a5.436 5.436 0 1 0 7.688 7.688l3-3a.75.75 0 1 0-1.06-1.06l-3 3a3.936 3.936 0 0 1-5.567-5.568z"/></svg> <span class=md-ellipsis> 网站 </span> </a> <label class="md-nav__link " for=__nav_5 id=__nav_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> 网站 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../websites/LLM/ class=md-nav__link> <span class=md-ellipsis> LLM </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6> <div class="md-nav__link md-nav__container"> <a href=../../../projects/ class="md-nav__link "> <span class=md-ellipsis> 项目 </span> </a> <label class="md-nav__link " for=__nav_6 id=__nav_6_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> 项目 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_2> <label class=md-nav__link for=__nav_6_2 id=__nav_6_2_label tabindex=0> <span class=md-ellipsis> CarLaneDetection </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_2_label aria-expanded=false> <label class=md-nav__title for=__nav_6_2> <span class="md-nav__icon md-icon"></span> CarLaneDetection </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../projects/CarLaneDetection/Canny/ class=md-nav__link> <span class=md-ellipsis> CannyEdgeDetection </span> </a> </li> <li class=md-nav__item> <a href=../../../projects/CarLaneDetection/HoughTransform/ class=md-nav__link> <span class=md-ellipsis> HoughTransform </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../about/ class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-90.6-190.1c20.4 28 53.4 46.1 90.6 46.1s70.2-18.1 90.6-46.1c7.8-10.7 22.8-13.1 33.5-5.3s13.1 22.8 5.3 33.5C356.3 390 309.2 416 256 416s-100.3-26-129.4-65.9c-7.8-10.7-5.4-25.7 5.3-33.5s25.7-5.4 33.5 5.3M144 208a32 32 0 1 1 64 0 32 32 0 1 1-64 0m164 8c0 11-9 20-20 20s-20-9-20-20c0-33.1 26.9-60 60-60h16c33.1 0 60 26.9 60 60 0 11-9 20-20 20s-20-9-20-20-9-20-20-20h-16c-11 0-20 9-20 20"/></svg> <span class=md-ellipsis> 关于我 </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#positivebceloss class=md-nav__link> <span class=md-ellipsis> PositiveBCELoss </span> </a> </li> <li class=md-nav__item> <a href=#l1-loss-mean-absolute-error-mae class=md-nav__link> <span class=md-ellipsis> L1 Loss (Mean Absolute Error - MAE) </span> </a> <nav class=md-nav aria-label="L1 Loss (Mean Absolute Error - MAE)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#negative-log-likelihood-loss-nll-loss class=md-nav__link> <span class=md-ellipsis> Negative Log Likelihood Loss (NLL Loss) </span> </a> <nav class=md-nav aria-label="Negative Log Likelihood Loss (NLL Loss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_6 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#poisson-negative-log-likelihood-loss-poissonnllloss class=md-nav__link> <span class=md-ellipsis> Poisson Negative Log Likelihood Loss (PoissonNLLLoss) </span> </a> <nav class=md-nav aria-label="Poisson Negative Log Likelihood Loss (PoissonNLLLoss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_7 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_8 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#gaussian-negative-log-likelihood-loss-gaussiannllloss class=md-nav__link> <span class=md-ellipsis> Gaussian Negative Log Likelihood Loss (GaussianNLLLoss) </span> </a> <nav class=md-nav aria-label="Gaussian Negative Log Likelihood Loss (GaussianNLLLoss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_10 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_11 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_12 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#kullback-leibler-divergence-loss-kldivloss class=md-nav__link> <span class=md-ellipsis> Kullback-Leibler Divergence Loss (KLDivLoss) </span> </a> <nav class=md-nav aria-label="Kullback-Leibler Divergence Loss (KLDivLoss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_13 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_14 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_15 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#mean-squared-error-loss-mseloss class=md-nav__link> <span class=md-ellipsis> Mean Squared Error Loss (MSELoss) </span> </a> <nav class=md-nav aria-label="Mean Squared Error Loss (MSELoss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_16 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_17 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_18 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#binary-cross-entropy-loss-bceloss class=md-nav__link> <span class=md-ellipsis> Binary Cross Entropy Loss (BCELoss) </span> </a> <nav class=md-nav aria-label="Binary Cross Entropy Loss (BCELoss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_19 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_20 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_21 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#binary-cross-entropy-with-logits-loss-bcewithlogitsloss class=md-nav__link> <span class=md-ellipsis> Binary Cross Entropy with Logits Loss (BCEWithLogitsLoss) </span> </a> <nav class=md-nav aria-label="Binary Cross Entropy with Logits Loss (BCEWithLogitsLoss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_22 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_23 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_24 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#hinge-embedding-loss class=md-nav__link> <span class=md-ellipsis> Hinge Embedding Loss </span> </a> <nav class=md-nav aria-label="Hinge Embedding Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_25 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_26 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_27 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#multi-label-margin-loss class=md-nav__link> <span class=md-ellipsis> Multi Label Margin Loss </span> </a> <nav class=md-nav aria-label="Multi Label Margin Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_28 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_29 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_30 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#smooth-l1-loss class=md-nav__link> <span class=md-ellipsis> Smooth L1 Loss </span> </a> <nav class=md-nav aria-label="Smooth L1 Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_31 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_32 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_33 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#huber-loss class=md-nav__link> <span class=md-ellipsis> Huber Loss </span> </a> <nav class=md-nav aria-label="Huber Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_34 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_35 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_36 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#soft-margin-loss class=md-nav__link> <span class=md-ellipsis> Soft Margin Loss </span> </a> <nav class=md-nav aria-label="Soft Margin Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_37 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_38 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_39 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#cross-entropy-loss class=md-nav__link> <span class=md-ellipsis> Cross Entropy Loss </span> </a> <nav class=md-nav aria-label="Cross Entropy Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_40 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_41 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_42 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#multi-label-soft-margin-loss class=md-nav__link> <span class=md-ellipsis> Multi Label Soft Margin Loss </span> </a> <nav class=md-nav aria-label="Multi Label Soft Margin Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_43 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_44 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_45 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#cosine-embedding-loss class=md-nav__link> <span class=md-ellipsis> Cosine Embedding Loss </span> </a> <nav class=md-nav aria-label="Cosine Embedding Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_46 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_47 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_48 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#margin-ranking-loss class=md-nav__link> <span class=md-ellipsis> Margin Ranking Loss </span> </a> <nav class=md-nav aria-label="Margin Ranking Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_49 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_50 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_51 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#multi-margin-loss class=md-nav__link> <span class=md-ellipsis> Multi Margin Loss </span> </a> <nav class=md-nav aria-label="Multi Margin Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_52 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_53 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_54 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#triplet-margin-loss class=md-nav__link> <span class=md-ellipsis> Triplet Margin Loss </span> </a> <nav class=md-nav aria-label="Triplet Margin Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_55 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_56 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_57 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#triplet-margin-with-distance-loss class=md-nav__link> <span class=md-ellipsis> Triplet Margin with Distance Loss </span> </a> <nav class=md-nav aria-label="Triplet Margin with Distance Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_58 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_59 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_60 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#connectionist-temporal-classification-loss-ctcloss class=md-nav__link> <span class=md-ellipsis> Connectionist Temporal Classification Loss (CTCLoss) </span> </a> <nav class=md-nav aria-label="Connectionist Temporal Classification Loss (CTCLoss)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_61 class=md-nav__link> <span class=md-ellipsis> 数学表达式 </span> </a> </li> <li class=md-nav__item> <a href=#_62 class=md-nav__link> <span class=md-ellipsis> 适用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_63 class=md-nav__link> <span class=md-ellipsis> 参数说明 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <div><h1 id=loss-function>Loss Function<a class=headerlink href=#loss-function title="Permanent link">¶</a></h1> <div style="margin-top: -30px; font-size: 0.75em; opacity: 0.7;"> <p><span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8zm6.78 1a.7.7 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38z"></path></svg></span> 约 3582 个字 <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M360.8 1.2c-17-4.9-34.7 5-39.6 22l-128 448c-4.9 17 5 34.7 22 39.6s34.7-5 39.6-22l128-448c4.9-17-5-34.7-22-39.6m64.6 136.1c-12.5 12.5-12.5 32.8 0 45.3l73.4 73.4-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l96-96c12.5-12.5 12.5-32.8 0-45.3l-96-96c-12.5-12.5-32.8-12.5-45.3 0zm-274.7 0c-12.5-12.5-32.8-12.5-45.3 0l-96 96c-12.5 12.5-12.5 32.8 0 45.3l96 96c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l73.3-73.4c12.5-12.5 12.5-32.8 0-45.3z"></path></svg></span> 451 行代码 <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3z"></path></svg></span> 预计阅读时间 24 分钟</p> </div> <h2 id=positivebceloss>PositiveBCELoss<a class=headerlink href=#positivebceloss title="Permanent link">¶</a></h2> <p>PositiveBCELoss 是一种 二元交叉熵损失（Binary Cross-Entropy Loss, BCE Loss）的变体，专门用于 仅计算正样本（Positive Samples）的损失。<br> 它的核心思想是：<strong>只关注正类（target=1）的预测概率，忽略负类（target=0）的贡献。</strong></p> <p>适用场景:</p> <ul> <li> <p>当数据中 <strong>负样本远多于正样本</strong>（类别不平衡）时，传统 BCE Loss 可能被负样本主导，导致模型对正样本学习不足。</p> </li> <li> <p>希望 <strong>更聚焦正样本的优化</strong>（如医学检测中的罕见病例、异常检测等）。</p> </li> </ul> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1></a><a href=#__codelineno-0-1><span class=linenos data-linenos=" 1 "></span></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2></a><a href=#__codelineno-0-2><span class=linenos data-linenos=" 2 "></span></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.nn.functional</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>F</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3></a><a href=#__codelineno-0-3><span class=linenos data-linenos=" 3 "></span></a>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4></a><a href=#__codelineno-0-4><span class=linenos data-linenos=" 4 "></span></a><span class=k>class</span><span class=w> </span><span class=nc>PositiveBCELoss</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5></a><a href=#__codelineno-0-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>class_weight</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6></a><a href=#__codelineno-0-6><span class=linenos data-linenos=" 6 "></span></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7></a><a href=#__codelineno-0-7><span class=linenos data-linenos=" 7 "></span></a>        <span class=bp>self</span><span class=o>.</span><span class=n>register_buffer</span><span class=p>(</span><span class=s2>"class_weight"</span><span class=p>,</span> <span class=n>class_weight</span><span class=p>)</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8></a><a href=#__codelineno-0-8><span class=linenos data-linenos=" 8 "></span></a>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9></a><a href=#__codelineno-0-9><span class=linenos data-linenos=" 9 "></span></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>logit</span><span class=p>,</span> <span class=n>target</span><span class=p>):</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10></a><a href=#__codelineno-0-10><span class=linenos data-linenos="10 "></span></a>        <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>logsigmoid</span><span class=p>(</span><span class=n>logit</span><span class=p>)</span> <span class=o>*</span> <span class=n>target</span>  <span class=c1># 关键步骤：仅正样本参与计算</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11></a><a href=#__codelineno-0-11><span class=linenos data-linenos="11 "></span></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>class_weight</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12></a><a href=#__codelineno-0-12><span class=linenos data-linenos="12 "></span></a>            <span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>class_weight</span>   <span class=c1># 可选：正样本的类别权重</span>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13></a><a href=#__codelineno-0-13><span class=linenos data-linenos="13 "></span></a>        <span class=n>loss</span> <span class=o>=</span> <span class=o>-</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span>              <span class=c1># 取平均并取负（最大化对数概率 = 最小化损失）</span>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14></a><a href=#__codelineno-0-14><span class=linenos data-linenos="14 "></span></a>        <span class=k>return</span> <span class=n>loss</span>
</span></code></pre></div> <p>代码讲解：</p> <ul> <li>F.logsigmoid(logit)</li> </ul> <p>对模型的原始输出 logit 计算对数 Sigmoid（即 log(σ(logit))），等价于 log(1 / (1 + exp(-logit)))。</p> <p>这表示 预测正类的对数概率（因为 σ(logit) 是预测正类的概率）。</p> <div class="admonition info"> <p class=admonition-title>在二元分类问题中，σ(logit)（即 Sigmoid 函数）的输出被解释为 预测正类的概率，这是由逻辑回归（Logistic Regression）的数学原理决定的。下面详细解释为什么：</p> </div> <blockquote> <p>Sigmoid 函数的作用:Sigmoid 函数定义为：<br> <span class=arithmatex>\(\sigma(x) = \frac{1}{1+e^{-x}}\)</span><br> 它将任意实数x（即 logit）映射到 (0,1) 区间，输出可以直观理解为概率。</p> <p>从 Logit 到概率的推导<br> 在二元分类中：<br> 模型的原始输出是 logit（也称为“对数几率”），范围是 <span class=arithmatex>\((-\infty,+\infty)\)</span>。<br> 通过 Sigmoid 将 logit 转换为概率：<br> <span class=arithmatex>\(P(y=1∣x)=σ(logit)\)</span><br> ​如果 logit 很大（如 +∞），P(y=1)→1。<br> 如果 logit 很小（如 -∞）, P(y=1)→0。</p> <p>为什么是“正类”的概率？<br> 对数几率的解释：<br> logit 的本质是 正类概率的对数几率（log-odds）：<br> <span class=arithmatex>\(logit=log(\frac{P(y=1)}{P(y=0)})\)</span><br> 通过 Sigmoid 的反向推导：<br> <span class=arithmatex>\(\sigma(logit)=\frac{P(y=1)}{P(y=0)+P(y=1)}=P(y=1)\)</span><br> 因此，σ(logit) 直接表示正类的概率。</p> </blockquote> <ul> <li>* target</li> </ul> <p>通过 target（0 或 1 的掩码）过滤，仅保留正样本的损失（target=1 的位置保留值，target=0 的位置归零）。</p> <ul> <li>class_weight（可选）</li> </ul> <p>如果提供 class_weight，会对正样本的损失加权（常用于进一步平衡类别）。</p> <ul> <li>-(x.mean())</li> </ul> <p>对剩余的正样本损失取平均，并取负号（因为 log(p) 是负数，取负后得到正损失值）。</p> <h2 id=l1-loss-mean-absolute-error-mae>L1 Loss (Mean Absolute Error - MAE)<a class=headerlink href=#l1-loss-mean-absolute-error-mae title="Permanent link">¶</a></h2> <h3 id=_1>数学表达式<a class=headerlink href=#_1 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = \frac{1}{n}\sum_{i=1}^{n} |x_i - y_i|<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测值（模型输出）<br> - <span class=arithmatex>\( y \)</span> 是目标值（真实标签）<br> - <span class=arithmatex>\( n \)</span> 是样本数量</p> <h3 id=_2>适用场景<a class=headerlink href=#_2 title="Permanent link">¶</a></h3> <ol> <li><strong>回归任务</strong>：当需要预测连续值且对异常值不敏感时</li> <li><strong>鲁棒性要求高</strong>：相比L2 Loss更不易受异常值影响</li> <li><strong>稀疏梯度需求</strong>：在需要梯度大小恒定的场景</li> </ol> <h3 id=_3>参数说明<a class=headerlink href=#_3 title="Permanent link">¶</a></h3> <p>在PyTorch中通过<code>torch.nn.L1Loss</code>实现，主要参数：</p> <p></p><div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1></a><a href=#__codelineno-1-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>L1Loss</span><span class=p>(</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2></a><a href=#__codelineno-1-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃（默认取mean）</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3></a><a href=#__codelineno-1-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4></a><a href=#__codelineno-1-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>    <span class=c1># 可选：'none'|'mean'|'sum'</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5></a><a href=#__codelineno-1-5><span class=linenos data-linenos=" 5 "></span></a><span class=p>)</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6></a><a href=#__codelineno-1-6><span class=linenos data-linenos=" 6 "></span></a><span class=sd>"""</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7></a><a href=#__codelineno-1-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>reduction:</span>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8></a><a href=#__codelineno-1-8><span class=linenos data-linenos=" 8 "></span></a>
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9></a><a href=#__codelineno-1-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>'none'：返回逐元素损失 The same shape as Input</span>
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10></a><a href=#__codelineno-1-10><span class=linenos data-linenos="10 "></span></a>
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11></a><a href=#__codelineno-1-11><span class=linenos data-linenos="11 "></span></a><span class=sd>'mean'（默认）：返回损失均值  (1,)</span>
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12></a><a href=#__codelineno-1-12><span class=linenos data-linenos="12 "></span></a>
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13></a><a href=#__codelineno-1-13><span class=linenos data-linenos="13 "></span></a><span class=sd>'sum'：返回损失总和  (1,)</span>
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14></a><a href=#__codelineno-1-14><span class=linenos data-linenos="14 "></span></a><span class=sd>"""</span>
</span></code></pre></div><br> <a href=https://docs.pytorch.org/docs/stable/generated/torch.nn.L1Loss.html>L1 Loss官方文档</a> <h2 id=negative-log-likelihood-loss-nll-loss>Negative Log Likelihood Loss (NLL Loss)<a class=headerlink href=#negative-log-likelihood-loss-nll-loss title="Permanent link">¶</a></h2> <h3 id=_4>数学表达式<a class=headerlink href=#_4 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = -\frac{1}{n}\sum_{i=1}^{n} x_{i,y_i}<br> $$<br> 或更一般的形式：<br> $$<br> \mathcal{L}(x, y) = -\sum_{i=1}^{n} \log(p_{y_i})<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测的对数概率（log-probabilities），形状为 (N, C)<br> - <span class=arithmatex>\( y \)</span> 是目标类别索引，形状为 (N)<br> - <span class=arithmatex>\( p_{y_i} \)</span> 是对应真实类别的预测概率<br> - <span class=arithmatex>\( n \)</span> 是 batch size<br> - <span class=arithmatex>\( C \)</span> 是类别数</p> <h3 id=_5>适用场景<a class=headerlink href=#_5 title="Permanent link">¶</a></h3> <ol> <li><strong>多分类问题</strong>：常与LogSoftmax配合使用</li> <li><strong>神经网络输出概率分布</strong>：要求输入已经是对数概率</li> <li><strong>语言模型/文本分类</strong>：在NLP任务中广泛使用</li> </ol> <h3 id=_6>参数说明<a class=headerlink href=#_6 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.NLLLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1></a><a href=#__codelineno-2-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>NLLLoss</span><span class=p>(</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2></a><a href=#__codelineno-2-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>weight</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 各类别的权重（1D Tensor）</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3></a><a href=#__codelineno-2-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4></a><a href=#__codelineno-2-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>ignore_index</span><span class=o>=-</span><span class=mi>100</span><span class=p>,</span>  <span class=c1># 忽略的目标类别索引</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5></a><a href=#__codelineno-2-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6></a><a href=#__codelineno-2-6><span class=linenos data-linenos=" 6 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>    <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7></a><a href=#__codelineno-2-7><span class=linenos data-linenos=" 7 "></span></a><span class=p>)</span>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8></a><a href=#__codelineno-2-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>"""</span>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9></a><a href=#__codelineno-2-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>ignore_index：指定忽略的类别（不贡献梯度）</span>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10></a><a href=#__codelineno-2-10><span class=linenos data-linenos="10 "></span></a>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11></a><a href=#__codelineno-2-11><span class=linenos data-linenos="11 "></span></a><span class=sd>weight：类别不平衡时可通过此参数调整权重</span>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12></a><a href=#__codelineno-2-12><span class=linenos data-linenos="12 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：</p> <ul> <li>输入需要先经过LogSoftmax</li> <li><strong>与CrossEntropyLoss的关系：CrossEntropy = LogSoftmax + NLLLoss</strong></li> <li>最小化负对数似然等价于最大化似然函数</li> </ul> <p>示例：</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1></a><a href=#__codelineno-3-1><span class=linenos data-linenos="1 "></span></a><span class=n>m</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LogSoftmax</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2></a><a href=#__codelineno-3-2><span class=linenos data-linenos="2 "></span></a><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>NLLLoss</span><span class=p>()</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3></a><a href=#__codelineno-3-3><span class=linenos data-linenos="3 "></span></a><span class=nb>input</span> <span class=o>=</span> <span class=n>m</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4></a><a href=#__codelineno-3-4><span class=linenos data-linenos="4 "></span></a><span class=n>target</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>4</span><span class=p>])</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5></a><a href=#__codelineno-3-5><span class=linenos data-linenos="5 "></span></a><span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=nb>input</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html>NLLLoss官方文档</a></p> <h2 id=poisson-negative-log-likelihood-loss-poissonnllloss>Poisson Negative Log Likelihood Loss (PoissonNLLLoss)<a class=headerlink href=#poisson-negative-log-likelihood-loss-poissonnllloss title="Permanent link">¶</a></h2> <h3 id=_7>数学表达式<a class=headerlink href=#_7 title="Permanent link">¶</a></h3> <div class=arithmatex>\[ \mathcal{L}(x, y) = \frac{1}{n}\sum_{i=1}^{n} (x_i - y_i \log(x_i)) $$ 当设置 `log_input=False`（默认）时计算上式。 当 `log_input=True` 时（输入已取对数）： $$ \mathcal{L}(x, y) = \frac{1}{n}\sum_{i=1}^{n} (\exp(x_i) - y_i x_i) \]</div> <h3 id=_8>适用场景<a class=headerlink href=#_8 title="Permanent link">¶</a></h3> <ol> <li><strong>计数数据建模</strong>：事件发生次数的预测（泊松分布）</li> <li><strong>非负连续值预测</strong>：如流量预测、疾病发病率</li> <li><strong>输入输出呈泊松分布关系</strong>：方差等于均值的情况</li> </ol> <h3 id=_9>参数说明<a class=headerlink href=#_9 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.PoissonNLLLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1></a><a href=#__codelineno-4-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>PoissonNLLLoss</span><span class=p>(</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2></a><a href=#__codelineno-4-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>log_input</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>      <span class=c1># 输入是否为对数形式（默认True）</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3></a><a href=#__codelineno-4-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>full</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>          <span class=c1># 是否计算完整损失（带斯特林近似项）</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4></a><a href=#__codelineno-4-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>   <span class=c1># 已废弃</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5></a><a href=#__codelineno-4-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>eps</span><span class=o>=</span><span class=mf>1e-8</span><span class=p>,</span>            <span class=c1># 防止log(0)的小数值</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6></a><a href=#__codelineno-4-6><span class=linenos data-linenos=" 6 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>         <span class=c1># 已废弃</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7></a><a href=#__codelineno-4-7><span class=linenos data-linenos=" 7 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>     <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8></a><a href=#__codelineno-4-8><span class=linenos data-linenos=" 8 "></span></a><span class=p>)</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9></a><a href=#__codelineno-4-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>"""</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10></a><a href=#__codelineno-4-10><span class=linenos data-linenos="10 "></span></a><span class=sd>log_input：</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11></a><a href=#__codelineno-4-11><span class=linenos data-linenos="11 "></span></a>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12></a><a href=#__codelineno-4-12><span class=linenos data-linenos="12 "></span></a><span class=sd>True：输入需先取对数（更数值稳定）</span>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13></a><a href=#__codelineno-4-13><span class=linenos data-linenos="13 "></span></a>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14></a><a href=#__codelineno-4-14><span class=linenos data-linenos="14 "></span></a><span class=sd>False：直接使用原始输入</span>
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15></a><a href=#__codelineno-4-15><span class=linenos data-linenos="15 "></span></a>
</span><span id=__span-4-16><a id=__codelineno-4-16 name=__codelineno-4-16></a><a href=#__codelineno-4-16><span class=linenos data-linenos="16 "></span></a><span class=sd>full：</span>
</span><span id=__span-4-17><a id=__codelineno-4-17 name=__codelineno-4-17></a><a href=#__codelineno-4-17><span class=linenos data-linenos="17 "></span></a>
</span><span id=__span-4-18><a id=__codelineno-4-18 name=__codelineno-4-18></a><a href=#__codelineno-4-18><span class=linenos data-linenos="18 "></span></a><span class=sd>True：增加斯特林近似项 y*log(y) - y + 0.5*log(2πy)</span>
</span><span id=__span-4-19><a id=__codelineno-4-19 name=__codelineno-4-19></a><a href=#__codelineno-4-19><span class=linenos data-linenos="19 "></span></a>
</span><span id=__span-4-20><a id=__codelineno-4-20 name=__codelineno-4-20></a><a href=#__codelineno-4-20><span class=linenos data-linenos="20 "></span></a><span class=sd>False（默认）：仅计算基本项</span>
</span><span id=__span-4-21><a id=__codelineno-4-21 name=__codelineno-4-21></a><a href=#__codelineno-4-21><span class=linenos data-linenos="21 "></span></a>
</span><span id=__span-4-22><a id=__codelineno-4-22 name=__codelineno-4-22></a><a href=#__codelineno-4-22><span class=linenos data-linenos="22 "></span></a><span class=sd>eps：防止数值不稳定（当 log_input=False 且输入接近0时）</span>
</span><span id=__span-4-23><a id=__codelineno-4-23 name=__codelineno-4-23></a><a href=#__codelineno-4-23><span class=linenos data-linenos="23 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.PoissonNLLLoss.html>PoissonNLLLoss官方文档</a></p> <h2 id=gaussian-negative-log-likelihood-loss-gaussiannllloss>Gaussian Negative Log Likelihood Loss (GaussianNLLLoss)<a class=headerlink href=#gaussian-negative-log-likelihood-loss-gaussiannllloss title="Permanent link">¶</a></h2> <h3 id=_10>数学表达式<a class=headerlink href=#_10 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y, \sigma) = \frac{1}{n}\sum_{i=1}^{n} \left( \frac{(x_i - y_i)<sup>2}{2\sigma_i</sup>2} + \log(\sigma_i) \right)<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测值（模型输出）<br> - <span class=arithmatex>\( y \)</span> 是目标值（真实标签）<br> - <span class=arithmatex>\( \sigma \)</span> 是预测的标准差（不确定性）<br> - <span class=arithmatex>\( n \)</span> 是样本数量</p> <h3 id=_11>适用场景<a class=headerlink href=#_11 title="Permanent link">¶</a></h3> <ol> <li><strong>不确定性建模</strong>：需要同时预测值和不确定性</li> <li><strong>贝叶斯神经网络</strong>：输出概率分布而非单点预测</li> <li><strong>异方差回归</strong>：方差随输入变化的回归任务</li> <li><strong>安全关键应用</strong>：如自动驾驶、医疗诊断等需要知道预测置信度的场景</li> </ol> <h3 id=_12>参数说明<a class=headerlink href=#_12 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.GaussianNLLLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1></a><a href=#__codelineno-5-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>GaussianNLLLoss</span><span class=p>(</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2></a><a href=#__codelineno-5-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>full</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>          <span class=c1># 是否计算完整损失（带常数项）</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3></a><a href=#__codelineno-5-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>eps</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>,</span>            <span class=c1># 防止方差为零的小数值</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4></a><a href=#__codelineno-5-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>     <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5></a><a href=#__codelineno-5-5><span class=linenos data-linenos=" 5 "></span></a><span class=p>)</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6></a><a href=#__codelineno-5-6><span class=linenos data-linenos=" 6 "></span></a><span class=sd>"""</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7></a><a href=#__codelineno-5-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>full：</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8></a><a href=#__codelineno-5-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>True：增加常数项 0.5*log(2π)</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9></a><a href=#__codelineno-5-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>False（默认）：不包含常数项</span>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10></a><a href=#__codelineno-5-10><span class=linenos data-linenos="10 "></span></a>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11></a><a href=#__codelineno-5-11><span class=linenos data-linenos="11 "></span></a><span class=sd>eps：防止数值不稳定（当方差接近0时）</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12></a><a href=#__codelineno-5-12><span class=linenos data-linenos="12 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.GaussianNLLLoss.html>GaussianNLLLoss官方文档</a></p> <h2 id=kullback-leibler-divergence-loss-kldivloss>Kullback-Leibler Divergence Loss (KLDivLoss)<a class=headerlink href=#kullback-leibler-divergence-loss-kldivloss title="Permanent link">¶</a></h2> <h3 id=_13>数学表达式<a class=headerlink href=#_13 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = \frac{1}{n}\sum_{i=1}^{n} \sum_{j=1}^{C} y_{i,j} \left( \log(y_{i,j}) - x_{i,j} \right)<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测的对数概率（log-probabilities），形状为 (N, C)<br> - <span class=arithmatex>\( y \)</span> 是目标概率分布，形状为 (N, C)<br> - <span class=arithmatex>\( n \)</span> 是 batch size<br> - <span class=arithmatex>\( C \)</span> 是类别数</p> <h3 id=_14>适用场景<a class=headerlink href=#_14 title="Permanent link">¶</a></h3> <ol> <li><strong>分布匹配</strong>：衡量两个概率分布的差异</li> <li><strong>变分自编码器（VAE）</strong>：作为正则化项</li> <li><strong>知识蒸馏</strong>：让学生模型学习教师模型的概率分布</li> <li><strong>生成模型</strong>：训练模型生成接近目标分布的数据</li> </ol> <h3 id=_15>参数说明<a class=headerlink href=#_15 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.KLDivLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1></a><a href=#__codelineno-6-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>KLDivLoss</span><span class=p>(</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2></a><a href=#__codelineno-6-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3></a><a href=#__codelineno-6-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4></a><a href=#__codelineno-6-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span><span class=p>,</span>   <span class=c1># 'none'|'batchmean'|'mean'|'sum'</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5></a><a href=#__codelineno-6-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>log_target</span><span class=o>=</span><span class=kc>False</span>    <span class=c1># 目标是否为对数概率</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6></a><a href=#__codelineno-6-6><span class=linenos data-linenos=" 6 "></span></a><span class=p>)</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7></a><a href=#__codelineno-6-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>"""</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8></a><a href=#__codelineno-6-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9></a><a href=#__codelineno-6-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>'none'：返回逐元素损失</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10></a><a href=#__codelineno-6-10><span class=linenos data-linenos="10 "></span></a><span class=sd>'batchmean'：返回batch的损失和（推荐用于KL散度）</span>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11></a><a href=#__codelineno-6-11><span class=linenos data-linenos="11 "></span></a><span class=sd>'mean'：返回损失均值</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12></a><a href=#__codelineno-6-12><span class=linenos data-linenos="12 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13></a><a href=#__codelineno-6-13><span class=linenos data-linenos="13 "></span></a>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14></a><a href=#__codelineno-6-14><span class=linenos data-linenos="14 "></span></a><span class=sd>log_target：</span>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15></a><a href=#__codelineno-6-15><span class=linenos data-linenos="15 "></span></a><span class=sd>True：目标已经是对数概率</span>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16></a><a href=#__codelineno-6-16><span class=linenos data-linenos="16 "></span></a><span class=sd>False（默认）：目标是普通概率</span>
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17></a><a href=#__codelineno-6-17><span class=linenos data-linenos="17 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - 输入x需要是对数概率（log-probabilities）<br> - 目标y需要是概率分布（sum to 1）<br> - KL散度是非对称的：KL(P||Q) ≠ KL(Q||P)</p> <p>示例：</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1></a><a href=#__codelineno-7-1><span class=linenos data-linenos="1 "></span></a><span class=c1># 输入需要是对数概率</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2></a><a href=#__codelineno-7-2><span class=linenos data-linenos="2 "></span></a><span class=nb>input</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>log_softmax</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3></a><a href=#__codelineno-7-3><span class=linenos data-linenos="3 "></span></a><span class=c1># 目标需要是概率分布</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4></a><a href=#__codelineno-7-4><span class=linenos data-linenos="4 "></span></a><span class=n>target</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5></a><a href=#__codelineno-7-5><span class=linenos data-linenos="5 "></span></a><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>KLDivLoss</span><span class=p>(</span><span class=n>reduction</span><span class=o>=</span><span class=s1>'batchmean'</span><span class=p>)</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6></a><a href=#__codelineno-7-6><span class=linenos data-linenos="6 "></span></a><span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=nb>input</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html>KLDivLoss官方文档</a></p> <h2 id=mean-squared-error-loss-mseloss>Mean Squared Error Loss (MSELoss)<a class=headerlink href=#mean-squared-error-loss-mseloss title="Permanent link">¶</a></h2> <h3 id=_16>数学表达式<a class=headerlink href=#_16 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = \frac{1}{n}\sum_{i=1}^{n} (x_i - y_i)^2<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测值（模型输出）<br> - <span class=arithmatex>\( y \)</span> 是目标值（真实标签）<br> - <span class=arithmatex>\( n \)</span> 是样本数量</p> <h3 id=_17>适用场景<a class=headerlink href=#_17 title="Permanent link">¶</a></h3> <ol> <li><strong>回归任务</strong>：预测连续值的标准损失函数</li> <li><strong>图像重建</strong>：如自编码器、图像去噪等</li> <li><strong>平滑数据</strong>：当数据噪声较小且需要精确预测时</li> <li><strong>梯度下降优化</strong>：提供平滑的梯度信号</li> </ol> <h3 id=_18>参数说明<a class=headerlink href=#_18 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.MSELoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1></a><a href=#__codelineno-8-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>MSELoss</span><span class=p>(</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2></a><a href=#__codelineno-8-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3></a><a href=#__codelineno-8-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4></a><a href=#__codelineno-8-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>    <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5></a><a href=#__codelineno-8-5><span class=linenos data-linenos=" 5 "></span></a><span class=p>)</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6></a><a href=#__codelineno-8-6><span class=linenos data-linenos=" 6 "></span></a><span class=sd>"""</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7></a><a href=#__codelineno-8-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8></a><a href=#__codelineno-8-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>'none'：返回逐元素损失 The same shape as Input</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9></a><a href=#__codelineno-8-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>'mean'（默认）：返回损失均值 (1,)</span>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10></a><a href=#__codelineno-8-10><span class=linenos data-linenos="10 "></span></a><span class=sd>'sum'：返回损失总和 (1,)</span>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11></a><a href=#__codelineno-8-11><span class=linenos data-linenos="11 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - MSE对异常值敏感，因为误差被平方<br> - 相比L1 Loss，MSE在接近最优点时梯度更小，有助于精细调整<br> - 最小化MSE等价于最大化高斯分布下的似然函数</p> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>MSELoss官方文档</a></p> <h2 id=binary-cross-entropy-loss-bceloss>Binary Cross Entropy Loss (BCELoss)<a class=headerlink href=#binary-cross-entropy-loss-bceloss title="Permanent link">¶</a></h2> <h3 id=_19>数学表达式<a class=headerlink href=#_19 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = -\frac{1}{n}\sum_{i=1}^{n} \left[ y_i \log(x_i) + (1 - y_i) \log(1 - x_i) \right]<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测概率，范围在 [0, 1]<br> - <span class=arithmatex>\( y \)</span> 是目标值（0 或 1）<br> - <span class=arithmatex>\( n \)</span> 是样本数量</p> <h3 id=_20>适用场景<a class=headerlink href=#_20 title="Permanent link">¶</a></h3> <ol> <li><strong>二元分类任务</strong>：判断样本属于两个类别中的哪一个</li> <li><strong>概率预测</strong>：输出样本属于正类的概率</li> <li><strong>多标签分类</strong>：每个样本可以属于多个类别</li> <li><strong>医学诊断</strong>：如疾病检测、风险预测等</li> </ol> <h3 id=_21>参数说明<a class=headerlink href=#_21 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.BCELoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1></a><a href=#__codelineno-9-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>BCELoss</span><span class=p>(</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2></a><a href=#__codelineno-9-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>weight</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 各样本的权重（1D Tensor）</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3></a><a href=#__codelineno-9-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4></a><a href=#__codelineno-9-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5></a><a href=#__codelineno-9-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>    <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6></a><a href=#__codelineno-9-6><span class=linenos data-linenos=" 6 "></span></a><span class=p>)</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7></a><a href=#__codelineno-9-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>"""</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8></a><a href=#__codelineno-9-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>weight：可用于样本不平衡时的加权</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9></a><a href=#__codelineno-9-9><span class=linenos data-linenos=" 9 "></span></a>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10></a><a href=#__codelineno-9-10><span class=linenos data-linenos="10 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11></a><a href=#__codelineno-9-11><span class=linenos data-linenos="11 "></span></a><span class=sd>'none'：返回逐元素损失</span>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12></a><a href=#__codelineno-9-12><span class=linenos data-linenos="12 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-9-13><a id=__codelineno-9-13 name=__codelineno-9-13></a><a href=#__codelineno-9-13><span class=linenos data-linenos="13 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-9-14><a id=__codelineno-9-14 name=__codelineno-9-14></a><a href=#__codelineno-9-14><span class=linenos data-linenos="14 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - 输入需要经过Sigmoid函数，确保在[0,1]范围内<br> - 如果输入接近0或1，可能导致数值不稳定<br> - 对于数值稳定性更好的实现，推荐使用BCEWithLogitsLoss</p> <p>示例：</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1></a><a href=#__codelineno-10-1><span class=linenos data-linenos="1 "></span></a><span class=n>m</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>()</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2></a><a href=#__codelineno-10-2><span class=linenos data-linenos="2 "></span></a><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BCELoss</span><span class=p>()</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3></a><a href=#__codelineno-10-3><span class=linenos data-linenos="3 "></span></a><span class=nb>input</span> <span class=o>=</span> <span class=n>m</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>))</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4></a><a href=#__codelineno-10-4><span class=linenos data-linenos="4 "></span></a><span class=n>target</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span><span class=o>.</span><span class=n>random_</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5></a><a href=#__codelineno-10-5><span class=linenos data-linenos="5 "></span></a><span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=nb>input</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html>BCELoss官方文档</a></p> <h2 id=binary-cross-entropy-with-logits-loss-bcewithlogitsloss>Binary Cross Entropy with Logits Loss (BCEWithLogitsLoss)<a class=headerlink href=#binary-cross-entropy-with-logits-loss-bcewithlogitsloss title="Permanent link">¶</a></h2> <h3 id=_22>数学表达式<a class=headerlink href=#_22 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = -\frac{1}{n}\sum_{i=1}^{n} \left[ y_i \log(\sigma(x_i)) + (1 - y_i) \log(1 - \sigma(x_i)) \right]<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测的原始输出（logits）<br> - <span class=arithmatex>\( y \)</span> 是目标值（0 或 1）<br> - <span class=arithmatex>\( \sigma \)</span> 是Sigmoid函数：<span class=arithmatex>\(\sigma(x) = \frac{1}{1+e^{-x}}\)</span><br> - <span class=arithmatex>\( n \)</span> 是样本数量</p> <h3 id=_23>适用场景<a class=headerlink href=#_23 title="Permanent link">¶</a></h3> <ol> <li><strong>二元分类任务</strong>：与BCELoss相同的应用场景</li> <li><strong>数值稳定性要求高</strong>：相比BCELoss + Sigmoid更稳定</li> <li><strong>深度神经网络</strong>：避免梯度消失/爆炸问题</li> <li><strong>大规模训练</strong>：更适合大规模数据集训练</li> </ol> <h3 id=_24>参数说明<a class=headerlink href=#_24 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.BCEWithLogitsLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1></a><a href=#__codelineno-11-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>BCEWithLogitsLoss</span><span class=p>(</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2></a><a href=#__codelineno-11-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>weight</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 各样本的权重（1D Tensor）</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3></a><a href=#__codelineno-11-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4></a><a href=#__codelineno-11-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5></a><a href=#__codelineno-11-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span><span class=p>,</span>   <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6></a><a href=#__codelineno-11-6><span class=linenos data-linenos=" 6 "></span></a>    <span class=n>pos_weight</span><span class=o>=</span><span class=kc>None</span>     <span class=c1># 正样本的权重（用于类别不平衡）</span>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7></a><a href=#__codelineno-11-7><span class=linenos data-linenos=" 7 "></span></a><span class=p>)</span>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8></a><a href=#__codelineno-11-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>"""</span>
</span><span id=__span-11-9><a id=__codelineno-11-9 name=__codelineno-11-9></a><a href=#__codelineno-11-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>weight：样本级别的权重</span>
</span><span id=__span-11-10><a id=__codelineno-11-10 name=__codelineno-11-10></a><a href=#__codelineno-11-10><span class=linenos data-linenos="10 "></span></a>
</span><span id=__span-11-11><a id=__codelineno-11-11 name=__codelineno-11-11></a><a href=#__codelineno-11-11><span class=linenos data-linenos="11 "></span></a><span class=sd>pos_weight：正样本的权重，可用于处理类别不平衡</span>
</span><span id=__span-11-12><a id=__codelineno-11-12 name=__codelineno-11-12></a><a href=#__codelineno-11-12><span class=linenos data-linenos="12 "></span></a><span class=sd>如果设置，正样本的损失将乘以该值</span>
</span><span id=__span-11-13><a id=__codelineno-11-13 name=__codelineno-11-13></a><a href=#__codelineno-11-13><span class=linenos data-linenos="13 "></span></a>
</span><span id=__span-11-14><a id=__codelineno-11-14 name=__codelineno-11-14></a><a href=#__codelineno-11-14><span class=linenos data-linenos="14 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-11-15><a id=__codelineno-11-15 name=__codelineno-11-15></a><a href=#__codelineno-11-15><span class=linenos data-linenos="15 "></span></a><span class=sd>'none'：返回逐元素损失</span>
</span><span id=__span-11-16><a id=__codelineno-11-16 name=__codelineno-11-16></a><a href=#__codelineno-11-16><span class=linenos data-linenos="16 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-11-17><a id=__codelineno-11-17 name=__codelineno-11-17></a><a href=#__codelineno-11-17><span class=linenos data-linenos="17 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-11-18><a id=__codelineno-11-18 name=__codelineno-11-18></a><a href=#__codelineno-11-18><span class=linenos data-linenos="18 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - 结合了Sigmoid和BCELoss，数值更稳定<br> - 使用log-sum-exp技巧避免数值溢出<br> - 推荐使用BCEWithLogitsLoss而非单独的Sigmoid + BCELoss<br> - pos_weight参数对于正负样本不平衡的情况很有用</p> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html>BCEWithLogitsLoss官方文档</a></p> <h2 id=hinge-embedding-loss>Hinge Embedding Loss<a class=headerlink href=#hinge-embedding-loss title="Permanent link">¶</a></h2> <h3 id=_25>数学表达式<a class=headerlink href=#_25 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = \frac{1}{n}\sum_{i=1}^{n} \begin{cases}<br> x_i, &amp; \text{if } y_i = 1 \<br> \max(0, \text{margin} - x_i), &amp; \text{if } y_i = -1<br> \end{cases}<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测值（通常是相似度得分）<br> - <span class=arithmatex>\( y \)</span> 是目标值（1 或 -1）<br> - <span class=arithmatex>\( n \)</span> 是样本数量<br> - margin 是边界参数（默认为1.0）</p> <h3 id=_26>适用场景<a class=headerlink href=#_26 title="Permanent link">¶</a></h3> <ol> <li><strong>度量学习</strong>：学习嵌入空间中的相似性</li> <li><strong>人脸识别/验证</strong>：判断两张人脸是否为同一个人</li> <li><strong>相似性学习</strong>：学习样本间的相似度度量</li> <li><strong>半监督学习</strong>：利用相似性信息进行学习</li> </ol> <h3 id=_27>参数说明<a class=headerlink href=#_27 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.HingeEmbeddingLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1></a><a href=#__codelineno-12-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>HingeEmbeddingLoss</span><span class=p>(</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2></a><a href=#__codelineno-12-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>margin</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span>         <span class=c1># 边界参数</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3></a><a href=#__codelineno-12-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4></a><a href=#__codelineno-12-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5></a><a href=#__codelineno-12-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>    <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6></a><a href=#__codelineno-12-6><span class=linenos data-linenos=" 6 "></span></a><span class=p>)</span>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7></a><a href=#__codelineno-12-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>"""</span>
</span><span id=__span-12-8><a id=__codelineno-12-8 name=__codelineno-12-8></a><a href=#__codelineno-12-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>margin：</span>
</span><span id=__span-12-9><a id=__codelineno-12-9 name=__codelineno-12-9></a><a href=#__codelineno-12-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>当y=-1时，如果x &lt; margin，则计算margin - x</span>
</span><span id=__span-12-10><a id=__codelineno-12-10 name=__codelineno-12-10></a><a href=#__codelineno-12-10><span class=linenos data-linenos="10 "></span></a><span class=sd>否则损失为0</span>
</span><span id=__span-12-11><a id=__codelineno-12-11 name=__codelineno-12-11></a><a href=#__codelineno-12-11><span class=linenos data-linenos="11 "></span></a>
</span><span id=__span-12-12><a id=__codelineno-12-12 name=__codelineno-12-12></a><a href=#__codelineno-12-12><span class=linenos data-linenos="12 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-12-13><a id=__codelineno-12-13 name=__codelineno-12-13></a><a href=#__codelineno-12-13><span class=linenos data-linenos="13 "></span></a><span class=sd>'none'：返回逐元素损失</span>
</span><span id=__span-12-14><a id=__codelineno-12-14 name=__codelineno-12-14></a><a href=#__codelineno-12-14><span class=linenos data-linenos="14 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-12-15><a id=__codelineno-12-15 name=__codelineno-12-15></a><a href=#__codelineno-12-15><span class=linenos data-linenos="15 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-12-16><a id=__codelineno-12-16 name=__codelineno-12-16></a><a href=#__codelineno-12-16><span class=linenos data-linenos="16 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - 目标标签应为1（相似）或-1（不相似）<br> - 对于相似样本（y=1），直接使用预测值作为损失<br> - 对于不相似样本（y=-1），只有当预测值小于margin时才有损失</p> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.HingeEmbeddingLoss.html>HingeEmbeddingLoss官方文档</a></p> <h2 id=multi-label-margin-loss>Multi Label Margin Loss<a class=headerlink href=#multi-label-margin-loss title="Permanent link">¶</a></h2> <h3 id=_28>数学表达式<a class=headerlink href=#_28 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = \frac{1}{n}\sum_{i=1}^{n} \sum_{j} \max(0, \text{margin} - (x_{i,y_i} - x_{i,j}))<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测值（通常是相似度得分）<br> - <span class=arithmatex>\( y \)</span> 是目标值（包含正样本类别的索引）<br> - <span class=arithmatex>\( n \)</span> 是样本数量<br> - <span class=arithmatex>\( j \)</span> 遍历所有不属于 <span class=arithmatex>\( y_i \)</span> 的类别<br> - margin 是边界参数（默认为1.0）</p> <h3 id=_29>适用场景<a class=headerlink href=#_29 title="Permanent link">¶</a></h3> <ol> <li><strong>多标签分类</strong>：每个样本可以属于多个类别</li> <li><strong>图像标注</strong>：一张图像可以有多个标签</li> <li><strong>文本分类</strong>：一篇文章可以属于多个主题</li> <li><strong>推荐系统</strong>：一个用户可能喜欢多个类别</li> </ol> <h3 id=_30>参数说明<a class=headerlink href=#_30 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.MultiLabelMarginLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1></a><a href=#__codelineno-13-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>MultiLabelMarginLoss</span><span class=p>(</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2></a><a href=#__codelineno-13-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3></a><a href=#__codelineno-13-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4></a><a href=#__codelineno-13-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>    <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5></a><a href=#__codelineno-13-5><span class=linenos data-linenos=" 5 "></span></a><span class=p>)</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6></a><a href=#__codelineno-13-6><span class=linenos data-linenos=" 6 "></span></a><span class=sd>"""</span>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7></a><a href=#__codelineno-13-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8></a><a href=#__codelineno-13-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>'none'：返回逐样本损失</span>
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9></a><a href=#__codelineno-13-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-13-10><a id=__codelineno-13-10 name=__codelineno-13-10></a><a href=#__codelineno-13-10><span class=linenos data-linenos="10 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-13-11><a id=__codelineno-13-11 name=__codelineno-13-11></a><a href=#__codelineno-13-11><span class=linenos data-linenos="11 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - 目标标签应包含所有正样本类别的索引<br> - 对于每个样本，损失计算正类别与所有负类别之间的margin<br> - 目标标签的维度应为 (N, C)，其中C是类别数<br> - 目标中，正样本位置的值应为1，负样本位置的值应为0</p> <p>示例：</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1></a><a href=#__codelineno-14-1><span class=linenos data-linenos="1 "></span></a><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MultiLabelMarginLoss</span><span class=p>()</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2></a><a href=#__codelineno-14-2><span class=linenos data-linenos="2 "></span></a><span class=nb>input</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>)</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3></a><a href=#__codelineno-14-3><span class=linenos data-linenos="3 "></span></a><span class=c1># 目标：第一个样本属于类别0和2，第二个样本属于类别1和3，第三个样本属于类别0和4</span>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4></a><a href=#__codelineno-14-4><span class=linenos data-linenos="4 "></span></a><span class=n>target</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]])</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5></a><a href=#__codelineno-14-5><span class=linenos data-linenos="5 "></span></a><span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=nb>input</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.MultiLabelMarginLoss.html>MultiLabelMarginLoss官方文档</a></p> <h2 id=smooth-l1-loss>Smooth L1 Loss<a class=headerlink href=#smooth-l1-loss title="Permanent link">¶</a></h2> <h3 id=_31>数学表达式<a class=headerlink href=#_31 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = \frac{1}{n}\sum_{i=1}^{n} \begin{cases}<br> 0.5 (x_i - y_i)^2 / \beta, &amp; \text{if } |x_i - y_i| &lt; \beta \<br> |x_i - y_i| - 0.5 \beta, &amp; \text{otherwise}<br> \end{cases}<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测值（模型输出）<br> - <span class=arithmatex>\( y \)</span> 是目标值（真实标签）<br> - <span class=arithmatex>\( n \)</span> 是样本数量<br> - <span class=arithmatex>\( \beta \)</span> 是平滑参数（默认为1.0）</p> <h3 id=_32>适用场景<a class=headerlink href=#_32 title="Permanent link">¶</a></h3> <ol> <li><strong>目标检测</strong>：如Faster R-CNN中的边界框回归</li> <li><strong>鲁棒回归</strong>：对异常值不敏感的回归任务</li> <li><strong>深度学习训练</strong>：作为L1和L2损失的折中方案</li> <li><strong>计算机视觉</strong>：需要既平滑又鲁棒的损失函数</li> </ol> <h3 id=_33>参数说明<a class=headerlink href=#_33 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.SmoothL1Loss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1></a><a href=#__codelineno-15-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>SmoothL1Loss</span><span class=p>(</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2></a><a href=#__codelineno-15-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3></a><a href=#__codelineno-15-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4></a><a href=#__codelineno-15-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span><span class=p>,</span>   <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5></a><a href=#__codelineno-15-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>beta</span><span class=o>=</span><span class=mf>1.0</span>            <span class=c1># 平滑参数</span>
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6></a><a href=#__codelineno-15-6><span class=linenos data-linenos=" 6 "></span></a><span class=p>)</span>
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7></a><a href=#__codelineno-15-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>"""</span>
</span><span id=__span-15-8><a id=__codelineno-15-8 name=__codelineno-15-8></a><a href=#__codelineno-15-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>beta：</span>
</span><span id=__span-15-9><a id=__codelineno-15-9 name=__codelineno-15-9></a><a href=#__codelineno-15-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>指定从二次损失转为线性损失的阈值点</span>
</span><span id=__span-15-10><a id=__codelineno-15-10 name=__codelineno-15-10></a><a href=#__codelineno-15-10><span class=linenos data-linenos="10 "></span></a><span class=sd>默认值为1.0</span>
</span><span id=__span-15-11><a id=__codelineno-15-11 name=__codelineno-15-11></a><a href=#__codelineno-15-11><span class=linenos data-linenos="11 "></span></a>
</span><span id=__span-15-12><a id=__codelineno-15-12 name=__codelineno-15-12></a><a href=#__codelineno-15-12><span class=linenos data-linenos="12 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-15-13><a id=__codelineno-15-13 name=__codelineno-15-13></a><a href=#__codelineno-15-13><span class=linenos data-linenos="13 "></span></a><span class=sd>'none'：返回逐元素损失</span>
</span><span id=__span-15-14><a id=__codelineno-15-14 name=__codelineno-15-14></a><a href=#__codelineno-15-14><span class=linenos data-linenos="14 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-15-15><a id=__codelineno-15-15 name=__codelineno-15-15></a><a href=#__codelineno-15-15><span class=linenos data-linenos="15 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-15-16><a id=__codelineno-15-16 name=__codelineno-15-16></a><a href=#__codelineno-15-16><span class=linenos data-linenos="16 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - 当误差小于beta时，使用二次损失（类似MSE）<br> - 当误差大于beta时，使用线性损失（类似MAE）<br> - 这种设计使得损失函数对异常值不敏感，同时在小误差处保持平滑<br> - 在目标检测中常用于边界框回归，因为对异常值不敏感</p> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.SmoothL1Loss.html>SmoothL1Loss官方文档</a></p> <h2 id=huber-loss>Huber Loss<a class=headerlink href=#huber-loss title="Permanent link">¶</a></h2> <h3 id=_34>数学表达式<a class=headerlink href=#_34 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = \frac{1}{n}\sum_{i=1}^{n} \begin{cases}<br> 0.5 (x_i - y_i)^2, &amp; \text{if } |x_i - y_i| &lt; \delta \<br> \delta (|x_i - y_i| - 0.5 \delta), &amp; \text{otherwise}<br> \end{cases}<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测值（模型输出）<br> - <span class=arithmatex>\( y \)</span> 是目标值（真实标签）<br> - <span class=arithmatex>\( n \)</span> 是样本数量<br> - <span class=arithmatex>\( \delta \)</span> 是阈值参数（默认为1.0）</p> <h3 id=_35>适用场景<a class=headerlink href=#_35 title="Permanent link">¶</a></h3> <ol> <li><strong>鲁棒回归</strong>：对异常值不敏感的回归任务</li> <li><strong>强化学习</strong>：作为Q-learning的损失函数</li> <li><strong>控制理论</strong>：系统控制中的误差度量</li> <li><strong>金融预测</strong>：对极端值不敏感的预测任务</li> </ol> <h3 id=_36>参数说明<a class=headerlink href=#_36 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.HuberLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1></a><a href=#__codelineno-16-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>HuberLoss</span><span class=p>(</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2></a><a href=#__codelineno-16-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span><span class=p>,</span>   <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3></a><a href=#__codelineno-16-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>delta</span><span class=o>=</span><span class=mf>1.0</span>           <span class=c1># 阈值参数</span>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4></a><a href=#__codelineno-16-4><span class=linenos data-linenos=" 4 "></span></a><span class=p>)</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5></a><a href=#__codelineno-16-5><span class=linenos data-linenos=" 5 "></span></a><span class=sd>"""</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6></a><a href=#__codelineno-16-6><span class=linenos data-linenos=" 6 "></span></a><span class=sd>delta：</span>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7></a><a href=#__codelineno-16-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>指定从二次损失转为线性损失的阈值点</span>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8></a><a href=#__codelineno-16-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>默认值为1.0</span>
</span><span id=__span-16-9><a id=__codelineno-16-9 name=__codelineno-16-9></a><a href=#__codelineno-16-9><span class=linenos data-linenos=" 9 "></span></a>
</span><span id=__span-16-10><a id=__codelineno-16-10 name=__codelineno-16-10></a><a href=#__codelineno-16-10><span class=linenos data-linenos="10 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-16-11><a id=__codelineno-16-11 name=__codelineno-16-11></a><a href=#__codelineno-16-11><span class=linenos data-linenos="11 "></span></a><span class=sd>'none'：返回逐元素损失</span>
</span><span id=__span-16-12><a id=__codelineno-16-12 name=__codelineno-16-12></a><a href=#__codelineno-16-12><span class=linenos data-linenos="12 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-16-13><a id=__codelineno-16-13 name=__codelineno-16-13></a><a href=#__codelineno-16-13><span class=linenos data-linenos="13 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-16-14><a id=__codelineno-16-14 name=__codelineno-16-14></a><a href=#__codelineno-16-14><span class=linenos data-linenos="14 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - 当误差小于delta时，使用二次损失（类似MSE）<br> - 当误差大于delta时，使用线性损失（类似MAE）<br> - Huber Loss是SmoothL1Loss的泛化形式，当delta=1.0时两者等价<br> - 对异常值不敏感，同时在小误差处保持平滑的梯度</p> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html>HuberLoss官方文档</a></p> <h2 id=soft-margin-loss>Soft Margin Loss<a class=headerlink href=#soft-margin-loss title="Permanent link">¶</a></h2> <h3 id=_37>数学表达式<a class=headerlink href=#_37 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = \frac{1}{n}\sum_{i=1}^{n} \log(1 + \exp(-y_i x_i))<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测值（模型输出）<br> - <span class=arithmatex>\( y \)</span> 是目标值（1 或 -1）<br> - <span class=arithmatex>\( n \)</span> 是样本数量</p> <h3 id=_38>适用场景<a class=headerlink href=#_38 title="Permanent link">¶</a></h3> <ol> <li><strong>二元分类</strong>：与Hinge Loss类似的应用场景</li> <li><strong>概率输出需求</strong>：需要概率解释的分类任务</li> <li><strong>SVM替代</strong>：作为SVM的平滑替代方案</li> <li><strong>神经网络训练</strong>：提供平滑的梯度信号</li> </ol> <h3 id=_39>参数说明<a class=headerlink href=#_39 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.SoftMarginLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1></a><a href=#__codelineno-17-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>SoftMarginLoss</span><span class=p>(</span>
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2></a><a href=#__codelineno-17-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3></a><a href=#__codelineno-17-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4></a><a href=#__codelineno-17-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>    <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5></a><a href=#__codelineno-17-5><span class=linenos data-linenos=" 5 "></span></a><span class=p>)</span>
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6></a><a href=#__codelineno-17-6><span class=linenos data-linenos=" 6 "></span></a><span class=sd>"""</span>
</span><span id=__span-17-7><a id=__codelineno-17-7 name=__codelineno-17-7></a><a href=#__codelineno-17-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-17-8><a id=__codelineno-17-8 name=__codelineno-17-8></a><a href=#__codelineno-17-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>'none'：返回逐元素损失</span>
</span><span id=__span-17-9><a id=__codelineno-17-9 name=__codelineno-17-9></a><a href=#__codelineno-17-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-17-10><a id=__codelineno-17-10 name=__codelineno-17-10></a><a href=#__codelineno-17-10><span class=linenos data-linenos="10 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-17-11><a id=__codelineno-17-11 name=__codelineno-17-11></a><a href=#__codelineno-17-11><span class=linenos data-linenos="11 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - 目标标签应为1（正类）或-1（负类）<br> - Soft Margin Loss是Hinge Loss的平滑版本<br> - 相比Hinge Loss，Soft Margin Loss处处可导，更适合梯度下降<br> - 损失值范围在[0, +∞)，当预测正确且置信度高时接近0</p> <p>示例：</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1></a><a href=#__codelineno-18-1><span class=linenos data-linenos="1 "></span></a><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>SoftMarginLoss</span><span class=p>()</span>
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2></a><a href=#__codelineno-18-2><span class=linenos data-linenos="2 "></span></a><span class=nb>input</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-18-3><a id=__codelineno-18-3 name=__codelineno-18-3></a><a href=#__codelineno-18-3><span class=linenos data-linenos="3 "></span></a><span class=n>target</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float</span><span class=p>)</span>
</span><span id=__span-18-4><a id=__codelineno-18-4 name=__codelineno-18-4></a><a href=#__codelineno-18-4><span class=linenos data-linenos="4 "></span></a><span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=nb>input</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.SoftMarginLoss.html>SoftMarginLoss官方文档</a></p> <h2 id=cross-entropy-loss>Cross Entropy Loss<a class=headerlink href=#cross-entropy-loss title="Permanent link">¶</a></h2> <h3 id=_40>数学表达式<a class=headerlink href=#_40 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = -\frac{1}{n}\sum_{i=1}^{n} \log\left(\frac{\exp(x_{i,y_i})}{\sum_{j=1}^{C} \exp(x_{i,j})}\right)<br> $$<br> 或等价形式：<br> $$<br> \mathcal{L}(x, y) = -\frac{1}{n}\sum_{i=1}^{n} \left[ x_{i,y_i} - \log\left(\sum_{j=1}^{C} \exp(x_{i,j})\right) \right]<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测的原始输出（logits），形状为 (N, C)<br> - <span class=arithmatex>\( y \)</span> 是目标类别索引，形状为 (N)<br> - <span class=arithmatex>\( n \)</span> 是 batch size<br> - <span class=arithmatex>\( C \)</span> 是类别数</p> <h3 id=_41>适用场景<a class=headerlink href=#_41 title="Permanent link">¶</a></h3> <ol> <li><strong>多分类任务</strong>：标准的多类别分类问题</li> <li><strong>图像分类</strong>：如MNIST、CIFAR、ImageNet等</li> <li><strong>自然语言处理</strong>：文本分类、情感分析等</li> <li><strong>语音识别</strong>：音频分类任务</li> </ol> <h3 id=_42>参数说明<a class=headerlink href=#_42 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.CrossEntropyLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1></a><a href=#__codelineno-19-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>(</span>
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2></a><a href=#__codelineno-19-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>weight</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 各类别的权重（1D Tensor）</span>
</span><span id=__span-19-3><a id=__codelineno-19-3 name=__codelineno-19-3></a><a href=#__codelineno-19-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-19-4><a id=__codelineno-19-4 name=__codelineno-19-4></a><a href=#__codelineno-19-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>ignore_index</span><span class=o>=-</span><span class=mi>100</span><span class=p>,</span>  <span class=c1># 忽略的目标类别索引</span>
</span><span id=__span-19-5><a id=__codelineno-19-5 name=__codelineno-19-5></a><a href=#__codelineno-19-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-19-6><a id=__codelineno-19-6 name=__codelineno-19-6></a><a href=#__codelineno-19-6><span class=linenos data-linenos=" 6 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span><span class=p>,</span>   <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-19-7><a id=__codelineno-19-7 name=__codelineno-19-7></a><a href=#__codelineno-19-7><span class=linenos data-linenos=" 7 "></span></a>    <span class=n>label_smoothing</span><span class=o>=</span><span class=mf>0.0</span> <span class=c1># 标签平滑参数</span>
</span><span id=__span-19-8><a id=__codelineno-19-8 name=__codelineno-19-8></a><a href=#__codelineno-19-8><span class=linenos data-linenos=" 8 "></span></a><span class=p>)</span>
</span><span id=__span-19-9><a id=__codelineno-19-9 name=__codelineno-19-9></a><a href=#__codelineno-19-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>"""</span>
</span><span id=__span-19-10><a id=__codelineno-19-10 name=__codelineno-19-10></a><a href=#__codelineno-19-10><span class=linenos data-linenos="10 "></span></a><span class=sd>weight：类别不平衡时可通过此参数调整权重</span>
</span><span id=__span-19-11><a id=__codelineno-19-11 name=__codelineno-19-11></a><a href=#__codelineno-19-11><span class=linenos data-linenos="11 "></span></a>
</span><span id=__span-19-12><a id=__codelineno-19-12 name=__codelineno-19-12></a><a href=#__codelineno-19-12><span class=linenos data-linenos="12 "></span></a><span class=sd>ignore_index：指定忽略的类别（不贡献梯度）</span>
</span><span id=__span-19-13><a id=__codelineno-19-13 name=__codelineno-19-13></a><a href=#__codelineno-19-13><span class=linenos data-linenos="13 "></span></a>
</span><span id=__span-19-14><a id=__codelineno-19-14 name=__codelineno-19-14></a><a href=#__codelineno-19-14><span class=linenos data-linenos="14 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-19-15><a id=__codelineno-19-15 name=__codelineno-19-15></a><a href=#__codelineno-19-15><span class=linenos data-linenos="15 "></span></a><span class=sd>'none'：返回逐样本损失</span>
</span><span id=__span-19-16><a id=__codelineno-19-16 name=__codelineno-19-16></a><a href=#__codelineno-19-16><span class=linenos data-linenos="16 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-19-17><a id=__codelineno-19-17 name=__codelineno-19-17></a><a href=#__codelineno-19-17><span class=linenos data-linenos="17 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-19-18><a id=__codelineno-19-18 name=__codelineno-19-18></a><a href=#__codelineno-19-18><span class=linenos data-linenos="18 "></span></a>
</span><span id=__span-19-19><a id=__codelineno-19-19 name=__codelineno-19-19></a><a href=#__codelineno-19-19><span class=linenos data-linenos="19 "></span></a><span class=sd>label_smoothing：</span>
</span><span id=__span-19-20><a id=__codelineno-19-20 name=__codelineno-19-20></a><a href=#__codelineno-19-20><span class=linenos data-linenos="20 "></span></a><span class=sd>标签平滑系数，范围[0,1]</span>
</span><span id=__span-19-21><a id=__codelineno-19-21 name=__codelineno-19-21></a><a href=#__codelineno-19-21><span class=linenos data-linenos="21 "></span></a><span class=sd>0表示不进行平滑，1表示完全平滑</span>
</span><span id=__span-19-22><a id=__codelineno-19-22 name=__codelineno-19-22></a><a href=#__codelineno-19-22><span class=linenos data-linenos="22 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - CrossEntropyLoss = LogSoftmax + NLLLoss<br> - 输入不需要经过Softmax，内部会自动处理<br> - 对类别不平衡问题，可以通过weight参数调整<br> - label_smoothing有助于提高模型的泛化能力和鲁棒性</p> <p>示例：</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1></a><a href=#__codelineno-20-1><span class=linenos data-linenos="1 "></span></a><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span><span id=__span-20-2><a id=__codelineno-20-2 name=__codelineno-20-2></a><a href=#__codelineno-20-2><span class=linenos data-linenos="2 "></span></a><span class=nb>input</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-20-3><a id=__codelineno-20-3 name=__codelineno-20-3></a><a href=#__codelineno-20-3><span class=linenos data-linenos="3 "></span></a><span class=n>target</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>)</span><span class=o>.</span><span class=n>random_</span><span class=p>(</span><span class=mi>5</span><span class=p>)</span>
</span><span id=__span-20-4><a id=__codelineno-20-4 name=__codelineno-20-4></a><a href=#__codelineno-20-4><span class=linenos data-linenos="4 "></span></a><span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=nb>input</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>CrossEntropyLoss官方文档</a></p> <h2 id=multi-label-soft-margin-loss>Multi Label Soft Margin Loss<a class=headerlink href=#multi-label-soft-margin-loss title="Permanent link">¶</a></h2> <h3 id=_43>数学表达式<a class=headerlink href=#_43 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = -\frac{1}{n}\sum_{i=1}^{n} \frac{1}{C} \sum_{j=1}^{C} \left[ y_{i,j} \log(\sigma(x_{i,j})) + (1 - y_{i,j}) \log(1 - \sigma(x_{i,j})) \right]<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测的原始输出（logits），形状为 (N, C)<br> - <span class=arithmatex>\( y \)</span> 是目标值（0 或 1），形状为 (N, C)<br> - <span class=arithmatex>\( \sigma \)</span> 是Sigmoid函数：<span class=arithmatex>\(\sigma(x) = \frac{1}{1+e^{-x}}\)</span><br> - <span class=arithmatex>\( n \)</span> 是 batch size<br> - <span class=arithmatex>\( C \)</span> 是类别数</p> <h3 id=_44>适用场景<a class=headerlink href=#_44 title="Permanent link">¶</a></h3> <ol> <li><strong>多标签分类</strong>：每个样本可以属于多个类别</li> <li><strong>图像标注</strong>：一张图像可以有多个标签</li> <li><strong>文本分类</strong>：一篇文章可以属于多个主题</li> <li><strong>推荐系统</strong>：一个用户可能喜欢多个类别</li> </ol> <h3 id=_45>参数说明<a class=headerlink href=#_45 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.MultiLabelSoftMarginLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1></a><a href=#__codelineno-21-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>MultiLabelSoftMarginLoss</span><span class=p>(</span>
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2></a><a href=#__codelineno-21-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>weight</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 各类别的权重（1D Tensor）</span>
</span><span id=__span-21-3><a id=__codelineno-21-3 name=__codelineno-21-3></a><a href=#__codelineno-21-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-21-4><a id=__codelineno-21-4 name=__codelineno-21-4></a><a href=#__codelineno-21-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-21-5><a id=__codelineno-21-5 name=__codelineno-21-5></a><a href=#__codelineno-21-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>    <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-21-6><a id=__codelineno-21-6 name=__codelineno-21-6></a><a href=#__codelineno-21-6><span class=linenos data-linenos=" 6 "></span></a><span class=p>)</span>
</span><span id=__span-21-7><a id=__codelineno-21-7 name=__codelineno-21-7></a><a href=#__codelineno-21-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>"""</span>
</span><span id=__span-21-8><a id=__codelineno-21-8 name=__codelineno-21-8></a><a href=#__codelineno-21-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>weight：类别不平衡时可通过此参数调整权重</span>
</span><span id=__span-21-9><a id=__codelineno-21-9 name=__codelineno-21-9></a><a href=#__codelineno-21-9><span class=linenos data-linenos=" 9 "></span></a>
</span><span id=__span-21-10><a id=__codelineno-21-10 name=__codelineno-21-10></a><a href=#__codelineno-21-10><span class=linenos data-linenos="10 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-21-11><a id=__codelineno-21-11 name=__codelineno-21-11></a><a href=#__codelineno-21-11><span class=linenos data-linenos="11 "></span></a><span class=sd>'none'：返回逐样本损失</span>
</span><span id=__span-21-12><a id=__codelineno-21-12 name=__codelineno-21-12></a><a href=#__codelineno-21-12><span class=linenos data-linenos="12 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-21-13><a id=__codelineno-21-13 name=__codelineno-21-13></a><a href=#__codelineno-21-13><span class=linenos data-linenos="13 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-21-14><a id=__codelineno-21-14 name=__codelineno-21-14></a><a href=#__codelineno-21-14><span class=linenos data-linenos="14 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - 目标标签应为0或1，表示样本是否属于该类别<br> - 内部使用Sigmoid函数将logits转换为概率<br> - 相比使用多个BCEWithLogitsLoss，这个损失函数对多标签任务进行了优化<br> - 适用于标签之间可能存在相关性的多标签任务</p> <p>示例：</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1></a><a href=#__codelineno-22-1><span class=linenos data-linenos="1 "></span></a><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MultiLabelSoftMarginLoss</span><span class=p>()</span>
</span><span id=__span-22-2><a id=__codelineno-22-2 name=__codelineno-22-2></a><a href=#__codelineno-22-2><span class=linenos data-linenos="2 "></span></a><span class=nb>input</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-22-3><a id=__codelineno-22-3 name=__codelineno-22-3></a><a href=#__codelineno-22-3><span class=linenos data-linenos="3 "></span></a><span class=n>target</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>)</span><span class=o>.</span><span class=n>random_</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-22-4><a id=__codelineno-22-4 name=__codelineno-22-4></a><a href=#__codelineno-22-4><span class=linenos data-linenos="4 "></span></a><span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=nb>input</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.MultiLabelSoftMarginLoss.html>MultiLabelSoftMarginLoss官方文档</a></p> <h2 id=cosine-embedding-loss>Cosine Embedding Loss<a class=headerlink href=#cosine-embedding-loss title="Permanent link">¶</a></h2> <h3 id=_46>数学表达式<a class=headerlink href=#_46 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = \frac{1}{n}\sum_{i=1}^{n} \begin{cases}<br> 1 - \cos(x_{i1}, x_{i2}), &amp; \text{if } y_i = 1 \<br> \max(0, \cos(x_{i1}, x_{i2}) - \text{margin}), &amp; \text{if } y_i = -1<br> \end{cases}<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是输入张量对，形状为 (N, *)<br> - <span class=arithmatex>\( y \)</span> 是目标值（1 或 -1），形状为 (N)<br> - <span class=arithmatex>\( \cos(x_{i1}, x_{i2}) \)</span> 是余弦相似度<br> - <span class=arithmatex>\( n \)</span> 是样本数量<br> - margin 是边界参数（默认为0.0）</p> <h3 id=_47>适用场景<a class=headerlink href=#_47 title="Permanent link">¶</a></h3> <ol> <li><strong>度量学习</strong>：学习嵌入空间中的相似性</li> <li><strong>人脸识别/验证</strong>：判断两张人脸是否为同一个人</li> <li><strong>相似性学习</strong>：学习样本间的相似度度量</li> <li><strong>孪生网络</strong>：训练孪生神经网络</li> </ol> <h3 id=_48>参数说明<a class=headerlink href=#_48 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.CosineEmbeddingLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1></a><a href=#__codelineno-23-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>CosineEmbeddingLoss</span><span class=p>(</span>
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2></a><a href=#__codelineno-23-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>margin</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span>         <span class=c1># 边界参数</span>
</span><span id=__span-23-3><a id=__codelineno-23-3 name=__codelineno-23-3></a><a href=#__codelineno-23-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-23-4><a id=__codelineno-23-4 name=__codelineno-23-4></a><a href=#__codelineno-23-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-23-5><a id=__codelineno-23-5 name=__codelineno-23-5></a><a href=#__codelineno-23-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>    <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-23-6><a id=__codelineno-23-6 name=__codelineno-23-6></a><a href=#__codelineno-23-6><span class=linenos data-linenos=" 6 "></span></a><span class=p>)</span>
</span><span id=__span-23-7><a id=__codelineno-23-7 name=__codelineno-23-7></a><a href=#__codelineno-23-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>"""</span>
</span><span id=__span-23-8><a id=__codelineno-23-8 name=__codelineno-23-8></a><a href=#__codelineno-23-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>margin：</span>
</span><span id=__span-23-9><a id=__codelineno-23-9 name=__codelineno-23-9></a><a href=#__codelineno-23-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>当y=-1时，如果余弦相似度大于margin，则计算余弦相似度-margin</span>
</span><span id=__span-23-10><a id=__codelineno-23-10 name=__codelineno-23-10></a><a href=#__codelineno-23-10><span class=linenos data-linenos="10 "></span></a><span class=sd>否则损失为0</span>
</span><span id=__span-23-11><a id=__codelineno-23-11 name=__codelineno-23-11></a><a href=#__codelineno-23-11><span class=linenos data-linenos="11 "></span></a><span class=sd>默认值为0.0</span>
</span><span id=__span-23-12><a id=__codelineno-23-12 name=__codelineno-23-12></a><a href=#__codelineno-23-12><span class=linenos data-linenos="12 "></span></a>
</span><span id=__span-23-13><a id=__codelineno-23-13 name=__codelineno-23-13></a><a href=#__codelineno-23-13><span class=linenos data-linenos="13 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-23-14><a id=__codelineno-23-14 name=__codelineno-23-14></a><a href=#__codelineno-23-14><span class=linenos data-linenos="14 "></span></a><span class=sd>'none'：返回逐样本损失</span>
</span><span id=__span-23-15><a id=__codelineno-23-15 name=__codelineno-23-15></a><a href=#__codelineno-23-15><span class=linenos data-linenos="15 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-23-16><a id=__codelineno-23-16 name=__codelineno-23-16></a><a href=#__codelineno-23-16><span class=linenos data-linenos="16 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-23-17><a id=__codelineno-23-17 name=__codelineno-23-17></a><a href=#__codelineno-23-17><span class=linenos data-linenos="17 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - 输入应为两个形状相同的张量（input1, input2）<br> - 目标标签应为1（相似）或-1（不相似）<br> - 余弦相似度计算：<span class=arithmatex>\(\cos(a, b) = \frac{a \cdot b}{||a|| \cdot ||b||}\)</span><br> - 对于相似样本（y=1），最大化余弦相似度<br> - 对于不相似样本（y=-1），最小化余弦相似度</p> <p>示例：</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1></a><a href=#__codelineno-24-1><span class=linenos data-linenos="1 "></span></a><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CosineEmbeddingLoss</span><span class=p>()</span>
</span><span id=__span-24-2><a id=__codelineno-24-2 name=__codelineno-24-2></a><a href=#__codelineno-24-2><span class=linenos data-linenos="2 "></span></a><span class=n>input1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-24-3><a id=__codelineno-24-3 name=__codelineno-24-3></a><a href=#__codelineno-24-3><span class=linenos data-linenos="3 "></span></a><span class=n>input2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-24-4><a id=__codelineno-24-4 name=__codelineno-24-4></a><a href=#__codelineno-24-4><span class=linenos data-linenos="4 "></span></a><span class=n>target</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float</span><span class=p>)</span>
</span><span id=__span-24-5><a id=__codelineno-24-5 name=__codelineno-24-5></a><a href=#__codelineno-24-5><span class=linenos data-linenos="5 "></span></a><span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=n>input1</span><span class=p>,</span> <span class=n>input2</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html>CosineEmbeddingLoss官方文档</a></p> <h2 id=margin-ranking-loss>Margin Ranking Loss<a class=headerlink href=#margin-ranking-loss title="Permanent link">¶</a></h2> <h3 id=_49>数学表达式<a class=headerlink href=#_49 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x_1, x_2, y) = \frac{1}{n}\sum_{i=1}^{n} \max(0, -y_i (x_{1i} - x_{2i}) + \text{margin})<br> $$<br> 其中：<br> - <span class=arithmatex>\( x_1 \)</span> 是第一个输入张量，形状为 (N, <em>)<br> - <span class=arithmatex>\( x_2 \)</span> 是第二个输入张量，形状为 (N, </em>)<br> - <span class=arithmatex>\( y \)</span> 是目标值（1 或 -1），形状为 (N)<br> - <span class=arithmatex>\( n \)</span> 是样本数量<br> - margin 是边界参数（默认为0.0）</p> <h3 id=_50>适用场景<a class=headerlink href=#_50 title="Permanent link">¶</a></h3> <ol> <li><strong>学习排序</strong>：训练模型学习正确的排序关系</li> <li><strong>推荐系统</strong>：学习用户偏好排序</li> <li><strong>信息检索</strong>：文档相关性排序</li> <li><strong>度量学习</strong>：学习样本间的相对距离</li> </ol> <h3 id=_51>参数说明<a class=headerlink href=#_51 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.MarginRankingLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-25-1><a id=__codelineno-25-1 name=__codelineno-25-1></a><a href=#__codelineno-25-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>MarginRankingLoss</span><span class=p>(</span>
</span><span id=__span-25-2><a id=__codelineno-25-2 name=__codelineno-25-2></a><a href=#__codelineno-25-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>margin</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span>         <span class=c1># 边界参数</span>
</span><span id=__span-25-3><a id=__codelineno-25-3 name=__codelineno-25-3></a><a href=#__codelineno-25-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-25-4><a id=__codelineno-25-4 name=__codelineno-25-4></a><a href=#__codelineno-25-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-25-5><a id=__codelineno-25-5 name=__codelineno-25-5></a><a href=#__codelineno-25-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>    <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-25-6><a id=__codelineno-25-6 name=__codelineno-25-6></a><a href=#__codelineno-25-6><span class=linenos data-linenos=" 6 "></span></a><span class=p>)</span>
</span><span id=__span-25-7><a id=__codelineno-25-7 name=__codelineno-25-7></a><a href=#__codelineno-25-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>"""</span>
</span><span id=__span-25-8><a id=__codelineno-25-8 name=__codelineno-25-8></a><a href=#__codelineno-25-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>margin：</span>
</span><span id=__span-25-9><a id=__codelineno-25-9 name=__codelineno-25-9></a><a href=#__codelineno-25-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>指定期望的边界大小</span>
</span><span id=__span-25-10><a id=__codelineno-25-10 name=__codelineno-25-10></a><a href=#__codelineno-25-10><span class=linenos data-linenos="10 "></span></a><span class=sd>默认值为0.0</span>
</span><span id=__span-25-11><a id=__codelineno-25-11 name=__codelineno-25-11></a><a href=#__codelineno-25-11><span class=linenos data-linenos="11 "></span></a>
</span><span id=__span-25-12><a id=__codelineno-25-12 name=__codelineno-25-12></a><a href=#__codelineno-25-12><span class=linenos data-linenos="12 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-25-13><a id=__codelineno-25-13 name=__codelineno-25-13></a><a href=#__codelineno-25-13><span class=linenos data-linenos="13 "></span></a><span class=sd>'none'：返回逐元素损失</span>
</span><span id=__span-25-14><a id=__codelineno-25-14 name=__codelineno-25-14></a><a href=#__codelineno-25-14><span class=linenos data-linenos="14 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-25-15><a id=__codelineno-25-15 name=__codelineno-25-15></a><a href=#__codelineno-25-15><span class=linenos data-linenos="15 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-25-16><a id=__codelineno-25-16 name=__codelineno-25-16></a><a href=#__codelineno-25-16><span class=linenos data-linenos="16 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - 目标标签应为1（x1应排名高于x2）或-1（x2应排名高于x1）<br> - 当y=1时，希望x1 &gt; x2 + margin<br> - 当y=-1时，希望x2 &gt; x1 + margin<br> - 如果条件满足，损失为0；否则损失为差距的绝对值</p> <p>示例：</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-26-1><a id=__codelineno-26-1 name=__codelineno-26-1></a><a href=#__codelineno-26-1><span class=linenos data-linenos="1 "></span></a><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MarginRankingLoss</span><span class=p>()</span>
</span><span id=__span-26-2><a id=__codelineno-26-2 name=__codelineno-26-2></a><a href=#__codelineno-26-2><span class=linenos data-linenos="2 "></span></a><span class=n>input1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-26-3><a id=__codelineno-26-3 name=__codelineno-26-3></a><a href=#__codelineno-26-3><span class=linenos data-linenos="3 "></span></a><span class=n>input2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-26-4><a id=__codelineno-26-4 name=__codelineno-26-4></a><a href=#__codelineno-26-4><span class=linenos data-linenos="4 "></span></a><span class=n>target</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float</span><span class=p>)</span>
</span><span id=__span-26-5><a id=__codelineno-26-5 name=__codelineno-26-5></a><a href=#__codelineno-26-5><span class=linenos data-linenos="5 "></span></a><span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=n>input1</span><span class=p>,</span> <span class=n>input2</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.MarginRankingLoss.html>MarginRankingLoss官方文档</a></p> <h2 id=multi-margin-loss>Multi Margin Loss<a class=headerlink href=#multi-margin-loss title="Permanent link">¶</a></h2> <h3 id=_52>数学表达式<a class=headerlink href=#_52 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y) = \frac{1}{n}\sum_{i=1}^{n} \frac{1}{C} \sum_{j \neq y_i} \max(0, \text{margin} - (x_{i,y_i} - x_{i,j}) + p_j)<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是预测值（模型输出），形状为 (N, C)<br> - <span class=arithmatex>\( y \)</span> 是目标类别索引，形状为 (N)<br> - <span class=arithmatex>\( n \)</span> 是 batch size<br> - <span class=arithmatex>\( C \)</span> 是类别数<br> - margin 是边界参数（默认为1.0）<br> - <span class=arithmatex>\( p_j \)</span> 是第j类的尺度因子（由weight参数决定）</p> <h3 id=_53>适用场景<a class=headerlink href=#_53 title="Permanent link">¶</a></h3> <ol> <li><strong>多分类任务</strong>：特别是需要区分相似类别的情况</li> <li><strong>图像分类</strong>：如细粒度分类任务</li> <li><strong>文本分类</strong>：区分语义相近的类别</li> <li><strong>语音识别</strong>：区分发音相似的词</li> </ol> <h3 id=_54>参数说明<a class=headerlink href=#_54 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.MultiMarginLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-27-1><a id=__codelineno-27-1 name=__codelineno-27-1></a><a href=#__codelineno-27-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>MultiMarginLoss</span><span class=p>(</span>
</span><span id=__span-27-2><a id=__codelineno-27-2 name=__codelineno-27-2></a><a href=#__codelineno-27-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>p</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>                <span class=c1># 范数参数（仅支持1或2）</span>
</span><span id=__span-27-3><a id=__codelineno-27-3 name=__codelineno-27-3></a><a href=#__codelineno-27-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>margin</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span>         <span class=c1># 边界参数</span>
</span><span id=__span-27-4><a id=__codelineno-27-4 name=__codelineno-27-4></a><a href=#__codelineno-27-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>weight</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 各类别的权重（1D Tensor）</span>
</span><span id=__span-27-5><a id=__codelineno-27-5 name=__codelineno-27-5></a><a href=#__codelineno-27-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-27-6><a id=__codelineno-27-6 name=__codelineno-27-6></a><a href=#__codelineno-27-6><span class=linenos data-linenos=" 6 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-27-7><a id=__codelineno-27-7 name=__codelineno-27-7></a><a href=#__codelineno-27-7><span class=linenos data-linenos=" 7 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>    <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-27-8><a id=__codelineno-27-8 name=__codelineno-27-8></a><a href=#__codelineno-27-8><span class=linenos data-linenos=" 8 "></span></a><span class=p>)</span>
</span><span id=__span-27-9><a id=__codelineno-27-9 name=__codelineno-27-9></a><a href=#__codelineno-27-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>"""</span>
</span><span id=__span-27-10><a id=__codelineno-27-10 name=__codelineno-27-10></a><a href=#__codelineno-27-10><span class=linenos data-linenos="10 "></span></a><span class=sd>p：</span>
</span><span id=__span-27-11><a id=__codelineno-27-11 name=__codelineno-27-11></a><a href=#__codelineno-27-11><span class=linenos data-linenos="11 "></span></a><span class=sd>范数参数，仅支持1或2</span>
</span><span id=__span-27-12><a id=__codelineno-27-12 name=__codelineno-27-12></a><a href=#__codelineno-27-12><span class=linenos data-linenos="12 "></span></a><span class=sd>默认值为1（L1范数）</span>
</span><span id=__span-27-13><a id=__codelineno-27-13 name=__codelineno-27-13></a><a href=#__codelineno-27-13><span class=linenos data-linenos="13 "></span></a>
</span><span id=__span-27-14><a id=__codelineno-27-14 name=__codelineno-27-14></a><a href=#__codelineno-27-14><span class=linenos data-linenos="14 "></span></a><span class=sd>margin：</span>
</span><span id=__span-27-15><a id=__codelineno-27-15 name=__codelineno-27-15></a><a href=#__codelineno-27-15><span class=linenos data-linenos="15 "></span></a><span class=sd>指定期望的边界大小</span>
</span><span id=__span-27-16><a id=__codelineno-27-16 name=__codelineno-27-16></a><a href=#__codelineno-27-16><span class=linenos data-linenos="16 "></span></a><span class=sd>默认值为1.0</span>
</span><span id=__span-27-17><a id=__codelineno-27-17 name=__codelineno-27-17></a><a href=#__codelineno-27-17><span class=linenos data-linenos="17 "></span></a>
</span><span id=__span-27-18><a id=__codelineno-27-18 name=__codelineno-27-18></a><a href=#__codelineno-27-18><span class=linenos data-linenos="18 "></span></a><span class=sd>weight：类别不平衡时可通过此参数调整权重</span>
</span><span id=__span-27-19><a id=__codelineno-27-19 name=__codelineno-27-19></a><a href=#__codelineno-27-19><span class=linenos data-linenos="19 "></span></a>
</span><span id=__span-27-20><a id=__codelineno-27-20 name=__codelineno-27-20></a><a href=#__codelineno-27-20><span class=linenos data-linenos="20 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-27-21><a id=__codelineno-27-21 name=__codelineno-27-21></a><a href=#__codelineno-27-21><span class=linenos data-linenos="21 "></span></a><span class=sd>'none'：返回逐样本损失</span>
</span><span id=__span-27-22><a id=__codelineno-27-22 name=__codelineno-27-22></a><a href=#__codelineno-27-22><span class=linenos data-linenos="22 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-27-23><a id=__codelineno-27-23 name=__codelineno-27-23></a><a href=#__codelineno-27-23><span class=linenos data-linenos="23 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-27-24><a id=__codelineno-27-24 name=__codelineno-27-24></a><a href=#__codelineno-27-24><span class=linenos data-linenos="24 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - 对于每个样本，计算正确类别与其他所有类别之间的边界<br> - 当p=1时，使用L1范数；当p=2时，使用L2范数<br> - 如果正确类别的分数与其他类别的分数差距大于margin，则损失为0<br> - 适用于需要强制模型区分相似类别的任务</p> <p>示例：</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-28-1><a id=__codelineno-28-1 name=__codelineno-28-1></a><a href=#__codelineno-28-1><span class=linenos data-linenos="1 "></span></a><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MultiMarginLoss</span><span class=p>()</span>
</span><span id=__span-28-2><a id=__codelineno-28-2 name=__codelineno-28-2></a><a href=#__codelineno-28-2><span class=linenos data-linenos="2 "></span></a><span class=nb>input</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-28-3><a id=__codelineno-28-3 name=__codelineno-28-3></a><a href=#__codelineno-28-3><span class=linenos data-linenos="3 "></span></a><span class=n>target</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>4</span><span class=p>])</span>
</span><span id=__span-28-4><a id=__codelineno-28-4 name=__codelineno-28-4></a><a href=#__codelineno-28-4><span class=linenos data-linenos="4 "></span></a><span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=nb>input</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.MultiMarginLoss.html>MultiMarginLoss官方文档</a></p> <h2 id=triplet-margin-loss>Triplet Margin Loss<a class=headerlink href=#triplet-margin-loss title="Permanent link">¶</a></h2> <h3 id=_55>数学表达式<a class=headerlink href=#_55 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(a, p, n) = \frac{1}{n}\sum_{i=1}^{n} \max(0, d(a_i, p_i) - d(a_i, n_i) + \text{margin})<br> $$<br> 其中：<br> - <span class=arithmatex>\( a \)</span> 是锚点样本（anchor），形状为 (N, <em>)<br> - <span class=arithmatex>\( p \)</span> 是正样本（positive），形状为 (N, </em>)<br> - <span class=arithmatex>\( n \)</span> 是负样本（negative），形状为 (N, *)<br> - <span class=arithmatex>\( d(x, y) \)</span> 是距离函数（默认为欧氏距离）<br> - <span class=arithmatex>\( n \)</span> 是样本数量<br> - margin 是边界参数（默认为1.0）</p> <h3 id=_56>适用场景<a class=headerlink href=#_56 title="Permanent link">¶</a></h3> <ol> <li><strong>度量学习</strong>：学习嵌入空间中的距离度量</li> <li><strong>人脸识别</strong>：学习人脸特征嵌入</li> <li><strong>图像检索</strong>：学习图像特征表示</li> <li><strong>推荐系统</strong>：学习用户和物品的嵌入表示</li> </ol> <h3 id=_57>参数说明<a class=headerlink href=#_57 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.TripletMarginLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-29-1><a id=__codelineno-29-1 name=__codelineno-29-1></a><a href=#__codelineno-29-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>TripletMarginLoss</span><span class=p>(</span>
</span><span id=__span-29-2><a id=__codelineno-29-2 name=__codelineno-29-2></a><a href=#__codelineno-29-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>margin</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span>         <span class=c1># 边界参数</span>
</span><span id=__span-29-3><a id=__codelineno-29-3 name=__codelineno-29-3></a><a href=#__codelineno-29-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>p</span><span class=o>=</span><span class=mf>2.0</span><span class=p>,</span>              <span class=c1># 范数参数（距离函数的阶数）</span>
</span><span id=__span-29-4><a id=__codelineno-29-4 name=__codelineno-29-4></a><a href=#__codelineno-29-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>eps</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>,</span>           <span class=c1># 数值稳定性小量</span>
</span><span id=__span-29-5><a id=__codelineno-29-5 name=__codelineno-29-5></a><a href=#__codelineno-29-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>swap</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>         <span class=c1># 是否使用swap</span>
</span><span id=__span-29-6><a id=__codelineno-29-6 name=__codelineno-29-6></a><a href=#__codelineno-29-6><span class=linenos data-linenos=" 6 "></span></a>    <span class=n>size_average</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 已废弃</span>
</span><span id=__span-29-7><a id=__codelineno-29-7 name=__codelineno-29-7></a><a href=#__codelineno-29-7><span class=linenos data-linenos=" 7 "></span></a>    <span class=n>reduce</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>        <span class=c1># 已废弃</span>
</span><span id=__span-29-8><a id=__codelineno-29-8 name=__codelineno-29-8></a><a href=#__codelineno-29-8><span class=linenos data-linenos=" 8 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>    <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-29-9><a id=__codelineno-29-9 name=__codelineno-29-9></a><a href=#__codelineno-29-9><span class=linenos data-linenos=" 9 "></span></a><span class=p>)</span>
</span><span id=__span-29-10><a id=__codelineno-29-10 name=__codelineno-29-10></a><a href=#__codelineno-29-10><span class=linenos data-linenos="10 "></span></a><span class=sd>"""</span>
</span><span id=__span-29-11><a id=__codelineno-29-11 name=__codelineno-29-11></a><a href=#__codelineno-29-11><span class=linenos data-linenos="11 "></span></a><span class=sd>margin：</span>
</span><span id=__span-29-12><a id=__codelineno-29-12 name=__codelineno-29-12></a><a href=#__codelineno-29-12><span class=linenos data-linenos="12 "></span></a><span class=sd>指定期望的边界大小</span>
</span><span id=__span-29-13><a id=__codelineno-29-13 name=__codelineno-29-13></a><a href=#__codelineno-29-13><span class=linenos data-linenos="13 "></span></a><span class=sd>默认值为1.0</span>
</span><span id=__span-29-14><a id=__codelineno-29-14 name=__codelineno-29-14></a><a href=#__codelineno-29-14><span class=linenos data-linenos="14 "></span></a>
</span><span id=__span-29-15><a id=__codelineno-29-15 name=__codelineno-29-15></a><a href=#__codelineno-29-15><span class=linenos data-linenos="15 "></span></a><span class=sd>p：</span>
</span><span id=__span-29-16><a id=__codelineno-29-16 name=__codelineno-29-16></a><a href=#__codelineno-29-16><span class=linenos data-linenos="16 "></span></a><span class=sd>范数参数，用于计算距离</span>
</span><span id=__span-29-17><a id=__codelineno-29-17 name=__codelineno-29-17></a><a href=#__codelineno-29-17><span class=linenos data-linenos="17 "></span></a><span class=sd>默认值为2.0（欧氏距离）</span>
</span><span id=__span-29-18><a id=__codelineno-29-18 name=__codelineno-29-18></a><a href=#__codelineno-29-18><span class=linenos data-linenos="18 "></span></a>
</span><span id=__span-29-19><a id=__codelineno-29-19 name=__codelineno-29-19></a><a href=#__codelineno-29-19><span class=linenos data-linenos="19 "></span></a><span class=sd>eps：</span>
</span><span id=__span-29-20><a id=__codelineno-29-20 name=__codelineno-29-20></a><a href=#__codelineno-29-20><span class=linenos data-linenos="20 "></span></a><span class=sd>防止除以零的小数值</span>
</span><span id=__span-29-21><a id=__codelineno-29-21 name=__codelineno-29-21></a><a href=#__codelineno-29-21><span class=linenos data-linenos="21 "></span></a><span class=sd>默认值为1e-6</span>
</span><span id=__span-29-22><a id=__codelineno-29-22 name=__codelineno-29-22></a><a href=#__codelineno-29-22><span class=linenos data-linenos="22 "></span></a>
</span><span id=__span-29-23><a id=__codelineno-29-23 name=__codelineno-29-23></a><a href=#__codelineno-29-23><span class=linenos data-linenos="23 "></span></a><span class=sd>swap：</span>
</span><span id=__span-29-24><a id=__codelineno-29-24 name=__codelineno-29-24></a><a href=#__codelineno-29-24><span class=linenos data-linenos="24 "></span></a><span class=sd>如果为True，当d(a,n) &lt; d(a,p)时，计算d(p,n) - d(a,p) + margin</span>
</span><span id=__span-29-25><a id=__codelineno-29-25 name=__codelineno-29-25></a><a href=#__codelineno-29-25><span class=linenos data-linenos="25 "></span></a><span class=sd>默认值为False</span>
</span><span id=__span-29-26><a id=__codelineno-29-26 name=__codelineno-29-26></a><a href=#__codelineno-29-26><span class=linenos data-linenos="26 "></span></a>
</span><span id=__span-29-27><a id=__codelineno-29-27 name=__codelineno-29-27></a><a href=#__codelineno-29-27><span class=linenos data-linenos="27 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-29-28><a id=__codelineno-29-28 name=__codelineno-29-28></a><a href=#__codelineno-29-28><span class=linenos data-linenos="28 "></span></a><span class=sd>'none'：返回逐样本损失</span>
</span><span id=__span-29-29><a id=__codelineno-29-29 name=__codelineno-29-29></a><a href=#__codelineno-29-29><span class=linenos data-linenos="29 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-29-30><a id=__codelineno-29-30 name=__codelineno-29-30></a><a href=#__codelineno-29-30><span class=linenos data-linenos="30 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-29-31><a id=__codelineno-29-31 name=__codelineno-29-31></a><a href=#__codelineno-29-31><span class=linenos data-linenos="31 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - 目标是使锚点与正样本的距离小于锚点与负样本的距离，且差距至少为margin<br> - 如果条件满足，损失为0；否则损失为差距的绝对值<br> - 常用于训练孪生网络或三元组网络<br> - swap参数有助于处理困难负样本的情况</p> <p>示例：</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-30-1><a id=__codelineno-30-1 name=__codelineno-30-1></a><a href=#__codelineno-30-1><span class=linenos data-linenos="1 "></span></a><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>TripletMarginLoss</span><span class=p>()</span>
</span><span id=__span-30-2><a id=__codelineno-30-2 name=__codelineno-30-2></a><a href=#__codelineno-30-2><span class=linenos data-linenos="2 "></span></a><span class=n>anchor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-30-3><a id=__codelineno-30-3 name=__codelineno-30-3></a><a href=#__codelineno-30-3><span class=linenos data-linenos="3 "></span></a><span class=n>positive</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-30-4><a id=__codelineno-30-4 name=__codelineno-30-4></a><a href=#__codelineno-30-4><span class=linenos data-linenos="4 "></span></a><span class=n>negative</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-30-5><a id=__codelineno-30-5 name=__codelineno-30-5></a><a href=#__codelineno-30-5><span class=linenos data-linenos="5 "></span></a><span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=n>anchor</span><span class=p>,</span> <span class=n>positive</span><span class=p>,</span> <span class=n>negative</span><span class=p>)</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginLoss.html>TripletMarginLoss官方文档</a></p> <h2 id=triplet-margin-with-distance-loss>Triplet Margin with Distance Loss<a class=headerlink href=#triplet-margin-with-distance-loss title="Permanent link">¶</a></h2> <h3 id=_58>数学表达式<a class=headerlink href=#_58 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(a, p, n) = \frac{1}{n}\sum_{i=1}^{n} \max(0, \text{distance_function}(a_i, p_i) - \text{distance_function}(a_i, n_i) + \text{margin})<br> $$<br> 其中：<br> - <span class=arithmatex>\( a \)</span> 是锚点样本（anchor），形状为 (N, <em>)<br> - <span class=arithmatex>\( p \)</span> 是正样本（positive），形状为 (N, </em>)<br> - <span class=arithmatex>\( n \)</span> 是负样本（negative），形状为 (N, *)<br> - <span class=arithmatex>\( \text{distance\_function} \)</span> 是自定义的距离函数<br> - <span class=arithmatex>\( n \)</span> 是样本数量<br> - margin 是边界参数（默认为1.0）</p> <h3 id=_59>适用场景<a class=headerlink href=#_59 title="Permanent link">¶</a></h3> <ol> <li><strong>度量学习</strong>：需要自定义距离函数的度量学习</li> <li><strong>人脸识别</strong>：使用特定距离度量的人脸特征嵌入</li> <li><strong>图像检索</strong>：使用特定相似度度量的图像特征表示</li> <li><strong>推荐系统</strong>：使用特定距离度量的用户和物品嵌入</li> </ol> <h3 id=_60>参数说明<a class=headerlink href=#_60 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.TripletMarginWithDistanceLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-31-1><a id=__codelineno-31-1 name=__codelineno-31-1></a><a href=#__codelineno-31-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>TripletMarginWithDistanceLoss</span><span class=p>(</span>
</span><span id=__span-31-2><a id=__codelineno-31-2 name=__codelineno-31-2></a><a href=#__codelineno-31-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>distance_function</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>  <span class=c1># 自定义距离函数</span>
</span><span id=__span-31-3><a id=__codelineno-31-3 name=__codelineno-31-3></a><a href=#__codelineno-31-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>margin</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span>             <span class=c1># 边界参数</span>
</span><span id=__span-31-4><a id=__codelineno-31-4 name=__codelineno-31-4></a><a href=#__codelineno-31-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span>         <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-31-5><a id=__codelineno-31-5 name=__codelineno-31-5></a><a href=#__codelineno-31-5><span class=linenos data-linenos=" 5 "></span></a><span class=p>)</span>
</span><span id=__span-31-6><a id=__codelineno-31-6 name=__codelineno-31-6></a><a href=#__codelineno-31-6><span class=linenos data-linenos=" 6 "></span></a><span class=sd>"""</span>
</span><span id=__span-31-7><a id=__codelineno-31-7 name=__codelineno-31-7></a><a href=#__codelineno-31-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>distance_function：</span>
</span><span id=__span-31-8><a id=__codelineno-31-8 name=__codelineno-31-8></a><a href=#__codelineno-31-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>自定义距离函数，签名为(Tensor, Tensor) -&gt; Tensor</span>
</span><span id=__span-31-9><a id=__codelineno-31-9 name=__codelineno-31-9></a><a href=#__codelineno-31-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>如果为None，默认使用p=2的范数距离</span>
</span><span id=__span-31-10><a id=__codelineno-31-10 name=__codelineno-31-10></a><a href=#__codelineno-31-10><span class=linenos data-linenos="10 "></span></a><span class=sd>默认值为None</span>
</span><span id=__span-31-11><a id=__codelineno-31-11 name=__codelineno-31-11></a><a href=#__codelineno-31-11><span class=linenos data-linenos="11 "></span></a>
</span><span id=__span-31-12><a id=__codelineno-31-12 name=__codelineno-31-12></a><a href=#__codelineno-31-12><span class=linenos data-linenos="12 "></span></a><span class=sd>margin：</span>
</span><span id=__span-31-13><a id=__codelineno-31-13 name=__codelineno-31-13></a><a href=#__codelineno-31-13><span class=linenos data-linenos="13 "></span></a><span class=sd>指定期望的边界大小</span>
</span><span id=__span-31-14><a id=__codelineno-31-14 name=__codelineno-31-14></a><a href=#__codelineno-31-14><span class=linenos data-linenos="14 "></span></a><span class=sd>默认值为1.0</span>
</span><span id=__span-31-15><a id=__codelineno-31-15 name=__codelineno-31-15></a><a href=#__codelineno-31-15><span class=linenos data-linenos="15 "></span></a>
</span><span id=__span-31-16><a id=__codelineno-31-16 name=__codelineno-31-16></a><a href=#__codelineno-31-16><span class=linenos data-linenos="16 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-31-17><a id=__codelineno-31-17 name=__codelineno-31-17></a><a href=#__codelineno-31-17><span class=linenos data-linenos="17 "></span></a><span class=sd>'none'：返回逐样本损失</span>
</span><span id=__span-31-18><a id=__codelineno-31-18 name=__codelineno-31-18></a><a href=#__codelineno-31-18><span class=linenos data-linenos="18 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-31-19><a id=__codelineno-31-19 name=__codelineno-31-19></a><a href=#__codelineno-31-19><span class=linenos data-linenos="19 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-31-20><a id=__codelineno-31-20 name=__codelineno-31-20></a><a href=#__codelineno-31-20><span class=linenos data-linenos="20 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - 这是TripletMarginLoss的泛化版本，允许使用自定义距离函数<br> - 距离函数应接受两个相同形状的张量并返回一个标量张量<br> - 目标是使锚点与正样本的距离小于锚点与负样本的距离，且差距至少为margin<br> - 常用于需要特定距离度量的场景，如余弦距离、马氏距离等</p> <p>示例：</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-32-1><a id=__codelineno-32-1 name=__codelineno-32-1></a><a href=#__codelineno-32-1><span class=linenos data-linenos=" 1 "></span></a><span class=c1># 使用欧氏距离</span>
</span><span id=__span-32-2><a id=__codelineno-32-2 name=__codelineno-32-2></a><a href=#__codelineno-32-2><span class=linenos data-linenos=" 2 "></span></a><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>TripletMarginWithDistanceLoss</span><span class=p>()</span>
</span><span id=__span-32-3><a id=__codelineno-32-3 name=__codelineno-32-3></a><a href=#__codelineno-32-3><span class=linenos data-linenos=" 3 "></span></a><span class=n>anchor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-32-4><a id=__codelineno-32-4 name=__codelineno-32-4></a><a href=#__codelineno-32-4><span class=linenos data-linenos=" 4 "></span></a><span class=n>positive</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-32-5><a id=__codelineno-32-5 name=__codelineno-32-5></a><a href=#__codelineno-32-5><span class=linenos data-linenos=" 5 "></span></a><span class=n>negative</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-32-6><a id=__codelineno-32-6 name=__codelineno-32-6></a><a href=#__codelineno-32-6><span class=linenos data-linenos=" 6 "></span></a><span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=n>anchor</span><span class=p>,</span> <span class=n>positive</span><span class=p>,</span> <span class=n>negative</span><span class=p>)</span>
</span><span id=__span-32-7><a id=__codelineno-32-7 name=__codelineno-32-7></a><a href=#__codelineno-32-7><span class=linenos data-linenos=" 7 "></span></a>
</span><span id=__span-32-8><a id=__codelineno-32-8 name=__codelineno-32-8></a><a href=#__codelineno-32-8><span class=linenos data-linenos=" 8 "></span></a><span class=c1># 使用自定义距离函数（如余弦距离）</span>
</span><span id=__span-32-9><a id=__codelineno-32-9 name=__codelineno-32-9></a><a href=#__codelineno-32-9><span class=linenos data-linenos=" 9 "></span></a><span class=k>def</span><span class=w> </span><span class=nf>cosine_distance</span><span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>x2</span><span class=p>):</span>
</span><span id=__span-32-10><a id=__codelineno-32-10 name=__codelineno-32-10></a><a href=#__codelineno-32-10><span class=linenos data-linenos="10 "></span></a>    <span class=k>return</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>F</span><span class=o>.</span><span class=n>cosine_similarity</span><span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>x2</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-32-11><a id=__codelineno-32-11 name=__codelineno-32-11></a><a href=#__codelineno-32-11><span class=linenos data-linenos="11 "></span></a>
</span><span id=__span-32-12><a id=__codelineno-32-12 name=__codelineno-32-12></a><a href=#__codelineno-32-12><span class=linenos data-linenos="12 "></span></a><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>TripletMarginWithDistanceLoss</span><span class=p>(</span><span class=n>distance_function</span><span class=o>=</span><span class=n>cosine_distance</span><span class=p>)</span>
</span><span id=__span-32-13><a id=__codelineno-32-13 name=__codelineno-32-13></a><a href=#__codelineno-32-13><span class=linenos data-linenos="13 "></span></a><span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=n>anchor</span><span class=p>,</span> <span class=n>positive</span><span class=p>,</span> <span class=n>negative</span><span class=p>)</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginWithDistanceLoss.html>TripletMarginWithDistanceLoss官方文档</a></p> <h2 id=connectionist-temporal-classification-loss-ctcloss>Connectionist Temporal Classification Loss (CTCLoss)<a class=headerlink href=#connectionist-temporal-classification-loss-ctcloss title="Permanent link">¶</a></h2> <h3 id=_61>数学表达式<a class=headerlink href=#_61 title="Permanent link">¶</a></h3> <p>$$<br> \mathcal{L}(x, y, l) = -\log(p(l|x))<br> $$<br> 其中：<br> - <span class=arithmatex>\( x \)</span> 是输入序列（通常是RNN的输出），形状为 (T, N, C)<br> - <span class=arithmatex>\( y \)</span> 是目标序列，形状为 (N, S) 或目标和长度的元组<br> - <span class=arithmatex>\( l \)</span> 是输入长度和目标长度<br> - <span class=arithmatex>\( p(l|x) \)</span> 是给定输入序列x时，目标序列l的条件概率</p> <h3 id=_62>适用场景<a class=headerlink href=#_62 title="Permanent link">¶</a></h3> <ol> <li><strong>序列标注</strong>：输入和输出长度不同的序列任务</li> <li><strong>语音识别</strong>：将音频信号转换为文本</li> <li><strong>手写识别</strong>：将手写图像转换为文本</li> <li><strong>视频分析</strong>：视频序列到标签序列的转换</li> </ol> <h3 id=_63>参数说明<a class=headerlink href=#_63 title="Permanent link">¶</a></h3> <p>PyTorch实现：<code>torch.nn.CTCLoss</code></p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-33-1><a id=__codelineno-33-1 name=__codelineno-33-1></a><a href=#__codelineno-33-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>CTCLoss</span><span class=p>(</span>
</span><span id=__span-33-2><a id=__codelineno-33-2 name=__codelineno-33-2></a><a href=#__codelineno-33-2><span class=linenos data-linenos=" 2 "></span></a>    <span class=n>blank</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>            <span class=c1># 空白标签索引</span>
</span><span id=__span-33-3><a id=__codelineno-33-3 name=__codelineno-33-3></a><a href=#__codelineno-33-3><span class=linenos data-linenos=" 3 "></span></a>    <span class=n>reduction</span><span class=o>=</span><span class=s1>'mean'</span><span class=p>,</span>   <span class=c1># 'none'|'mean'|'sum'</span>
</span><span id=__span-33-4><a id=__codelineno-33-4 name=__codelineno-33-4></a><a href=#__codelineno-33-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>zero_infinity</span><span class=o>=</span><span class=kc>False</span> <span class=c1># 是否将无限损失设为零</span>
</span><span id=__span-33-5><a id=__codelineno-33-5 name=__codelineno-33-5></a><a href=#__codelineno-33-5><span class=linenos data-linenos=" 5 "></span></a><span class=p>)</span>
</span><span id=__span-33-6><a id=__codelineno-33-6 name=__codelineno-33-6></a><a href=#__codelineno-33-6><span class=linenos data-linenos=" 6 "></span></a><span class=sd>"""</span>
</span><span id=__span-33-7><a id=__codelineno-33-7 name=__codelineno-33-7></a><a href=#__codelineno-33-7><span class=linenos data-linenos=" 7 "></span></a><span class=sd>blank：</span>
</span><span id=__span-33-8><a id=__codelineno-33-8 name=__codelineno-33-8></a><a href=#__codelineno-33-8><span class=linenos data-linenos=" 8 "></span></a><span class=sd>空白标签的索引</span>
</span><span id=__span-33-9><a id=__codelineno-33-9 name=__codelineno-33-9></a><a href=#__codelineno-33-9><span class=linenos data-linenos=" 9 "></span></a><span class=sd>默认值为0</span>
</span><span id=__span-33-10><a id=__codelineno-33-10 name=__codelineno-33-10></a><a href=#__codelineno-33-10><span class=linenos data-linenos="10 "></span></a>
</span><span id=__span-33-11><a id=__codelineno-33-11 name=__codelineno-33-11></a><a href=#__codelineno-33-11><span class=linenos data-linenos="11 "></span></a><span class=sd>reduction：</span>
</span><span id=__span-33-12><a id=__codelineno-33-12 name=__codelineno-33-12></a><a href=#__codelineno-33-12><span class=linenos data-linenos="12 "></span></a><span class=sd>'none'：返回逐样本损失</span>
</span><span id=__span-33-13><a id=__codelineno-33-13 name=__codelineno-33-13></a><a href=#__codelineno-33-13><span class=linenos data-linenos="13 "></span></a><span class=sd>'mean'（默认）：返回损失均值</span>
</span><span id=__span-33-14><a id=__codelineno-33-14 name=__codelineno-33-14></a><a href=#__codelineno-33-14><span class=linenos data-linenos="14 "></span></a><span class=sd>'sum'：返回损失总和</span>
</span><span id=__span-33-15><a id=__codelineno-33-15 name=__codelineno-33-15></a><a href=#__codelineno-33-15><span class=linenos data-linenos="15 "></span></a>
</span><span id=__span-33-16><a id=__codelineno-33-16 name=__codelineno-33-16></a><a href=#__codelineno-33-16><span class=linenos data-linenos="16 "></span></a><span class=sd>zero_infinity：</span>
</span><span id=__span-33-17><a id=__codelineno-33-17 name=__codelineno-33-17></a><a href=#__codelineno-33-17><span class=linenos data-linenos="17 "></span></a><span class=sd>如果为True，将无限损失设为零（用于处理异常情况）</span>
</span><span id=__span-33-18><a id=__codelineno-33-18 name=__codelineno-33-18></a><a href=#__codelineno-33-18><span class=linenos data-linenos="18 "></span></a><span class=sd>默认值为False</span>
</span><span id=__span-33-19><a id=__codelineno-33-19 name=__codelineno-33-19></a><a href=#__codelineno-33-19><span class=linenos data-linenos="19 "></span></a><span class=sd>"""</span>
</span></code></pre></div> <p>注意：<br> - CTC允许输入和输出序列长度不同<br> - 输入通常需要经过log_softmax处理<br> - 需要提供输入长度和目标长度<br> - 空白标签用于对齐不同长度的序列<br> - 适用于不需要先验对齐信息的序列到序列任务</p> <p>示例：</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-34-1><a id=__codelineno-34-1 name=__codelineno-34-1></a><a href=#__codelineno-34-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>T</span> <span class=o>=</span> <span class=mi>50</span>      <span class=c1># 输入序列长度</span>
</span><span id=__span-34-2><a id=__codelineno-34-2 name=__codelineno-34-2></a><a href=#__codelineno-34-2><span class=linenos data-linenos=" 2 "></span></a><span class=n>C</span> <span class=o>=</span> <span class=mi>20</span>      <span class=c1># 类别数（包括空白标签）</span>
</span><span id=__span-34-3><a id=__codelineno-34-3 name=__codelineno-34-3></a><a href=#__codelineno-34-3><span class=linenos data-linenos=" 3 "></span></a><span class=n>N</span> <span class=o>=</span> <span class=mi>16</span>      <span class=c1># batch size</span>
</span><span id=__span-34-4><a id=__codelineno-34-4 name=__codelineno-34-4></a><a href=#__codelineno-34-4><span class=linenos data-linenos=" 4 "></span></a><span class=n>S</span> <span class=o>=</span> <span class=mi>30</span>      <span class=c1># 目标序列长度</span>
</span><span id=__span-34-5><a id=__codelineno-34-5 name=__codelineno-34-5></a><a href=#__codelineno-34-5><span class=linenos data-linenos=" 5 "></span></a><span class=n>S_min</span> <span class=o>=</span> <span class=mi>10</span>  <span class=c1># 最小目标长度</span>
</span><span id=__span-34-6><a id=__codelineno-34-6 name=__codelineno-34-6></a><a href=#__codelineno-34-6><span class=linenos data-linenos=" 6 "></span></a>
</span><span id=__span-34-7><a id=__codelineno-34-7 name=__codelineno-34-7></a><a href=#__codelineno-34-7><span class=linenos data-linenos=" 7 "></span></a><span class=c1># 随机生成数据</span>
</span><span id=__span-34-8><a id=__codelineno-34-8 name=__codelineno-34-8></a><a href=#__codelineno-34-8><span class=linenos data-linenos=" 8 "></span></a><span class=nb>input</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>C</span><span class=p>)</span><span class=o>.</span><span class=n>log_softmax</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-34-9><a id=__codelineno-34-9 name=__codelineno-34-9></a><a href=#__codelineno-34-9><span class=linenos data-linenos=" 9 "></span></a><span class=n>target</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=n>low</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>high</span><span class=o>=</span><span class=n>C</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>S</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>)</span>
</span><span id=__span-34-10><a id=__codelineno-34-10 name=__codelineno-34-10></a><a href=#__codelineno-34-10><span class=linenos data-linenos="10 "></span></a>
</span><span id=__span-34-11><a id=__codelineno-34-11 name=__codelineno-34-11></a><a href=#__codelineno-34-11><span class=linenos data-linenos="11 "></span></a><span class=c1># 生成随机长度</span>
</span><span id=__span-34-12><a id=__codelineno-34-12 name=__codelineno-34-12></a><a href=#__codelineno-34-12><span class=linenos data-linenos="12 "></span></a><span class=n>input_lengths</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>full</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>N</span><span class=p>,),</span> <span class=n>fill_value</span><span class=o>=</span><span class=n>T</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>)</span>
</span><span id=__span-34-13><a id=__codelineno-34-13 name=__codelineno-34-13></a><a href=#__codelineno-34-13><span class=linenos data-linenos="13 "></span></a><span class=n>target_lengths</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=n>low</span><span class=o>=</span><span class=n>S_min</span><span class=p>,</span> <span class=n>high</span><span class=o>=</span><span class=n>S</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>N</span><span class=p>,),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>)</span>
</span><span id=__span-34-14><a id=__codelineno-34-14 name=__codelineno-34-14></a><a href=#__codelineno-34-14><span class=linenos data-linenos="14 "></span></a>
</span><span id=__span-34-15><a id=__codelineno-34-15 name=__codelineno-34-15></a><a href=#__codelineno-34-15><span class=linenos data-linenos="15 "></span></a><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CTCLoss</span><span class=p>()</span>
</span><span id=__span-34-16><a id=__codelineno-34-16 name=__codelineno-34-16></a><a href=#__codelineno-34-16><span class=linenos data-linenos="16 "></span></a><span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=nb>input</span><span class=p>,</span> <span class=n>target</span><span class=p>,</span> <span class=n>input_lengths</span><span class=p>,</span> <span class=n>target_lengths</span><span class=p>)</span>
</span></code></pre></div> <p><a href=https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html>CTCLoss官方文档</a></p></div> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="August 18, 2025 22:22:07 CST">August 18, 2025 22:22:07</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="August 18, 2025 22:22:07 CST">August 18, 2025 22:22:07</span> </span> </aside> <!-- Insert generated snippet here --> <script src=https://giscus.app/client.js data-repo=6chHenry/6chHenry.github.io data-repo-id=R_kgDONZrjcA data-category=Announcements data-category-id=DIC_kwDONZrjcM4Ck-PT data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=1 data-input-position=top data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous async>
    </script> <!-- Synchronize Giscus theme with palette --> <script>
    var giscus = document.querySelector("script[src*=giscus]")

    // Set palette on initial load
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate"
            ? "transparent_dark"
            : "light"

        // Instruct Giscus to set theme
        giscus.setAttribute("data-theme", theme)
    }

    // Register event handlers after documented loaded
    document.addEventListener("DOMContentLoaded", function () {
        var ref = document.querySelector("[data-md-component=palette]")
        ref.addEventListener("change", function () {
            var palette = __md_get("__palette")
            if (palette && typeof palette.color === "object") {
                var theme = palette.color.scheme === "slate"
                    ? "transparent_dark"
                    : "light"

                // Instruct Giscus to change theme
                var frame = document.querySelector(".giscus-frame")
                frame.contentWindow.postMessage(
                    {giscus: {setConfig: {theme}}},
                    "https://giscus.app"
                )
            }
        })
    })
</script> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024-2025 - Present <a href=https://github.com/6chHenry target=_blank rel=noopener>6ch.</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/6chHenry/ target=_blank rel=noopener title=GitHub class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=/img/qq.png target=_blank rel=noopener title=加加我的QQ class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M434.1 420.4c-11.5 1.4-44.9-52.7-44.9-52.7 0 31.3-16.1 72.2-51 101.8 16.8 5.2 54.8 19.2 45.8 34.4-7.3 12.3-125.5 7.9-159.6 4-34.1 3.8-152.3 8.3-159.6-4-9-15.2 28.9-29.2 45.8-34.4-34.9-29.5-51.1-70.4-51.1-101.8 0 0-33.3 54.1-44.9 52.7-5.4-.6-12.4-29.6 9.3-99.7 10.3-33 22-60.5 40.1-105.8C60.9 98 109.2-.1 224.3-.1 338-.1 387.5 96 384.6 214.9c18.1 45.2 29.9 72.9 40.1 105.8 21.8 70.1 14.7 99.1 9.3 99.7z"/></svg> </a> <a href=/img/wechat.png target=_blank rel=noopener title=Zhihu class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M385.2 167.6c6.4 0 12.6.3 18.8 1.1C387.4 90.3 303.3 32 207.7 32 100.5 32 13 104.8 13 197.4c0 53.4 29.3 97.5 77.9 131.6l-19.3 58.6 68-34.1c24.4 4.8 43.8 9.7 68.2 9.7 6.2 0 12.1-.3 18.3-.8-4-12.9-6.2-26.6-6.2-40.8-.1-84.9 72.9-154 165.3-154m-104.5-52.9c14.5 0 24.2 9.7 24.2 24.4 0 14.5-9.7 24.2-24.2 24.2-14.8 0-29.3-9.7-29.3-24.2.1-14.7 14.6-24.4 29.3-24.4m-136.4 48.6c-14.5 0-29.3-9.7-29.3-24.2 0-14.8 14.8-24.4 29.3-24.4 14.8 0 24.4 9.7 24.4 24.4 0 14.6-9.6 24.2-24.4 24.2M563 319.4c0-77.9-77.9-141.3-165.4-141.3-92.7 0-165.4 63.4-165.4 141.3S305 460.7 397.6 460.7c19.3 0 38.9-5.1 58.6-9.9l53.4 29.3-14.8-48.6C534 402.1 563 363.2 563 319.4m-219.1-24.5c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.8 0 24.4 9.7 24.4 19.3 0 10-9.7 19.6-24.4 19.6m107.1 0c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.5 0 24.4 9.7 24.4 19.3.1 10-9.9 19.6-24.4 19.6"/></svg> </a> <a href=mailto:2313287840@qq.com target=_blank rel=noopener title="send email to me!" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M536.4-26.3c9.8-3.5 20.6-1 28 6.3s9.8 18.2 6.3 28l-178 496.9c-5 13.9-18.1 23.1-32.8 23.1-14.2 0-27-8.6-32.3-21.7l-64.2-158c-4.5-11-2.5-23.6 5.2-32.6l94.5-112.4c5.1-6.1 4.7-15-.9-20.6s-14.6-6-20.6-.9l-112.4 94.3c-9.1 7.6-21.6 9.6-32.6 5.2L38.1 216.8c-13.1-5.3-21.7-18.1-21.7-32.3 0-14.7 9.2-27.8 23.1-32.8z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["content.code.annotate", "content.code.copy", "content.code.select", "content.footnote.tooltips", "content.tabs.link", "header.autohide", "navigation.tracking", "navigation.tabs", "navigation.top", "navigation.path", "navigation.indexes", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../../assets/javascripts/bundle.92b07e13.min.js></script> <script src=../../../javascripts/mathjax.js></script> <script src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>