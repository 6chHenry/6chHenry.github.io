<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="6ch. 的个人网站"><meta name=author content=6ch.><link href=https://6chHenry.github.io/notes/RL/Chap3BellmanOptimalEquation/ rel=canonical><link href=../Chap2BellmanEquation/ rel=prev><link href=../../Python-Tutorial/For-Loop/ rel=next><link rel=icon href=../../../img/avatar1.jpg><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.18"><title>Chapter3 Bellman Optimality - 6ch's Website</title><link rel=stylesheet href=../../../assets/stylesheets/main.7e37652d.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M64%20480c-35.3%200-64-28.7-64-64V96c0-35.3%2028.7-64%2064-64h320c35.3%200%2064%2028.7%2064%2064v213.5c0%2017-6.7%2033.3-18.7%2045.3L322.7%20461.3c-12%2012-28.3%2018.7-45.3%2018.7zm325.5-176H296c-13.3%200-24%2010.7-24%2024v93.5z%22/%3E%3C/svg%3E');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M384%20512H96c-53%200-96-43-96-96V96C0%2043%2043%200%2096%200h304c26.5%200%2048%2021.5%2048%2048v288c0%2020.9-13.4%2038.7-32%2045.3V448c17.7%200%2032%2014.3%2032%2032s-14.3%2032-32%2032zM96%20384c-17.7%200-32%2014.3-32%2032s14.3%2032%2032%2032h256v-64zm32-232c0%2013.3%2010.7%2024%2024%2024h176c13.3%200%2024-10.7%2024-24s-10.7-24-24-24H152c-13.3%200-24%2010.7-24%2024m24%2072c-13.3%200-24%2010.7-24%2024s10.7%2024%2024%2024h176c13.3%200%2024-10.7%2024-24s-10.7-24-24-24z%22/%3E%3C/svg%3E');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M256%20512a256%20256%200%201%200%200-512%20256%20256%200%201%200%200%20512m-32-352a32%2032%200%201%201%2064%200%2032%2032%200%201%201-64%200m-8%2064h48c13.3%200%2024%2010.7%2024%2024v88h8c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-80c-13.3%200-24-10.7-24-24s10.7-24%2024-24h24v-64h-24c-13.3%200-24-10.7-24-24s10.7-24%2024-24%22/%3E%3C/svg%3E');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M461.2%2018.9C472.7%2024%20480%2035.4%20480%2048v416c0%2012.6-7.3%2024-18.8%2029.1s-24.8%203.2-34.3-5.1l-46.6-40.7c-43.6-38.1-98.7-60.3-156.4-63V480c0%2017.7-14.3%2032-32%2032h-32c-17.7%200-32-14.3-32-32v-96C57.3%20384%200%20326.7%200%20256s57.3-128%20128-128h84.5c61.8-.2%20121.4-22.7%20167.9-63.3L427%2024c9.4-8.3%2022.9-10.2%2034.3-5.1zM224%20320v.2c70.3%202.7%20137.8%2028.5%20192%2073.4V118.3c-54.2%2044.9-121.7%2070.7-192%2073.4z%22/%3E%3C/svg%3E');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M434.8%2070.1c14.3%2010.4%2017.5%2030.4%207.1%2044.7l-256%20352c-5.5%207.6-14%2012.3-23.4%2013.1s-18.5-2.7-25.1-9.3l-128-128c-12.5-12.5-12.5-32.8%200-45.3s32.8-12.5%2045.3%200l101.5%20101.5%20234-321.7c10.4-14.3%2030.4-17.5%2044.7-7.1z%22/%3E%3C/svg%3E');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M256%20512a256%20256%200%201%200%200-512%20256%20256%200%201%200%200%20512m0-336c-17.7%200-32%2014.3-32%2032%200%2013.3-10.7%2024-24%2024s-24-10.7-24-24c0-44.2%2035.8-80%2080-80s80%2035.8%2080%2080c0%2047.2-36%2067.2-56%2074.5v3.8c0%2013.3-10.7%2024-24%2024s-24-10.7-24-24v-8.1c0-20.5%2014.8-35.2%2030.1-40.2%206.4-2.1%2013.2-5.5%2018.2-10.3%204.3-4.2%207.7-10%207.7-19.6%200-17.7-14.3-32-32-32zm-32%20192a32%2032%200%201%201%2064%200%2032%2032%200%201%201-64%200%22/%3E%3C/svg%3E');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M256%200c14.7%200%2028.2%208.1%2035.2%2021l216%20400c6.7%2012.4%206.4%2027.4-.8%2039.5S486.1%20480%20472%20480H40c-14.1%200-27.1-7.4-34.4-19.5s-7.5-27.1-.8-39.5l216-400c7-12.9%2020.5-21%2035.2-21m0%20168c-13.3%200-24%2010.7-24%2024v112c0%2013.3%2010.7%2024%2024%2024s24-10.7%2024-24V192c0-13.3-10.7-24-24-24m26.7%20216a26.7%2026.7%200%201%200-53.3%200%2026.7%2026.7%200%201%200%2053.3%200%22/%3E%3C/svg%3E');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20576%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M480-16c6.9%200%2013%204.4%2015.2%2010.9l13.5%2040.4%2040.4%2013.5C555.6%2051%20560%2057.1%20560%2064s-4.4%2013-10.9%2015.2l-40.4%2013.5-13.5%2040.4c-2.2%206.5-8.3%2010.9-15.2%2010.9s-13-4.4-15.2-10.9l-13.5-40.4-40.4-13.5C404.4%2077%20400%2070.9%20400%2064s4.4-13%2010.9-15.2l40.4-13.5%2013.5-40.4C467-11.6%20473.1-16%20480-16M321.4%2097.4c12.5-12.5%2032.8-12.5%2045.3%200l80%2080c12.5%2012.5%2012.5%2032.8%200%2045.3l-10.9%2010.9c7.9%2022%2012.2%2045.7%2012.2%2070.5%200%20114.9-93.1%20208-208%20208S32%20418.9%2032%20304%20125.1%2096%20240%2096c24.7%200%2048.5%204.3%2070.5%2012.3zM144%20304c0-53%2043-96%2096-96%2013.3%200%2024-10.7%2024-24s-10.7-24-24-24c-79.5%200-144%2064.5-144%20144%200%2013.3%2010.7%2024%2024%2024s24-10.7%2024-24%22/%3E%3C/svg%3E');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M416%20427.4c58.5-44%2096-111.6%2096-187.4C512%20107.5%20397.4%200%20256%200S0%20107.5%200%20240c0%2075.8%2037.5%20143.4%2096%20187.4V464c0%2026.5%2021.5%2048%2048%2048h32v-40c0-13.3%2010.7-24%2024-24s24%2010.7%2024%2024v40h64v-40c0-13.3%2010.7-24%2024-24s24%2010.7%2024%2024v40h32c26.5%200%2048-21.5%2048-48zM96%20256a64%2064%200%201%201%20128%200%2064%2064%200%201%201-128%200m256-64a64%2064%200%201%201%200%20128%2064%2064%200%201%201%200-128%22/%3E%3C/svg%3E');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20640%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M352%200c0-17.7-14.3-32-32-32s-32%2014.3-32%2032v64h-96c-53%200-96%2043-96%2096v224c0%2053%2043%2096%2096%2096h256c53%200%2096-43%2096-96V160c0-53-43-96-96-96h-96zM160%20368c0-13.3%2010.7-24%2024-24h32c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-32c-13.3%200-24-10.7-24-24m120%200c0-13.3%2010.7-24%2024-24h32c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-32c-13.3%200-24-10.7-24-24m120%200c0-13.3%2010.7-24%2024-24h32c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-32c-13.3%200-24-10.7-24-24M224%20176a48%2048%200%201%201%200%2096%2048%2048%200%201%201%200-96m144%2048a48%2048%200%201%201%2096%200%2048%2048%200%201%201-96%200m-304%200c0-17.7-14.3-32-32-32S0%20206.3%200%20224v96c0%2017.7%2014.3%2032%2032%2032s32-14.3%2032-32zm544-32c-17.7%200-32%2014.3-32%2032v96c0%2017.7%2014.3%2032%2032%2032s32-14.3%2032-32v-96c0-17.7-14.3-32-32-32%22/%3E%3C/svg%3E');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M288%200H128c-17.7%200-32%2014.3-32%2032s14.3%2032%2032%2032v151.5L7.5%20426.3C2.6%20435%200%20444.7%200%20454.7%200%20486.4%2025.6%20512%2057.3%20512h333.4c31.6%200%2057.3-25.6%2057.3-57.3%200-10-2.6-19.8-7.5-28.4L320%20215.5V64c17.7%200%2032-14.3%2032-32S337.7%200%20320%200zm-96%20215.5V64h64v151.5c0%2011.1%202.9%2022.1%208.4%2031.8L306%20320H142l41.6-72.7c5.5-9.7%208.4-20.6%208.4-31.8%22/%3E%3C/svg%3E');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.0.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20fill%3D%22currentColor%22%20d%3D%22M0%20216C0%20149.7%2053.7%2096%20120%2096h8c17.7%200%2032%2014.3%2032%2032s-14.3%2032-32%2032h-8c-30.9%200-56%2025.1-56%2056v8h64c35.3%200%2064%2028.7%2064%2064v64c0%2035.3-28.7%2064-64%2064H64c-35.3%200-64-28.7-64-64zm256%200c0-66.3%2053.7-120%20120-120h8c17.7%200%2032%2014.3%2032%2032s-14.3%2032-32%2032h-8c-30.9%200-56%2025.1-56%2056v8h64c35.3%200%2064%2028.7%2064%2064v64c0%2035.3-28.7%2064-64%2064h-64c-35.3%200-64-28.7-64-64z%22/%3E%3C/svg%3E');}</style><style>:root{--md-annotation-icon:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2024%2024%22%3E%3Cpath%20d%3D%22M22%2012a10%2010%200%200%201-10%2010A10%2010%200%200%201%202%2012%2010%2010%200%200%201%2012%202a10%2010%200%200%201%2010%2010M6%2013h8l-3.5%203.5%201.42%201.42L17.84%2012l-5.92-5.92L10.5%207.5%2014%2011H6z%22/%3E%3C/svg%3E');}</style><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=LXGW+WenKai+Screen:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"LXGW WenKai Screen";--md-code-font:"Fira Code"}</style><link rel=stylesheet href=../../../css/custom.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=../../../css/card.css><link rel=stylesheet href=../../../css/flink.css><link rel=stylesheet href=../../../css/tasklist.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><link href=../../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style><script src=../../../assets/javascripts/glightbox.min.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#3- class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="6ch's Website" class="md-header__button md-logo" aria-label="6ch's Website" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> 6ch's Website </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Chapter3 Bellman Optimality </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=indigo aria-label="light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="dark mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 256 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/6chHenry/6chHenry.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> 6ch.'s Site </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"/></svg> 主页 </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"/></svg> 笔记 </a> </li> <li class=md-tabs__item> <a href=../../../summary/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1zM5 8v11h14V8zm2 2h10v2H7z"/></svg> 总结 </a> </li> <li class=md-tabs__item> <a href=../../../websites/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.78 3.653a3.936 3.936 0 1 1 5.567 5.567l-3.627 3.627a3.936 3.936 0 0 1-5.88-.353.75.75 0 0 0-1.18.928 5.436 5.436 0 0 0 8.12.486l3.628-3.628a5.436 5.436 0 1 0-7.688-7.688l-3 3a.75.75 0 0 0 1.06 1.061z"/><path d="M7.28 11.153a3.936 3.936 0 0 1 5.88.353.75.75 0 0 0 1.18-.928 5.436 5.436 0 0 0-8.12-.486L2.592 13.72a5.436 5.436 0 1 0 7.688 7.688l3-3a.75.75 0 1 0-1.06-1.06l-3 3a3.936 3.936 0 0 1-5.567-5.568z"/></svg> 网站 </a> </li> <li class=md-tabs__item> <a href=../../../projects/ class=md-tabs__link> 项目 </a> </li> <li class=md-tabs__item> <a href=../../../about/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-90.6-190.1c20.4 28 53.4 46.1 90.6 46.1s70.2-18.1 90.6-46.1c7.8-10.7 22.8-13.1 33.5-5.3s13.1 22.8 5.3 33.5C356.3 390 309.2 416 256 416s-100.3-26-129.4-65.9c-7.8-10.7-5.4-25.7 5.3-33.5s25.7-5.4 33.5 5.3M144 208a32 32 0 1 1 64 0 32 32 0 1 1-64 0m164 8c0 11-9 20-20 20s-20-9-20-20c0-33.1 26.9-60 60-60h16c33.1 0 60 26.9 60 60 0 11-9 20-20 20s-20-9-20-20-9-20-20-20h-16c-11 0-20 9-20 20"/></svg> 关于我 </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="6ch's Website" class="md-nav__button md-logo" aria-label="6ch's Website" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"/></svg> </a> 6ch's Website </label> <div class=md-nav__source> <a href=https://github.com/6chHenry/6chHenry.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> 6ch.'s Site </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"/></svg> <span class=md-ellipsis> 主页 </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"/></svg> <span class=md-ellipsis> 笔记 </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> 笔记 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex=0> <span class=md-ellipsis> EECS 498(Deep Learning for Computer Vision) </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> EECS 498(Deep Learning for Computer Vision) </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../EECS498/Linear%20Classifiers/ class=md-nav__link> <span class=md-ellipsis> Linear Classifiers </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/Optimization/ class=md-nav__link> <span class=md-ellipsis> Optimization </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/A1/ class=md-nav__link> <span class=md-ellipsis> 第一次作业(pytorch & KNN) </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/Neural%20Network/ class=md-nav__link> <span class=md-ellipsis> Neural Network </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/Back%20Propagation/ class=md-nav__link> <span class=md-ellipsis> Back Propagation </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/Derivative%20of%20Matrix/ class=md-nav__link> <span class=md-ellipsis> 矩阵求导 </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/A2/ class=md-nav__link> <span class=md-ellipsis> 第二次作业(Linear Classifiers) </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/2-layer-network/ class=md-nav__link> <span class=md-ellipsis> 第二次作业(Two Layer Net) </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/CNN/ class=md-nav__link> <span class=md-ellipsis> CNN </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/CNNArchiture/ class=md-nav__link> <span class=md-ellipsis> CNNArchitecture </span> </a> </li> <li class=md-nav__item> <a href=../../EECS498/TrainingNN/ class=md-nav__link> <span class=md-ellipsis> TrainingNN </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3> <label class=md-nav__link for=__nav_2_3 id=__nav_2_3_label tabindex=0> <span class=md-ellipsis> 概率统计（荣誉）(MATH1207H) </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> 概率统计（荣誉）(MATH1207H) </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Probability/%E8%AE%A8%E8%AE%BA2/ class=md-nav__link> <span class=md-ellipsis> 第二次讨论 </span> </a> </li> <li class=md-nav__item> <a href=../../Probability/%E8%AE%A8%E8%AE%BA3/ class=md-nav__link> <span class=md-ellipsis> 第三次讨论 </span> </a> </li> <li class=md-nav__item> <a href=../../Probability/%E8%AE%A8%E8%AE%BA4/ class=md-nav__link> <span class=md-ellipsis> 第四次讨论 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_4> <label class=md-nav__link for=__nav_2_4 id=__nav_2_4_label tabindex=0> <span class=md-ellipsis> 数据结构（荣誉）(CS0501H) </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_4> <span class="md-nav__icon md-icon"></span> 数据结构（荣誉）(CS0501H) </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../CS0501H/%E9%93%BE%E8%A1%A8/ class=md-nav__link> <span class=md-ellipsis> 线性表 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_5> <label class=md-nav__link for=__nav_2_5 id=__nav_2_5_label tabindex=0> <span class=md-ellipsis> 从零构建GPT(Karpathy) </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_5_label aria-expanded=false> <label class=md-nav__title for=__nav_2_5> <span class="md-nav__icon md-icon"></span> 从零构建GPT(Karpathy) </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../GPT/micrograd/ class=md-nav__link> <span class=md-ellipsis> Micrograd </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/makemore/ class=md-nav__link> <span class=md-ellipsis> Makemore(First Status) </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/makemoreMLP/ class=md-nav__link> <span class=md-ellipsis> Makemore(MLP) </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/makemoreActivation/ class=md-nav__link> <span class=md-ellipsis> Makemore(Activation) </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/makemoreNinja/ class=md-nav__link> <span class=md-ellipsis> Makemore(Become a Backprop Ninja) </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/makemoreComnet/ class=md-nav__link> <span class=md-ellipsis> Makemore(Convolution Layer) </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/ShakespeareGPT/ class=md-nav__link> <span class=md-ellipsis> ShakespeareGPT </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/Attention%20is%20All%20You%20Need/ class=md-nav__link> <span class=md-ellipsis> Attention is All You Need </span> </a> </li> <li class=md-nav__item> <a href=../../GPT/diveintogpt/ class=md-nav__link> <span class=md-ellipsis> Dive into GPT </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_6> <label class=md-nav__link for=__nav_2_6 id=__nav_2_6_label tabindex=0> <span class=md-ellipsis> 6.S091(Representation Learning) </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_6_label aria-expanded=false> <label class=md-nav__title for=__nav_2_6> <span class="md-nav__icon md-icon"></span> 6.S091(Representation Learning) </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../6.S091/Representation/ class=md-nav__link> <span class=md-ellipsis> Representation Learning </span> </a> </li> <li class=md-nav__item> <a href=../../6.S091/Structural%20Causal%20Model/ class=md-nav__link> <span class=md-ellipsis> Structural Causal Model </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_7 checked> <label class=md-nav__link for=__nav_2_7 id=__nav_2_7_label tabindex=0> <span class=md-ellipsis> Reinforcement Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_7_label aria-expanded=true> <label class=md-nav__title for=__nav_2_7> <span class="md-nav__icon md-icon"></span> Reinforcement Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/ class=md-nav__link> <span class=md-ellipsis> 大模型强化学习PPO </span> </a> </li> <li class=md-nav__item> <a href=../PPO%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/ class=md-nav__link> <span class=md-ellipsis> PPO算法原理 </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_7_3 checked> <label class=md-nav__link for=__nav_2_7_3 id=__nav_2_7_3_label tabindex=0> <span class=md-ellipsis> 强化学习的数学原理 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_7_3_label aria-expanded=true> <label class=md-nav__title for=__nav_2_7_3> <span class="md-nav__icon md-icon"></span> 强化学习的数学原理 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Overall%20Map/ class=md-nav__link> <span class=md-ellipsis> Overall Map </span> </a> </li> <li class=md-nav__item> <a href=../Chapter1/ class=md-nav__link> <span class=md-ellipsis> Chapter1 </span> </a> </li> <li class=md-nav__item> <a href=../Chapter2StateValue/ class=md-nav__link> <span class=md-ellipsis> Chapter2 StateValue </span> </a> </li> <li class=md-nav__item> <a href=../Chap2BellmanEquation/ class=md-nav__link> <span class=md-ellipsis> Chapter2 Bellman Equation </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Chapter3 Bellman Optimality </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Chapter3 Bellman Optimality </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> 一、最优策略的定义与核心问题 </span> </a> <nav class=md-nav aria-label=一、最优策略的定义与核心问题> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1 class=md-nav__link> <span class=md-ellipsis> 1. 策略优劣的比较标准 </span> </a> </li> <li class=md-nav__item> <a href=#2 class=md-nav__link> <span class=md-ellipsis> 2. 最优策略的四大核心问题 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 二、贝尔曼最优公式 </span> </a> <nav class=md-nav aria-label=二、贝尔曼最优公式> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1_1 class=md-nav__link> <span class=md-ellipsis> 1. 公式形式与核心改动 </span> </a> </li> <li class=md-nav__item> <a href=#2_1 class=md-nav__link> <span class=md-ellipsis> 2. 已知条件与求解目标 </span> </a> </li> <li class=md-nav__item> <a href=#3 class=md-nav__link> <span class=md-ellipsis> 3. 公式的“优美性”与“复杂性” </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 三、贝尔曼最优公式的求解思路（核心推导） </span> </a> <nav class=md-nav aria-label=三、贝尔曼最优公式的求解思路（核心推导）> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1_2 class=md-nav__link> <span class=md-ellipsis> 1. 求解逻辑：分两步拆解“双未知量”问题 </span> </a> <nav class=md-nav aria-label="1. 求解逻辑：分两步拆解“双未知量”问题"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1how-to-solve-2-unknowns-from-1-equation class=md-nav__link> <span class=md-ellipsis> 例1：How to solve 2 unknowns from 1 equation </span> </a> </li> <li class=md-nav__item> <a href=#2-how-to-solve-max_pi-sum_a-piasqsamax_pi-sum_a-piasqsa class=md-nav__link> <span class=md-ellipsis> 例2 How to solve \max_{\pi} \sum_{a} \pi(a|s)q(s,a)\max_{\pi} \sum_{a} \pi(a|s)q(s,a) </span> </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 强化学习场景（映射到贝尔曼最优公式） </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#2_2 class=md-nav__link> <span class=md-ellipsis> 2. 核心结论 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> 四、公式与最优策略的关联 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_8> <label class=md-nav__link for=__nav_2_8 id=__nav_2_8_label tabindex=0> <span class=md-ellipsis> Python进阶教程 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_8_label aria-expanded=false> <label class=md-nav__title for=__nav_2_8> <span class="md-nav__icon md-icon"></span> Python进阶教程 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Python-Tutorial/For-Loop/ class=md-nav__link> <span class=md-ellipsis> 减少For-Loop </span> </a> </li> <li class=md-nav__item> <a href=../../Python-Tutorial/Pyplot/ class=md-nav__link> <span class=md-ellipsis> Matplotlib </span> </a> </li> <li class=md-nav__item> <a href=../../Python-Tutorial/pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class=md-nav__item> <a href=../../Python-Tutorial/Tensorboard/ class=md-nav__link> <span class=md-ellipsis> Tensorboard </span> </a> </li> <li class=md-nav__item> <a href=../../Python-Tutorial/Logging/ class=md-nav__link> <span class=md-ellipsis> Logging </span> </a> </li> <li class=md-nav__item> <a href=../../Python-Tutorial/WhatIsPickle/ class=md-nav__link> <span class=md-ellipsis> Pickle </span> </a> </li> <li class=md-nav__item> <a href=../../Python-Tutorial/LearnRegex/ class=md-nav__link> <span class=md-ellipsis> Regex </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_9> <label class=md-nav__link for=__nav_2_9 id=__nav_2_9_label tabindex=0> <span class=md-ellipsis> 科研笔记 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_9_label aria-expanded=false> <label class=md-nav__title for=__nav_2_9> <span class="md-nav__icon md-icon"></span> 科研笔记 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_9_1> <label class=md-nav__link for=__nav_2_9_1 id=__nav_2_9_1_label tabindex=0> <span class=md-ellipsis> OCL </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_9_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_9_1> <span class="md-nav__icon md-icon"></span> OCL </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Research/OCL/OCL/ class=md-nav__link> <span class=md-ellipsis> OCL </span> </a> </li> <li class=md-nav__item> <a href=../../Research/OCL/CosineSimilarity/ class=md-nav__link> <span class=md-ellipsis> 余弦相似度 </span> </a> </li> <li class=md-nav__item> <a href=../../Research/OCL/mAP/ class=md-nav__link> <span class=md-ellipsis> mAP </span> </a> </li> <li class=md-nav__item> <a href=../../Research/OCL/tSNE/ class=md-nav__link> <span class=md-ellipsis> tSNE </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_9_2> <label class=md-nav__link for=__nav_2_9_2 id=__nav_2_9_2_label tabindex=0> <span class=md-ellipsis> Causal Discovery </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_9_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_9_2> <span class="md-nav__icon md-icon"></span> Causal Discovery </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_9_2_1> <label class=md-nav__link for=__nav_2_9_2_1 id=__nav_2_9_2_1_label tabindex=0> <span class=md-ellipsis> Papers </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_9_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_9_2_1> <span class="md-nav__icon md-icon"></span> Papers </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Research/CausalDiscovery/Papers/Causal_Structure_Distributions/ class=md-nav__link> <span class=md-ellipsis> Causal Structure Distributions </span> </a> </li> <li class=md-nav__item> <a href=../../Research/CausalDiscovery/Papers/Llava/ class=md-nav__link> <span class=md-ellipsis> Llava </span> </a> </li> <li class=md-nav__item> <a href=../../Research/CausalDiscovery/Papers/CELLO/ class=md-nav__link> <span class=md-ellipsis> CELLO </span> </a> </li> <li class=md-nav__item> <a href=../../Research/CausalDiscovery/Papers/ALCM/ class=md-nav__link> <span class=md-ellipsis> ALCM </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_9_2_1_5> <label class=md-nav__link for=__nav_2_9_2_1_5 id=__nav_2_9_2_1_5_label tabindex=0> <span class=md-ellipsis> Causal Representation learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=5 aria-labelledby=__nav_2_9_2_1_5_label aria-expanded=false> <label class=md-nav__title for=__nav_2_9_2_1_5> <span class="md-nav__icon md-icon"></span> Causal Representation learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Research/CausalDiscovery/Papers/Towards%20Causal%20Representation%20Learning/ class=md-nav__link> <span class=md-ellipsis> Causal Representation Learning </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_9_2_2> <label class=md-nav__link for=__nav_2_9_2_2 id=__nav_2_9_2_2_label tabindex=0> <span class=md-ellipsis> Algorithms </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_9_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_9_2_2> <span class="md-nav__icon md-icon"></span> Algorithms </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Research/CausalDiscovery/Algorithms/PCAlgorithm/ class=md-nav__link> <span class=md-ellipsis> PC Algorithm </span> </a> </li> <li class=md-nav__item> <a href=../../Research/CausalDiscovery/Algorithms/NOTEARS/ class=md-nav__link> <span class=md-ellipsis> NOTEARS </span> </a> </li> <li class=md-nav__item> <a href=../../Research/CausalDiscovery/Algorithms/MissNODAG/ class=md-nav__link> <span class=md-ellipsis> MissNODAG </span> </a> </li> <li class=md-nav__item> <a href=../../Research/CausalDiscovery/Algorithms/DAG-GNN/ class=md-nav__link> <span class=md-ellipsis> DAG-GNN </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../SeveralQ/ class=md-nav__link> <span class=md-ellipsis> 一些问题 </span> </a> </li> <li class=md-nav__item> <a href=../../Latex/ class=md-nav__link> <span class=md-ellipsis> Latex基本教程 </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_12> <label class=md-nav__link for=__nav_2_12 id=__nav_2_12_label tabindex=0> <span class=md-ellipsis> Pytorch进阶教程 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_12_label aria-expanded=false> <label class=md-nav__title for=__nav_2_12> <span class="md-nav__icon md-icon"></span> Pytorch进阶教程 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_12_1> <label class=md-nav__link for=__nav_2_12_1 id=__nav_2_12_1_label tabindex=0> <span class=md-ellipsis> Loss Function </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_12_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_12_1> <span class="md-nav__icon md-icon"></span> Loss Function </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Pytorch-Tutorial/LossFunction/LossFunction/ class=md-nav__link> <span class=md-ellipsis> 概述 </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch-Tutorial/LossFunction/TripletLoss/ class=md-nav__link> <span class=md-ellipsis> Triplet Loss </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../Pytorch-Tutorial/Einsum/ class=md-nav__link> <span class=md-ellipsis> Einsum </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch-Tutorial/addmm/ class=md-nav__link> <span class=md-ellipsis> addmm </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch-Tutorial/where/ class=md-nav__link> <span class=md-ellipsis> where </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../../../summary/ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1zM5 8v11h14V8zm2 2h10v2H7z"/></svg> <span class=md-ellipsis> 总结 </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> 总结 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> 影评 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> 影评 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../summary/Movies/3%20Idiots/ class=md-nav__link> <span class=md-ellipsis> 3 Idiots </span> </a> </li> <li class=md-nav__item> <a href=../../../summary/Movies/Hachi/ class=md-nav__link> <span class=md-ellipsis> Hachi </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3> <label class=md-nav__link for=__nav_3_3 id=__nav_3_3_label tabindex=0> <span class=md-ellipsis> 音乐 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> 音乐 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../summary/Music/%E5%AD%A4%E5%84%BF%E4%BB%94/ class=md-nav__link> <span class=md-ellipsis> 孤儿仔 --Eason Chan </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../summary/%E9%AB%98%E4%B8%AD%E5%9B%9E%E5%BF%86%E5%BD%95/ class=md-nav__link> <span class=md-ellipsis> 我的高中 </span> </a> </li> <li class=md-nav__item> <a href=../../../summary/%E7%9D%A1%E7%9C%A0%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7/ class=md-nav__link> <span class=md-ellipsis> 睡眠 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <div class="md-nav__link md-nav__container"> <a href=../../../websites/ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.78 3.653a3.936 3.936 0 1 1 5.567 5.567l-3.627 3.627a3.936 3.936 0 0 1-5.88-.353.75.75 0 0 0-1.18.928 5.436 5.436 0 0 0 8.12.486l3.628-3.628a5.436 5.436 0 1 0-7.688-7.688l-3 3a.75.75 0 0 0 1.06 1.061z"/><path d="M7.28 11.153a3.936 3.936 0 0 1 5.88.353.75.75 0 0 0 1.18-.928 5.436 5.436 0 0 0-8.12-.486L2.592 13.72a5.436 5.436 0 1 0 7.688 7.688l3-3a.75.75 0 1 0-1.06-1.06l-3 3a3.936 3.936 0 0 1-5.567-5.568z"/></svg> <span class=md-ellipsis> 网站 </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> 网站 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../websites/LLM/ class=md-nav__link> <span class=md-ellipsis> LLM </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <div class="md-nav__link md-nav__container"> <a href=../../../projects/ class="md-nav__link "> <span class=md-ellipsis> 项目 </span> </a> <label class="md-nav__link " for=__nav_5 id=__nav_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> 项目 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_2> <label class=md-nav__link for=__nav_5_2 id=__nav_5_2_label tabindex=0> <span class=md-ellipsis> CarLaneDetection </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_2_label aria-expanded=false> <label class=md-nav__title for=__nav_5_2> <span class="md-nav__icon md-icon"></span> CarLaneDetection </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../projects/CarLaneDetection/Canny/ class=md-nav__link> <span class=md-ellipsis> CannyEdgeDetection </span> </a> </li> <li class=md-nav__item> <a href=../../../projects/CarLaneDetection/HoughTransform/ class=md-nav__link> <span class=md-ellipsis> HoughTransform </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../about/ class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-90.6-190.1c20.4 28 53.4 46.1 90.6 46.1s70.2-18.1 90.6-46.1c7.8-10.7 22.8-13.1 33.5-5.3s13.1 22.8 5.3 33.5C356.3 390 309.2 416 256 416s-100.3-26-129.4-65.9c-7.8-10.7-5.4-25.7 5.3-33.5s25.7-5.4 33.5 5.3M144 208a32 32 0 1 1 64 0 32 32 0 1 1-64 0m164 8c0 11-9 20-20 20s-20-9-20-20c0-33.1 26.9-60 60-60h16c33.1 0 60 26.9 60 60 0 11-9 20-20 20s-20-9-20-20-9-20-20-20h-16c-11 0-20 9-20 20"/></svg> <span class=md-ellipsis> 关于我 </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> 一、最优策略的定义与核心问题 </span> </a> <nav class=md-nav aria-label=一、最优策略的定义与核心问题> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1 class=md-nav__link> <span class=md-ellipsis> 1. 策略优劣的比较标准 </span> </a> </li> <li class=md-nav__item> <a href=#2 class=md-nav__link> <span class=md-ellipsis> 2. 最优策略的四大核心问题 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 二、贝尔曼最优公式 </span> </a> <nav class=md-nav aria-label=二、贝尔曼最优公式> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1_1 class=md-nav__link> <span class=md-ellipsis> 1. 公式形式与核心改动 </span> </a> </li> <li class=md-nav__item> <a href=#2_1 class=md-nav__link> <span class=md-ellipsis> 2. 已知条件与求解目标 </span> </a> </li> <li class=md-nav__item> <a href=#3 class=md-nav__link> <span class=md-ellipsis> 3. 公式的“优美性”与“复杂性” </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 三、贝尔曼最优公式的求解思路（核心推导） </span> </a> <nav class=md-nav aria-label=三、贝尔曼最优公式的求解思路（核心推导）> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1_2 class=md-nav__link> <span class=md-ellipsis> 1. 求解逻辑：分两步拆解“双未知量”问题 </span> </a> <nav class=md-nav aria-label="1. 求解逻辑：分两步拆解“双未知量”问题"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1how-to-solve-2-unknowns-from-1-equation class=md-nav__link> <span class=md-ellipsis> 例1：How to solve 2 unknowns from 1 equation </span> </a> </li> <li class=md-nav__item> <a href=#2-how-to-solve-max_pi-sum_a-piasqsamax_pi-sum_a-piasqsa class=md-nav__link> <span class=md-ellipsis> 例2 How to solve \max_{\pi} \sum_{a} \pi(a|s)q(s,a)\max_{\pi} \sum_{a} \pi(a|s)q(s,a) </span> </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 强化学习场景（映射到贝尔曼最优公式） </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#2_2 class=md-nav__link> <span class=md-ellipsis> 2. 核心结论 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> 四、公式与最优策略的关联 </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <div><h1 id=3->第3课-贝尔曼最优公式（最优策略和公式推导）知识点整理<a class=headerlink href=#3- title="Permanent link">¶</a></h1> <div style="margin-top: -30px; font-size: 0.75em; opacity: 0.7;"> <p><span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8zm6.78 1a.7.7 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38z"></path></svg></span> 约 3125 个字 <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3z"></path></svg></span> 预计阅读时间 16 分钟</p> </div> <h2 id=_1>一、最优策略的定义与核心问题<a class=headerlink href=#_1 title="Permanent link">¶</a></h2> <h3 id=1>1. 策略优劣的比较标准<a class=headerlink href=#1 title="Permanent link">¶</a></h3> <ul> <li>若存在两个策略<span class=arithmatex><span class=MathJax_Preview>\pi_1</span><script type=math/tex>\pi_1</script></span>和<span class=arithmatex><span class=MathJax_Preview>\pi_2</span><script type=math/tex>\pi_2</script></span>，对于<strong>所有状态<span class=arithmatex><span class=MathJax_Preview>s</span><script type=math/tex>s</script></span></strong>，<span class=arithmatex><span class=MathJax_Preview>\pi_1</span><script type=math/tex>\pi_1</script></span>对应的状态价值<span class=arithmatex><span class=MathJax_Preview>v_{\pi_1}(s)</span><script type=math/tex>v_{\pi_1}(s)</script></span>均大于<span class=arithmatex><span class=MathJax_Preview>\pi_2</span><script type=math/tex>\pi_2</script></span>对应的状态价值<span class=arithmatex><span class=MathJax_Preview>v_{\pi_2}(s)</span><script type=math/tex>v_{\pi_2}(s)</script></span>，则称<span class=arithmatex><span class=MathJax_Preview>\pi_1</span><script type=math/tex>\pi_1</script></span>优于<span class=arithmatex><span class=MathJax_Preview>\pi_2</span><script type=math/tex>\pi_2</script></span>。</li> <li>最优策略<span class=arithmatex><span class=MathJax_Preview>\pi^*</span><script type=math/tex>\pi^*</script></span>的定义：对<strong>任意状态<span class=arithmatex><span class=MathJax_Preview>s</span><script type=math/tex>s</script></span></strong> 和<strong>任意其他策略<span class=arithmatex><span class=MathJax_Preview>\pi</span><script type=math/tex>\pi</script></span></strong>，均满足<span class=arithmatex><span class=MathJax_Preview>v_{\pi^*}(s) \geq v_{\pi}(s)</span><script type=math/tex>v_{\pi^*}(s) \geq v_{\pi}(s)</script></span>，即<span class=arithmatex><span class=MathJax_Preview>\pi^*</span><script type=math/tex>\pi^*</script></span>在所有状态下的价值都不低于其他任何策略。</li> </ul> <h3 id=2>2. 最优策略的四大核心问题<a class=headerlink href=#2 title="Permanent link">¶</a></h3> <ol> <li><strong>存在性</strong>：是否存在满足上述定义的最优策略<span class=arithmatex><span class=MathJax_Preview>\pi^*</span><script type=math/tex>\pi^*</script></span>？（理想中“全状态优于其他策略”的策略是否真实存在？）</li> <li><strong>唯一性</strong>：最优策略是唯一的，还是存在多个不同但均满足“最优”条件的策略？</li> <li><strong>策略类型</strong>：最优策略是确定性策略（某状态下固定选择一个动作），还是随机性策略（某状态下按概率选择多个动作）？</li> <li><strong>求解方法</strong>：如何通过数学工具推导并得到最优策略<span class=arithmatex><span class=MathJax_Preview>\pi^*</span><script type=math/tex>\pi^*</script></span>？（核心问题，需通过贝尔曼最优公式解答）</li> </ol> <h2 id=_2>二、贝尔曼最优公式<a class=headerlink href=#_2 title="Permanent link">¶</a></h2> <h3 id=1_1>1. 公式形式与核心改动<a class=headerlink href=#1_1 title="Permanent link">¶</a></h3> <p>贝尔曼最优公式是在<strong>普通贝尔曼公式</strong>（依赖给定策略<span class=arithmatex><span class=MathJax_Preview>\pi</span><script type=math/tex>\pi</script></span>）的基础上，增加了“策略最大化”操作，具体形式如下：</p> <table> <thead> <tr> <th>公式类型</th> <th>表达式核心逻辑</th> <th>关键区别</th> </tr> </thead> <tbody> <tr> <td>普通贝尔曼公式</td> <td><span class=arithmatex><span class=MathJax_Preview>v_{\pi}(s) = \mathbb{E}_{\pi}\left[ r + \gamma v_{\pi}(s') \mid s \right]</span><script type=math/tex>v_{\pi}(s) = \mathbb{E}_{\pi}\left[ r + \gamma v_{\pi}(s') \mid s \right]</script></span></td> <td>策略<span class=arithmatex><span class=MathJax_Preview>\pi</span><script type=math/tex>\pi</script></span>是<strong>给定的</strong>，仅需计算该策略下的状态价值<span class=arithmatex><span class=MathJax_Preview>v_{\pi}(s)</span><script type=math/tex>v_{\pi}(s)</script></span></td> </tr> <tr> <td>贝尔曼最优公式</td> <td><span class=arithmatex><span class=MathJax_Preview>v_*(s) = \max_{\pi} \mathbb{E}_{\pi}\left[ r + \gamma v_*(s') \mid s \right]</span><script type=math/tex>v_*(s) = \max_{\pi} \mathbb{E}_{\pi}\left[ r + \gamma v_*(s') \mid s \right]</script></span></td> <td>策略<span class=arithmatex><span class=MathJax_Preview>\pi</span><script type=math/tex>\pi</script></span>是<strong>待优化的</strong>，需先找到使价值最大的<span class=arithmatex><span class=MathJax_Preview>\pi</span><script type=math/tex>\pi</script></span>，再计算最优状态价值<span class=arithmatex><span class=MathJax_Preview>v_*(s)</span><script type=math/tex>v_*(s)</script></span></td> </tr> </tbody> </table> <ul> <li>符号说明：<span class=arithmatex><span class=MathJax_Preview>v_*(s)</span><script type=math/tex>v_*(s)</script></span>表示“最优状态价值”，即最优策略<span class=arithmatex><span class=MathJax_Preview>\pi^*</span><script type=math/tex>\pi^*</script></span>对应的状态价值；<span class=arithmatex><span class=MathJax_Preview>\max_{\pi}</span><script type=math/tex>\max_{\pi}</script></span>表示对所有可能的策略取最大值。</li> <li>简化表达：公式中期望项可缩写为动作价值<span class=arithmatex><span class=MathJax_Preview>q(s,a)</span><script type=math/tex>q(s,a)</script></span>（即状态<span class=arithmatex><span class=MathJax_Preview>s</span><script type=math/tex>s</script></span>下选择动作<span class=arithmatex><span class=MathJax_Preview>a</span><script type=math/tex>a</script></span>的价值），因此最优公式可进一步简化为<span class=arithmatex><span class=MathJax_Preview>v_*(s) = \max_a q(s,a)</span><script type=math/tex>v_*(s) = \max_a q(s,a)</script></span>。</li> </ul> <h3 id=2_1>2. 已知条件与求解目标<a class=headerlink href=#2_1 title="Permanent link">¶</a></h3> <table> <thead> <tr> <th>类别</th> <th>具体内容</th> </tr> </thead> <tbody> <tr> <td>已知条件</td> <td>1. 状态转移概率<span class=arithmatex><span class=MathJax_Preview>p(s' \mid s,a)</span><script type=math/tex>p(s' \mid s,a)</script></span>（系统模型参数，描述“状态<span class=arithmatex><span class=MathJax_Preview>s</span><script type=math/tex>s</script></span>选动作<span class=arithmatex><span class=MathJax_Preview>a</span><script type=math/tex>a</script></span>后转移到<span class=arithmatex><span class=MathJax_Preview>s'</span><script type=math/tex>s'</script></span>”的概率）<br>2. 即时奖励<span class=arithmatex><span class=MathJax_Preview>r</span><script type=math/tex>r</script></span>（环境反馈，如“选动作<span class=arithmatex><span class=MathJax_Preview>a</span><script type=math/tex>a</script></span>后获得的收益/惩罚”）<br>3. 折扣因子<span class=arithmatex><span class=MathJax_Preview>\gamma</span><script type=math/tex>\gamma</script></span>（控制未来奖励的权重，<span class=arithmatex><span class=MathJax_Preview>0 \leq \gamma \leq 1</span><script type=math/tex>0 \leq \gamma \leq 1</script></span>）</td> </tr> <tr> <td>求解目标</td> <td>1. 最优状态价值<span class=arithmatex><span class=MathJax_Preview>v_*(s)</span><script type=math/tex>v_*(s)</script></span>（所有状态下的最优价值向量）<br>2. 最优策略<span class=arithmatex><span class=MathJax_Preview>\pi^*</span><script type=math/tex>\pi^*</script></span>（使<span class=arithmatex><span class=MathJax_Preview>v(s)</span><script type=math/tex>v(s)</script></span>达到<span class=arithmatex><span class=MathJax_Preview>v_*(s)</span><script type=math/tex>v_*(s)</script></span>的策略）</td> </tr> </tbody> </table> <h3 id=3>3. 公式的“优美性”与“复杂性”<a class=headerlink href=#3 title="Permanent link">¶</a></h3> <ul> <li><strong>优美性</strong>：形式简洁，仅通过“<span class=arithmatex><span class=MathJax_Preview>\max_{\pi}</span><script type=math/tex>\max_{\pi}</script></span>”操作，就将“最优策略”与“最优状态价值”的关系刻画清楚，统一了“策略优化”与“价值计算”两个问题。</li> <li><strong>复杂性</strong>：<br> 1. 嵌套优化：公式右侧包含“对策略<span class=arithmatex><span class=MathJax_Preview>\pi</span><script type=math/tex>\pi</script></span>求最大值”的优化问题，需先解决优化问题才能计算<span class=arithmatex><span class=MathJax_Preview>v_*(s)</span><script type=math/tex>v_*(s)</script></span>；<br> 2. 双未知量：表面上需同时求解<span class=arithmatex><span class=MathJax_Preview>v_*(s)</span><script type=math/tex>v_*(s)</script></span>（价值向量）和<span class=arithmatex><span class=MathJax_Preview>\pi^*</span><script type=math/tex>\pi^*</script></span>（策略），初学者易困惑“如何用一个公式解两个未知量”。</li> </ul> <h2 id=_3>三、贝尔曼最优公式的求解思路（核心推导）<a class=headerlink href=#_3 title="Permanent link">¶</a></h2> <h3 id=1_2>1. 求解逻辑：分两步拆解“双未知量”问题<a class=headerlink href=#1_2 title="Permanent link">¶</a></h3> <p>贝尔曼最优公式的求解核心是<strong>先固定价值求策略，再代入策略求价值</strong>，通过“分步拆解”解决“双未知量”困境，具体以两个例子说明：</p> <p>目标:</p> <p><span class=arithmatex><span class=MathJax_Preview>v(s) = \max_\pi \sum_a \pi(a|s)(\sum_r (p|s,a)r+\gamma \sum_{s'}p(s'|s,a)v(s')),\forall s \in \mathcal{S} \\ = \max_\pi \sum_a \pi(a|s)q(s,a)</span><script type=math/tex>v(s) = \max_\pi \sum_a \pi(a|s)(\sum_r (p|s,a)r+\gamma \sum_{s'}p(s'|s,a)v(s')),\forall s \in \mathcal{S} \\ = \max_\pi \sum_a \pi(a|s)q(s,a)</script></span></p> <h4 id=1how-to-solve-2-unknowns-from-1-equation>例1：How to solve 2 unknowns from 1 equation<a class=headerlink href=#1how-to-solve-2-unknowns-from-1-equation title="Permanent link">¶</a></h4> <p>假设存在公式<span class=arithmatex><span class=MathJax_Preview>x = \max_a (2x - 1 - a^2)</span><script type=math/tex>x = \max_a (2x - 1 - a^2)</script></span>，需求解<span class=arithmatex><span class=MathJax_Preview>x</span><script type=math/tex>x</script></span>（对应<span class=arithmatex><span class=MathJax_Preview>v_*(s)</span><script type=math/tex>v_*(s)</script></span>）和<span class=arithmatex><span class=MathJax_Preview>a</span><script type=math/tex>a</script></span>（对应策略<span class=arithmatex><span class=MathJax_Preview>\pi^*</span><script type=math/tex>\pi^*</script></span>的动作选择）：<br> 1. <strong>第一步：固定<span class=arithmatex><span class=MathJax_Preview>x</span><script type=math/tex>x</script></span>，求最优<span class=arithmatex><span class=MathJax_Preview>a</span><script type=math/tex>a</script></span></strong>：<br> 对<span class=arithmatex><span class=MathJax_Preview>a</span><script type=math/tex>a</script></span>求最大值，因<span class=arithmatex><span class=MathJax_Preview>-a^2</span><script type=math/tex>-a^2</script></span>的最大值在<span class=arithmatex><span class=MathJax_Preview>a=0</span><script type=math/tex>a=0</script></span>时取得（此时<span class=arithmatex><span class=MathJax_Preview>-a^2=0</span><script type=math/tex>-a^2=0</script></span>），因此<span class=arithmatex><span class=MathJax_Preview>\max_a (2x - 1 - a^2) = 2x - 1</span><script type=math/tex>\max_a (2x - 1 - a^2) = 2x - 1</script></span>，最优<span class=arithmatex><span class=MathJax_Preview>a=0</span><script type=math/tex>a=0</script></span>。<br> 2. <strong>第二步：代入<span class=arithmatex><span class=MathJax_Preview>a=0</span><script type=math/tex>a=0</script></span>，求<span class=arithmatex><span class=MathJax_Preview>x</span><script type=math/tex>x</script></span></strong>：<br> 公式变为<span class=arithmatex><span class=MathJax_Preview>x = 2x - 1</span><script type=math/tex>x = 2x - 1</script></span>，解得<span class=arithmatex><span class=MathJax_Preview>x=1</span><script type=math/tex>x=1</script></span>。<br> 最终结果：<span class=arithmatex><span class=MathJax_Preview>x=1</span><script type=math/tex>x=1</script></span>（最优价值），<span class=arithmatex><span class=MathJax_Preview>a=0</span><script type=math/tex>a=0</script></span>（最优动作）。</p> <h4 id=2-how-to-solve-max_pi-sum_a-piasqsamax_pi-sum_a-piasqsa>例2 How to solve <span class=arithmatex><span class=MathJax_Preview>\max_{\pi} \sum_{a} \pi(a|s)q(s,a)</span><script type=math/tex>\max_{\pi} \sum_{a} \pi(a|s)q(s,a)</script></span><a class=headerlink href=#2-how-to-solve-max_pi-sum_a-piasqsamax_pi-sum_a-piasqsa title="Permanent link">¶</a></h4> <p>Suppose <span class=arithmatex><span class=MathJax_Preview>q_1, q_2, q_3 \in \mathbb{R}</span><script type=math/tex>q_1, q_2, q_3 \in \mathbb{R}</script></span> are given. Find <span class=arithmatex><span class=MathJax_Preview>c_1^*, c_2^*, c_3^*</span><script type=math/tex>c_1^*, c_2^*, c_3^*</script></span> solving<br> $$<br> \max_{c_1,c_2,c_3} c_1q_1 + c_2q_2 + c_3q_3.<br> $$<br> where <span class=arithmatex><span class=MathJax_Preview>c_1 + c_2 + c_3 = 1</span><script type=math/tex>c_1 + c_2 + c_3 = 1</script></span> and <span class=arithmatex><span class=MathJax_Preview>c_1, c_2, c_3 \geq 0</span><script type=math/tex>c_1, c_2, c_3 \geq 0</script></span>.</p> <p>Without loss of generality, suppose <span class=arithmatex><span class=MathJax_Preview>q_3 \geq q_1, q_2</span><script type=math/tex>q_3 \geq q_1, q_2</script></span>. Then, the optimal solution is <span class=arithmatex><span class=MathJax_Preview>c_3^* = 1</span><script type=math/tex>c_3^* = 1</script></span> and <span class=arithmatex><span class=MathJax_Preview>c_1^* = c_2^* = 0</span><script type=math/tex>c_1^* = c_2^* = 0</script></span>. That is because for any <span class=arithmatex><span class=MathJax_Preview>c_1, c_2, c_3</span><script type=math/tex>c_1, c_2, c_3</script></span><br> $$<br> q_3 = (c_1 + c_2 + c_3)q_3 = c_1q_3 + c_2q_3 + c_3q_3 \geq c_1q_1 + c_2q_2 + c_3q_3.<br> $$</p> <h4 id=_4>强化学习场景（映射到贝尔曼最优公式）<a class=headerlink href=#_4 title="Permanent link">¶</a></h4> <p>假设某状态<span class=arithmatex><span class=MathJax_Preview>s</span><script type=math/tex>s</script></span>下有5个可能动作<span class=arithmatex><span class=MathJax_Preview>a_1 \sim a_5</span><script type=math/tex>a_1 \sim a_5</script></span>，对应动作价值<span class=arithmatex><span class=MathJax_Preview>q(s,a_1) \sim q(s,a_5)</span><script type=math/tex>q(s,a_1) \sim q(s,a_5)</script></span>，需求解<span class=arithmatex><span class=MathJax_Preview>\pi^*(s,a)</span><script type=math/tex>\pi^*(s,a)</script></span>（策略）和<span class=arithmatex><span class=MathJax_Preview>v_*(s)</span><script type=math/tex>v_*(s)</script></span>（最优价值）：<br> 1. <strong>第一步：固定<span class=arithmatex><span class=MathJax_Preview>v_*(s')</span><script type=math/tex>v_*(s')</script></span>，求最优<span class=arithmatex><span class=MathJax_Preview>\pi</span><script type=math/tex>\pi</script></span></strong>：<br> 动作价值<span class=arithmatex><span class=MathJax_Preview>q(s,a) = r + \gamma \sum_{s'} p(s' \mid s,a) v_*(s')</span><script type=math/tex>q(s,a) = r + \gamma \sum_{s'} p(s' \mid s,a) v_*(s')</script></span>，若暂时固定<span class=arithmatex><span class=MathJax_Preview>v_*(s')</span><script type=math/tex>v_*(s')</script></span>（可先设初始值），则<span class=arithmatex><span class=MathJax_Preview>q(s,a)</span><script type=math/tex>q(s,a)</script></span>可计算。<br> 最优策略需满足：对“使<span class=arithmatex><span class=MathJax_Preview>q(s,a)</span><script type=math/tex>q(s,a)</script></span>最大的动作<span class=arithmatex><span class=MathJax_Preview>a^*</span><script type=math/tex>a^*</script></span>”，取<span class=arithmatex><span class=MathJax_Preview>\pi^*(s,a^*) = 1</span><script type=math/tex>\pi^*(s,a^*) = 1</script></span>（确定性选择该动作）；对其他动作<span class=arithmatex><span class=MathJax_Preview>a \neq a^*</span><script type=math/tex>a \neq a^*</script></span>，取<span class=arithmatex><span class=MathJax_Preview>\pi^*(s,a) = 0</span><script type=math/tex>\pi^*(s,a) = 0</script></span>。<br> 此时<span class=arithmatex><span class=MathJax_Preview>\max_{\pi} \mathbb{E}_{\pi}[q(s,a)] = \max_a q(s,a)</span><script type=math/tex>\max_{\pi} \mathbb{E}_{\pi}[q(s,a)] = \max_a q(s,a)</script></span>（即最优动作对应的动作价值）。<br> 2. <strong>第二步：代入最优<span class=arithmatex><span class=MathJax_Preview>\pi</span><script type=math/tex>\pi</script></span>，求<span class=arithmatex><span class=MathJax_Preview>v_*(s)</span><script type=math/tex>v_*(s)</script></span></strong>：<br> 最优状态价值<span class=arithmatex><span class=MathJax_Preview>v_*(s) = \max_a q(s,a)</span><script type=math/tex>v_*(s) = \max_a q(s,a)</script></span>，即“最优动作的动作价值”就是该状态的最优状态价值。</p> <p>Inspired by the above example, considering that <span class=arithmatex><span class=MathJax_Preview>\sum_a \pi(a|s) = 1</span><script type=math/tex>\sum_a \pi(a|s) = 1</script></span>, </p> <p>we have <span class=arithmatex><span class=MathJax_Preview>\underbrace{\max_{\pi} \sum_a \pi(a|s) q(s, a)} = \underbrace{\max_{a \in \mathcal{A}(s)} q(s, a)},</span><script type=math/tex>\underbrace{\max_{\pi} \sum_a \pi(a|s) q(s, a)} = \underbrace{\max_{a \in \mathcal{A}(s)} q(s, a)},</script></span> </p> <p>where the optimality is achieved when <span class=arithmatex><span class=MathJax_Preview>\pi(a|s) = \begin{cases} 1 &amp; a = a^* \\ 0 &amp; a \neq a^* \end{cases}</span><script type=math/tex>\pi(a|s) = \begin{cases}  1 & a = a^* \\ 0 & a \neq a^*  \end{cases}</script></span></p> <p>where <span class=arithmatex><span class=MathJax_Preview>a^* = \arg \max_a q(s, a)</span><script type=math/tex>a^* = \arg \max_a q(s, a)</script></span>.</p> <h3 id=2_2>2. 核心结论<a class=headerlink href=#2_2 title="Permanent link">¶</a></h3> <ul> <li>贝尔曼最优公式的求解本质是“<strong>贪心策略</strong>”：在每个状态下，选择能使“即时奖励+未来最优价值”最大的动作，该动作对应的策略即为局部最优策略，所有状态的局部最优策略构成全局最优策略<span class=arithmatex><span class=MathJax_Preview>\pi^*</span><script type=math/tex>\pi^*</script></span>。</li> <li>最优策略的类型：通过上述推导可知，最优策略可表示为<strong>确定性策略</strong>（选择<span class=arithmatex><span class=MathJax_Preview>q(s,a)</span><script type=math/tex>q(s,a)</script></span>最大的动作），即使存在多个动作的<span class=arithmatex><span class=MathJax_Preview>q(s,a)</span><script type=math/tex>q(s,a)</script></span>相等，也可通过“确定性选择其中任意一个”实现最优，无需随机性策略。</li> </ul> <h2 id=_5>四、公式与最优策略的关联<a class=headerlink href=#_5 title="Permanent link">¶</a></h2> <p>贝尔曼最优公式是连接“最优价值”与“最优策略”的桥梁：<br> 1. 若已知最优状态价值<span class=arithmatex><span class=MathJax_Preview>v_*(s)</span><script type=math/tex>v_*(s)</script></span>，可通过<span class=arithmatex><span class=MathJax_Preview>q(s,a) = r + \gamma \sum_{s'} p(s' \mid s,a) v_*(s')</span><script type=math/tex>q(s,a) = r + \gamma \sum_{s'} p(s' \mid s,a) v_*(s')</script></span>计算所有动作价值，再选择<span class=arithmatex><span class=MathJax_Preview>q(s,a)</span><script type=math/tex>q(s,a)</script></span>最大的动作，得到最优策略<span class=arithmatex><span class=MathJax_Preview>\pi^*</span><script type=math/tex>\pi^*</script></span>；<br> 2. 若已知最优策略<span class=arithmatex><span class=MathJax_Preview>\pi^*</span><script type=math/tex>\pi^*</script></span>，可通过普通贝尔曼公式<span class=arithmatex><span class=MathJax_Preview>v_*(s) = \mathbb{E}_{\pi^*}\left[ r + \gamma v_*(s') \mid s \right]</span><script type=math/tex>v_*(s) = \mathbb{E}_{\pi^*}\left[ r + \gamma v_*(s') \mid s \right]</script></span>计算最优状态价值<span class=arithmatex><span class=MathJax_Preview>v_*(s)</span><script type=math/tex>v_*(s)</script></span>。</p> <h1 id=3-_1>第3课-贝尔曼最优公式（公式求解以及最优性）知识点整理<a class=headerlink href=#3-_1 title="Permanent link">¶</a></h1> <h2 id=_6>一、贝尔曼最优公式的简化形式<a class=headerlink href=#_6 title="Permanent link">¶</a></h2> <ol> <li> <p><strong>核心转化逻辑</strong>：将贝尔曼最优公式中右侧的<span class=arithmatex><span class=MathJax_Preview>maxπ</span><script type=math/tex>maxπ</script></span>（对策略的最大化）定义为函数<span class=arithmatex><span class=MathJax_Preview>f(v)</span><script type=math/tex>f(v)</script></span>，其中<span class=arithmatex><span class=MathJax_Preview>v</span><script type=math/tex>v</script></span>为状态值函数（State Value）。<br> - 关键前提：固定<span class=arithmatex><span class=MathJax_Preview>v</span><script type=math/tex>v</script></span>后，可求解出对应策略<span class=arithmatex><span class=MathJax_Preview>π</span><script type=math/tex>π</script></span>，最终最优值仅与<span class=arithmatex><span class=MathJax_Preview>v</span><script type=math/tex>v</script></span>相关，因此<span class=arithmatex><span class=MathJax_Preview>maxπ</span><script type=math/tex>maxπ</script></span>的结果可表示为<span class=arithmatex><span class=MathJax_Preview>v</span><script type=math/tex>v</script></span>的函数<span class=arithmatex><span class=MathJax_Preview>f(v)</span><script type=math/tex>f(v)</script></span>。<br> - 简化后公式：<span class=arithmatex><span class=MathJax_Preview>v = f(v)</span><script type=math/tex>v = f(v)</script></span>（<span class=arithmatex><span class=MathJax_Preview>f(v)</span><script type=math/tex>f(v)</script></span>为向量，向量中对应状态<span class=arithmatex><span class=MathJax_Preview>s</span><script type=math/tex>s</script></span>的元素即该状态下的最优值计算项）。</p> </li> <li> <p><strong><span class=arithmatex><span class=MathJax_Preview>f(v)</span><script type=math/tex>f(v)</script></span>的向量属性</strong>：<span class=arithmatex><span class=MathJax_Preview>f(v)</span><script type=math/tex>f(v)</script></span>的每个元素对应一个状态<span class=arithmatex><span class=MathJax_Preview>s</span><script type=math/tex>s</script></span>，描述该状态在最优策略下的价值，需结合状态转移概率、奖励等强化学习核心要素计算（承接前序课程中贝尔曼公式的基础定义）。</p> </li> </ol> <h2 id=contraction-mapping-theorem>二、核心数学工具：收缩映射定理（Contraction Mapping Theorem）<a class=headerlink href=#contraction-mapping-theorem title="Permanent link">¶</a></h2> <h3 id=_7>（一）前置基础概念<a class=headerlink href=#_7 title="Permanent link">¶</a></h3> <ol> <li> <p><strong>不动点（Fixed Point）</strong><br> - 定义：若在集合<span class=arithmatex><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>上存在点<span class=arithmatex><span class=MathJax_Preview>x</span><script type=math/tex>x</script></span>，映射（函数）<span class=arithmatex><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span>满足<span class=arithmatex><span class=MathJax_Preview>f(x) = x</span><script type=math/tex>f(x) = x</script></span>，则<span class=arithmatex><span class=MathJax_Preview>x</span><script type=math/tex>x</script></span>称为<span class=arithmatex><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span>的不动点。<br> - 直观解释：点<span class=arithmatex><span class=MathJax_Preview>x</span><script type=math/tex>x</script></span>经过函数<span class=arithmatex><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span>映射后仍回到自身，“位置不变”。</p> </li> <li> <p><strong>收缩映射（Contraction Mapping / Contractive Function）</strong><br> - 定义：对任意两个点<span class=arithmatex><span class=MathJax_Preview>x₁</span><script type=math/tex>x₁</script></span>、<span class=arithmatex><span class=MathJax_Preview>x₂</span><script type=math/tex>x₂</script></span>，若存在常数<span class=arithmatex><span class=MathJax_Preview>γ &lt; 1</span><script type=math/tex>γ < 1</script></span>（收缩因子），使得<span class=arithmatex><span class=MathJax_Preview>||f(x₁) - f(x₂)|| ≤ γ·||x₁ - x₂||</span><script type=math/tex>||f(x₁) - f(x₂)|| ≤ γ·||x₁ - x₂||</script></span>（<span class=arithmatex><span class=MathJax_Preview>||·||</span><script type=math/tex>||·||</script></span>表示范数，衡量“距离”），则<span class=arithmatex><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span>为收缩映射。<br> - 直观解释：任意两点经过<span class=arithmatex><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span>映射后，它们的“距离”会被缩小（收缩因子<span class=arithmatex><span class=MathJax_Preview>γ</span><script type=math/tex>γ</script></span>控制缩小比例），因此函数具有“压缩”特性。</p> </li> <li> <p><strong>示例验证</strong><br> | 案例 | 不动点验证 | 收缩映射验证 |<br> | -------------------------------- | ----------------------------------- | ------------------------------------------------------------ |<br> | 标量函数<span class=arithmatex><span class=MathJax_Preview>f(x) = 0.5x</span><script type=math/tex>f(x) = 0.5x</script></span> | <span class=arithmatex><span class=MathJax_Preview>f(0) = 0.5×0 = 0</span><script type=math/tex>f(0) = 0.5×0 = 0</script></span>，故<span class=arithmatex><span class=MathJax_Preview>x=0</span><script type=math/tex>x=0</script></span>是不动点 | 对任意<span class=arithmatex><span class=MathJax_Preview>x_1、x_2</span><script type=math/tex>x_1、x_2</script></span>，<span class=arithmatex><span class=MathJax_Preview>||0.5x_1 - 0.5x_2|| = 0.5×||x_1 - x_2||</span><script type=math/tex>||0.5x_1 - 0.5x_2|| = 0.5×||x_1 - x_2||</script></span>，取<span class=arithmatex><span class=MathJax_Preview>γ=0.5 &lt; 1</span><script type=math/tex>γ=0.5 < 1</script></span>，满足定义 |<br> | 向量函数<span class=arithmatex><span class=MathJax_Preview>f(x) = Ax</span><script type=math/tex>f(x) = Ax</script></span>（<span class=arithmatex><span class=MathJax_Preview>A</span><script type=math/tex>A</script></span>为矩阵） | <span class=arithmatex><span class=MathJax_Preview>f(0) = A×0 = 0</span><script type=math/tex>f(0) = A×0 = 0</script></span>，故<span class=arithmatex><span class=MathJax_Preview>x=0</span><script type=math/tex>x=0</script></span>是不动点 | 若矩阵<span class=arithmatex><span class=MathJax_Preview>A</span><script type=math/tex>A</script></span>的范数<span class=arithmatex><span class=MathJax_Preview>||A|| &lt; 1</span><script type=math/tex>||A|| < 1</script></span>，则<span class=arithmatex><span class=MathJax_Preview>||Ax_1 - Ax_2|| ≤ ||A||·||x_1 - x_2||</span><script type=math/tex>||Ax_1 - Ax_2|| ≤ ||A||·||x_1 - x_2||</script></span>，满足定义 |</p> </li> </ol> <h3 id=_8>（二）收缩映射定理的核心结论<a class=headerlink href=#_8 title="Permanent link">¶</a></h3> <p>若<span class=arithmatex><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span>是收缩映射，则方程<span class=arithmatex><span class=MathJax_Preview>x = f(x)</span><script type=math/tex>x = f(x)</script></span>满足以下3个关键性质（为贝尔曼最优公式求解提供理论保障）：<br> 1. <strong>存在性（Existence）</strong>：必然存在至少一个不动点<span class=arithmatex><span class=MathJax_Preview>x_*</span><script type=math/tex>x_*</script></span>，使得<span class=arithmatex><span class=MathJax_Preview>f(x_*) = x_*</span><script type=math/tex>f(x_*) = x_*</script></span>（无需关注<span class=arithmatex><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span>的具体表达式，仅需确认其为收缩映射）。<br> 2. <strong>唯一性（Uniqueness）</strong>：上述不动点<span class=arithmatex><span class=MathJax_Preview>x_*</span><script type=math/tex>x_*</script></span>是唯一的（排除“多解”问题，确保最优值的确定性）。<br> 3. <strong>可解性（Solvability）</strong>：可通过迭代算法求解<span class=arithmatex><span class=MathJax_Preview>x_*</span><script type=math/tex>x_*</script></span>，迭代公式为<span class=arithmatex><span class=MathJax_Preview>x_{k+1} = f(x_k)</span><script type=math/tex>x_{k+1} = f(x_k)</script></span>（<span class=arithmatex><span class=MathJax_Preview>x_0</span><script type=math/tex>x_0</script></span>为初始值）：<br> - 收敛性：当迭代次数<span class=arithmatex><span class=MathJax_Preview>k→∞</span><script type=math/tex>k→∞</script></span>时，<span class=arithmatex><span class=MathJax_Preview>x_k</span><script type=math/tex>x_k</script></span>会收敛到不动点<span class=arithmatex><span class=MathJax_Preview>x_*</span><script type=math/tex>x_*</script></span>；<br> - 实用性：实际计算中无需迭代至无穷次，迭代若干步后即可得到满足精度的近似解；<br> - 收敛速度：指数级收敛（收敛速度快，计算效率高）。</p> <div class="admonition info"> <p class=admonition-title># 压缩映射定理的证明</p> <h3 id=1-x_k_k1inftyx_k_k1infty-x_k-fx_k-1x_k-fx_k-1>部分1：证明序列 <span class=arithmatex><span class=MathJax_Preview>\{x_k\}_{k=1}^\infty</span><script type=math/tex>\{x_k\}_{k=1}^\infty</script></span>（其中 <span class=arithmatex><span class=MathJax_Preview>x_k = f(x_{k-1})</span><script type=math/tex>x_k = f(x_{k-1})</script></span>）收敛<a class=headerlink href=#1-x_k_k1inftyx_k_k1infty-x_k-fx_k-1x_k-fx_k-1 title="Permanent link">¶</a></h3> <p>证明依赖<strong>柯西序列</strong>的概念：若序列 <span class=arithmatex><span class=MathJax_Preview>x_1, x_2, \dots</span><script type=math/tex>x_1, x_2, \dots</script></span> 满足“对任意小的 <span class=arithmatex><span class=MathJax_Preview>\varepsilon &gt; 0</span><script type=math/tex>\varepsilon > 0</script></span>，存在整数 <span class=arithmatex><span class=MathJax_Preview>N</span><script type=math/tex>N</script></span>，使得对所有 <span class=arithmatex><span class=MathJax_Preview>m, n &gt; N</span><script type=math/tex>m, n > N</script></span>，有 <span class=arithmatex><span class=MathJax_Preview>\|x_m - x_n\| &lt; \varepsilon</span><script type=math/tex>\|x_m - x_n\| < \varepsilon</script></span>”，则称该序列为柯西序列。其直观含义是“<span class=arithmatex><span class=MathJax_Preview>N</span><script type=math/tex>N</script></span> 之后的所有元素都足够接近”。柯西序列的核心性质是：<strong>柯西序列必收敛到一个极限</strong>，这一性质是证明的关键。</p> <p>注意：仅满足“相邻项差趋于0（<span class=arithmatex><span class=MathJax_Preview>x_{n+1} - x_n \to 0</span><script type=math/tex>x_{n+1} - x_n \to 0</script></span>）”不足以说明是柯西序列（例如 <span class=arithmatex><span class=MathJax_Preview>x_n = \sqrt{n}</span><script type=math/tex>x_n = \sqrt{n}</script></span>，虽 <span class=arithmatex><span class=MathJax_Preview>x_{n+1} - x_n \to 0</span><script type=math/tex>x_{n+1} - x_n \to 0</script></span>，但 <span class=arithmatex><span class=MathJax_Preview>x_n = \sqrt{n}</span><script type=math/tex>x_n = \sqrt{n}</script></span> 发散）。</p> <p>接下来证明 <span class=arithmatex><span class=MathJax_Preview>\{x_k = f(x_{k-1})\}_{k=1}^\infty</span><script type=math/tex>\{x_k = f(x_{k-1})\}_{k=1}^\infty</script></span> 是柯西序列（从而收敛）：</p> <ol> <li> <p><strong>压缩映射的递推估计</strong>：<br> 因 <span class=arithmatex><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span> 是压缩映射（存在常数 <span class=arithmatex><span class=MathJax_Preview>\gamma</span><script type=math/tex>\gamma</script></span>，<span class=arithmatex><span class=MathJax_Preview>0 \leq \gamma &lt; 1</span><script type=math/tex>0 \leq \gamma < 1</script></span>，使得对任意 <span class=arithmatex><span class=MathJax_Preview>x, y</span><script type=math/tex>x, y</script></span>，有 <span class=arithmatex><span class=MathJax_Preview>\|f(x) - f(y)\| \leq \gamma \|x - y\|</span><script type=math/tex>\|f(x) - f(y)\| \leq \gamma \|x - y\|</script></span>），故：<br> $$<br> |x_{k+1} - x_k| = |f(x_k) - f(x_{k-1})| \leq \gamma |x_k - x_{k-1}|<br> $$<br> 递推可得：<br> $$<br> |x_k - x_{k-1}| \leq \gamma |x_{k-1} - x_{k-2}|, \quad \dots, \quad |x_2 - x_1| \leq \gamma |x_1 - x_0|<br> $$<br> 因此，通过迭代放缩：<br> $$<br> |x_{k+1} - x_k| \leq \gamma^k |x_1 - x_0|<br> $$<br> 由于 <span class=arithmatex><span class=MathJax_Preview>\gamma &lt; 1</span><script type=math/tex>\gamma < 1</script></span>，<span class=arithmatex><span class=MathJax_Preview>\|x_{k+1} - x_k\|</span><script type=math/tex>\|x_{k+1} - x_k\|</script></span> 随 <span class=arithmatex><span class=MathJax_Preview>k \to \infty</span><script type=math/tex>k \to \infty</script></span> 指数级收敛到0，但这<strong>不足以直接推出 <span class=arithmatex><span class=MathJax_Preview>\{x_k\}</span><script type=math/tex>\{x_k\}</script></span> 收敛</strong>，需进一步分析任意两项的差。</p> </li> <li> <p><strong>任意两项差的估计（柯西序列判定）</strong>：<br> 对任意 <span class=arithmatex><span class=MathJax_Preview>m &gt; n</span><script type=math/tex>m > n</script></span>，将 <span class=arithmatex><span class=MathJax_Preview>\|x_m - x_n\|</span><script type=math/tex>\|x_m - x_n\|</script></span> 拆分为相邻项的累加和：<br> $$<br> |x_m - x_n| = |x_m - x_{m-1} + x_{m-1} - \dots - x_{n+1} + x_{n+1} - x_n|<br> $$<br> 由范数的三角不等式，得：<br> $$<br> |x_m - x_n| \leq |x_m - x_{m-1}| + \dots + |x_{n+1} - x_n|<br> $$<br> 代入“<span class=arithmatex><span class=MathJax_Preview>\|x_{k+1} - x_k\| \leq \gamma^k \|x_1 - x_0\|</span><script type=math/tex>\|x_{k+1} - x_k\| \leq \gamma^k \|x_1 - x_0\|</script></span>”的估计，得：<br> $$<br> |x_m - x_n| \leq \gamma^{m-1} |x_1 - x_0| + \dots + \gamma^n |x_1 - x_0|<br> $$<br> 这是公比为 <span class=arithmatex><span class=MathJax_Preview>\gamma</span><script type=math/tex>\gamma</script></span>（<span class=arithmatex><span class=MathJax_Preview>\gamma &lt; 1</span><script type=math/tex>\gamma < 1</script></span>）的等比数列求和，因此：<br> $$<br> |x_m - x_n| \leq \gamma^n \cdot \frac{1 - \gamma^{m-n}}{1 - \gamma} \cdot |x_1 - x_0| \leq \frac{\gamma^n}{1 - \gamma} |x_1 - x_0| \tag{3.4}<br> $$</p> </li> <li> <p><strong>柯西序列的结论</strong>：<br> 对任意 <span class=arithmatex><span class=MathJax_Preview>\varepsilon &gt; 0</span><script type=math/tex>\varepsilon > 0</script></span>，由于 <span class=arithmatex><span class=MathJax_Preview>\gamma^n \to 0</span><script type=math/tex>\gamma^n \to 0</script></span>（当 <span class=arithmatex><span class=MathJax_Preview>n \to \infty</span><script type=math/tex>n \to \infty</script></span>），总能找到 <span class=arithmatex><span class=MathJax_Preview>N</span><script type=math/tex>N</script></span>，使得对所有 <span class=arithmatex><span class=MathJax_Preview>m, n &gt; N</span><script type=math/tex>m, n > N</script></span>，有 <span class=arithmatex><span class=MathJax_Preview>\|x_m - x_n\| &lt; \varepsilon</span><script type=math/tex>\|x_m - x_n\| < \varepsilon</script></span>。因此，<span class=arithmatex><span class=MathJax_Preview>\{x_k\}</span><script type=math/tex>\{x_k\}</script></span> 是柯西序列，故必收敛到极限点 <span class=arithmatex><span class=MathJax_Preview>x^* = \lim_{k \to \infty} x_k</span><script type=math/tex>x^* = \lim_{k \to \infty} x_k</script></span>。</p> </li> </ol> <h3 id=2-x-lim_k-to-infty-x_kx-lim_k-to-infty-x_k>部分2：证明极限 <span class=arithmatex><span class=MathJax_Preview>x^* = \lim_{k \to \infty} x_k</span><script type=math/tex>x^* = \lim_{k \to \infty} x_k</script></span> 是不动点<a class=headerlink href=#2-x-lim_k-to-infty-x_kx-lim_k-to-infty-x_k title="Permanent link">¶</a></h3> <p>由压缩映射的估计，<span class=arithmatex><span class=MathJax_Preview>\|f(x_k) - x_k\| = \|x_{k+1} - x_k\| \leq \gamma^k \|x_1 - x_0\|</span><script type=math/tex>\|f(x_k) - x_k\| = \|x_{k+1} - x_k\| \leq \gamma^k \|x_1 - x_0\|</script></span>。由于 <span class=arithmatex><span class=MathJax_Preview>\gamma &lt; 1</span><script type=math/tex>\gamma < 1</script></span>，<span class=arithmatex><span class=MathJax_Preview>\|f(x_k) - x_k\|</span><script type=math/tex>\|f(x_k) - x_k\|</script></span> 随 <span class=arithmatex><span class=MathJax_Preview>k \to \infty</span><script type=math/tex>k \to \infty</script></span> 指数级收敛到0。</p> <p>对 <span class=arithmatex><span class=MathJax_Preview>f(x_k) - x_k</span><script type=math/tex>f(x_k) - x_k</script></span> 取极限（因 <span class=arithmatex><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span> 连续，极限可交换），得：<br> $$<br> \lim_{k \to \infty} |f(x_k) - x_k| = |f(x^<em>) - x^</em>| = 0<br> $$<br> 故 <span class=arithmatex><span class=MathJax_Preview>f(x^*) = x^*</span><script type=math/tex>f(x^*) = x^*</script></span>，即 <span class=arithmatex><span class=MathJax_Preview>x^*</span><script type=math/tex>x^*</script></span> 是不动点。</p> <h3 id=3_1>部分3：证明不动点唯一<a class=headerlink href=#3_1 title="Permanent link">¶</a></h3> <p>假设存在另一个不动点 <span class=arithmatex><span class=MathJax_Preview>x'</span><script type=math/tex>x'</script></span>（满足 <span class=arithmatex><span class=MathJax_Preview>f(x') = x'</span><script type=math/tex>f(x') = x'</script></span>），则由压缩映射的定义：<br> $$<br> |x' - x^<em>| = |f(x') - f(x^</em>)| \leq \gamma |x' - x^*|<br> $$<br> 由于 <span class=arithmatex><span class=MathJax_Preview>\gamma &lt; 1</span><script type=math/tex>\gamma < 1</script></span>，上述不等式成立当且仅当 <span class=arithmatex><span class=MathJax_Preview>\|x' - x^*\| = 0</span><script type=math/tex>\|x' - x^*\| = 0</script></span>，故 <span class=arithmatex><span class=MathJax_Preview>x' = x^*</span><script type=math/tex>x' = x^*</script></span>，即不动点唯一。</p> <h3 id=4-x_kx_k-xx>部分4：证明 <span class=arithmatex><span class=MathJax_Preview>x_k</span><script type=math/tex>x_k</script></span> 指数级收敛到 <span class=arithmatex><span class=MathJax_Preview>x^*</span><script type=math/tex>x^*</script></span><a class=headerlink href=#4-x_kx_k-xx title="Permanent link">¶</a></h3> <p>回顾式 (3.4)：对任意 <span class=arithmatex><span class=MathJax_Preview>m &gt; n</span><script type=math/tex>m > n</script></span>，有 <span class=arithmatex><span class=MathJax_Preview>\|x_m - x_n\| \leq \frac{\gamma^n}{1 - \gamma} \|x_1 - x_0\|</span><script type=math/tex>\|x_m - x_n\| \leq \frac{\gamma^n}{1 - \gamma} \|x_1 - x_0\|</script></span>。令 <span class=arithmatex><span class=MathJax_Preview>m \to \infty</span><script type=math/tex>m \to \infty</script></span>（利用极限的保序性），则：<br> $$<br> |x^* - x_n| = \lim_{m \to \infty} |x_m - x_n| \leq \frac{\gamma^n}{1 - \gamma} |x_1 - x_0|<br> $$<br> 由于 <span class=arithmatex><span class=MathJax_Preview>\gamma &lt; 1</span><script type=math/tex>\gamma < 1</script></span>，当 <span class=arithmatex><span class=MathJax_Preview>n \to \infty</span><script type=math/tex>n \to \infty</script></span> 时，误差 <span class=arithmatex><span class=MathJax_Preview>\|x^* - x_n\|</span><script type=math/tex>\|x^* - x_n\|</script></span> 随 <span class=arithmatex><span class=MathJax_Preview>\gamma^n</span><script type=math/tex>\gamma^n</script></span> 指数级收敛到0。</p> </div> <h2 id=_9>三、贝尔曼最优公式的求解（基于收缩映射定理）<a class=headerlink href=#_9 title="Permanent link">¶</a></h2> <h3 id=fvfv>（一）关键前提：证明<span class=arithmatex><span class=MathJax_Preview>f(v)</span><script type=math/tex>f(v)</script></span>是收缩映射<a class=headerlink href=#fvfv title="Permanent link">¶</a></h3> <p>贝尔曼最优公式中的<span class=arithmatex><span class=MathJax_Preview>f(v)</span><script type=math/tex>f(v)</script></span>满足收缩映射定义，核心依据是<strong>折扣因子<span class=arithmatex><span class=MathJax_Preview>γ &lt; 1</span><script type=math/tex>γ < 1</script></span></strong>（强化学习中<span class=arithmatex><span class=MathJax_Preview>γ</span><script type=math/tex>γ</script></span>用于衡量未来奖励的权重，通常取<span class=arithmatex><span class=MathJax_Preview>0 &lt; γ &lt; 1</span><script type=math/tex>0 < γ < 1</script></span>），由此可推导出<span class=arithmatex><span class=MathJax_Preview>||f(v_1) - f(v_2)|| ≤ γ·||v_1 - v_2||</span><script type=math/tex>||f(v_1) - f(v_2)|| ≤ γ·||v_1 - v_2||</script></span>，故<span class=arithmatex><span class=MathJax_Preview>f(v)</span><script type=math/tex>f(v)</script></span>是收缩映射。</p> <h3 id=3_2>（二）求解结论（对应收缩映射定理的3个性质）<a class=headerlink href=#3_2 title="Permanent link">¶</a></h3> <ol> <li><strong>解的存在性</strong>：贝尔曼最优公式<span class=arithmatex><span class=MathJax_Preview>v = f(v)</span><script type=math/tex>v = f(v)</script></span>必然存在解，记为最优状态值函数<span class=arithmatex><span class=MathJax_Preview>v*</span><script type=math/tex>v*</script></span>。 </li> <li><strong>解的唯一性</strong>：最优状态值函数<span class=arithmatex><span class=MathJax_Preview>v^*</span><script type=math/tex>v^*</script></span>是唯一的（不存在多个“最优值”）。 </li> <li><strong>迭代求解方法</strong>：通过<span class=arithmatex><span class=MathJax_Preview>v_{k+1} = f(v_k)</span><script type=math/tex>v_{k+1} = f(v_k)</script></span>迭代计算，<span class=arithmatex><span class=MathJax_Preview>v_k</span><script type=math/tex>v_k</script></span>最终会收敛到<span class=arithmatex><span class=MathJax_Preview>v^*</span><script type=math/tex>v^*</script></span>（后续课程中的“值迭代算法”即基于此原理）。</li> </ol> <h2 id=_10>四、贝尔曼最优公式解的最优性（与最优策略的关联）<a class=headerlink href=#_10 title="Permanent link">¶</a></h2> <h3 id=_11>（一）最优策略的定义与推导<a class=headerlink href=#_11 title="Permanent link">¶</a></h3> <ol> <li><strong>最优策略<span class=arithmatex><span class=MathJax_Preview>π^*</span><script type=math/tex>π^*</script></span>的定义</strong>：当状态值函数固定为<span class=arithmatex><span class=MathJax_Preview>v^*</span><script type=math/tex>v^*</script></span>时，能使<span class=arithmatex><span class=MathJax_Preview>f(v^*) = v^*</span><script type=math/tex>f(v^*) = v^*</script></span>成立的策略，即对每个状态<span class=arithmatex><span class=MathJax_Preview>s</span><script type=math/tex>s</script></span>，选择能最大化“即时奖励 + 折扣后未来价值”的动作。 </li> <li><strong>公式转化</strong>：将贝尔曼最优公式中的<span class=arithmatex><span class=MathJax_Preview>\max π</span><script type=math/tex>\max π</script></span>替换为<span class=arithmatex><span class=MathJax_Preview>π^*</span><script type=math/tex>π^*</script></span>，得到<span class=arithmatex><span class=MathJax_Preview>v^* = r + γP_{π^*}v^*</span><script type=math/tex>v^* = r + γP_{π^*}v^*</script></span>（<span class=arithmatex><span class=MathJax_Preview>r</span><script type=math/tex>r</script></span>为奖励向量，<span class=arithmatex><span class=MathJax_Preview>P_{π^*}</span><script type=math/tex>P_{π^*}</script></span>为<span class=arithmatex><span class=MathJax_Preview>π^*</span><script type=math/tex>π^*</script></span>对应的状态转移概率矩阵），该式本质是<strong>对应最优策略<span class=arithmatex><span class=MathJax_Preview>π^*</span><script type=math/tex>π^*</script></span>的贝尔曼公式</strong>。<br> - 结论：<span class=arithmatex><span class=MathJax_Preview>v^*</span><script type=math/tex>v^*</script></span>就是最优策略<span class=arithmatex><span class=MathJax_Preview>π^*</span><script type=math/tex>π^*</script></span>对应的状态值函数，即<span class=arithmatex><span class=MathJax_Preview>v^* = v_{π^*}</span><script type=math/tex>v^* = v_{π^*}</script></span>（<span class=arithmatex><span class=MathJax_Preview>v^π*</span><script type=math/tex>v^π*</script></span>表示策略<span class=arithmatex><span class=MathJax_Preview>π*</span><script type=math/tex>π*</script></span>的状态值）。</li> </ol> <h3 id=vv>（二）<span class=arithmatex><span class=MathJax_Preview>v*</span><script type=math/tex>v*</script></span>的最优性证明<a class=headerlink href=#vv title="Permanent link">¶</a></h3> <p><span class=arithmatex><span class=MathJax_Preview>v*</span><script type=math/tex>v*</script></span>是<strong>所有可能策略对应的状态值函数中的最大值</strong>：<br> - 对任意非最优策略<span class=arithmatex><span class=MathJax_Preview>π</span><script type=math/tex>π</script></span>，其状态值函数<span class=arithmatex><span class=MathJax_Preview>v_π</span><script type=math/tex>v_π</script></span>满足<span class=arithmatex><span class=MathJax_Preview>v_π ≤ v^*</span><script type=math/tex>v_π ≤ v^*</script></span>（即<span class=arithmatex><span class=MathJax_Preview>v*</span><script type=math/tex>v*</script></span>优于所有非最优策略的价值）；<br> - 因此，<span class=arithmatex><span class=MathJax_Preview>π^*</span><script type=math/tex>π^*</script></span>是最优策略（其对应的<span class=arithmatex><span class=MathJax_Preview>v_{π^*} = v^*</span><script type=math/tex>v_{π^*} = v^*</script></span>为最大价值）。</p> <h3 id=_12>（三）最优策略<span class=arithmatex><span class=MathJax_Preview>π*</span><script type=math/tex>π*</script></span>的形式<a class=headerlink href=#_12 title="Permanent link">¶</a></h3> <p><span class=arithmatex><span class=MathJax_Preview>π*</span><script type=math/tex>π*</script></span>是<strong>确定性（Deterministic）贪心策略（Greedy Policy）</strong>：<br> - 对每个状态<span class=arithmatex><span class=MathJax_Preview>s</span><script type=math/tex>s</script></span>，<span class=arithmatex><span class=MathJax_Preview>π^*</span><script type=math/tex>π^*</script></span>会选择使“动作值函数（Action Value）<span class=arithmatex><span class=MathJax_Preview>q^*(s,a)</span><script type=math/tex>q^*(s,a)</script></span>”最大的动作<span class=arithmatex><span class=MathJax_Preview>a^*</span><script type=math/tex>a^*</script></span>；<br> - 选择概率：<span class=arithmatex><span class=MathJax_Preview>π^*(a^*|s) = 1</span><script type=math/tex>π^*(a^*|s) = 1</script></span>（必然选择最优动作），<span class=arithmatex><span class=MathJax_Preview>π^*(a|s) = 0</span><script type=math/tex>π^*(a|s) = 0</script></span>（不选择其他动作）。</p> <h1 id=3-_2>第3课-贝尔曼最优公式（最优策略的有趣性质）知识点整理<a class=headerlink href=#3-_2 title="Permanent link">¶</a></h1> <h2 id=_13>一、贝尔曼最优公式核心逻辑<a class=headerlink href=#_13 title="Permanent link">¶</a></h2> <ol> <li><strong>公式作用</strong>：作为求解强化学习中<strong>最优策略（π*）</strong> 和<strong>最优状态价值（v*）</strong> 的核心工具，能直接关联已知条件与目标解，为策略优化提供数学依据。</li> <li><strong>变量关系</strong>：<br> - <strong>已知量（红色变量）</strong>：决定最优策略的关键输入，是构建贝尔曼最优公式的基础，包括三类：<ul> <li>系统模型（概率P）：描述状态转移规律的量化指标，即从当前状态s执行动作a后，转移到下一状态s'的概率，反映环境本身的动态特性。</li> <li>奖励函数（r）：人工定义的奖惩规则，用于引导智能体行为，例如到达目标区域奖励为正（如+1）、进入禁止区域或撞边界奖励为负（如-1）。</li> <li>折扣因子（γ）：调节智能体对短期奖励与长期奖励重视程度的参数，取值范围为[0,1)，是平衡即时收益与未来收益的核心。</li> <li><strong>求解量（黑色变量）</strong>：通过贝尔曼最优公式计算得出的目标结果，即能使长期收益最大化的最优策略（π<em>），以及对应策略下各状态的最优状态价值（v</em>）。</li> </ul> </li> </ol> <h2 id=_14>二、影响最优策略的关键因素（实验验证）<a class=headerlink href=#_14 title="Permanent link">¶</a></h2> <p>以“网格世界”为实验场景（包含目标区域、禁止区域与边界），验证<strong>奖励函数（r）</strong> 和<strong>折扣因子（γ）</strong> 对最优策略的直接影响（系统模型通常由环境决定，难以改变，故暂不讨论）。</p> <h3 id=1_3>1. 折扣因子（γ）的影响：控制智能体“短视/远视”特性<a class=headerlink href=#1_3 title="Permanent link">¶</a></h3> <p>折扣因子的大小直接决定智能体对未来奖励的权重分配，进而改变策略选择，实验分三种典型场景：</p> <table> <thead> <tr> <th>折扣因子（γ）</th> <th>智能体特性</th> <th>策略表现（网格世界案例）</th> <th>核心原因</th> </tr> </thead> <tbody> <tr> <td>0.9（较大）</td> <td>远视：重视长期总收益</td> <td>主动穿过禁止区域（短期承受-1惩罚），快速抵达目标区域</td> <td>虽然穿过禁止区域会有短期惩罚，但能更早获得目标区域的长期奖励；γ较大时，未来奖励折扣幅度小，总收益高于绕路方案。</td> </tr> <tr> <td>0.5（中等）</td> <td>中性：平衡短期与长期收益</td> <td>绕开禁止区域，选择更长路径前往目标区域</td> <td>此时绕路的短期无惩罚，叠加未来奖励的折扣效应后，总收益超过穿过禁止区域的方案，策略自然倾向规避风险。</td> </tr> <tr> <td>0（极小）</td> <td>极端短视：仅关注即时奖励</td> <td>原地不动或仅选择即时奖励≥0的动作，无法到达目标区域</td> <td>当γ=0时，未来奖励经折扣后全部为0，总收益等价于即时奖励；智能体仅规避即时惩罚（如撞边界、进禁止区），完全忽略长期目标。</td> </tr> </tbody> </table> <h3 id=2-r>2. 奖励函数（r）的影响：调整奖惩权重引导行为<a class=headerlink href=#2-r title="Permanent link">¶</a></h3> <p>通过改变“禁止区域”的惩罚力度，可直接反转智能体的策略选择：<br> - 原设置（禁止区域r=-1，γ=0.9）：智能体选择穿过禁止区域，以短期小惩罚换取长期高收益。<br> - 调整后（禁止区域r=-10，γ=0.9）：智能体选择绕开禁止区域，因短期大惩罚的代价远超长期奖励收益，策略随奖惩权重变化而反转。</p> <h2 id=_15>三、最优策略的不变性：奖励线性变换不改变策略<a class=headerlink href=#_15 title="Permanent link">¶</a></h2> <h3 id=1_4>1. 核心结论<a class=headerlink href=#1_4 title="Permanent link">¶</a></h3> <p>若对所有奖励进行<strong>线性变换</strong>（即<span class=arithmatex><span class=MathJax_Preview><span class=arithmatex><span class=MathJax_Preview>r' = a \cdot r + b</span><script type=math/tex>r' = a \cdot r + b</script></span></span><script type=math/tex><span class="arithmatex"><span class="MathJax_Preview">r' = a \cdot r + b</span><script type="math/tex">r' = a \cdot r + b</script></span>，其中a&gt;0为正的缩放因子，b为偏置量），则<strong>最优策略（π*）保持不变</strong>，仅最优状态价值（v*）会同步发生线性变换（变换公式为<span class=arithmatex><span class=MathJax_Preview><span class=arithmatex><span class=MathJax_Preview>v' = a \cdot v^* + \frac{b}{1-\gamma}</span><script type=math/tex>v' = a \cdot v^* + \frac{b}{1-\gamma}</script></span></span><script type=math/tex><span class="arithmatex"><span class="MathJax_Preview">v' = a \cdot v^* + \frac{b}{1-\gamma}</span><script type="math/tex">v' = a \cdot v^* + \frac{b}{1-\gamma}</script></span>）。</p> <h3 id=2_3>2. 原理分析<a class=headerlink href=#2_3 title="Permanent link">¶</a></h3> <p>最优策略的选择依赖<strong>动作价值（Q值）的相对大小</strong>，而非绝对数值：<br> - 线性变换后，所有动作的Q值会同步进行缩放和偏移（例如原Q值为[1,2,1]，变换后可能为[100,200,100]），但“最大值对应的动作”始终不变，因此策略不会改变。<br> - 示例验证：<br> - 原奖励规则：边界/禁止区r=-1，目标区域r=+1，其他步骤r=0。<br> - 线性变换（r'=r+1）：边界/禁止区r'=0，目标区域r'=2，其他步骤r'=1。<br> - 结果：最优策略完全一致，仅状态价值数值发生变化（如原v=5，变换后<span class=arithmatex><span class=MathJax_Preview><span class=arithmatex><span class=MathJax_Preview>v' = 5 + \frac{1}{1-0.9} = 15</span><script type=math/tex>v' = 5 + \frac{1}{1-0.9} = 15</script></span></span><script type=math/tex><span class="arithmatex"><span class="MathJax_Preview">v' = 5 + \frac{1}{1-0.9} = 15</span><script type="math/tex">v' = 5 + \frac{1}{1-0.9} = 15</script></span>）。</p> <h2 id=_16>四、最优策略的“避绕性”：为何不做无意义绕路？<a class=headerlink href=#_16 title="Permanent link">¶</a></h2> <h3 id=1_5>1. 问题背景<a class=headerlink href=#1_5 title="Permanent link">¶</a></h3> <p>若“非目标/非禁止区域”的奖励r=0（无步数惩罚），理论上智能体可选择绕路（如s1→s2→s1→目标），但最优策略仍倾向最短路径，核心原因与折扣因子（γ）相关。</p> <h3 id=2_4>2. 核心原因：折扣因子的“时间惩罚”效应<a class=headerlink href=#2_4 title="Permanent link">¶</a></h3> <p>绕路会延迟智能体到达目标区域的时间，导致“目标奖励”的折扣次数增加：<br> - 假设γ=0.9，最短路径2步到达目标，目标奖励折后为<span class=arithmatex><span class=MathJax_Preview><span class=arithmatex><span class=MathJax_Preview>1 \cdot \gamma^2 = 0.81</span><script type=math/tex>1 \cdot \gamma^2 = 0.81</script></span></span><script type=math/tex><span class="arithmatex"><span class="MathJax_Preview">1 \cdot \gamma^2 = 0.81</span><script type="math/tex">1 \cdot \gamma^2 = 0.81</script></span>；若绕路4步到达，目标奖励折后为<span class=arithmatex><span class=MathJax_Preview><span class=arithmatex><span class=MathJax_Preview>1 \cdot \gamma^4 \approx 0.656</span><script type=math/tex>1 \cdot \gamma^4 \approx 0.656</script></span></span><script type=math/tex><span class="arithmatex"><span class="MathJax_Preview">1 \cdot \gamma^4 \approx 0.656</span><script type="math/tex">1 \cdot \gamma^4 \approx 0.656</script></span>，后者收益显著更低。<br> - 结论：即使无明确“步数惩罚”，γ的存在也会对“延迟奖励”产生天然的折扣效应，使最优策略倾向选择最短路径，避免无意义绕路。</p> <h2 id=_17>五、贝尔曼最优公式的基础性质（回顾与补充）<a class=headerlink href=#_17 title="Permanent link">¶</a></h2> <ol> <li><strong>解的存在性与唯一性</strong>：<br> - 最优状态价值（v<em>）：在马尔可夫决策过程（MDP）框架下，由</em><em>压缩映射定理（Contraction Mapping Theorem）</em><em> 可证明其</em><em>存在且唯一</em><em>。<br> - 最优策略（π</em>）：对应最优状态价值（v<em>）的最优策略</em><em>不一定唯一</em><em>，可能存在多个策略能使状态价值达到v</em>。</li> <li><strong>求解方法</strong>：已介绍的迭代类算法（值迭代、策略迭代）可通过反复更新状态价值（v）和策略（π），逐步收敛到最优解（v<em>和π</em>）。</li> </ol> <h2 id=_18>六、关键总结<a class=headerlink href=#_18 title="Permanent link">¶</a></h2> <ol> <li>最优策略由<strong>奖励函数（r）、折扣因子（γ）、系统模型（P）</strong> 共同决定，其中r和γ是人工可调控的核心参数，需根据任务目标设计。</li> <li>折扣因子（γ）控制智能体“短视/远视”特性：γ越大，智能体越重视长期收益；γ越小，越关注即时收益。</li> <li>奖励的线性变换不改变最优策略，仅影响状态价值数值，可利用此特性简化奖励设计（如将负奖励调整为非负，降低计算复杂度）。</li> <li>折扣因子（γ）具有天然的“反绕路”作用，无需额外设计“步数惩罚”，即可引导智能体选择最短路径。</li> </ol></div> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="September 2, 2025 13:04:37 CST">September 2, 2025 13:04:37</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="September 2, 2025 13:04:37 CST">September 2, 2025 13:04:37</span> </span> </aside> <!-- Insert generated snippet here --> <script src=https://giscus.app/client.js data-repo=6chHenry/6chHenry.github.io data-repo-id=R_kgDONZrjcA data-category=Announcements data-category-id=DIC_kwDONZrjcM4Ck-PT data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=1 data-input-position=top data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous async>
    </script> <!-- Synchronize Giscus theme with palette --> <script>
    var giscus = document.querySelector("script[src*=giscus]")

    // Set palette on initial load
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate"
            ? "transparent_dark"
            : "light"

        // Instruct Giscus to set theme
        giscus.setAttribute("data-theme", theme)
    }

    // Register event handlers after documented loaded
    document.addEventListener("DOMContentLoaded", function () {
        var ref = document.querySelector("[data-md-component=palette]")
        ref.addEventListener("change", function () {
            var palette = __md_get("__palette")
            if (palette && typeof palette.color === "object") {
                var theme = palette.color.scheme === "slate"
                    ? "transparent_dark"
                    : "light"

                // Instruct Giscus to change theme
                var frame = document.querySelector(".giscus-frame")
                frame.contentWindow.postMessage(
                    {giscus: {setConfig: {theme}}},
                    "https://giscus.app"
                )
            }
        })
    })
</script> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024-2025 - Present <a href=https://github.com/6chHenry target=_blank rel=noopener>6ch.</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/6chHenry/ target=_blank rel=noopener title=GitHub class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=/img/qq.png target=_blank rel=noopener title=加加我的QQ class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M434.1 420.4c-11.5 1.4-44.9-52.7-44.9-52.7 0 31.3-16.1 72.2-51 101.8 16.8 5.2 54.8 19.2 45.8 34.4-7.3 12.3-125.5 7.9-159.6 4-34.1 3.8-152.3 8.3-159.6-4-9-15.2 28.9-29.2 45.8-34.4-34.9-29.5-51.1-70.4-51.1-101.8 0 0-33.3 54.1-44.9 52.7-5.4-.6-12.4-29.6 9.3-99.7 10.3-33 22-60.5 40.1-105.8C60.9 98 109.2-.1 224.3-.1 338-.1 387.5 96 384.6 214.9c18.1 45.2 29.9 72.9 40.1 105.8 21.8 70.1 14.7 99.1 9.3 99.7z"/></svg> </a> <a href=/img/wechat.png target=_blank rel=noopener title=Zhihu class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M385.2 167.6c6.4 0 12.6.3 18.8 1.1C387.4 90.3 303.3 32 207.7 32 100.5 32 13 104.8 13 197.4c0 53.4 29.3 97.5 77.9 131.6l-19.3 58.6 68-34.1c24.4 4.8 43.8 9.7 68.2 9.7 6.2 0 12.1-.3 18.3-.8-4-12.9-6.2-26.6-6.2-40.8-.1-84.9 72.9-154 165.3-154m-104.5-52.9c14.5 0 24.2 9.7 24.2 24.4 0 14.5-9.7 24.2-24.2 24.2-14.8 0-29.3-9.7-29.3-24.2.1-14.7 14.6-24.4 29.3-24.4m-136.4 48.6c-14.5 0-29.3-9.7-29.3-24.2 0-14.8 14.8-24.4 29.3-24.4 14.8 0 24.4 9.7 24.4 24.4 0 14.6-9.6 24.2-24.4 24.2M563 319.4c0-77.9-77.9-141.3-165.4-141.3-92.7 0-165.4 63.4-165.4 141.3S305 460.7 397.6 460.7c19.3 0 38.9-5.1 58.6-9.9l53.4 29.3-14.8-48.6C534 402.1 563 363.2 563 319.4m-219.1-24.5c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.8 0 24.4 9.7 24.4 19.3 0 10-9.7 19.6-24.4 19.6m107.1 0c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.5 0 24.4 9.7 24.4 19.3.1 10-9.9 19.6-24.4 19.6"/></svg> </a> <a href=mailto:2313287840@qq.com target=_blank rel=noopener title="send email to me!" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M536.4-26.3c9.8-3.5 20.6-1 28 6.3s9.8 18.2 6.3 28l-178 496.9c-5 13.9-18.1 23.1-32.8 23.1-14.2 0-27-8.6-32.3-21.7l-64.2-158c-4.5-11-2.5-23.6 5.2-32.6l94.5-112.4c5.1-6.1 4.7-15-.9-20.6s-14.6-6-20.6-.9l-112.4 94.3c-9.1 7.6-21.6 9.6-32.6 5.2L38.1 216.8c-13.1-5.3-21.7-18.1-21.7-32.3 0-14.7 9.2-27.8 23.1-32.8z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["content.code.annotate", "content.code.copy", "content.code.select", "content.footnote.tooltips", "content.tabs.link", "header.autohide", "navigation.tracking", "navigation.tabs", "navigation.top", "navigation.path", "navigation.indexes", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../../assets/javascripts/bundle.92b07e13.min.js></script> <script src=../../../javascripts/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>