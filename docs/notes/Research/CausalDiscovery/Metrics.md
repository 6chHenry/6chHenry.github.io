# Metrics

### 核心基础：混淆矩阵

要理解这四个指标，首先必须了解**混淆矩阵**。它是一切计算的基础。

假设我们预测一个病人是否患病（正例=患病，负例=健康）。混淆矩阵如下：

|                     | **实际为正例** | **实际为负例** |
| :------------------ | :------------- | :------------- |
| **预测为正例**      | True Positive (TP) | False Positive (FP) |
| **预测为负例**      | False Negative (FN) | True Negative (TN) |

*   **TP（真阳性）**：预测正确。病人确实患病，我们预测他也患病。
*   **FP（假阳性）**：预测错误。病人实际健康，我们误预测他患病。（**Type I Error**）
*   **FN（假阴性）**：预测错误。病人实际患病，我们误预测他健康。（**Type II Error**）
*   **TN（真阴性）**：预测正确。病人确实健康，我们预测他也健康。

---

### 四个指标的定义与区别

现在我们基于混淆矩阵来定义这四个指标。

#### 1. Accuracy（准确率）

*   **定义**：**所有预测中，预测正确的比例**。是最直观的指标。
*   **公式**：$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$
*   **理解**：“蒙对的”概率有多大？它衡量了模型的整体正确性。
*   **优点与局限**：
    *   在数据类别均衡（正负样本数量差不多）时，Accuracy是一个很好的指标。
    *   **但在数据极度不平衡时，Accuracy会失效**。
    *   **例子**：在一个有99个健康人、1个病人的数据集中，即使模型把所有人都预测为健康，它的Accuracy也能高达99%。但这个模型毫无用处，因为它漏掉了所有病人。

#### 2. Precision（精确率/查准率）

*   **定义**：**在所有被预测为正例的样本中，真正是正例的比例**。它关注的是**预测结果的精准度**。
*   **公式**：$Precision = \frac{TP}{TP + FP}$
*   **理解**：“我说他对，他有多大概率真的对？” 衡量的是模型**避免误报（False Alarm）** 的能力。
*   **应用场景**：**非常注重减少FP（假阳性）的场景**。
    *   **垃圾邮件检测**：把正常邮件预测为垃圾邮件（FP）的后果很严重（用户可能错过重要邮件），所以需要极高的Precision。宁可放过一些垃圾邮件（FN），也不能错杀正常邮件。

#### 3. Recall（召回率/查全率）

*   **定义**：**在所有实际为正例的样本中，被成功预测为正例的比例**。它关注的是**找出正例的能力**。
*   **公式**：$Recall = \frac{TP}{TP + FN}$
*   **理解**：“真正对的，我找出了多少？” 衡量的是模型**避免漏检（Missing Detection）** 的能力。
*   **应用场景**：**非常注重减少FN（假阴性）的场景**。
    *   **疾病诊断**：把一个病人预测为健康（FN）的后果是灾难性的（延误治疗），所以需要极高的Recall。宁可误判一些健康人（FP）去做进一步检查，也不能漏掉一个病人。

#### 4. F1 Score（F1分数）

*   **定义**：**Precision和Recall的调和平均数**。是综合衡量模型稳健性的指标。
*   **公式**：$F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}$
*   **理解**：Precision和Recall通常是一对矛盾的指标（提高一个往往会降低另一个）。F1 Score试图找到一个平衡点。
    *   **为什么用调和平均而不是算术平均？** 调和平均更注重较小值的表现。只有当P和R都比较高时，F1才会高。如果其中一个很低，会立刻拉低F1。
*   **应用场景**：
    *   当你需要在Precision和Recall之间寻求一个平衡时。
    *   当数据类别分布不平衡时，F1是比Accuracy更好的指标。
    *   当你没有明确的偏好是更需要Precision还是Recall时。

---

### 总结与对比

| 指标          | 关注点                                     | 公式                                  | 核心问题                                     | 应用场景举例                     |
| :------------ | :----------------------------------------- | :------------------------------------ | :------------------------------------------- | :------------------------------- |
| **Accuracy**  | **整体正确性**                             | (TP+TN) / All                         | 所有预测中，猜对的占多大比例？               | 均衡数据集，整体评估             |
| **Precision** | **预测正例的准确性**（减少误报FP）         | TP / (TP+FP)                          | **我说他对，他有多大概率真的对？**           | 垃圾邮件检测、推荐系统           |
| **Recall**    | **找出所有正例的能力**（减少漏检FN）       | TP / (TP+FN)                          | **真正对的，我找出了多少？**                 | 疾病诊断、欺诈检测、逃犯识别     |
| **F1 Score**  | **Precision和Recall的平衡**                | 2 * (P*R) / (P+R)                     | 模型在避免误报和漏检上的**综合表现**如何？   | 不平衡数据集，没有特殊偏好时     |

### 一个生动的比喻

假设你在果园里用机器挑果子（好果子=正例，坏果子=负例）：

*   **Accuracy**：所有被挑出来的果子中，好果子和被留下的坏果子占总数的比例。（整体挑得有多准）
*   **Precision**：被机器**放进好果子筐**里的果子，**真正是好果子的比例**。（好果子筐的纯净度）
    *    Precision低：好果子筐里混了很多坏果子。
*   **Recall**：**果园里所有好果子**，**被机器成功挑进好果子筐的比例**。（好果子的回收率）
    *   Recall低：很多好果子被遗漏，丢进了坏果子筐。
*   **F1 Score**：综合衡量了“筐有多干净”和“果子回收得多全面”。

希望这个解释能帮助你清晰地区分这四个重要指标！

您提供的这段描述非常精准，它定义了在图结构（尤其是因果图）比较中使用的**归一化汉明距离 (NHD)**。这个定义与比较简单字符串的NHD在精神上一致，但在计算细节上有一个关键区别：

**核心区别：分母不同**
*   **字符串NHD**：分母是**序列的实际长度**。
*   **图NHD**：分母是**图中所有可能边的总数**（对于一个有 `m` 个节点的有向图，这个值是 `m*(m-1)`，因为不允许有自环）。

您提供的定义是图比较领域的标准用法。下面我将根据您的描述，通过一个详细的例子来说明这个计算过程。

---

### 图NHD计算步骤

1.  **确定图的表示**：通常使用**邻接矩阵**。矩阵中元素 `(i, j)` 为 `1` 表示存在从节点 `i` 到节点 `j` 的边，为 `0` 则表示不存在。
2.  **计算差异**：对两个图的邻接矩阵进行**异或（XOR）** 操作。结果为 `1` 的位置就是两个图不一致的边（即一个图中有，另一个图中没有）。
3.  **统计差异数量**：统计异或矩阵中 `1` 的数量。这就是汉明距离。
4.  **归一化**：将汉明距离除以所有可能边的总数 `m*(m-1)`，得到NHD。

**公式（Equation 6）**：
$NHD(G, G_p) = \frac{\sum_{i=1}^{m} \sum_{j=1, j \neq i}^{m} \mathbb{1}[G(i, j) \neq G_p(i, j)]}{m(m-1)}$
其中 $\mathbb{1}$ 是指示函数，内部条件为真时返回1，否则返回0。

---

### 举例说明

假设我们有一个包含 **3个节点** (X, Y, Z) 的因果图。所有可能的有向边数量为 `3 * (3-1) = 6` 条，即：X→Y, X→Z, Y→X, Y→Z, Z→X, Z→Y。

*   **真实图 G** 的结构为：`X -> Y -> Z`（一条链）。
*   **预测图 G_p** 的结构为：`X -> Y <- Z`（一个V型结构）。

让我们为这两个图构建邻接矩阵。

**第1步：创建邻接矩阵**

*   **真实图 G 的邻接矩阵**:
    |     | X   | Y   | Z   |
    | --- | --- | --- | --- |
    | **X** | 0   | 1   | 0   |
    | **Y** | 0   | 0   | 1   |
    | **Z** | 0   | 0   | 0   |

*   **预测图 G_p 的邻接矩阵**:
    |     | X   | Y   | Z   |
    | --- | --- | --- | --- |
    | **X** | 0   | 1   | 0   |
    | **Y** | 0   | 0   | 0   | // 注意，Y->Z 的边消失了
    | **Z** | 0   | 1   | 0   | // 注意，这里多了一条 Z->Y 的边

**第2步：计算异或矩阵 (XOR)**
我们将两个矩阵逐位比较，如果值不同则标记为1，相同则标记为0。

|           | X   | Y     | Z     |
| --------- | --- | ----- | ----- |
| **X**     | 0⊕0=0 | 1⊕1=0 | 0⊕0=0 |
| **Y**     | 0⊕0=0 | 0⊕0=0 | **1⊕0=1** | // G中有Y->Z，G_p中没有，所以不同 |
| **Z**     | 0⊕0=0 | **0⊕1=1** | 0⊕0=0 | // G中没有Z->Y，G_p中有，所以不同 |

**异或矩阵结果**:
|     | X   | Y   | Z   |
| --- | --- | --- | --- |
| **X** | 0   | 0   | 0   |
| **Y** | 0   | 0   | **1** |
| **Z** | 0   | **1** | 0   |

**第3步：统计差异数量（汉明距离）**
异或矩阵中一共有 **2** 个 `1`。
*   一个是 `(Y, Z)`，对应真实图中 `Y->Z` 被漏掉了（False Negative）。
*   一个是 `(Z, Y)`，对应预测图中多了一个 `Z->Y`（False Positive）。

**因此，汉明距离 = 2**。

**第4步：归一化 (NHD)**
所有可能边的总数是 `m(m-1) = 3*2 = 6`。

$NHD = \frac{Hamming\,Distance}{Total\,Possible\,Edges} = \frac{2}{6} \approx 0.333$

### 结果解释

**NHD ≈ 0.333** 意味着预测图 `G_p` 与真实图 `G` 之间有 **33.3%** 的边不一致。

这个值量化了您描述中的“nuanced differences”：
1.  它捕捉到了**漏掉的边**（FN：Y->Z）。
2.  它也捕捉到了**多余的边**（FP：Z->Y）。
3.  它同时 reward 了**正确预测的边**（TP：X->Y）和**正确预测的不存在的边**（TN：例如X->Z, Y->X等），因为这些在异或矩阵中都是 `0`。

### 总结

在图结构的上下文中，NHD是一个极其有价值的指标，因为它：
*   **归一化**：允许比较不同节点数量的图。
*   **全面**：同时惩罚了**假阳性**（多编的边）和**假阴性**（丢失的边）。
*   **直观**：结果可以解释为“错误边的比例”。NHD为0表示图完全匹配，为1表示图完全相反。
