{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\u4e3b\u9875","text":"Welcome to 6ch.'s Blog! \ud83c\udf89  <p>  About Me /   Academic Page /  Statistics </p> <li>Website Operating Time: </li> <li>Total Visitors:  people</li> <li>Total Visits:  times</li>"},{"location":"academy/","title":"KeWei Liu(\u5218\u53ef\u552f)","text":""},{"location":"academy/#kewei-liu","title":"KeWei Liu(\u5218\u53ef\u552f)","text":"<p> Work Email: HenryLiu</p> <p> Personal Email: HenryLiu13550060700[at]sjtu[dot]edu[dot]cn</p> <p> CV: Empty</p> <p></p>"},{"location":"academy/#bio","title":"Bio","text":"<p>I am a first-year undergraduate student majoring in AI at SAI of Shanghai Jiao Tong University (SJTU). </p> <p>Currently, I am an active participant in Zhiyuan Honors Program, which fosters academic excellence and innovation.</p> <p>I am enthusiastic about Deep Learning in Computer Vision! Please feel free to reach out to me if you want to share experiences with me! \ud83e\udd70\ud83e\udd70\ud83e\udd70</p>"},{"location":"academy/#research-interest","title":"Research Interest","text":"<ul> <li>Computer Vision: I love the charm of computer vision which is amazing,because it makes computer able to see the images and videos!</li> <li>Embodied AI: Building the brain for the robots is also interesting for me!</li> </ul>"},{"location":"academy/#news","title":"News","text":"20252024 <p>[04/2025]  I was admitted to SAI !</p> <p>[03/2025]  I became a member of A+ Club of SJTU ME.</p> <p>[02/2025]  I became a member of Zhiyuan Honor Program,SJTU.</p> <p>[09/2024] Excited to start my ME B.Eng. at SJTU ME.</p>"},{"location":"academy/#education","title":"Education","text":""},{"location":"academy/#school-of-artificial-intelligenceshanghai-jiaotong-university","title":"School of Artificial Intelligence,Shanghai Jiaotong University","text":"<p>Apr. 2025 -- Present</p> <p></p>"},{"location":"academy/#a-club-of-sjtu-meshanghai-jiao-tong-university","title":"A+ Club of SJTU ME,Shanghai Jiao Tong University","text":"<p>Mar. 2025 -- Present</p> <p></p>"},{"location":"academy/#zhiyuan-honor-program-shanghai-jiao-tong-university","title":"Zhiyuan Honor Program, Shanghai Jiao Tong University","text":"<p>Feb. 2025 -- Present</p> <p></p>"},{"location":"academy/#school-of-mechanical-engineering-shanghai-jiao-tong-university","title":"School of Mechanical Engineering, Shanghai Jiao Tong University","text":"<p>Sept. 2024 -- Apr. 2025</p>"},{"location":"academy/#publications-manuscripts","title":"Publications &amp; Manuscripts","text":"<p>Coming soon...</p>"},{"location":"academy/#experience","title":"Experience","text":""},{"location":"academy/#projects","title":"Projects","text":"<p>2025\u6691\u5047\uff1a\u81ea\u52a8\u9a7e\u9a76\u884c\u4e3a\u4eff\u771f</p>"},{"location":"academy/#media-exposures","title":"Media Exposures","text":"<p>Coming soon...</p>"},{"location":"academy/#honors","title":"Honors","text":"<p>Coming soon...</p>"},{"location":"math-test/","title":"\u6570\u5b66\u516c\u5f0f\u6d4b\u8bd5\u9875\u9762","text":""},{"location":"math-test/#_1","title":"\u6570\u5b66\u516c\u5f0f\u6d4b\u8bd5\u9875\u9762","text":"<p> \u7ea6 8315 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 42 \u5206\u949f</p>"},{"location":"math-test/#_2","title":"\u884c\u5185\u516c\u5f0f\u6d4b\u8bd5","text":"<p>\u8fd9\u662f\u4e00\u4e2a\u884c\u5185\u516c\u5f0f\uff1a\\(E = mc^2\\)</p> <p>\u53e6\u4e00\u4e2a\u884c\u5185\u516c\u5f0f\uff1a\\(\\alpha + \\beta = \\gamma\\)</p>"},{"location":"math-test/#_3","title":"\u5757\u7ea7\u516c\u5f0f\u6d4b\u8bd5","text":""},{"location":"math-test/#_4","title":"\u4f7f\u7528 \\(\\(...\\)\\) \u683c\u5f0f","text":"\\[ f(x) = \\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2\\pi i \\xi x} d\\xi \\]"},{"location":"math-test/#_5","title":"\u4f7f\u7528 [...] \u683c\u5f0f","text":"\\[ \\frac{\\partial f}{\\partial t} + \\frac{1}{2}\\sigma^2\\frac{\\partial^2 f}{\\partial x^2} = 0 \\]"},{"location":"math-test/#_6","title":"\u590d\u6742\u516c\u5f0f\u6d4b\u8bd5","text":""},{"location":"math-test/#_7","title":"\u5e26\u6709\u5bf9\u9f50\u73af\u5883\u7684\u516c\u5f0f","text":""},{"location":"math-test/#beginaligned","title":"\u4f7f\u7528 \\begin{aligned} \u73af\u5883","text":"\\[ \\begin{aligned} \\nabla \\times \\vec{\\mathbf{B}} -\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{E}}}{\\partial t} &amp;= \\frac{4\\pi}{c}\\vec{\\mathbf{j}} \\\\ \\nabla \\cdot \\vec{\\mathbf{E}} &amp;= 4 \\pi \\rho \\\\ \\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} &amp;= \\vec{\\mathbf{0}} \\\\ \\nabla \\cdot \\vec{\\mathbf{B}} &amp;= 0 \\end{aligned} \\]"},{"location":"math-test/#beginalign","title":"\u4f7f\u7528 \\begin{align} \u73af\u5883","text":"\\[ \\begin{align} \\mathbb{E}[G_{t+1}|S_t = s] &amp;= \\sum_{s'} \\mathbb{E}[G_{t+1}|S_t = s, S_{t+1} = s']p(s'|s) \\\\ &amp;= \\sum_{s'} \\mathbb{E}[G_{t+1}|S_{t+1} = s']p(s'|s) \\\\ &amp;= \\sum_{s'} v_\\pi(s')p(s'|s) \\\\ &amp;= \\sum_{s'} v_\\pi(s') \\sum_{a} p(s'|s,a)\\pi(a|s) \\\\ &amp;=\\sum_a\\pi(a|s)\\sum_{s'}p(s'|s,a)v_\\pi(s') \\end{align} \\]"},{"location":"math-test/#_8","title":"\u5e26\u6709\u77e9\u9635\u7684\u516c\u5f0f","text":"\\[ \\mathbf{X} = \\begin{bmatrix} x_{11} &amp; x_{12} &amp; \\cdots &amp; x_{1n} \\\\ x_{21} &amp; x_{22} &amp; \\cdots &amp; x_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ x_{m1} &amp; x_{m2} &amp; \\cdots &amp; x_{mn} \\end{bmatrix} \\]"},{"location":"math-test/#_9","title":"\u5e26\u6709\u6c42\u548c\u7b26\u53f7\u7684\u516c\u5f0f","text":"\\[ \\sum_{i=1}^{n} i = \\frac{n(n+1)}{2} \\]"},{"location":"math-test/#_10","title":"\u5e26\u6709\u6781\u9650\u7684\u516c\u5f0f","text":"\\[ \\lim_{x \\to \\infty} \\left(1 + \\frac{1}{x}\\right)^x = e \\]"},{"location":"math-test/#_11","title":"\u5e26\u6709\u79ef\u5206\u7684\u516c\u5f0f","text":"\\[ \\int_{a}^{b} f(x) dx = F(b) - F(a) \\]"},{"location":"math-test/#_12","title":"\u5e26\u6709\u5e0c\u814a\u5b57\u6bcd\u7684\u516c\u5f0f","text":"\\[ \\Delta = b^2 - 4ac \\]"},{"location":"math-test/#_13","title":"\u5e26\u6709\u4e0a\u4e0b\u6807\u7684\u516c\u5f0f","text":"\\[ x_1^2 + x_2^2 + \\cdots + x_n^2 = r^2 \\]"},{"location":"math-test/#_14","title":"\u5e26\u6709\u5206\u6570\u7684\u516c\u5f0f","text":"\\[ \\frac{a}{b} = \\frac{c}{d} \\implies ad = bc \\]"},{"location":"math-test/#_15","title":"\u5e26\u6709\u6839\u53f7\u7684\u516c\u5f0f","text":"\\[ x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} \\]"},{"location":"math-test/#_16","title":"\u5e26\u6709\u96c6\u5408\u7b26\u53f7\u7684\u516c\u5f0f","text":"\\[ A \\cup B = \\{x \\mid x \\in A \\text{ or } x \\in B\\} \\]"},{"location":"math-test/#_17","title":"\u5e26\u6709\u903b\u8f91\u7b26\u53f7\u7684\u516c\u5f0f","text":"\\[ P \\land Q \\implies R \\]"},{"location":"math-test/#_18","title":"\u5e26\u6709\u6982\u7387\u7b26\u53f7\u7684\u516c\u5f0f","text":"\\[ \\mathbb{P}(X = x) = \\frac{e^{-\\lambda}\\lambda^x}{x!} \\]"},{"location":"math-test/#_19","title":"\u5e26\u6709\u671f\u671b\u7b26\u53f7\u7684\u516c\u5f0f","text":"\\[ \\mathbb{E}[X] = \\sum_{x \\in \\mathcal{X}} x \\cdot \\mathbb{P}(X = x) \\]"},{"location":"math-test/#_20","title":"\u5e26\u6709\u65b9\u5dee\u7b26\u53f7\u7684\u516c\u5f0f","text":"\\[ \\mathrm{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2 \\]"},{"location":"math-test/#_21","title":"\u5e26\u6709\u534f\u65b9\u5dee\u7b26\u53f7\u7684\u516c\u5f0f","text":"\\[ \\mathrm{Cov}(X, Y) = \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])] \\]"},{"location":"math-test/#argmax-argmin","title":"\u5e26\u6709 argmax \u548c argmin \u7684\u516c\u5f0f","text":"\\[ \\hat{\\theta} = \\arg\\max_{\\theta} \\mathcal{L}(\\theta) \\]"},{"location":"math-test/#_22","title":"\u5e26\u6709\u6761\u4ef6\u6982\u7387\u7684\u516c\u5f0f","text":"\\[ \\mathbb{P}(A \\mid B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)} \\]"},{"location":"math-test/#_23","title":"\u5e26\u6709\u8d1d\u53f6\u65af\u516c\u5f0f\u7684\u516c\u5f0f","text":"\\[ \\mathbb{P}(A \\mid B) = \\frac{\\mathbb{P}(B \\mid A) \\cdot \\mathbb{P}(A)}{\\mathbb{P}(B)} \\]"},{"location":"math-test/#_24","title":"\u5e26\u6709\u5411\u91cf\u7b26\u53f7\u7684\u516c\u5f0f","text":"\\[ \\vec{v} = \\begin{pmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{pmatrix} \\]"},{"location":"math-test/#_25","title":"\u5e26\u6709\u68af\u5ea6\u7b26\u53f7\u7684\u516c\u5f0f","text":"\\[ \\nabla f = \\left( \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\ldots, \\frac{\\partial f}{\\partial x_n} \\right) \\]"},{"location":"math-test/#_26","title":"\u5e26\u6709\u6563\u5ea6\u7b26\u53f7\u7684\u516c\u5f0f","text":"\\[ \\nabla \\cdot \\vec{F} = \\frac{\\partial F_x}{\\partial x} + \\frac{\\partial F_y}{\\partial y} + \\frac{\\partial F_z}{\\partial z} \\]"},{"location":"math-test/#_27","title":"\u5e26\u6709\u65cb\u5ea6\u7b26\u53f7\u7684\u516c\u5f0f","text":"\\[ \\nabla \\times \\vec{F} = \\begin{vmatrix} \\hat{i} &amp; \\hat{j} &amp; \\hat{k} \\\\ \\frac{\\partial}{\\partial x} &amp; \\frac{\\partial}{\\partial y} &amp; \\frac{\\partial}{\\partial z} \\\\ F_x &amp; F_y &amp; F_z \\end{vmatrix} \\]"},{"location":"math-test/#_28","title":"\u5e26\u6709\u62c9\u666e\u62c9\u65af\u7b97\u5b50\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\nabla^2 f = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2} + \\frac{\\partial^2 f}{\\partial z^2} \\]"},{"location":"math-test/#_29","title":"\u5e26\u6709\u5085\u91cc\u53f6\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ \\hat{f}(\\xi) = \\int_{-\\infty}^{\\infty} f(x) e^{-2\\pi i x \\xi} dx \\]"},{"location":"math-test/#_30","title":"\u5e26\u6709\u62c9\u666e\u62c9\u65af\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ F(s) = \\mathcal{L}\\{f(t)\\} = \\int_0^{\\infty} f(t) e^{-st} dt \\]"},{"location":"math-test/#_31","title":"\u5e26\u6709\u6cf0\u52d2\u7ea7\u6570\u7684\u516c\u5f0f","text":"\\[ f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n!}(x-a)^n \\]"},{"location":"math-test/#_32","title":"\u5e26\u6709\u9ea6\u514b\u52b3\u6797\u7ea7\u6570\u7684\u516c\u5f0f","text":"\\[ f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(0)}{n!}x^n \\]"},{"location":"math-test/#_33","title":"\u5e26\u6709\u6b27\u62c9\u516c\u5f0f\u7684\u516c\u5f0f","text":"\\[ e^{i\\theta} = \\cos \\theta + i \\sin \\theta \\]"},{"location":"math-test/#_34","title":"\u5e26\u6709\u6b27\u62c9\u6052\u7b49\u5f0f\u7684\u516c\u5f0f","text":"\\[ e^{i\\pi} + 1 = 0 \\]"},{"location":"math-test/#_35","title":"\u5e26\u6709\u4e8c\u9879\u5f0f\u5b9a\u7406\u7684\u516c\u5f0f","text":"\\[ (a + b)^n = \\sum_{k=0}^{n} \\binom{n}{k} a^{n-k} b^k \\]"},{"location":"math-test/#_36","title":"\u5e26\u6709\u7ec4\u5408\u6570\u7684\u516c\u5f0f","text":"\\[ \\binom{n}{k} = \\frac{n!}{k!(n-k)!} \\]"},{"location":"math-test/#_37","title":"\u5e26\u6709\u6392\u5217\u6570\u7684\u516c\u5f0f","text":"\\[ P(n, k) = \\frac{n!}{(n-k)!} \\]"},{"location":"math-test/#_38","title":"\u5e26\u6709\u9636\u4e58\u7684\u516c\u5f0f","text":"\\[ n! = n \\times (n-1) \\times (n-2) \\times \\cdots \\times 2 \\times 1 \\]"},{"location":"math-test/#_39","title":"\u5e26\u6709\u53cc\u9636\u4e58\u7684\u516c\u5f0f","text":"\\[ n!! = n \\times (n-2) \\times (n-4) \\times \\cdots \\times 2 \\text{ \u6216 } 1 \\]"},{"location":"math-test/#_40","title":"\u5e26\u6709\u4f3d\u9a6c\u51fd\u6570\u7684\u516c\u5f0f","text":"\\[ \\Gamma(z) = \\int_0^{\\infty} t^{z-1} e^{-t} dt \\]"},{"location":"math-test/#_41","title":"\u5e26\u6709\u8d1d\u5854\u51fd\u6570\u7684\u516c\u5f0f","text":"\\[ B(x, y) = \\int_0^1 t^{x-1} (1-t)^{y-1} dt = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)} \\]"},{"location":"math-test/#zeta","title":"\u5e26\u6709\u9ece\u66fc zeta \u51fd\u6570\u7684\u516c\u5f0f","text":"\\[ \\zeta(s) = \\sum_{n=1}^{\\infty} \\frac{1}{n^s} \\]"},{"location":"math-test/#_42","title":"\u5e26\u6709\u8bef\u5dee\u51fd\u6570\u7684\u516c\u5f0f","text":"\\[ \\operatorname{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_0^x e^{-t^2} dt \\]"},{"location":"math-test/#_43","title":"\u5e26\u6709\u4e92\u8865\u8bef\u5dee\u51fd\u6570\u7684\u516c\u5f0f","text":"\\[ \\operatorname{erfc}(x) = 1 - \\operatorname{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_x^{\\infty} e^{-t^2} dt \\]"},{"location":"math-test/#_44","title":"\u5e26\u6709\u6b63\u5f26\u79ef\u5206\u7684\u516c\u5f0f","text":"\\[ \\operatorname{Si}(x) = \\int_0^x \\frac{\\sin t}{t} dt \\]"},{"location":"math-test/#_45","title":"\u5e26\u6709\u4f59\u5f26\u79ef\u5206\u7684\u516c\u5f0f","text":"\\[ \\operatorname{Ci}(x) = -\\int_x^{\\infty} \\frac{\\cos t}{t} dt \\]"},{"location":"math-test/#_46","title":"\u5e26\u6709\u6307\u6570\u79ef\u5206\u7684\u516c\u5f0f","text":"\\[ E_1(x) = \\int_x^{\\infty} \\frac{e^{-t}}{t} dt \\]"},{"location":"math-test/#_47","title":"\u5e26\u6709\u5bf9\u6570\u79ef\u5206\u7684\u516c\u5f0f","text":"\\[ \\operatorname{li}(x) = \\int_0^x \\frac{dt}{\\ln t} \\]"},{"location":"math-test/#_48","title":"\u5e26\u6709\u83f2\u6d85\u5c14\u79ef\u5206\u7684\u516c\u5f0f","text":"\\[ S(x) = \\int_0^x \\sin\\left(\\frac{\\pi t^2}{2}\\right) dt \\]"},{"location":"math-test/#_49","title":"\u5e26\u6709\u692d\u5706\u79ef\u5206\u7684\u516c\u5f0f","text":"\\[ F(\\phi, k) = \\int_0^{\\phi} \\frac{d\\theta}{\\sqrt{1 - k^2 \\sin^2 \\theta}} \\]"},{"location":"math-test/#_50","title":"\u5e26\u6709\u8d1d\u585e\u5c14\u51fd\u6570\u7684\u516c\u5f0f","text":"\\[ J_n(x) = \\frac{1}{\\pi} \\int_0^{\\pi} \\cos(n\\theta - x \\sin \\theta) d\\theta \\]"},{"location":"math-test/#_51","title":"\u5e26\u6709\u52d2\u8ba9\u5fb7\u591a\u9879\u5f0f\u7684\u516c\u5f0f","text":"\\[ P_n(x) = \\frac{1}{2^n n!} \\frac{d^n}{dx^n} \\left[(x^2 - 1)^n\\right] \\]"},{"location":"math-test/#_52","title":"\u5e26\u6709\u57c3\u5c14\u7c73\u7279\u591a\u9879\u5f0f\u7684\u516c\u5f0f","text":"\\[ H_n(x) = (-1)^n e^{x^2} \\frac{d^n}{dx^n} e^{-x^2} \\]"},{"location":"math-test/#_53","title":"\u5e26\u6709\u62c9\u76d6\u5c14\u591a\u9879\u5f0f\u7684\u516c\u5f0f","text":"\\[ L_n(x) = \\frac{e^x}{n!} \\frac{d^n}{dx^n} (x^n e^{-x}) \\]"},{"location":"math-test/#_54","title":"\u5e26\u6709\u5207\u6bd4\u96ea\u592b\u591a\u9879\u5f0f\u7684\u516c\u5f0f","text":"\\[ T_n(x) = \\cos(n \\arccos x) \\]"},{"location":"math-test/#_55","title":"\u5e26\u6709\u62c9\u76d6\u5c14\u4f34\u968f\u591a\u9879\u5f0f\u7684\u516c\u5f0f","text":"\\[ L_n^{(k)}(x) = \\frac{d^k}{dx^k} L_{n+k}(x) \\]"},{"location":"math-test/#_56","title":"\u5e26\u6709\u96c5\u53ef\u6bd4\u591a\u9879\u5f0f\u7684\u516c\u5f0f","text":"\\[ P_n^{(\\alpha, \\beta)}(x) = \\frac{(\\alpha + 1)_n}{n!} \\sum_{k=0}^n \\binom{n}{k} \\frac{(\\alpha + \\beta + n + 1)_k}{(\\alpha + 1)_k} \\left(\\frac{x-1}{2}\\right)^k \\]"},{"location":"math-test/#_57","title":"\u5e26\u6709\u8d85\u51e0\u4f55\u51fd\u6570\u7684\u516c\u5f0f","text":"\\[ {}_2F_1(a, b; c; z) = \\sum_{n=0}^{\\infty} \\frac{(a)_n (b)_n}{(c)_n} \\frac{z^n}{n!} \\]"},{"location":"math-test/#_58","title":"\u5e26\u6709\u5408\u6d41\u8d85\u51e0\u4f55\u51fd\u6570\u7684\u516c\u5f0f","text":"\\[ {}_1F_1(a; b; z) = \\sum_{n=0}^{\\infty} \\frac{(a)_n}{(b)_n} \\frac{z^n}{n!} \\]"},{"location":"math-test/#_59","title":"\u5e26\u6709\u5e7f\u4e49\u8d85\u51e0\u4f55\u51fd\u6570\u7684\u516c\u5f0f","text":"\\[ {}_pF_q(a_1, \\ldots, a_p; b_1, \\ldots, b_q; z) = \\sum_{n=0}^{\\infty} \\frac{(a_1)_n \\cdots (a_p)_n}{(b_1)_n \\cdots (b_q)_n} \\frac{z^n}{n!} \\]"},{"location":"math-test/#_60","title":"\u5e26\u6709\u6885\u6797\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ \\mathcal{M}\\{f(t)\\}(s) = \\int_0^{\\infty} t^{s-1} f(t) dt \\]"},{"location":"math-test/#_61","title":"\u5e26\u6709\u6c49\u514b\u5c14\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ F_\\nu(k) = \\int_0^{\\infty} f(r) J_\\nu(kr) r dr \\]"},{"location":"math-test/#_62","title":"\u5e26\u6709\u5e0c\u5c14\u4f2f\u7279\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ \\mathcal{H}\\{f(t)\\}(u) = \\frac{1}{\\pi} \\text{p.v.} \\int_{-\\infty}^{\\infty} \\frac{f(t)}{t-u} dt \\]"},{"location":"math-test/#_63","title":"\u5e26\u6709\u54c8\u7279\u5229\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ H(\\omega) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} f(t) (\\cos(\\omega t) + \\sin(\\omega t)) dt \\]"},{"location":"math-test/#_64","title":"\u5e26\u6709\u5c0f\u6ce2\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ W(a, b) = \\frac{1}{\\sqrt{|a|}} \\int_{-\\infty}^{\\infty} f(t) \\psi^*\\left(\\frac{t-b}{a}\\right) dt \\]"},{"location":"math-test/#z","title":"\u5e26\u6709Z\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ X(z) = \\sum_{n=-\\infty}^{\\infty} x[n] z^{-n} \\]"},{"location":"math-test/#_65","title":"\u5e26\u6709\u79bb\u6563\u65f6\u95f4\u5085\u91cc\u53f6\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ X(e^{j\\omega}) = \\sum_{n=-\\infty}^{\\infty} x[n] e^{-j\\omega n} \\]"},{"location":"math-test/#_66","title":"\u5e26\u6709\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ X[k] = \\sum_{n=0}^{N-1} x[n] e^{-j 2\\pi kn/N} \\]"},{"location":"math-test/#_67","title":"\u5e26\u6709\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ X[k] = \\sum_{n=0}^{N-1} x[n] W_N^{kn}, \\quad W_N = e^{-j 2\\pi / N} \\]"},{"location":"math-test/#_68","title":"\u5e26\u6709\u4f59\u5f26\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ X[k] = \\sum_{n=0}^{N-1} x[n] \\cos\\left[\\frac{\\pi}{N}\\left(n + \\frac{1}{2}\\right)k\\right] \\]"},{"location":"math-test/#_69","title":"\u5e26\u6709\u6b63\u5f26\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ X[k] = \\sum_{n=0}^{N-1} x[n] \\sin\\left[\\frac{\\pi}{N}\\left(n + \\frac{1}{2}\\right)k\\right] \\]"},{"location":"math-test/#_70","title":"\u5e26\u6709\u6c83\u5c14\u4ec0\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ X[k] = \\sum_{n=0}^{N-1} x[n] \\text{wal}(k, n) \\]"},{"location":"math-test/#_71","title":"\u5e26\u6709\u54c8\u8fbe\u739b\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ X[k] = \\sum_{n=0}^{N-1} x[n] (-1)^{\\sum_{i=0}^{m-1} k_i n_i} \\]"},{"location":"math-test/#_72","title":"\u5e26\u6709\u54c8\u5c14\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ X[k] = \\sum_{n=0}^{N-1} x[n] h_k(n) \\]"},{"location":"math-test/#_73","title":"\u5e26\u6709\u659c\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ X[k] = \\sum_{n=0}^{N-1} x[n] s(k, n) \\]"},{"location":"math-test/#_74","title":"\u5e26\u6709\u79bb\u6563\u4f59\u5f26\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ X[k] = c_k \\sum_{n=0}^{N-1} x[n] \\cos\\left[\\frac{\\pi}{N}\\left(n + \\frac{1}{2}\\right)k\\right] \\]"},{"location":"math-test/#_75","title":"\u5e26\u6709\u79bb\u6563\u6b63\u5f26\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ X[k] = \\sum_{n=0}^{N-1} x[n] \\sin\\left[\\frac{\\pi}{N+1}(n+1)(k+1)\\right] \\]"},{"location":"math-test/#_76","title":"\u5e26\u6709\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ W_{j,k} = \\sum_{n} x[n] \\psi_{j,k}[n] \\]"},{"location":"math-test/#_77","title":"\u5e26\u6709\u8fde\u7eed\u5c0f\u6ce2\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ W(a, b) = \\frac{1}{\\sqrt{|a|}} \\int_{-\\infty}^{\\infty} x(t) \\psi^*\\left(\\frac{t-b}{a}\\right) dt \\]"},{"location":"math-test/#_78","title":"\u5e26\u6709\u77ed\u65f6\u5085\u91cc\u53f6\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ X(\\tau, \\omega) = \\int_{-\\infty}^{\\infty} x(t) w(t-\\tau) e^{-j\\omega t} dt \\]"},{"location":"math-test/#_79","title":"\u5e26\u6709\u7ef4\u683c\u7eb3\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ W_x(t, \\omega) = \\int_{-\\infty}^{\\infty} x\\left(t + \\frac{\\tau}{2}\\right) x^*\\left(t - \\frac{\\tau}{2}\\right) e^{-j\\omega \\tau} d\\tau \\]"},{"location":"math-test/#_80","title":"\u5e26\u6709\u79d1\u6069\u7c7b\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ C_x(t, \\omega) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} A_x(\\theta, \\tau) \\phi(\\theta, \\tau) e^{j(\\theta t + \\tau \\omega - \\theta \\tau)} d\\theta d\\tau \\]"},{"location":"math-test/#_81","title":"\u5e26\u6709\u6a21\u7cca\u51fd\u6570\u7684\u516c\u5f0f","text":"\\[ A_x(\\theta, \\tau) = \\int_{-\\infty}^{\\infty} x\\left(t + \\frac{\\tau}{2}\\right) x^*\\left(t - \\frac{\\tau}{2}\\right) e^{j\\theta t} dt \\]"},{"location":"math-test/#_82","title":"\u5e26\u6709\u8c31\u56fe\u7684\u516c\u5f0f","text":"\\[ S_x(t, \\omega) = \\left| \\int_{-\\infty}^{\\infty} x(\\tau) w(\\tau - t) e^{-j\\omega \\tau} d\\tau \\right|^2 \\]"},{"location":"math-test/#_83","title":"\u5e26\u6709\u6807\u91cf\u56fe\u7684\u516c\u5f0f","text":"\\[ S_x(t, \\omega) = \\left| STFT_x(t, \\omega) \\right|^2 \\]"},{"location":"math-test/#_84","title":"\u5e26\u6709\u91cd\u6392\u7684\u516c\u5f0f","text":"\\[ R_x(t, \\omega) = \\iint S_x(t', \\omega') \\delta\\left(t - \\hat{t}(t', \\omega')\\right) \\delta\\left(\\omega - \\hat{\\omega}(t', \\omega')\\right) dt' d\\omega' \\]"},{"location":"math-test/#_85","title":"\u5e26\u6709\u540c\u6b65\u538b\u7f29\u7684\u516c\u5f0f","text":"\\[ T_x(t, \\omega) = \\frac{1}{g(\\omega)} \\iint S_x(t', \\omega') \\delta\\left(\\omega - \\hat{\\omega}(t', \\omega')\\right) dt' d\\omega' \\]"},{"location":"math-test/#_86","title":"\u5e26\u6709\u7ecf\u9a8c\u6a21\u6001\u5206\u89e3\u7684\u516c\u5f0f","text":"\\[ x(t) = \\sum_{i=1}^{n} c_i(t) + r_n(t) \\]"},{"location":"math-test/#-","title":"\u5e26\u6709\u5e0c\u5c14\u4f2f\u7279-\u9ec4\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ H(t, \\omega) = \\operatorname{Re} \\sum_{i=1}^{n} a_i(t) e^{j \\int \\omega_i(t) dt} \\]"},{"location":"math-test/#_87","title":"\u5e26\u6709\u53d8\u5206\u6a21\u6001\u5206\u89e3\u7684\u516c\u5f0f","text":"\\[ \\min_{\\{u_k\\}, \\{\\omega_k\\}} \\left\\{ \\sum_{k=1}^{K} \\left\\| \\partial_t \\left[ \\left( \\delta(t) + \\frac{j}{\\pi t} \\right) * u_k(t) \\right) e^{-j\\omega_k t} \\right\\|_2^2 \\right\\} \\]"},{"location":"math-test/#_88","title":"\u5e26\u6709\u7ecf\u9a8c\u5c0f\u6ce2\u53d8\u6362\u7684\u516c\u5f0f","text":"\\[ W(a, b) = \\frac{1}{\\sqrt{a}} \\int_{-\\infty}^{\\infty} x(t) \\psi^*\\left(\\frac{t-b}{a}\\right) dt \\]"},{"location":"math-test/#_89","title":"\u5e26\u6709\u591a\u91cd\u5206\u5f62\u53bb\u8d8b\u52bf\u6ce2\u52a8\u5206\u6790\u7684\u516c\u5f0f","text":"\\[ F_q(s) = \\left\\{ \\frac{1}{N_s} \\sum_{v=1}^{N_s} \\left[ F^2(v, s) \\right]^{q/2} \\right\\}^{1/q} \\]"},{"location":"math-test/#_90","title":"\u5e26\u6709\u53bb\u8d8b\u52bf\u79fb\u52a8\u5e73\u5747\u5206\u6790\u7684\u516c\u5f0f","text":"\\[ F_2(s) = \\sqrt{\\frac{1}{N-s+1} \\sum_{i=1}^{N-s+1} \\left[ Y(i) - \\tilde{Y}_s(i) \\right]^2} \\]"},{"location":"math-test/#_91","title":"\u5e26\u6709\u9012\u5f52\u5b9a\u91cf\u5206\u6790\u7684\u516c\u5f0f","text":"\\[ RR = \\frac{1}{N^2} \\sum_{i,j=1}^{N} R_{i,j} \\]"},{"location":"math-test/#_92","title":"\u5e26\u6709\u9012\u5f52\u71b5\u7684\u516c\u5f0f","text":"\\[ H_{rec} = -\\sum_{l=l_{\\min}}^{N} p(l) \\ln p(l) \\]"},{"location":"math-test/#_93","title":"\u5e26\u6709\u9012\u5f52\u7387\u7684\u516c\u5f0f","text":"\\[ DET = \\frac{\\sum_{l=l_{\\min}}^{N} l P(l)}{\\sum_{l=1}^{N} l P(l)} \\]"},{"location":"math-test/#_94","title":"\u5e26\u6709\u5c42\u6d41\u7387\u7684\u516c\u5f0f","text":"\\[ LAM = \\frac{\\sum_{l=1}^{l_{\\min}-1} l P(l)}{\\sum_{l=1}^{N} l P(l)} \\]"},{"location":"math-test/#_95","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u71b5\u7684\u516c\u5f0f","text":"\\[ RTD = -\\sum_{i=1}^{N} p_i \\ln p_i \\]"},{"location":"math-test/#_96","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ p_i = \\frac{\\tau_i}{\\sum_{j=1}^{N} \\tau_j} \\]"},{"location":"math-test/#_97","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\tau_i = t_i - t_{i-1} \\]"},{"location":"math-test/#_98","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ t_i = \\min \\{ t &gt; t_{i-1} : R_{i,j} = 1 \\} \\]"},{"location":"math-test/#_99","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ R_{i,j} = \\Theta(\\varepsilon - \\| \\vec{x}_i - \\vec{x}_j \\|) \\]"},{"location":"math-test/#_100","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Theta(x) = \\begin{cases} 1, &amp; x \\geq 0 \\\\ 0, &amp; x &lt; 0 \\end{cases} \\]"},{"location":"math-test/#_101","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\| \\vec{x}_i - \\vec{x}_j \\| = \\sqrt{\\sum_{k=1}^{d} (x_{i,k} - x_{j,k})^2} \\]"},{"location":"math-test/#_102","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\vec{x}_i = (x_{i,1}, x_{i,2}, \\ldots, x_{i,d}) \\]"},{"location":"math-test/#_103","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ x_{i,k} = x(t_i + (k-1)\\tau) \\]"},{"location":"math-test/#_104","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ t_i = t_0 + i \\Delta t \\]"},{"location":"math-test/#_105","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_106","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_107","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\tau = \\frac{1}{f_0} \\]"},{"location":"math-test/#_108","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_0 = \\frac{1}{\\tau} \\]"},{"location":"math-test/#_109","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ d = m \\tau \\]"},{"location":"math-test/#_110","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ m = \\frac{d}{\\tau} \\]"},{"location":"math-test/#_111","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\varepsilon = \\alpha \\sigma \\]"},{"location":"math-test/#_112","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\sigma = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\bar{x})^2} \\]"},{"location":"math-test/#_113","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\bar{x} = \\frac{1}{N} \\sum_{i=1}^{N} x_i \\]"},{"location":"math-test/#_114","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ x_i = x(t_i) \\]"},{"location":"math-test/#_115","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ t_i = t_0 + i \\Delta t \\]"},{"location":"math-test/#_116","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_117","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_118","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ t_0 = 0 \\]"},{"location":"math-test/#_119","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ i = 1, 2, \\ldots, N \\]"},{"location":"math-test/#_120","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{T}{\\Delta t} \\]"},{"location":"math-test/#_121","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_122","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_123","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{f_0} \\]"},{"location":"math-test/#_124","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_0 = \\frac{1}{T} \\]"},{"location":"math-test/#_125","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_126","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_k = k \\Delta f \\]"},{"location":"math-test/#_127","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ k = 0, 1, \\ldots, N-1 \\]"},{"location":"math-test/#_128","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_129","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_130","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_{\\max} = \\frac{f_s}{2} \\]"},{"location":"math-test/#_131","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_{\\min} = 0 \\]"},{"location":"math-test/#_132","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_{\\text{Nyquist}} = \\frac{f_s}{2} \\]"},{"location":"math-test/#_133","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s \\geq 2 f_{\\max} \\]"},{"location":"math-test/#_134","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_{\\max} = \\frac{f_s}{2} \\]"},{"location":"math-test/#_135","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = 2 f_{\\max} \\]"},{"location":"math-test/#_136","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_137","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_138","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_139","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_140","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_141","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_142","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_143","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_144","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_145","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_146","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_147","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_148","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_149","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_150","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_151","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_152","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_153","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_154","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_155","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_156","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_157","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_158","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_159","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_160","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_161","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_162","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_163","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_164","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_165","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_166","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_167","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_168","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_169","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_170","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_171","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_172","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_173","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_174","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_175","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_176","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_177","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_178","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_179","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_180","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_181","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_182","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_183","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_184","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_185","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_186","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_187","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_188","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_189","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_190","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_191","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_192","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_193","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_194","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_195","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_196","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_197","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_198","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_199","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_200","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_201","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_202","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_203","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_204","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_205","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_206","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_207","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_208","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_209","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_210","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_211","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_212","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_213","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_214","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_215","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_216","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_217","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_218","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_219","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_220","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_221","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_222","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_223","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_224","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_225","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_226","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_227","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_228","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_229","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_230","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_231","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_232","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_233","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_234","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_235","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_236","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_237","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_238","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_239","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_240","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_241","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_242","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_243","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_244","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_245","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_246","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_247","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_248","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_249","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_250","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_251","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_252","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_253","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_254","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_255","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_256","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_257","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_258","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_259","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_260","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_261","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_262","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_263","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_264","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_265","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_266","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_267","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_268","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_269","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_270","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_271","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_272","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_273","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_274","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_275","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_276","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_277","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_278","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_279","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_280","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_281","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_282","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_283","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_284","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_285","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_286","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_287","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_288","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_289","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_290","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_291","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_292","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_293","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_294","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_295","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_296","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_297","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_298","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_299","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_300","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_301","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_302","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_303","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_304","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_305","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_306","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_307","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_308","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_309","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_310","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_311","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_312","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_313","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_314","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_315","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_316","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_317","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_318","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_319","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_320","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_321","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_322","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_323","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_324","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_325","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_326","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_327","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_328","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_329","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_330","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_331","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_332","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_333","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_334","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_335","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_336","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_337","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_338","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_339","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_340","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_341","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_342","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_343","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_344","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_345","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_346","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_347","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_348","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_349","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_350","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_351","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_352","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_353","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_354","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_355","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_356","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_357","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_358","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_359","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_360","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_361","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_362","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_363","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_364","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_365","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_366","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_367","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_368","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_369","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_370","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_371","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_372","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_373","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_374","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_375","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_376","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_377","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_378","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_379","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_380","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_381","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_382","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_383","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_384","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_385","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_386","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_387","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_388","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_389","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_390","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_391","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_392","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_393","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_394","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_395","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_396","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_397","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_398","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_399","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_400","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_401","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_402","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_403","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_404","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_405","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_406","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_407","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_408","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_409","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_410","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_411","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_412","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_413","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_414","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_415","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_416","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_417","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_418","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_419","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_420","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_421","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_422","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_423","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_424","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_425","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_426","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_427","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_428","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_429","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_430","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_431","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_432","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_433","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_434","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_435","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_436","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_437","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_438","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_439","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{1}{f_s} \\]"},{"location":"math-test/#_440","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{f_s}{N} \\]"},{"location":"math-test/#_441","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{1}{\\Delta t} \\]"},{"location":"math-test/#_442","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta t = \\frac{T}{N} \\]"},{"location":"math-test/#_443","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = N \\Delta t \\]"},{"location":"math-test/#_444","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = \\frac{N}{T} \\]"},{"location":"math-test/#_445","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ \\Delta f = \\frac{1}{T} \\]"},{"location":"math-test/#_446","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{1}{\\Delta f} \\]"},{"location":"math-test/#_447","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ f_s = N \\Delta f \\]"},{"location":"math-test/#_448","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = \\frac{f_s}{\\Delta f} \\]"},{"location":"math-test/#_449","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ N = f_s T \\]"},{"location":"math-test/#_450","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"\\[ T = \\frac{N}{f_s} \\]"},{"location":"math-test/#_451","title":"\u5e26\u6709\u9012\u5f52\u65f6\u95f4\u5206\u5e03\u7684\u516c\u5f0f","text":"<p>$$ \\Delta t =</p>"},{"location":"about/","title":"\u5173\u4e8e\u6211","text":""},{"location":"about/#about","title":"About \ud83e\udd73","text":"<p> \u7ea6 414 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> \u4e2d\u6587English <p>\u4f60\u597d\uff01\u6211\u662f 6ch.\uff0c\u4e0a\u6d77\u4ea4\u901a\u5927\u5b66 24 \u7ea7\u4eba\u5de5\u667a\u80fd\u5b66\u9662\u4eba\u5de5\u667a\u80fd\uff08\u62d4\u5c16\u82f1\u624d\u8bd5\u70b9\u73ed\uff09\u7684\u672c\u79d1\u751f\u3002\u5f88\u9ad8\u5174\u80fd\u5728\u4e92\u8054\u7f51\u4e0a\u4e0e\u4f60\u76f8\u9047\ud83e\udd70\u3002</p> <p>\u6211\u5bf9\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u5177\u8eab\u667a\u80fd\u7b49\u9886\u57df\u5f88\u6709\u70ed\u60c5\uff0c\u4e5f\u559c\u6b22\u5206\u4eab\u81ea\u5df1\u7684\u5b66\u4e60\u7ecf\u9a8c\u548c\u601d\u8003\ud83e\udd13\u3002</p> <p>\u60f3\u4e86\u89e3\u6211\u7684\u5b66\u672f\u7ecf\u5386\uff1f\u53ef\u4ee5\u67e5\u770b\u6211\u7684\u5b66\u672f\u4e3b\u9875\ud83c\udf93\u3002</p> <p>\u5982\u679c\u6709\u4efb\u4f55\u95ee\u9898\uff0c\u6216\u8005\u60f3\u548c\u6211\u4ea4\u6d41\uff0c\u6b22\u8fce\u53d1\u90ae\u4ef6\u6216\u8005\u76f4\u63a5\u5728\u4e0b\u65b9\u7559\u8a00\uff0c\u6211\u4f1a\u5c3d\u5feb\u56de\u590d\ud83d\ude0e\u3002  \u5982\u679c\u4f60\u4e5f\u5728\u4e0a\u6d77\uff0c\u6b22\u8fce\u8054\u7cfb\u6211\u3002\u6211\u4eec\u53ef\u4ee5\u4e00\u8d77\u804a\u5929\u3001\u5b66\u4e60\uff0c\u6216\u8005\u4ea4\u6d41\u5171\u540c\u7684\u5174\u8da3\u7231\u597d\ud83d\udc7b\u3002</p> <p>GitHub \u70b9\u4e2a\u5173\u6ce8\u8c22\u8c22\u55b5\ud83d\ude3a\uff0cGitHub \u70b9\u4e2a\u5173\u6ce8\u8c22\u8c22\u55b5\ud83d\ude3a</p> <p>\u6211\u5e73\u65f6\u559c\u6b22\u542c\u97f3\u4e50(Eason!)\u3001\u9605\u8bfb\u3001\u6253\u7fbd\u6bdb\u7403\uff0c\u4e5f\u4f1a\u5728\u65e5\u8bb0\u4e2d\u8bb0\u5f55\u4e00\u4e9b\u76f8\u5173\u5185\u5bb9\uff0c\u5206\u4eab\u4e2a\u4eba\u611f\u53d7\u270d\u3002</p> <p>\u81f3\u4e8e\u6211\u7684\u540d\u5b57\u201c6ch.\u201d\u561b\uff0c\u89e3\u91ca\u8d77\u6765\u592a\u56f0\u96be\u4e86\uff0c\u5c31\u5f53\u662f\u6211\u968f\u4fbf\u53d6\u7684\u597d\u5566\uff01</p> <p>Hello. I'm 6ch!I'm an undergraduate student majoring in AI in the 24<sup>th</sup> grade at AI Honored Class, Shanghai Jiaotong University. I'm glad to meet you on the internet \ud83e\udd70.</p> <p>I am passionate about the fields of deep learning for computer vision, embodied AI, and I like to share my learning experience and thinking \ud83e\udd13.</p> <p>Want to know more about my academic experience? Check out my [academic homepage \ud83c\udf93] (.. /academy.md).</p> <p>If you have any questions or would like to communicate with me, please feel free to email or just leave a message below and I will reply as soon as possible \ud83d\ude0e. If you are also in Shanghai, feel free to contact me. We can chat, learn, or exchange common interests together \ud83d\udc7b.</p> <p>Follow my github thank you meow \ud83d\ude3a, follow my Github thank you meow \ud83d\ude3a~</p> <p>I usually like listening to music(Eason!), reading and playing badminton, and I also write diaries about it and share my personal feelings \u270d.</p> <p>As for my name \u201c6ch.\u201d, it's a long long story.</p>"},{"location":"diaries/","title":"Diaries \u270d","text":""},{"location":"diaries/#diaries","title":"Diaries \u270d","text":"<p>Abstract</p> <p>\u4e2a\u4eba\u65e5\u8bb0\uff0c\u4e3b\u8981\u8bb0\u5f55</p> <ul> <li>\u751f\u6d3b\u611f\u609f(Just Be Happy!)\uff1b</li> <li>\u8bfb\u4e66\u6458\u5f55\uff0c\u53ef\u80fd\u4f1a\u6709\u4e00\u4e9b\u7b14\u8bb0\uff1b</li> <li>\u4e00\u4e9b\u6742\u8c08\u3002</li> </ul> <p>\u4e00\u4e9b\u6bd4\u8f83\u6210\u4f53\u7cfb\u7684\u7b14\u8bb0\u4f1a\u8bb0\u5f55\u5728 Notes \u4e2d\u3002</p> <p>\u672c\u90e8\u5206\u5185\u5bb9\uff08\u9664\u7279\u522b\u58f0\u660e\u5916\uff09\u91c7\u7528 \u7f72\u540d-\u975e\u5546\u4e1a\u6027\u4f7f\u7528-\u4fdd\u6301\u4e00\u81f4 4.0 \u56fd\u9645 (CC BY-NC-SA 4.0) \u8bb8\u53ef\u534f\u8bae\u8fdb\u884c\u8bb8\u53ef\u3002</p>"},{"location":"diaries/#archives","title":"Archives","text":"<p>\u5982\u679c\u5bfb\u627e\u4e0d\u65b9\u4fbf\u7684\u8bdd\uff0c\u4e0d\u59a8\u8bd5\u8bd5\u641c\u7d22</p>"},{"location":"diaries/2024/20241226/","title":"20241226","text":"<p> \u7ea6 58 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u4e3b\u8981\u4efb\u52a1\uff1a</p> <ul> <li> 1.\u68b3\u7406\u671f\u672b\u8003\u8bd5\u590d\u4e60\u8ba1\u5212  </li> <li> 2.\u68b3\u7406\u5237\u8bfe\u8fdb\u5ea6\u5b89\u6392</li> <li> 3.\u5b8c\u6210\u6570\u5206\u4f5c\u4e1a</li> <li> 4.\u590d\u4e60\u82f1\u8bedquiz</li> <li> 5.\u505a\u8c22\u60e0\u6c11\u65e0\u7a77\u7ea7\u6570Part1\uff08\u5f85\u6574\u7406\uff09</li> <li> 6.\u5b8c\u6210\u7ebf\u4ee3\u4f5c\u4e1a</li> <li> 7.\u4e00\u7bc7tpo</li> </ul>"},{"location":"diaries/2024/20241231/","title":"20241231","text":"<p> \u7ea6 5 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u6700\u540e\u4e00\u5929\u4e86</p>"},{"location":"diaries/2025/Aug/","title":"8\u6708","text":""},{"location":"diaries/2025/Aug/#8","title":"8\u6708","text":"<p> \u7ea6 41 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"diaries/2025/Aug/#0805","title":"0805","text":"<p>\u8bfb\u4e86OCL\u8bba\u6587\uff08\u9664Appendix\u548cSupplementary\u7684\u90e8\u5206\uff09\uff0c\u770b\u4e86OCL\u7684metrics\u90e8\u5206\u4ee3\u7801</p>"},{"location":"diaries/2025/Aug/#0806","title":"0806","text":"<p>\u7eaf\u73a9\uff0c\u4e0b\u5348\u4e00\u76f4\u5728\u90e8\u7f72Qwen\uff0c\u4e0d\u592a\u4f1a\uff0c\u6446\u70c2\u4e86</p>"},{"location":"diaries/2025/1%E6%9C%88/20250101/","title":"20250101","text":"<p> \u7ea6 36 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>NEW YEAR RESOLUTION</p> <p>1.\u65c5\u884c</p> <p>2.\u6444\u5f71</p> <p>3.\u8f6c\u4e13\u4e1a</p> <p>4.\u770b\u4e00\u573a\u6f14\u5531\u4f1a</p> <p>5.Be Happy</p> <p>\u65b0\u7684\u4e00\u5e74\u8fd8\u5f97\u7ee7\u7eed\u52aa\u529b</p> <p>\u7ed3\u675f2.1\u7684\u300a\u6df1\u5ea6\u5b66\u4e60\u300b</p>"},{"location":"diaries/2025/2%E6%9C%88/20250228/","title":"20250228","text":"<p> \u7ea6 63 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u4eca\u5929\u665a\u4e0a\u53bb\u5357\u4f53\u8dd1\u4e86\u4f1a\u6b65\u3002\u7531\u4e8e\u662f\u590d\u5065\u72b6\u6001\uff0c\u53ea\u8dd1\u4e862.6\u516c\u91cc\uff0c\u817f\u7279\u522b\u9178\u75db\u3002\u611f\u89c9\u4ee5\u540e\u8fd8\u662f\u5f97\u6bcf\u5929\uff08\uff1f\uff09\u953b\u70bc\u4e00\u4e0b\uff0c\u6bd5\u7adf\u73b0\u5728\u597d\u4e45\u90fd\u6ca1\u6253\u7fbd\u6bdb\u7403\u4e86\uff0c\u8be5\u6362\u79cd\u8fd0\u52a8\u65b9\u5f0f\u4e86\u3002</p>"},{"location":"diaries/2025/3%E6%9C%88/20250301/","title":"20250301","text":"<p> \u7ea6 83 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u4eca\u5929\u82b1\u4e86\u597d\u4e45\u7ec8\u4e8e\u628a\u7f51\u7ad9\u642d\u597d\u4e86\u3002\u6700\u7ec8\u91c7\u7528Actions\u89e3\u51b3\u7684\uff0c\u7b49\u6709\u7a7a\u4e86\u5199\u4e2a\u7ecf\u9a8c\u5e16\u5b50\u3002</p> <p>\u4e0a\u5348\u53bb\u62cd\u4e86\u81f4\u8fdc\u65b0\u751f\u7167\uff0c\u611f\u89c9\u81ea\u5df1\u6700\u8fd1\u53c8\u7626\u4e86\u4e00\u70b9\uff0c\u53ef\u80fd\u8981\u66f4\u7cbe\u795e\u4e00\u4e9b\u3002</p> <p>\u4eca\u5929EECS\u5b66\u5230\u4e86\u7b2c\u516d\u8bfe\uff0c\u660e\u5929\u628aassignment02\u7ed9\u5199\u6389\u3002</p> <p>\u9644\u4e0a\u4eca\u65e5\u6253\u5361\uff1a</p>"},{"location":"diaries/2025/3%E6%9C%88/20250302/","title":"20250302","text":"<p> \u7ea6 361 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> Text Only<pre><code>\u4eca\u5929\u82b1\u4e86\u51e0\u4e4e\u4e00\u6574\u5929\u7684\u65f6\u95f4\u5b8c\u6210EECS498-A2\uff0c\u5e76\u4e14\u53ea\u662fA2\u7684\u4e00\u90e8\u5206(Linear Classifier)\u3002\u771f\u7684\u597d\u96be\u3002\u77e9\u9635\u6c42\u5bfc\u3001\u94fe\u5f0f\u6cd5\u5219\u3001\u5404\u79cd\u5de7\u5999\u7684\u53d8\u5f62\uff0c\u8d8a\u53d1\u89c9\u5f97\u5b66\u597d\u7ebf\u6027\u4ee3\u6570\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u6570\u5b66\u5728\u5176\u4e2d\u626e\u6f14\u7684\u91cd\u8981\u89d2\u8272\u3002\u5f88\u591a\u6280\u5de7\u4e5f\u53ef\u4ee5\u7528\u5230\u6570\u5b66\u5f53\u4e2d\u3002\u5f88\u591a\u65f6\u5019\u90fd\u641e\u4e0d\u592a\u61c2\u77e9\u9635\u7684\u5f62\u72b6\uff0c\u4e0d\u77e5\u9053\u600e\u4e48\u8fd0\u7b97\u624d\u662f\u6b63\u786e\u7684\u3002\u54ce~\u6162\u6162\u6765\u5427\n</code></pre> <p>\u200b   \u4e0b\u5348\u53bbA+\u4ff1\u4e50\u90e8\u9762\u8bd5\u4e86\uff0c\u611f\u89c9\u5c1a\u53ef\uff0c\u4ecb\u7ecd\u7684\u65f6\u5019\u8fd8\u662f\u6709\u70b9\u7d27\u5f20\u3002</p> <p>\u200b   \u665a\u4e0a\u8fd8\u6709\u5f88\u591a\u4e8b\u60c5\uff0c\u611f\u89c9\u6bcf\u5929\u90fd\u5728\u52aa\u529b\u5b66\u4e60\uff0c\u4e0d\u8fc7\u611f\u89c9\u6ca1\u6709\u771f\u6b63\u641e\u61c2\uff0c\u6548\u76ca\u4e0d\u5927\u3002\u4e0b\u5468\u53ef\u4ee5\u9002\u5f53\u8c03\u6574\u4e00\u4e0b\uff0c\u6bd4\u5982\u628a\u76f8\u5173\u7684\u77e5\u8bc6\u638c\u63e1\u7262\u9760\u518d\u7ee7\u7eed\u5b66\uff0ci.e.\u77e9\u9635\u6c42\u5bfc\uff0c\u53cd\u5411\u4f20\u64ad\u3002\u6211\u559c\u6b22\u62ffcsdiy\u91cc\u7684\u4e00\u53e5\u8bdd\u6fc0\u52b1\u81ea\u5df1\uff1a\u201c\u53ea\u6709\u4e00\u4e2a\u5ff5\u5934\uff0c\u5c31\u662f\u4f60\u6b63\u5728\u53d8\u5f3a\u3002\u201d</p> <p>\u200b   \u6700\u8fd1\u8bfe\u5185\u7684\u538b\u529b\u4e5f\u5f88\u5927\uff0c\u6570\u5206\u3001\u5927\u7269\u90fd\u5f00\u59cb\u4e0a\u96be\u5ea6\u4e86\uff0c\u5927\u7269\u771f\u7684\u597d\u96be\uff0c\u53ea\u80fd\u9760\u8003\u524d\u505a\u9898+\u62df\u5408\u4e86\u3002\u6982\u7edf\u7684\u8bdd\u4ee5\u540e\u8fd8\u662f\u4e0d\u53bb\u4e0a\u8bfe\u4e86\uff0c\u591a\u770b\u4e66\u5427\u3002</p> <p>\u200b   \u597d\u4e45\u6ca1\u53bb\u6253\u7403\u4e86\uff0c\u611f\u89c9\u8eab\u4f53\u771f\u7684\u8981\u751f\u9508\u4e86\u3002</p> <p>\u200b   \u4eca\u5929\u5929\u6c14\u5f88\u597d\uff0c\u9762\u8bd5\u7ed3\u675f\u4e4b\u540e\u53bb\u673a\u7535\u5927\u8349\u576a\u901b\u4e86\u4e00\u5708\uff0c\u8349\u576a\u4e0a\u957f\u6ee1\u4e86\u4eba\u3002\u597d\u591a\u4eba\u5728\u62cd\u7167\uff0c\u771f\u597d\u3002</p> <p>\u200b   \u8fd8\u662f\u7ee7\u7eed\u52aa\u529b\u5427\u3002</p> <p>\u8865\u4e00\u4e2a\u4eca\u5929\u7684\u5b66\u4e60\u65f6\u95f4\uff1a</p>"},{"location":"diaries/2025/3%E6%9C%88/20250303/","title":"20250303","text":"<p> \u7ea6 148 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u7ef7\u4e0d\u4f4f\u4e86\u4eca\u5929\u3002\u4eba\u600e\u4e48\u53ef\u4ee5\u8fd9\u4e48\u7b28\uff0c\u8fd9\u4e48\u8822\u3002\u3002\u3002</p> <p>\u6211\u4eca\u5929\u665a\u4e0a\u516d\u70b9\u4e0d\u5230\u5c31\u53bb\u7269\u7406\u5b9e\u9a8c\u5ba4\u4e86\uff0c\u7ed3\u679c\u5750\u4e86\u534a\u5929\u624d\u53d1\u73b0\u6211\u8be5\u662f\u4e0b\u5468\u505a\u3002</p> <p>\u4eca\u5929\u4e0a\u5348\u56fe\u4e66\u9986\u53c8\u8fdd\u7ea6\u4e86\uff0c\u6628\u5929\u665a\u4e0a\u62a2\u4e86\u4f4d\u7f6e\u5fd8\u8bb0\u6539\u65f6\u95f4\u4e86\u3002</p> <p>\u597d\u5728\u4eca\u5929\u6709\u4e2a\u597d\u6d88\u606f\u662f\u6211\u52a0\u5165A+\u4ff1\u4e50\u90e8\u4e86\uff0c\u53c8\u62a5\u540d\u53c2\u52a0\u4e86\u8363\u6636\u50a8\u624d\u8ba1\u5212\uff0c\u611f\u89c9\u8fd8\u4e0d\u9519\u3002</p> <p>\u4eca\u5929\u665a\u4e0a\u641e\u4e86\u4e09\u4e2a\u5c0f\u65f6\u7684A2\u7b14\u8bb0\uff0c\u8fd8\u662f\u6ca1\u6574\u61c2\uff0c\u6211\u771f\u7684\u670d\u4e86\u6211\u8fd9\u7b28\u8111\u5b50\u4e86\u3002\u3002\u3002</p> <p>\u9644\u4e0a\u4eca\u5929\u7684\u65f6\u95f4\u5b89\u6392\uff1a</p>"},{"location":"diaries/2025/3%E6%9C%88/20250304/","title":"20250304","text":"<p> \u7ea6 175 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u4eca\u5929\u4e0b\u5348\u53bb\u6e38\u6cf3\u4e86\uff0c\u597d\u4e45\u6e38\u6cf3\u4e86\uff0c\u524d\u9762\u8fd8\u5728\u6c34\u91cc\u6251\u817e\uff0c\u6cf3\u955c\u53c8\u6ca1\u5e26\u7d27\u3002\u4e0d\u8fc7\u57fa\u672c\u52a8\u4f5c\u8fd8\u6ca1\u600e\u4e48\u5fd8\uff0c\u6c34\u91cc\u662f\u771f\u7684\u51b7\u554a\uff0c\u8001\u5e08\u53c8\u4e0d\u8ba9\u4e71\u6e38\u3002\u3002</p> <p>\u4eca\u5929C++\u8bfe\u5927\u6982\u628a\u6628\u5929\u9057\u7559\u4e0b\u6765\u7684svm\u95ee\u9898\u770b\u61c2\u4e86\uff0c\u4ee5\u540e\u8fd8\u8981\u591a\u590d\u4e60\u3002</p> <p>\u54c7\u54c8\u54c8\uff01\uff01\u7ec8\u4e8e\u628acuda\u88c5\u597d\u4e86\uff0c\u6211\u771f\u670d\u4e86\uff0c\u672c\u6765C\u76d8\u90fd\u6ee1\u4e86\uff0c\u88c5\u5b8ccuda\u4e4b\u540e\u53cd\u800c\u591a\u4e8610\u4e2aG\uff1f\u5f88\u795e\u5947\u5427\uff01</p> <p>\u590f\u8001\u5e08\u8ba9\u6211\u53c2\u52a0\u4ed6\u4eec\u7684\u8bfe\u9898\u7ec4\uff0c\u90fd\u5f00\u59cb\u4e3a\u56fd\u521b\u8d5b\u51c6\u5907\u4e86\u3002\u6ca1\u60f3\u5230\u53bb\u5e74\u8fd8\u5728\u5f53\u5fd7\u613f\u8005\uff0c\u4eca\u5e74\u5c31\u8981\u5e2e\u4e0a\u5fd9\u4e86\uff08\u867d\u7136\u4e0d\u4e00\u5b9a\u80fd\u5e2e\u4e0a\u5565\u5927\u5fd9\uff09</p> <p>\u8d34\u4e2a\u4f7f\u7528\u65f6\u95f4\uff1a</p> <p></p>"},{"location":"diaries/2025/3%E6%9C%88/20250305/","title":"20250305","text":"<p> \u7ea6 210 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u4eca\u5929\u4e0b\u5348\u628a\u7535\u8111\u6454\u4e86\u3002\u3002\u3002\u5fc3\u788e</p> <p>\u4e2d\u5348\u8e6d\u4e86\u81f4\u8fdc\u7684\u514d\u8d39\u5348\u9910\uff0c\u662f\u98df\u5176\u5bb6\uff0c\u611f\u89c9\u5473\u9053\u4e00\u822c\uff0c\u53ef\u80fd\u6211\u5403\u4e0d\u6765\u548c\u725b\u5427\u3002</p> <p>\u4eca\u5929\u4e0b\u5348\u5f00\u4e86\u5e74\u7ea7\u5927\u4f1a\uff0c\u5e74\u7ea7\u6700\u9ad8\u5206\uff08\u673a\u68b0\u7c7b\uff09\u7adf\u7136\u662f92.6\uff01\u592a\u725b\u4e86\uff0c\u6bd4\u6211\u9ad8\u4e86\u6574\u65741.4\u5206\uff0c\u679c\u7136\uff0c\u4eba\u5916\u6709\u4eba\uff0c\u5929\u5916\u6709\u5929\u3002\u6700\u540e\u4e13\u4e1a\u5206\u6d41\u5927\u6982\u7387\u56de\u53bb\u5de5\u4e1a\u5de5\u7a0b\u5427\uff0c\u56e0\u4e3a\u6211\u5b9e\u5728\u5bf9\u786c\u4ef6\u63d0\u4e0d\u8d77\u5174\u8da3\u3002\u8fd8\u662f\u504f\u7801\u65b9\u5411\u9002\u5408\u6211\u3002</p> <p>\u4eca\u5929\u665a\u4e0a\u7ec8\u4e8e\u89e3\u51b3\u4e86\u4e00\u5927\u56f0\u6270\u6211\u7684\u96be\u9898\uff0c\u591a\u4e8f\u4e86StackExchange\u3002jupyter notebook\u7ecf\u5e38\u5d29\u6e83\uff0c\u8bf4\u67d0\u4e2adll\u6587\u4ef6\u591a\u5f00\uff0c\u6700\u540e\u628anumpy\u5378\u8f7d\u53c8\u91cd\u88c5\u5c31\u89e3\u51b3\u4e86\u3002\u6211\u89c9\u5f97\u5f88\u795e\u5947\u554a\uff0c\u6211\u90fd\u7528\u7684pytorch\uff0c\u6ca1\u60f3\u5230numpy\u8fd8\u80fd\u6765\u5f71\u54cd\u3002</p> <p>\u770b\u4eca\u665a\u4e0a\u80fd\u4e0d\u80fd\u628a\u6570\u5b66\u539f\u7406\u5728\u8fdb\u4e00\u6b65\u7406\u89e3\u5427\u3002</p> <p></p>"},{"location":"diaries/2025/3%E6%9C%88/20250307/","title":"20250307","text":"<p> \u7ea6 123 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>3.8\u8865\uff1a</p> <p>\u4eca\u5929\u7279\u522b\u96be\u53d7\uff0c\u6574\u5929\u90fd\u75c5\u600f\u600f\u7684\uff0c\u8868\u73b0\u4e3a\u7279\u522b\u56f0\u3002\u8fd8\u597d\u4eca\u5929\u7684\u8bfe\u5168\u90e8\u662f\u6c34\u8bfe\uff0c\u6211\u624d\u9003\u8fc7\u4e00\u52ab\u3002</p> <p>\u672c\u6765\u8fd8\u7ea6\u4e86\u56fe\u4e66\u9986\u7684\uff0c\u4f46\u662f\u6ca1\u5750\u4e00\u4f1a\u5c31\u6491\u4e0d\u4f4f\u4e86\uff0c\u4e8e\u662f\u4e03\u70b9\u5c31\u56de\u5bdd\u5ba4\u6d17\u6f31\u3002</p> <p>\u4e0b\u5348\u53bb\u4ea4\u4e86\u50a8\u624d\u8ba1\u5212\u7684\u7533\u8bf7\u8868\uff0c\u548c\u8f85\u5bfc\u5458\u4ea4\u6d41\u4e86\u4e00\u4e0b\uff0c\u6ca1\u60f3\u5230\u50a8\u624d\u8ba1\u5212\u4e3b\u8981\u662f\u63d0\u4f9b\u51fa\u56fd\u673a\u4f1a\uff0c\u9644\u5e26\u662f\u8ba4\u8bc6\u66f4\u591a\u7684\u4eba\u3002</p> <p>\u5e0c\u671b\u660e\u5929\u75c5\u80fd\u597d\u5427\u3002</p>"},{"location":"diaries/2025/3%E6%9C%88/20250312/","title":"20250312","text":"<p> \u7ea6 437 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <p>\u597d\u4e45\u6ca1\u66f4\u65b0\u7f51\u7ad9\u4e86\uff0c\u6700\u8fd1\u751f\u75c5\u4e86\uff0c\u5fc3\u60c5\u4e0d\u592a\u597d\u3002\u4eca\u5929\u597d\u4e0d\u5bb9\u6613\u6709\u7a7a\u95f2\u4e86\uff0c\u6765\u5199\u4e00\u5199\u65e5\u8bb0\u3002</p> <p>\u6700\u8fd1\u7684\u8ba1\u5212\u6709\u6240\u8f6c\u53d8\uff0c\u6839\u636e\u7fa4\u53cb\u7684\u5efa\u8bae\uff0c\u6211\u73b0\u5728\u51c6\u5907\u8ddf\u7740Karpathy\u7684\u4ece\u96f6\u5f00\u59cb\u6784\u5efaGPT\u5b66\u4e60\uff0c\u4e3b\u8981\u662f\u4e3a\u4e86\u80fd\u591f\u505a\u51fa\u4e00\u4e2a\u9879\u76ee\u3002\u540c\u65f6\u6211\u4e5f\u54a8\u8be2\u4e86\u5b9e\u9a8c\u5ba4\u7684\u5b66\u957f\uff0c\u4ed6\u7ed9\u6211\u63a8\u8350\u4e86Kaggle\u4e0a \u7684\u4e24\u4e2a\u9879\u76ee\uff0c\u4e0d\u8fc7\u6211\u770b\u4e86\u4e00\u4e0b\uff0c\u6ca1\u6709\u81ea\u5df1\u8981\u5b8c\u6210\u7684\u90e8\u5206\uff0c\u5168\u90e8\u90fd\u662f\u522b\u4eba\u5df2\u7ecf\u5199\u597d\u7684\u4ee3\u7801\uff0c\u6240\u4ee5\u6211\u51c6\u5907\u6700\u540e\u518d\u53bb\u770b\u770b\u3002</p> <p>\u5468\u5929\u56e0\u4e3a\u751f\u75c5\u561b\uff0c\u4e0b\u5348\u770b\u4e86\u4e24\u90e8\u7535\u5f71\uff0c\u300a\u8096\u7533\u514b\u7684\u6551\u8d4e\u300b\u548c\u300a\u963f\u7518\u6b63\u4f20\u300b\uff0c\u8fd9\u4e24\u90e8\u7535\u5f71\u4e4b\u524d\u4e5f\u770b\u8fc7\uff0c\u4e0d\u8fc7\u771f\u7684\u662f\u5e38\u770b\u5e38\u65b0\uff0c\u5c24\u5176\u662f\u8096\u7533\u514b\uff0c\u4eba\u7269\u5f62\u8c61\u523b\u753b\u7684\u592a\u597d\u4e86\uff0c\u771f\u7684\u597d\u559c\u6b22Freeman\u51fa\u72f1\u53bb\u6811\u4e0b\u627e\u76d2\u5b50\u7684\u90a3\u4e2a\u573a\u9762\uff0c\u611f\u89c9\u662f\u5728\u68a6\u91cc\u4f1a\u51fa\u73b0\u7684\u3002\u300a\u963f\u7518\u6b63\u4f20\u300b\u600e\u4e48\u8bf4\u5462\uff0c\u6211\u89c9\u5f97\u524d\u9762\u633a\u4e0d\u9519\u7684\uff0c\u7ed3\u5c3e\u611f\u89c9\u5267\u60c5\u6709\u70b9\u62d6\u6c93\uff0c\u786c\u662f\u62d6\u5230\u4e86\u4e24\u4e2a\u534a\u5c0f\u65f6\uff0c\u6211\u89c9\u5f97\u6ca1\u5565\u5fc5\u8981\u3002</p> <p>\u5468\u516d\u53c2\u52a0\u4e86A+\u4ff1\u4e50\u90e8\u7684\u8fce\u65b0\u4f1a\u548c\u665a\u9910\uff0c\u8ddf\u5b66\u957f\u4eec\u804a\u4e86\u5f88\u591a\uff0c\u611f\u89c9\u8fd9\u79cd\u805a\u4f1a\u592a\u5fc5\u8981\u4e86\uff0c\u56e0\u4e3a\u771f\u7684\u80fd\u6253\u7834\u4fe1\u606f\u5dee\uff01</p> <p>\u79bb\u8f6c\u4e13\u4e1a\u7684\u65f6\u95f4\u4e5f\u4e0d\u591a\u4e86\uff0c\u770b\u4e86\u4e00\u4e0b\u81ea\u5df1\u611f\u5174\u8da3\u7684\u65b9\u5411\uff0c\u5176\u5b9e\u5c31\u662fCV\uff0c\u4e0d\u60f3\u505a\u5177\u8eab\u667a\u80fd\u76f8\u5173\u7684\uff0c\u56e0\u4e3a\u8fd9\u6837\u7684\u8bdd\u8001\u5e08\u53ef\u80fd\u4f1a\u62f7\u6253\u6211\uff0c\u8ba9\u6211\u7559\u5728\u673a\u68b0\u4e86\u3002</p> <p>\u8eab\u4f53\u771f\u7684\u5f88\u91cd\u8981\u3002\u6211\u5468\u5929\u8fd8\u53bb\u6253\u4e86\u4f1a\u7403\uff0c\u7ed3\u679c\u771f\u7684\u7740\u4e0d\u4f4f\uff0c\u5934\u662f\u6655\u7684\uff0c\u6574\u4e2a\u4eba\u5934\u91cd\u811a\u8f7b\u3002\u8fd8\u597d\u5b66\u957f\u4e5f\u7406\u89e3\u6211\uff0c\u6211\u6253\u4e86\u534a\u4e2a\u5c0f\u65f6\u5c31\u8d70\u4e86\u3002</p> <p></p>"},{"location":"diaries/2025/3%E6%9C%88/20250315/","title":"20250315","text":"<p> \u7ea6 292 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u4e00\u5f00\u59cb\u4ee5\u4e3a\u767e\u56e2\u5927\u6218\u662f\u4eca\u5929\uff0c\u5230\u4e86\u5149\u4f53\u4e4b\u540e\u624d\u53d1\u73b0\u662f\u660e\u5929\uff0c\u54c8\u54c8\u54c8\u3002\u4e0d\u8fc7\u5462\uff0c\u6765\u90fd\u6765\u4e86\u561b\uff0c\u987a\u4fbf\u53bb\u7a0b\u53ca\u7f8e\u672f\u9986\u901b\u4e86\u4e00\u5708\u3002\u6765\u4ea4\u5927\u4e00\u4e2a\u5b66\u671f\u591a\u4e86\uff0c\u5305\u56fe\u4e5f\u53bb\u8fc7\u4e00\u767e\u591a\u6b21\u7684\u9009\u624b\uff0c\u7adf\u7136\u6ca1\u53bb\u8fc7\u7a0b\u53ca\u7f8e\u672f\u9986\uff1f\u56e0\u4e3a\u6211\u592a\u5fd9\u4e86\uff08\u90fd\u662f\u501f\u53e3\uff09\u3002\u91cc\u9762\u6709\u70b9\u50cf\u535a\u7269\u9986\uff0c\u5b9a\u671f\u8fd8\u4f1a\u6362\u5c55\u54c1\uff0c\u4e0d\u9519\u4e0d\u9519\u3002\u4e0d\u8fc7\u827a\u672f\u54c1\u6211\u8fd8\u662f\u6b23\u8d4f\u4e0d\u592a\u6765\uff0c\u611f\u89c9\u753b\u7684\u5927\u5dee\u4e0d\u5dee\uff0c\u5176\u5b9e\u5c31\u662f\u6211\u827a\u672f\u9020\u8be3\u592a\u4f4e\u4e86\u3002</p> <p>\u665a\u4e0a\u548c\u5ba4\u53cb\u51fa\u53bb\u723d\u5403\u7ea2\u65d7\u725b\u8089\uff0c\u4eba\u574745\uff0c\u771f\u662f\u5403\u723d\u4e86\u3002\u7f8a\u8089\u4e5f\u4e0d\u8165\uff0c\u5206\u91cf\u8fd8\u633a\u8db3\uff0c\u751a\u81f3\u8fde\u8471\u6cb9\u62cc\u9762\u90fd\u6ca1\u5403\u5b8c\u3002\u611f\u89c9\u771f\u5e78\u798f\u554a\u3002\u5e0c\u671b\u5728\u4ea4\u5927\u7684\u8fd9\u51e0\u5e74\u91cc\u80fd\u591f\u628a\u5b66\u6821\u5916\u9762\u7684\u9986\u5b50\u90fd\u5403\u4e00\u904d\u3002</p> <p>\u5403\u5b8c\u996d\u5c31\u53bb\u7ec3\u7434\u4e86\u3002\u6362\u7434\u5f26\u7684\u65f6\u5019\u4e00\u5f26\u53c8\u65ad\u4e86\uff0c\u5fc3\u788e\ud83d\udc94\u3002\u6700\u540e\u76f4\u63a5\u53bb\u5f39\u94a2\u7434\u4e86\uff0c\u770bb\u7ad9\u6559\u7a0b\u7b80\u5355\u5b66\u4e60\u4e86\u4e00\u4e0b\u952e\u4f4d\uff0c\u7136\u540e\u627e\u4e86\u300a\u6708\u7403\u4e0a\u7684\u4eba\u300b\u7684\u7b80\u8c31\u5f39\u4e86\u5f39\uff08\u5f53\u7136\u662f\u5355\u624b\u7684\uff09\uff0c\u611f\u89c9\u719f\u7ec3\u4e4b\u540e\u4e5f\u8fd8\u597d\u3002\u4e0b\u6b21\u8fd8\u5f39\u94a2\u7434\uff01</p> <p></p>"},{"location":"diaries/2025/3%E6%9C%88/20250316/","title":"20250316","text":"<p> \u7ea6 212 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u4e0a\u5348\u53bb\u50a8\u624d\u9762\u8bd5\u4e86\u3002\u591a\u8c22\u5b66\u957f\u5b66\u59d0\u4e0d\u6740\u4e4b\u6069\uff0c\u6ca1\u6709\u600e\u4e48\u62f7\u6253\u6211\u3002\u4e0d\u8fc7\u6211\u8bf4\u4e0d\u51fa\u6765\u5177\u8eab\u667a\u80fd\u7684\u5b9a\u4e49\uff0c\u611f\u89c9\u81ea\u5df1\u7b28\u7b28\u7684\u3002</p> <p>\u4e0b\u5348\u53bb\u548c\u5b66\u957f\u5b66\u59d0\u6253\u4e86\u4e00\u4e2a\u5c0f\u65f6\u5feb\u4e50\u7fbd\u6bdb\u7403\uff0c\u5b66\u59d0\u4eba\u771f\u597d\uff0c\u7ed9\u6211\u8bb2\u4e86\u4fe1\u606f\u5dee\u7684\u91cd\u8981\u6027\uff0c\u786e\u5b9e\u554a\uff0c\u5f88\u591a\u6210\u529f\u7684\u4eba\u4e0d\u662f\u8bf4\u4ed6\u4eec\u6709\u591a\u806a\u660e\uff0c\u53ea\u662f\u4ed6\u4eec\u4e86\u89e3\u7684\u4e1c\u897f\u6bd4\u522b\u4eba\u8981\u591a\uff0c\u77e5\u9053\u600e\u4e48\u505a\u662f\u6700\u7701\u65f6\u7684\uff0c\u7136\u540e\u5411\u7740\u201c\u6377\u5f84\u201d\u7684\u65b9\u5411\u52aa\u529b\u3002\u4e0d\u8fc7\u6211\u4e2a\u4eba\u8ba4\u4e3a\u6211\u5728\u8fd9\u65b9\u9762\u505a\u7684\u8fd8\u86ee\u597d\u7684~</p> <p>\u4eca\u5929\u665a\u4e0a\u6709\u767e\u56e2\u5927\u6218\u548c\u6c34\u706f\u8282\uff0c\u4e0d\u8fc7\u6211\u6ca1\u6709\u53bb\uff0c\u56e0\u4e3a\u6ca1\u6709\u4eba\u966a\u6211\uff08\u545c\u545c\u545c\uff09 \u597d\u5427\uff0c\u5176\u5b9e\u662f\u56e0\u4e3a\u6211\u592a\u61d2\u4e86\uff0c\u6253\u5b8c\u7403\u771f\u7684\u7d2f\u4e86\uff0c\u800c\u4e14\u4eca\u5929\u7684\u4efb\u52a1\u8fd8\u6709\u4e00\u70b9\u5c3e\u5df4\u3002</p> <p></p>"},{"location":"diaries/2025/3%E6%9C%88/20250317/","title":"20250317","text":"<p> \u7ea6 102 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u4eca\u5929\u6548\u7387\u6709\u70b9\u4f4e\uff0c\u611f\u89c9\u6700\u8fd1\u53c8\u6709\u70b9\u677e\u61c8\u4e0b\u6765\u4e86\u3002\u660e\u660e\u8fd8\u5269\u4e00\u4e2a\u6708\u4e0d\u5230\u7684\u65f6\u95f4\uff0c\u6211\u53ef\u80fd\u6709\u70b9\u8f7b\u654c\u4e86\u3002\u6211\u89c9\u5f97\u8fd8\u5f97\u662f\u8ba4\u771f\u5b66\uff0c\u811a\u8e0f\u5b9e\u5730\u7684\u5b66\uff0c\u800c\u4e0d\u662f\u8d70\u9a6c\u89c2\u82b1\u7684\u6cdb\u6cdb\u4e86\u89e3\u3002\u5982\u679c\u4e0d\u60f3\u5728\u9762\u8bd5\u7684\u65f6\u5019\u88ab\u62f7\u6253\u5c31\u4e00\u5b9a\u8981\u60f3\u6e05\u695a\uff0c\u7406\u89e3\u6e05\u695a\u3002\u8bd5\u7740\u641e\u6e05\u695a\u4e3a\u4ec0\u4e48\u8981\u8fd9\u4e48\u505a\uff01</p> <p></p>"},{"location":"diaries/2025/3%E6%9C%88/20250318/","title":"20250318","text":"<p> \u7ea6 103 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u6211\u4eec\u8fd9\u79cd\u5b64\u513f\u4ed4\uff0c\u6d41\u843d\u5230\u8c37\u5e95\uff0c\u6211\u6050\u6015\u662f\u70ed\u604b\u7684\u540e\u9057\u3002</p> <p>\u4eca\u5929\u665a\u4e0a\u7a81\u53d1\u5947\u60f3\u60f3\u542c\u5b64\u513f\u4ed4\uff0cEason\u548c\u82e6\u8363\u5408\u4f5c\u7684\u6b4c\u3002\u82e6\u8363\u7684\u58f0\u97f3\u5f88\u72ec\u7279\uff0c\u611f\u89c9\u50cf\u662f\u6545\u610f\u8fd9\u4e48\u5531\u7684\u3002\u542c\u591a\u4e86\u7a81\u7136\u60f3\u54ed\uff0c\u611f\u89c9\u8fd9\u9996\u6b4c\u7684\u60c5\u611f\u592a\u9971\u6ee1\u4e86\u3002</p> <p>\u4eca\u5929\u665a\u4e0a\u51c6\u5907\u770b\u300a\u4e09\u50bb\u5927\u95f9\u5b9d\u83b1\u575e\u300b\uff0c\u5230\u65f6\u5019\u770b\u5b8c\u6765\u5199\u89c2\u540e\u611f\u3002</p>"},{"location":"diaries/2025/3%E6%9C%88/20250320/","title":"20250320","text":"<p> \u7ea6 105 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u4eca\u5929\u4e0a\u5348\u53bb\u4f53\u6d4b\u8dd1\u6b65\u4e86\uff0c\u611f\u89c9\u592a\u4e45\u6ca1\u8dd1\u4e86\u6574\u4e2a\u4eba\u91cd\u5fc3\u6709\u70b9\u540e\u4ef0\uff0c\u8dd1\u5f97\u4e0d\u662f\u5f88\u5feb\u3002\u4e0b\u5348\u53c8\u53bb\u548c\u4e00\u4e2a\u5927\u4f6c\u6253\u7403\uff0c\u4ed6\u6253\u7684\u771f\u597d\u554a\uff0c\u6211\u540e\u6765\u624d\u53d1\u73b0\u6211\u548c\u8fd9\u4e2a\u5b66\u957f\u65b0\u751f\u676f\u7684\u65f6\u5019\u8fd8\u6253\u8fc7\uff0c\u5f53\u65f6\u5c31\u662f\u624b\u4e0b\u8d25\u5c06\uff0c\u4eca\u5929\u4f9d\u65e7\u662f\u6253\u4e0d\u8fc7\u3002\u665a\u4e0a\u548c\u5ba4\u53cb\u53bb\u5403\u4e86\u70e7\u70e4\uff0c\u5f88\u5f00\u5fc3\uff0c\u5c31\u662f\u6709\u70b9\u5c0f\u8d35\u3002</p>"},{"location":"diaries/2025/3%E6%9C%88/20250321/","title":"20250321","text":"<p> \u7ea6 1158 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 6 \u5206\u949f</p> <p>\u524d\u4e24\u5929\u90fd\u6ca1\u5199\u65e5\u8bb0\uff0c\u6700\u8fd1\u53c8\u5f00\u59cb\u8ff7\u832b\u4e86\u3002\u4e3b\u8981\u662f\u4ece\u96f6\u5f00\u59cb\u6784\u5efaGPT\u5feb\u770b\u5b8c\u4e86\uff0c\u82b1\u4e8630\u591a\u4e2a\u5c0f\u65f6\uff0c\u7a81\u7136\u4e00\u4e0b\u5b50\u65e0\u4e8b\u53ef\u5e72\u4e86\u3002\u6700\u8fd1\u60f3\u6b47\u4e00\u4e0b\u3002\u54c8\u54c8\u54c8\uff0c\u8fde\u8f93\u5165\u6cd5\u90fd\u89c9\u5f97\u6211\u5e94\u8be5\u4f11\u6574\u4e00\u4e0b\u4e86\u3002</p> <p>\u6700\u8fd1\u60f3\u5199\u4e00\u4e0b\u9879\u76ee\uff0c\u51c6\u5907\u5c31\u5199Karpathy\u7684minbpe\u4e86\u3002\u4f46\u662f\u611f\u89c9\u7b2c\u4e00\u6b21\u5199\u9879\u76ee\u50cf\u4e2a\u65e0\u5934\u82cd\u8747\u4e00\u6837\u4e0d\u77e5\u9053\u600e\u4e48\u6784\u5efa\u9879\u76ee\u624d\u7b97\u7f8e\u89c2\u5408\u7406\u3002\u5fd9\u4e86\u597d\u4e00\u9635\u5b50\u7a81\u7136\u95f2\u4e0b\u6765\u8fd8\u6709\u70b9\u4e0d\u4e60\u60ef\u3002\u660e\u660e\u77e5\u9053\u81ea\u5df1\u8fd8\u6709\u597d\u591a\u4e8b\u60c5\u6ca1\u505a\u4f46\u662f\u53c8\u6709\u70b9\u75b2\u60eb\u4e86\uff0c\u6ca1\u6709\u7cbe\u529b\u518d\u53bb\u8ba4\u771f\u505a\u4e86\u3002\u7136\u540e\u53c8\u60f3\u4e86\u60f3\u79d1\u7814\u7684\u4e8b\u60c5\uff0c\u7a81\u7136\u611f\u5230\u5bb3\u6015\u3002\u5012\u4e0d\u662f\u8bf4\u4e0d\u559c\u6b22\u79d1\u7814\uff0c\u53ea\u662f\u6211\u89c9\u5f97\u96be\u5ea6\u4e0d\u5c0f\u3002\u60f3\u8981\u4ece\u96f6\u5f00\u59cb\u56fa\u7136\u662f\u6709\u8da3\u7684\uff0c\u4f46\u662f\u786e\u5b9e\u5f88\u7d2f\u3002\u90a3\u79d1\u7814\u5b8c\u4e86\u53c8\u5e72\u4ec0\u4e48\u5462\uff1f\u53bb\u5de5\u4f5c\u5417\uff1f\u5de5\u4f5c\u53ef\u80fd\u548c\u6211\u5b66\u7684\u77e5\u8bc6\u5e76\u6ca1\u6709\u4ec0\u4e48\u7d27\u5bc6\u7684\u8054\u7cfb\u3002\u4e00\u60f3\u5230\u672a\u6765\u6709\u53ef\u80fd\u6210\u4e3a\u725b\u9a6c\uff0c\u7ed9\u522b\u4eba\u6253\u5de5\uff0c\u6211\u5c31\u53c8\u9677\u5165\u4e86\u6050\u60e7\u4e4b\u4e2d\u3002</p> <p>\u8fd8\u6709\uff0c\u611f\u89c9\u81ea\u5df1\u603b\u662f\u5728\u7ed9\u81ea\u5df1\u627e\u501f\u53e3\u3002\u6bd4\u5982\u6211\u60f3\u8ddf\u7740\u505aACM\u7684\u4f5c\u4e1a\uff0c\u4f46\u662f\u53c8\u4f1a\u7ed9\u81ea\u5df1\u627e\u501f\u53e3\u8bf4\u81ea\u5df1\u73b0\u5728\u4fa7\u91cdAI\uff0c\u7528\u7684\u90fd\u662fpython\u8bed\u8a00\uff0c\u5f88\u5c11\u7528C++\uff0c\u800c\u4e14\u5b66AI\u4e5f\u4e0d\u592a\u9700\u8981\u638c\u63e1\u975e\u5e38\u6df1\u523b\u7684C++\u77e5\u8bc6\uff0c\u6ca1\u5fc5\u8981\u4e3a\u96be\u81ea\u5df1\u3002\u4f46\u662f\u6211\u662f\u771f\u7684\u7fa1\u6155ACM\u73ed\u554a\uff0c\u4ed6\u4eec\u7684\u4f5c\u4e1a\u8d28\u91cf\u592a\u9ad8\u4e86\uff0c\u6216\u8bb8\u8fd9\u4e9b\u8bed\u8a00\u53ea\u662f\u8f7d\u4f53\uff0c\u6700\u7ec8\u7684\u8fd8\u662f\u7f16\u7a0b\u7684\u601d\u60f3\uff0c\u53ea\u4e0d\u8fc7\u6709\u4e0d\u540c\u7684\u8868\u8fbe\u5f62\u5f0f\u7f62\u4e86\u3002\u6211\u53c8\u60f3\u8ba4\u771f\u5b66\u6570\u636e\u7ed3\u6784\uff0c\u4f46\u662f\u5b9e\u5728\u662f\u5f88\u96be\uff0c\u800c\u4e14\u6211\u4e5f\u7ed9\u81ea\u5df1\u8bf4\u6570\u636e\u7ed3\u6784\u5bf9\u6211\u73b0\u5728\u5e2e\u52a9\u4e0d\u5927\u3002\u4ec0\u4e48\u90fd\u60f3\u5b66\uff0c\u4ec0\u4e48\u53c8\u90fd\u4e0d\u6562\u5b66\uff0c\u4ec0\u4e48\u90fd\u6ca1\u65f6\u95f4\u5b66\uff08\uff1f\u771f\u7684\u5417\uff09</p> <p>\u96be\u9053\u771f\u7684\u8f6c\u5230AI\u4e4b\u540e\u5c31\u4e07\u4e8b\u5927\u5409\u4e86\u5417\uff1f\u672a\u5fc5\u554a\uff01\u6211\u6216\u8bb8\u7f8e\u5316\u4e86\u4e00\u6761\u6211\u6ca1\u6709\u8d70\u8fc7\u7684\u9053\u8def\u3002AI\u8fd9\u4e2a\u98ce\u53e3\u8fd8\u80fd\u6d3b\u591a\u4e45\u5462\uff1f\u5176\u5b9e\u5e94\u8be5\u8fd8\u662f\u633a\u4e45\u7684\uff0c\u56e0\u4e3aAI\u4e0d\u53ea\u6709LLM\uff0c\u8fd8\u6709\u5177\u8eab\u667a\u80fd\uff0cRobotics\uff0cCV\u7b49\u7b49\u3002\u4f60\u60f3\u505a\u4ec0\u4e48\u90fd\u662f\u6709\u53ef\u80fd\u7684\uff0c\u4f60\u4e5f\u65e0\u6cd5\u9884\u6d4b\u672a\u6765\u662f\u4ec0\u4e48\u6837\u7684\u3002\u6700\u8fd1\u4e0a\u4e86Karpathy\u7684\u8bfe\u624d\u53d1\u73b0\u8fd9\u4e2a\u9886\u57df\u771f\u7684\u597d\u591a\u5927\u4f6c\uff0c\u5f88\u65e9\u4e4b\u524d\uff0c\u751a\u81f3\u5728gpt\u6ca1\u51fa\u6765\u4e4b\u524d\u5176\u5b9e\u5df2\u7ecf\u7814\u7a76\u8fc7\u5f88\u591a\u4e86\u3002\u4f60\u6562\u4fe1Transformer\u662f2017\u5e74\u51fa\u6765\u7684\uff08Attention is All You Need\u5c31\u662f2017\u5e74\u7684\u8bba\u6587\uff09\uff1f\u4f60\u6ca1\u529e\u6cd5\u9884\u6d4b\u4e0b\u4e00\u4e2a\u706b\u7684\u662f\u4ec0\u4e48\uff0c\u5c31\u53ea\u6709\u5148\u591a\u5b66\uff0c\u5148\u505a\u81ea\u5df1\u559c\u6b22\u7684\u65b9\u5411\uff0c\u56e0\u4e3a\u53ea\u8981\u9760\u8fd1AI\u7684\u65b9\u5411\u5176\u5b9e\u85aa\u8d44\u5f85\u9047\u4e0d\u4f1a\u592a\u5dee\uff08\u81f3\u5c11\u6bd4\u4f20\u7edf\u673a\u68b0\u7684\u597d\uff09\u3002</p> <p>\u603b\u662f\u5728\u4ef0\u671b\u522b\u4eba\uff0c\u603b\u662f\u770b\u522b\u4eba\u7684\u6210\u529f\u7ecf\u5386\u7136\u540e\u5e7b\u60f3\u81ea\u5df1\u7684\u672a\u6765\uff0c\u8fd9\u4e9b\u90fd\u662f\u4e0d\u592a\u597d\u7684\u3002\u5c31\u5728\u5fc3\u91cc\u60f3\u5c31\u597d\u4e86\uff0c\u628a\u8fd9\u4e9b\u5f53\u6210\u81ea\u5df1\u7684\u52a8\u673a\uff0c\u6fc0\u52b1\u81ea\u5df1\u524d\u8fdb\u5427\u3002\u5176\u5b9e\u79bb\u8f6c\u4e13\u4e1a\u8fd8\u6709\u4e00\u4e2a\u6708\uff0c\u8fd9\u4e00\u4e2a\u6708\u8bf4\u957f\u4e0d\u957f\uff0c\u8bf4\u77ed\u4e0d\u77ed\uff0c\u8fd8\u53ef\u4ee5\u505a\u5f88\u591a\u4e8b\u60c5\uff0c\u5c31\u770b\u81ea\u5df1\u7684\u610f\u613f\u4e86\u3002\u6211\u6216\u8bb8\u89c9\u5f97\u81ea\u5df1\u505a\u7684\u5df2\u7ecf\u591f\u4e86\uff0c\u53ef\u662f\u672a\u5fc5\u554a\uff0c\u4e5f\u6709\u5f88\u591a\u50cf\u6211\u4e00\u6837\u7684\u6697\u81ea\u52aa\u529b\u53d1\u594b\u7684\u4eba\uff0c\u8fd9\u4e9b\u4eba\u8bf4\u4e0d\u5b9a\u5377\u7684\u66f4\u5389\u5bb3\uff0c\u90a3\u6211\u8fd8\u6709\u4ec0\u4e48\u7406\u7531\u505c\u6ede\u4e0d\u524d\uff0c\u6cbe\u6cbe\u81ea\u559c\u5462\uff1f\u7559\u5728\u673a\u52a8\u5230\u5e95\u53ef\u4e0d\u53ef\u4ee5\u5462\uff1f\u8fd9\u8c01\u77e5\u9053\u5462\uff1f\u4f60\u6ca1\u529e\u6cd5\u540c\u65f6\u8d70\u4e24\u6761\u4e0d\u91cd\u5408\u7684\u9053\u8def\u554a\uff01\u4f46\u662f\u8bf4\u597d\u7684\u3001\u951a\u5b9a\u597d\u7684\u76ee\u6807\u5c31\u5343\u4e07\u4e0d\u8981\u4e34\u9635\u9000\u7f29\uff01</p> <p>\u6211\u89c9\u5f97\u6211\u73b0\u5728\u6709\u4e2a\u95ee\u9898\uff0c\u6ca1\u529e\u6cd5\u627e\u5230\u548c\u6211\u6c34\u5e73\u76f8\u8fd1\u7684\u540c\u9f84\u4eba\u3002\u6211\u6ca1\u6709\u6e20\u9053\uff08\u53c8\u5728\u7ed9\u81ea\u5df1\u627e\u501f\u53e3\u4e86\uff09\u8ba4\u8bc6\u8fd9\u4e9b\u4eba\uff0c\u5927\u4f6c\u6211\u53c8\u89c9\u5f97\u9ad8\u4e0d\u53ef\u6500\u3002\u6ca1\u529e\u6cd5\u8f93\u51fa\u7684\u95ee\u9898\u6211\u6700\u8fd1\u4e5f\u611f\u53d7\u5230\u4e86\uff0c\u6ca1\u529e\u6cd5\u771f\u6b63\u7406\u89e3\u3002\u5c31\u597d\u6bd4\u8d39\u66fc\u5b66\u4e60\u6cd5\uff0c\u5f53\u7136\u53ef\u4ee5\u8bb2\u7ed9\u81ea\u5df1\u542c\uff0c\u4f46\u662f\u8ddf\u540c\u9f84\u4eba\u8bb2\u66f4\u80fd\u638c\u63e1\u900f\u5f7b\uff0c\u4e5f\u80fd\u6536\u83b7\u53cb\u8c0a\uff0c\u66f4\u80fd\u77e5\u9053\u522b\u4eba\u662f\u600e\u4e48\u60f3\u7684\uff0c\u522b\u4eba\u72ec\u7279\u7684\u89c1\u89e3\u3002\u6211\u89c9\u5f97\u6211\u81ea\u5df1\u8fd8\u662f\u6709\u70b9\u81ea\u79c1\u7684\uff0c\u4e0d\u613f\u610f\u8ba9\u522b\u4eba\u77e5\u9053\u6211\u7684\u6c34\u5e73\uff0c\u4e0d\u613f\u610f\u66f4\u522b\u4eba\u4ea4\u6d41\uff0c\u8fd9\u6837\u4e5f\u80fd\u7f13\u89e3\u6211\u8fd9\u65b9\u9762\u7684\u7f3a\u9677\u3002</p> <p>\u4e0d\u77e5\u9053\u8fd9\u6837\u8fd8\u80fd\u575a\u6301\u591a\u4e45\uff0c\u5176\u5b9e\u6ca1\u6709\u4ebapush\u771f\u7684\u4f1a\u677e\u61c8\u3002\u4f46\u662f\u8fd8\u6709\u4e00\u4e2a\u6708\u4e86\uff0c\u628a\u5b83\u5f53\u6210\u9ad8\u8003\u5427\uff0c\u6700\u540e\u51b2\u523a\u9636\u6bb5\u8981\u4f11\u606f\u597d\uff0c\u4f46\u662f\u4e5f\u8981\u4fdd\u6301\u4e4b\u524d\u7684\u6c34\u5e73\uff0c\u5bf9\u5e94\u7684\u67e5\u6f0f\u8865\u7f3a\uff01</p> <p>\u5927\u5b66\u751f\u5c31\u662f\u723d\u554a\uff01</p> <p></p>"},{"location":"diaries/2025/3%E6%9C%88/20250322/","title":"20250322","text":"<p> \u7ea6 369 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <p>\u4eca\u5929\u4e0b\u5348\u53bb\u5e02\u4e2d\u5fc3\u5f90\u6c47\u73a9\u4e86\uff0c\u63d0\u524d\u7ed9\ud83e\udd5a\u8fc7\u751f\u65e5\uff0c\u540c\u884c\u7684\u8fd8\u6709\u975e\u54e5\u3001log\u3001\ud83e\udd86\u54e5\u3002\u73a9\u7684\u5f88\u5f00\u5fc3\uff0c\u5148\u662f\u53bb\u6b66\u5eb7\u8defcitywalk\u4e86\uff0c\u53bb\u62cd\u4e86\u4e00\u4e9b\u7167\u7247\uff0c\u90a3\u91cc\u7684\u5efa\u7b51\u786e\u5b9e\u5f88\u6709\u53e4\u5473\uff0c\u4e5f\u89c1\u5230\u4e86\u4e09\u89d2\u5f62\u7684\u5927\u53a6\u3002\u540e\u9762\u53c8\u53bb\u4ea4\u5927\u5f90\u6c47\u6821\u533a\u901b\u4e86\u4e00\u5708\uff0c\u611f\u89c9\u8fd8\u633a\u597d\u73a9\u7684\uff0c\u867d\u7136\u4e4b\u524d\u53bb\u8fc7\u4e00\u6b21\u4e86\u3002\u4eca\u5929\u597d\u591a\u6bd5\u4e1a\u751f\u5728\u62cd\u7167\uff0c\u771f\u597d\u554a\u3002\u8fd8\u6709\u5f88\u591aMBA\u7684\u5927\u4f6c\uff08\u91d1\u878d\u7cbe\u82f1\uff09\u611f\u89c9\u5f88\u725b\u3002</p> <p>\u665a\u4e0a\u53bb\u5403\u4e86\u70e4\u9c7c\uff0c\u662f\u957f\u6c99\u98ce\u5473\uff0c\u786e\u5b9e\u5f88\u8fa3\u3002\u6700\u540e\u53bb\u73a9\u4e86\u4e24\u4e2a\u5c0f\u65f6\u7684switch \uff0c\u5148\u73a9\u4e86\u4f1a\u6c34\u679c\u5207\u5207\u5207\uff0c\u633a\u597d\u73a9\u7684\uff0c\u4e0d\u8fc7\u6211\u53d1\u73b0\u6211\u771f\u7684\u4e0d\u592a\u9002\u5408\u5bf9\u6297\u7c7b\u7684\u6e38\u620f\uff0c\u6211\u53ef\u80fd\u66f4\u9002\u5408\u60f3\u80e1\u95f9\u53a8\u623f\u8fd9\u79cd\u591a\u4eba\u5408\u4f5c\u7c7b\u7684\u6e38\u620f\u5427\u3002\u7136\u540e\u53c8\u73a9\u4e86\u4efb\u5929\u5802\u5927\u4e71\u6597\uff0c\u8fde\u8d62\u4e86\u4e24\u628a\u5c31\u662f\u8bf4\uff0c\u611f\u89c9\u968f\u4fbf\u4e71\u6309\u6309\u952e\uff0c\u53ea\u8981\u4fdd\u8bc1\u81ea\u5df1\u4e0d\u6389\u4e0b\u53bb\u5c31\u80fd\u8d62\u3002\u6700\u540e\u5462\u73a9\u4e86\u4f1a\u8d85\u7ea7\u9e21\u9a6c\uff0c\u8fd9\u6e38\u620f\u662f\u771f\u7684\u96be\u83b7\u80dc\u3002\u9e2d\u54e5\u662f\u6709\u6e38\u620f\u5929\u8d4b\u7684\uff0c\u8d62\u4e86\u597d\u591a\u628a\u3002\u6700\u540e\u5f88\u820d\u4e0d\u5f97\u8bf4\u518d\u89c1\uff0c\u56e0\u4e3a\u73a9\u7684\u771f\u7684\u4e0d\u4ea6\u4e50\u4e4e\uff01</p> <p>\u5230\u4e86\u5927\u5b66\u73a9\u7684\u6700\u597d\u7684\u7adf\u7136\u8fd8\u662f\u9ad8\u4e2d\u540c\u5b66\uff0c\u5176\u5b9e\u8fd9\u4e5f\u7b97\u6b63\u5e38\u5427\u3002\u4e5f\u53ef\u80fd\u662f\u6211\u4e0d\u613f\u610f\u4ea4\u65b0\u670b\u53cb\uff0c\u4e0d\u8fc7\u6211\u73b0\u5728\u5927\u90e8\u5206\u4e00\u4e2a\u4eba\u611f\u89c9\u633a\u597d\u7684\uff0c\u81f3\u5c11\u6211\u8db3\u591f\u81ea\u7531\uff0c\u53ef\u4ee5\u5e72\u81ea\u5df1\u60f3\u5e72\u7684\u4e8b\u60c5\u3002</p>"},{"location":"diaries/2025/3%E6%9C%88/20250323/","title":"20250323","text":"<p> \u7ea6 266 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u4eca\u5929\u4e0b\u5348\u53bb\u542c\u4e86ACM\u548cJohn\u73ed\u5b66\u957f\u5b66\u59d0\u7684\u5206\u4eab\u3002\u6211\u60f3\u8bf4\u4e0d\u6127\u662f\u975e\u5e38\u806a\u660e\u7684\u4eba\uff0c\u5206\u4eab\u7684\u6761\u7406\u903b\u8f91\u5341\u5206\u6e05\u6670\u3002\u6211\u4ece\u4e2d\u4e5f\u5b66\u4e60\u5230\u4e86\u5f88\u591a\u3002\u5176\u4e2d\u6709\u4e24\u4f4d\u90fd\u63d0\u5230\u4e86\u505a\u8ba1\u5212\u505a\u603b\u7ed3\uff0c\u4e00\u5468\u4e00\u6b21\uff0c\u5199\u6e05\u695a\u81ea\u5df1\u672c\u5468\u5e72\u4e86\u4ec0\u4e48\uff0c\u4e0b\u4e00\u5468\u7684\u8ba1\u5212\u53c8\u662f\u4ec0\u4e48\u3002\u6211\u5e73\u65f6\u53ea\u5199\u65e5\u8bb0\uff0c\u50cf\u6d41\u6c34\u5e10\u4e00\u6837\uff0c\u4f46\u662f\u771f\u6b63\u6709\u7528\u7684\u4e1c\u897f\u4e0d\u662f\u5f88\u591a\uff0c\u66f4\u591a\u90fd\u53ea\u662f\u673a\u68b0\u7684\u8bb0\u5f55\u4e00\u5929\u53d1\u751f\u4e86\u4ec0\u4e48\uff0c\u5076\u5c14\u4f1a\u6df1\u523b\u7684\u5256\u6790\uff0c\u4f46\u662f\u8fd8\u4e0d\u591f\u3002\u6240\u4ee5\u8bf4\u4ece\u8fd9\u5468\u5f00\u59cb\u8fdb\u884c\u6bcf\u5468\u4e00\u6b21\u7684\u5468\u7ed3\u3002\u5468\u7ed3\u7684\u8bdd\u5c31\u4e0d\u8981\u8bb0\u5f55\u751f\u6d3b\u4e0a\u7684\u4e8b\u4e86\uff0c\u4e3b\u8981\u8fd8\u662f\u8bb0\u5f55\u4e00\u4e0b\u5b66\u672f\u751f\u6d3b\u4e0a\u7684\u5185\u5bb9\uff0c\u907f\u514d\u548c\u65e5\u8bb0\u91cd\u590d\uff0c\u4e5f\u907f\u514d\u65e0\u75c5\u547b\u541f\uff0c\u8bf4\u4e00\u4e9b\u6ca1\u6709\u8425\u517b\u7684\u8bdd\u3002</p> <p>\u7533\u8bf7\u8fd8\u771f\u96be\u554a\uff0c\u4e5f\u633a\u7384\u5b66\u7684\u3002Connection\u662f\u771f\u7684\u91cd\u8981\uff0c\u5f88\u591a\u65f6\u5019\u4e5f\u770b\u8fd0\u6c14\u548c\u4e0e\u4eba\u4ea4\u6d41\u7684\u80fd\u529b\uff0c\u627e\u5b66\u957f\u5b66\u59d0\u4e0d\u5c31\u5f97\u9760\u81ea\u5df1\u53bb\u8054\u7cfb\u5417\uff1f</p>"},{"location":"diaries/2025/3%E6%9C%88/20250324/","title":"20250324","text":"<p> \u7ea6 158 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u4eca\u5929\u53d1\u73b0\u8ba1\u5212\u5f97\u4fee\u6539\u4e00\u4e0b\u3002\u91cd\u65b0\u5b66\u4e00\u4e0bpytorch\u3002\u5df2\u7ecf\u5f00\u59cb\u8ddf\u7740\u89c6\u9891\u7cfb\u7edf\u5b66\u4e60computer vision\u4e86\u3002\u611f\u89c9\u8fd8\u662f\u6709\u70b9\u6536\u8d27\u7684\uff0c\u8ba4\u8bc6\u5230\u4e86\u5b98\u65b9\u6587\u6863\u7684\u91cd\u8981\u6027\uff0c\u771f\u7684\u5f88\u91cd\u8981\uff01\u96be\u602aKarpathy\u8fd9\u4e48\u559c\u6b22\u8bfb\u5b98\u65b9\u6587\u6863\uff0c\u539f\u6765\u80fd\u4e86\u89e3\u5f88\u591a\u4e1c\u897f\uff0c\u4e5f\u53ef\u4ee5\u953b\u70bc\u82f1\u8bed\u9605\u8bfb\u80fd\u529b\u3002</p> <p>\u665a\u4e0a\u7684\u5b9e\u9a8c\u505a\u5f97\u4e0d\u597d\u3002\u6211\u662f\u771f\u7684\u8ba8\u538c\u4e5f\u4e0d\u9002\u5408\u5b9e\u9a8c\uff0c\u65e0\u8bba\u662f\u4e0a\u5b66\u671f\u7684\u5316\u5b66\u8fd8\u662f\u8fd9\u5b66\u671f\u7684\u7269\u7406\u3002\u770b\u6765\u6211\u662f\u771f\u7684\u9002\u5408\u7801\u519c\uff0c\u53ef\u80fd\u4e5f\u4e0d\u592a\u9002\u5408\u673a\u5668\u4eba\u65b9\u5411\u7684\u4e86\u3002\u7406\u8bba\u4e5f\u8fd8\u4e0d\u9519\u3002</p>"},{"location":"diaries/2025/3%E6%9C%88/20250325/","title":"20250325","text":"<p> \u7ea6 43 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u4eca\u5929\u8fc7\u5f97\u5f88\u5e73\u6de1\uff0c\u6ca1\u6709\u53bb\u56fe\u4e66\u9986\u4e5f\u6ca1\u6709\u7fd8\u8bfe\u3002\u4e00\u5207\u6b63\u5e38\u3002\u665a\u4e0a\u770b\u4e86\u300a\u5fe0\u72ac\u516b\u516c\u7684\u6545\u4e8b\u300b\uff0c\u5f88\u68d2\uff0c\u4e5f\u770b\u54ed\u4e86\u3002\u4e0b\u5468\u7ee7\u7eed\uff01</p>"},{"location":"diaries/2025/3%E6%9C%88/20250326/","title":"20250326","text":"<p> \u7ea6 124 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u521a\u521a\u53f3\u952e\u65b0\u5efa\u6587\u4ef6\u7684\u65f6\u5019\u7adf\u7136\u627e\u4e0d\u5230txt\u4e86\uff0c\u771f\u7684\u5f88\u795e\u5947\u3002\u6211\u6000\u7591\u6211\u7684\u7535\u8111\u88abWPS\u52ab\u6301\u4e86\uff0c\u4e0d\u8fc7\u521a\u521a\u7ec8\u4e8e\u5f04\u597d\u4e86\u3002\u4eca\u5929\u4e0b\u5348\u4e00\u76f4\u5728\u5b66CNN\uff0c\u611f\u89c9\u6548\u7387\u4e00\u822c\uff0c\u56e0\u4e3a\u57fa\u672c\u4e0a\u5149\u770b\u6ca1\u52a8\u624b\u5199\u4ee3\u7801\u3002\u665a\u4e0a\u628acatordog\u5206\u7c7b\u5668\u91cd\u6784\u4e86\u4e00\u4e0b\uff0c\u56de\u5bdd\u5ba4\u8dd1\u4e00\u8dd1\uff0c\u6211\u4e0d\u6562\u5728\u56fe\u4e66\u9986\u8dd1\uff0c\u56e0\u4e3a\u566a\u58f0\u6709\u4e00\u70b9\u5927\u3002\u4eca\u5929\u539f\u795e\u66f4\u65b0\u4e86\uff0c\u56de\u53bb\u542f\u52a8\u3002</p> <p>\u8865\u4e2a\u4eca\u5929\u7684\u5b89\u6392\uff1a</p>"},{"location":"diaries/2025/3%E6%9C%88/20250327/","title":"20250327","text":"<p> \u7ea6 54 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u723d\u4e86\uff0c\u7b2c\u4e00\u6b21\u8bad\u7ec3\u4e00\u4e2a\u771f\u6b63\u7684CNN\u6a21\u578b\uff0c\u8fd9\u4e00\u6b21\u8bad\u7ec3\u4e867\u5206\u949f\uff0c\u867d\u7136\u6211\u7684\u663e\u5361\u662f4060\u7684\u5df2\u7ecf\u8ddf\u4e0d\u4e0a\u65f6\u4ee3\u4e86\uff0c\u4f46\u662f\u8bad\u7ec3\u4e00\u6b21\u6a21\u578b\u8fd8\u662f\u5f88\u723d\u7684\u3002</p>"},{"location":"diaries/2025/3%E6%9C%88/20250328/","title":"20250328","text":"<p> \u7ea6 31 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5c0f\u65f6\u7684\u6b8b\u5dee\u7248CNN\uff0c\u7ed3\u679c\u51c6\u786e\u7387\u8fd8\u6ca1CNN\u9ad8\uff0c\u6655\u3002\u662f\u6211\u6253\u5f00\u65b9\u5f0f\u4e0d\u5bf9\u5417\uff1f</p> <p></p>"},{"location":"diaries/2025/3%E6%9C%88/20250331/","title":"20250331","text":"<p> \u7ea6 5 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u8f6c\u4e13\u4e1a\u542f\u52a8\uff01</p>"},{"location":"diaries/2025/4%E6%9C%88/20250401/","title":"20250401","text":"<p> \u7ea6 55 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u4eca\u5929\u665a\u4e0a\u628a\u8f66\u8f86\u68c0\u6d4b\u91cd\u65b0\u5f04\u4e86\u4e00\u4e0b\uff0c\u771f\u4e0d\u9519\u3002\u8c03\u53c2\u6570\u7684\u65f6\u5019\u5f88\u5f00\u5fc3\uff0c\u6709\u4e00\u79cd\u4e3a\u4e86\u76ee\u6807\u800c\u594b\u6597\u7684\u7f8e\u3002\u4e00\u5f00\u59cb\u6211\u4ee5\u4e3a\u81ea\u5df1\u505a\u4e0d\u5230\uff0c\u7ed3\u679c\u8fd8\u53ef\u4ee5\u3002</p>"},{"location":"diaries/2025/4%E6%9C%88/20250402/","title":"20250402","text":"<p> \u7ea6 93 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u6211\u592a\u559c\u6b22\u5199\u4ee3\u7801\u4e86\uff01\u4eca\u5929\u665a\u4e0a\u5199\u723d\u4e86\uff0c\u7528\u7eb8\u548c\u7b14\u63a8\u5bfc\u6570\u5b66\u516c\u5f0f\uff0c\u518d\u628a\u516c\u5f0f\u8f93\u5165\u5230jupyter notebook\u4e2d\uff0c\u70b9\u51fb\u8fd0\u884c\uff0c\u6210\u529f\u7684\u559c\u60a6\u77ac\u95f4seizes me.\u4eca\u65e5\u5b8c\u6210\uff1aCanny Edge Detector and Hough Line Transforms \u6570\u5b66\u539f\u7406+\u4ee3\u7801\u5b9e\u73b0</p> <p>\u867d\u7136\u641e\u4e86\u6709\u56db\u4e2a\u5c0f\u65f6\uff08\uff1f\uff09\u6211\u611f\u89c9\u65f6\u95f4\u8fc7\u5f97\u597d\u5feb\uff0c\u4f46\u662f\u5f88\u6295\u5165\uff0c\u5f88\u5f00\u5fc3\uff01</p>"},{"location":"diaries/2025/4%E6%9C%88/20250404/","title":"20250404","text":"<p> \u7ea6 47 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u4eca\u5929\u53bb\u62cd\u7167\u4e86\uff0c\u611f\u89c9\u8fd8\u4e0d\u9519\u3002\u5929\u6c14\u771f\u597d\uff0c\u5b66\u6821\u91cc\u771f\u6f02\u4eae\u554a\u3002\u5c31\u50cf\u662f\u516c\u56ed\u91cc\u9762\u4fee\u4e86\u5ea7\u5b66\u6821\u3002\u7c7b\u4f3c\u516c\u56ed\u91cc\u4fee\u4e86\u4e00\u5ea7\u57ce\u5e02\uff08\u201c\u6210\u90fd\u201d\uff09</p>"},{"location":"diaries/2025/4%E6%9C%88/20250406/","title":"20250406","text":"<p> \u7ea6 198 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u4eca\u5929\u4e0a\u534811\u70b9\u624d\u8d77\uff0c\u5c5e\u5b9e\u662f\u521b\u9020\u5386\u53f2\u4e86\uff0c\u4e0a\u5348\u8fde\u5fd9\u8d76\u53bb\u6253\u7fbd\u6bdb\u7403\u9009\u62d4\u9662\u961f\uff0c\u5176\u5b9e\u611f\u89c9\u81ea\u5df1\u6c34\u5e73\u4e0b\u964d\u633a\u660e\u663e\u7684\uff0c\u5e78\u8fd0\u7684\u662f\u8fd8\u662f\u9009\u4e0a\u4e86\u9662\u961f\u3002</p> <p>\u665a\u4e0a\u590f\u8001\u5e08\u6765\u627e\u6211\u804a\u5929\u804a\u4e86\u5f88\u4e45\uff0c\u6536\u83b7\u4e86\u5f88\u591a\u3002\u6ca1\u60f3\u5230\u6070\u597d\u5f15\u7528\u4e86\u6211\u660e\u5929\u8981\u8bb2\u7684\u201cFake it till you make it.\u201d\u590f\u8001\u5e08\u4eba\u592a\u597d\u4e86\uff0c\u660e\u786e\u652f\u6301\u6211\u60f3\u6e05\u695a\u4e86\u8f6c\u4e13\u4e1a\u7684\u4e8b\u60c5\uff0c\u4e5f\u7ed9\u6211\u8bf4\u4e86\u4e00\u4e9b\u6211\u5e94\u8be5\u5bf9\u672a\u6765\u751f\u6d3b\u7684\u601d\u8003\u548c\u8003\u91cf\u3002\u4f46\u662f\u8bf4\u5230\u8fd9\u91cc\u53c8\u6709\u4e9b\u8ff7\u832b\u4e86\uff0c\u4e0d\u77e5\u9053\u81ea\u5df1\u662f\u5426\u9002\u5408\u641e\u79d1\u7814\u3002\u6211\u662f\u4e0d\u662f\u81ea\u79c1\u7684\u4eba\u5462\uff1f\u6211\u7684\u5bb6\u5ead\u652f\u4e0d\u652f\u6301\u6211\u51fa\u56fd\u5462\uff1f\u672a\u5fc5\u3002\u5f88\u591a\u4e8b\u60c5\u4e5f\u53ea\u6709\u8d70\u4e00\u6b65\u770b\u4e00\u6b65\u4e86</p>"},{"location":"diaries/2025/4%E6%9C%88/20250407/","title":"20250407","text":"<p> \u7ea6 48 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u6bcf\u5468\u56fa\u5b9a\u7834\u9632 \u6211\u771f\u670d\u4e86</p> <p>\u6211\u771f\u7684\u4e0d\u662f\u505a\u5b9e\u9a8c\u7684\u6599\u554a\uff0c\u6211\u611f\u89c9\u81ea\u5df1\u52a8\u624b\u80fd\u529b\u597d\u5dee\u3002\u90a3\u4e2a\u5b9e\u9a8c\u6570\u636e\u4e5f\u5f88\u96be\u5904\u7406\uff0c\u771f\u7684\u7834\u9632\u4e86\u3002</p>"},{"location":"diaries/2025/4%E6%9C%88/20250411/","title":"20250411","text":"<p> \u7ea6 111 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u4eca\u5929\u6536\u5230\u4e86\u901a\u77e5\uff0c\u770b\u5230\u5165\u9009AI\u73ed\u9762\u8bd5\u4e86\uff0c\u611f\u89c9\u538b\u529b\u5f88\u5927\uff0c\u56e0\u4e3a\u8ddf\u6211\u7ade\u4e89\u7684\u670916\u4e2a\u4eba\uff0c\u91cc\u9762\u8fd8\u6709\u5df2\u7ecf\u964d\u8f6c\u8fc7\u7684\u540c\u5b66\u300123\u7ea7\u7684\u540c\u5b66\u3001\u8ba1\u7b97\u673a\u4e13\u4e1a\u7684\u540c\u5b66\uff0c\u8fd9\u4e9b\u4eba\u90fd\u5f88\u5389\u5bb3\uff0c\u4e0d\u8fc7\u6211\u81ea\u5df1\u4e5f\u51c6\u5907\u7684\u5f88\u5145\u5206\u4e86\uff0c\u5fc5\u987b\u80cc\u6c34\u4e00\u6218\u3002</p> <p>\u660e\u5929\u8fd8\u8981\u53bb\u6253\u4f53\u603b\u676f\uff0c\u4e0d\u77e5\u9053\u80fd\u53d1\u6325\u51fa\u51e0\u6210\u529f\u529b\uff0c\u4e0d\u8fc7\u5f00\u5fc3\u5c31\u597d\u561b\uff01</p>"},{"location":"diaries/2025/4%E6%9C%88/20250412/","title":"20250412","text":"<p> \u7ea6 165 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u4eca\u5929\u4f53\u603b\u676f\u8fd8\u662f\u592a\u7d27\u5f20\u4e86\uff0c\u6ca1\u53d1\u6325\u51fa\u6765\u5168\u90e8\u5b9e\u529b\uff0c\u7136\u540e\u6211\u4eec\u961f\u6ca1\u80fd\u5c0f\u7ec4\u51fa\u7ebf\u3002\u4e0d\u8fc7\u4e5f\u8fd8\u597d\uff0c\u597d\u4e45\u6ca1\u6709\u6253\u56e2\u4f53\u8d5b\u4e86\uff0c\u4e5f\u7b97\u662f\u627e\u56de\u4e86\u4e00\u70b9\u5c0f\u5b66\u51fa\u53bb\u6253\u6bd4\u8d5b\u7684\u611f\u89c9\u3002</p> <p>\u665a\u4e0a\u4e00\u65f6\u5174\u8d77\uff0c\u6253\u7b97\u91cd\u65b0\u770b\u4e00\u904d\u300a\u7591\u72af\u8ffd\u8e2a\u300b\uff0c\u6211\u8fd8\u8bb0\u5f97\u521d\u4e2d\u7684\u65f6\u5019\u770b\u5230\u7b2c\u4e09\u5b63\u4e86\uff08\uff1f\uff09\uff0c\u8fd8\u5728\u82f1\u8bed\u8bfe\u5802\u4e0a\u5206\u4eab\u8fc7\u8fd9\u90e8\u5267\u3002\u611f\u89c9\u4e00\u4e0b\u5b50\u56de\u5230\u4e86\u521d\u4e2d\u3002\u65f6\u95f4\u8fc7\u5f97\u771f\u5feb\u554a\uff01</p> <p>\u505a\u7684\u68a6\u662f\u6709\u70b9\u79bb\u5947\u7684\uff1a\u6211\u80fd\u5728\u68a6\u91cc\u548c\u540c\u5b66\u63a2\u8ba8\u201c\u68a6\u201d\u8fd9\u4ef6\u4e8b\uff0c\u8bf4\u6211\u53c8\u5728\u68a6\u91cc\u9884\u77e5\u9898\u76ee\u7684\u80fd\u529b\uff0c\u592a\u795e\u5947\u4e86\uff01</p>"},{"location":"diaries/2025/4%E6%9C%88/20250416/","title":"20250416","text":"<p> \u7ea6 431 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <p>\u9762\u8bd5\u7684\u65f6\u5019\u611f\u89c9\u4e0d\u592a\u7d27\u5f20\uff0c\u4f46\u662f\u8fdb\u53bb\u4e4b\u524d\u8fd8\u662f\u6709\u70b9\u7d27\u4e86\u3002\u5b8c\u5168\u53ef\u4ee5\u653e\u5f00\u8868\u8fbe\u81ea\u5df1\u7684\u60f3\u6cd5\uff0c\u591a\u6c9f\u901a\u561b\u3002\u4ee5\u771f\u5fc3\u6362\u771f\u5fc3\u3002</p> <p>\u4eba\u7a81\u7136\u6ca1\u6709\u538b\u529b\u4e86\u5c31\u60f3\u54ed\u3002\u3002\u3002</p> <p>\u8fd9\u79cd\u5982\u91ca\u91cd\u8d1f\u7684\u611f\u89c9\u597d\u96be\u5f97\u3002</p> <p>\u6765\u597d\u597d\u8c08\u4e00\u8c08\u611f\u53d7\u5427\u3002\u8bf4\u5b9e\u8bdd\uff0c\u611f\u89c9\u4ece\u5927\u4e00\u5165\u5b66\u4ee5\u6765\u5c31\u592a\u7d27\u7ef7\u4e86\uff0c\u4f60\u53ef\u4ee5\u8bf4\u8fd9\u662f\u4e3a\u4e86\u76ee\u6807\u201cWhatever it takes\u201d\uff0c\u4f46\u662f\u5b9e\u9645\u4e0a\u51fa\u73b0\u4e86\u4e00\u4e9b\u95ee\u9898\uff0c\u76f2\u76ee\u5730\u5377\uff0c\u53ea\u662f\u53bb\u5237\u9898\uff0c\u56e0\u4e3a\u53ea\u6709\u5237\u9898\u80fd\u591f\u4fdd\u8bc1\u5b66\u79ef\u5206\u7684\u63d0\u5347\uff0c\u867d\u7136\u63d0\u5347\u4e0d\u4e00\u5b9a\u591a\uff0c\u4f46\u662f\u81f3\u5c11\u4e0d\u4f1a\u4e0b\u964d\u3002\u800c\u53c2\u52a0\u4e00\u4e9b\u6d3b\u52a8\u867d\u7136\u4e5f\u4e0d\u4e00\u5b9a\u4f7f\u5b66\u79ef\u5206\u4e0b\u964d\uff0c\u4f46\u8fd8\u662f\u6709\u98ce\u9669\uff0c\u4e3a\u4e86\u4fdd\u9669\uff0c\u8fd8\u662f\u6ca1\u6709\u600e\u4e48\u53c2\u52a0\u6d3b\u52a8\u3002\u4e0a\u5b66\u671f\u8ddf\u522b\u4eba\u4ea4\u6d41\u8fd8\u662f\u5c11\u4e86\u3002</p> <p>\u800c\u6211\u81ea\u5df1\u505a\u7684\u51c6\u5907\u8fd8\u662f\u6b20\u7f3a\u4e86\u4e00\u4e9b\uff0c\u6211\u5e94\u8be5\u518d\u8fdb\u4e00\u6b65\uff0c\u800c\u4e0d\u662f\u4ecd\u7136\u505c\u7559\u5728\u4e00\u4e2a\u6708\u4e4b\u524d\u7684\u6c34\u5e73\u4ee5\u53ca\u9879\u76ee\u3002\u4f46\u662fWHO KNOWS?\u6211\u662fAI\u9662\u7b2c\u4e00\u5c4a\u8f6c\u4e13\u4e1a\u7684\uff0c\u6ca1\u4eba\u8bf4\u7684\u51c6\u8fd9\u79cd\u5f62\u5f0f\u6216\u8005\u8bf4\u8003\u6838\u65b9\u6cd5\uff0c\u8003\u6838\u5185\u5bb9\u3002\u6211\u80fd\u505a\u5230\u7684\u5c31\u53ea\u6709\u5305\u88c5\u5b8c\u5584\u6211\u5df2\u6709\u7684\u7ecf\u5386\u9879\u76ee\uff0c\u4e89\u53d6\u4e0d\u7559\u9057\u61be\u3002</p> <p>\u6211\u611f\u89c9\u81ea\u5df1\u60f3\u592a\u591a\u800c\u505a\u592a\u5c11\u4e86\uff0c\u603b\u662f\u754f\u5934\u754f\u5c3e\uff0c\u800c\u5b9e\u9645\u5e72\u7684\u4e8b\u81ea\u5df1\u4ee5\u4e3a\u8fd8\u4e0d\u9519\uff0c\u5b9e\u5219\u6f0f\u6d1e\u767e\u51fa\u3002\u6211\u8fd8\u662f\u9700\u8981\u52aa\u529b\u554a\uff01\u5148\u7ed9\u81ea\u5df1\u653e\u51e0\u5929\u5047\uff0c\u4ece\u8fd9\u4e2a\u5468\u672b\u5f00\u59cb\u53c8\u7ee7\u7eed\u5427\uff01\u8fd9\u4e0b\u53ef\u4ee5\u771f\u6b63\u5b66\u4e60\u81ea\u5df1\u611f\u5174\u8da3\u7684\u4e1c\u897f\u4e86\uff01</p> <p>\u6211\u53ef\u80fd\u4f1a\u8003\u8651\u8fdb\u7ec4\u800c\u4e0d\u662f\u7ee7\u7eed\u5b66\u4e60\u516c\u5f00\u8bfe\uff0c\u6bd5\u7adf\u540e\u8005\u79bb\u79d1\u7814\u4ea7\u4e1a\u8fd8\u662f\u6709\u4e00\u5b9a\u8ddd\u79bb\u3002</p>"},{"location":"diaries/2025/4%E6%9C%88/20250418/","title":"20250418","text":"<p> \u7ea6 49 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u6cea\u6c34\u6d8c\u4e0a\u5fc3\u5934\u3002</p> <p>\u5b9e\u5728\u662f\u592a\u611f\u52a8\u4e86\u3002\u53ea\u60f3\u54ed\u3002\u524d\u9762\u771f\u7684\u5f88\u7d2f\uff0c\u4f46\u662f\u62ff\u5230\u7ed3\u679c\u7684\u4e00\u5239\u90a3\u53ea\u6709\u6fc0\u52a8\u548c\u611f\u6069\u3002</p> <p>\u8010\u5fc3\u7684\u4eba\u624d\u80fd\u770b\u5230\u7ae5\u8bdd\u3002</p>"},{"location":"diaries/2025/4%E6%9C%88/20250425/","title":"20250425","text":"<p> \u7ea6 40 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u8ddd\u79bb\u8f6c\u4e13\u4e1a\u6210\u529f\u4e5f\u4e00\u4e2a\u5468\u4e86\uff0c\u611f\u89c9\u751f\u6d3b\u4e0a\u81ea\u7531\u4e86\u5f88\u591a\uff0c\u4e5f\u653e\u6162\u4e86\u811a\u6b65\u3002\u8fd8\u662f\u5f97\u7ed9\u81ea\u5df1\u627e\u4e00\u70b9\u4e8b\u60c5\u505a\uff01</p>"},{"location":"diaries/2025/5%E6%9C%88/20250514/","title":"20250514","text":"<p> \u7ea6 256 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u7a81\u7136\u610f\u8bc6\u5230\u81ea\u5df1\u5df2\u7ecf\u6709\u5f88\u4e45\u6ca1\u6709\u5199\u65e5\u8bb0\u4e86\uff0c\u4eca\u5929\u770b\u5230\u6c34\u6e90\u4e0a\u7684\u5e16\u5b50\u624d\u53d1\u73b0\u6709\u4eba\u548c\u6211\u4e00\u6837\u6709\u8bb0\u65e5\u8bb0\u7684\u4e60\u60ef\uff0c\u4e0d\u8fc7\u4ed6\u6bcf\u5929\u80fd\u5199\u52301.5k\u5b57\u5de6\u53f3\uff0c\u771f\u7684\u5f88\u5389\u5bb3\u3002\u6700\u8fd1\u5728\u8f6c\u4e13\u4e1a\u4e4b\u540e\uff0c\u6709\u70b9\u6446\u70c2\uff0c\u53ef\u80fd\u662f\u77e5\u9053\u53ea\u7528\u53ca\u683c\u5c31\u884c\uff0c\u4e5f\u6709\u53ef\u80fd\u662f\u771f\u7684\u4e00\u6446\u5c31\u505c\u4e0d\u4e0b\u6765\u4e86\u3002\u603b\u89c9\u5f97\u81ea\u5df1\u7406\u6240\u5f53\u7136\u7684\u5e94\u8be5\u6446\u70c2\uff0c\u201c\u62a5\u590d\u6027\u6446\u70c2\u201d\u3002\u4f46\u662f\u8fd8\u6709\u4e00\u4e2a\u6708\u5c31\u671f\u672b\u8003\u8bd5\uff0c\u8fd9\u4e2a\u671f\u672b\u8981\u8003\u7684\u79d1\u76ee\u5c24\u5176\u7684\u591a\uff0c\u4e0d\u77e5\u9053\u600e\u4e48\u5e94\u5bf9\u4e86\u3002\u6700\u8fd1\u770b\u8d77\u6765\u4e0d\u5fd9\uff0c\u4f46\u5b9e\u9645\u4e0a\u6709\u5404\u79cd\u5de5\u4f5c\u8981\u505a\u3002\u8bfe\u7a0b\u5e94\u4ed8\u7684\u8fd8\u884c\uff0c\u4e0d\u77e5\u9053\u540e\u9762\u4f1a\u600e\u4e48\u6837\u3002\u867d\u7136\u8bf4\u53ca\u683c\u5c31\u884c\uff0c\u4f46\u6211\u6253\u5fc3\u91cc\u8fd8\u662f\u89c9\u5f97\u5e94\u8be5\u8003\u597d\u4e00\u4e9b\u3002\u5426\u5219\u53ef\u80fd\u90fd\u6ca1\u529e\u6cd5\u4fdd\u7814\u4e86\u3002\u6700\u8fd1\u53c8\u5f00\u59cb\u8ff7\u604b\u4e0a\u4e86\u539f\u795e\uff0c\u56e0\u4e3a\u62bd\u5230\u4e86\u65b0\u89d2\u8272\uff0c\u611f\u89c9\u8fd9\u4e2a\u6e38\u620f\u8fd8\u4e0d\u9519\uff0c\u5728\u7b49\u4e0b\u4e2a\u7248\u672c\u7684\u65b0\u89d2\u8272~</p>"},{"location":"diaries/2025/6%E6%9C%88/20250601/","title":"20250601","text":"<p> \u7ea6 155 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u6700\u8fd1\u592a\u61d2\u4e86\uff0c\u5c06\u8fd1\u4e00\u4e2a\u6708\u6ca1\u6709\u5199\u8fc7\u65e5\u8bb0\u4e86\u3002\u611f\u89c9\u4e0a\u4e2a\u6708\u4e5f\u633a\u9893\u5e9f\u7684\uff0c\u5377\u4e0d\u52a8\u4e86\u3002\u672c\u6765\u8fd8\u8bf4\u6309\u7167\u8ba1\u5212\u590d\u4e60\u7684\uff0c\u4f46\u662f\u4e5f\u6ca1\u6709\u575a\u6301\u4e0b\u6765\u3002\u54ce\u3002\u6ca1\u5173\u7cfb\uff0c\u8fd9\u4e2a\u6708\u8003\u5b8c\u5c31\u6682\u65f6\u7ed3\u675f\u4e86\u3002\u4f46\u662f\u6211\u771f\u7684\u597d\u60f3\u56de\u5bb6\u554a\uff0c\u8fd8\u8981\u4e00\u4e2a\u534a\u6708\u624d\u80fd\u56de\u53bb\u3002\u60f3\u5230\u4e0b\u5b66\u671f\u6211\u5c31\u5927\u4e8c\u4e86\uff0c\u65f6\u95f4\u8fc7\u5f97\u597d\u5feb\uff0c\u611f\u89c9\u81ea\u5df1\u8fd8\u662f\u521a\u8fdb\u6821\u7684\u65b0\u751f\uff0c\u5f88\u591a\u4e1c\u897f\u53d1\u751f\u7684\u592a\u5feb\u4e86\uff0c\u5f53\u7136\uff0c\u6211\u662f\u6ca1\u4ec0\u4e48\u611f\u89c9\u5bf9\u7684\uff0c\u56e0\u4e3a\u8fd9\u4e00\u5b66\u5e74\u57fa\u672c\u4e0a\u90fd\u662f\u56f4\u7ed5\u7740\u8f6c\u4e13\u4e1a\u5c55\u5f00\u7684\u3002</p>"},{"location":"diaries/2025/6%E6%9C%88/20250612/","title":"20250612","text":"<p> \u7ea6 609 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> <p>\u8bb0\u68a6</p> <p>\u6545\u4e8b\u5f00\u7aef\u5728\u5730\u94c1\u7ad9\uff0c\u5730\u94c1\u7ad9\u5185\u8fc7\u5b89\u68c0\u7684\u65f6\u5019\uff0c\u6211\u4eec\u90fd\u8fc7\u4e86\u5b89\u68c0\uff0c\u7136\u540e\u6211\u4eec\u540e\u9762\u6709\u4e00\u4e2a\u4f53\u578b\u7a0d\u80d6\u7684\u7537\u5b50\uff0c\u5b89\u68c0\u7684\u65f6\u5019\u600e\u4e48\u626b\u90fd\u53d1\u51fa\u54d4\u54d4\u54d4\u7684\u58f0\u97f3\uff0c\u4f46\u662f\u786e\u5b9e\u5e76\u6ca1\u6709\u770b\u5230\u8fdd\u7981\u7269\u54c1\uff0c\u4f46\u662f\u90a3\u4e2a\u5b89\u68c0\u4eba\u5458\u6267\u610f\u8bf4\u4ed6\u5f88\u80d6\uff0c\u8eab\u4e0a\u6709\u4e1c\u897f\u3002\u8fd9\u65f6\u5019\u6211\u5c31\u6253\u62b1\u4e0d\u5e73\uff0c\u95ee\u5b89\u68c0\u4eba\u5458\uff0c\u4e3a\u4ec0\u4e48\u80d6\u5c31\u4e00\u5b9a\u4f1a\u8fdd\u6cd5\u5462\uff0c\u4ec0\u4e48\u65f6\u5019\u80d6\u4e5f\u4f1a\u88ab\u6b67\u89c6\u4e86\u3002\u6211\u8fd8\u8bb0\u5f97\u90a3\u4e2a\u7537\u4eba\u624b\u81c2\u4e0a\u6709\u7eb9\u8eab\uff0c\u7ed3\u679c\u540e\u6765\u4ed6\u597d\u50cf\u6253\u4e86\uff08\uff1f\uff09\u90a3\u4e2a\u5b89\u68c0\u4eba\u5458\uff0c\u7136\u540e\u6211\u4eec\u5c31\u8dd1\u4e86\uff08\u6211\u4eec\uff1a\u6211\uff0c\u5988\u5988\uff0c\u59b9\u59b9\uff0c\u5976\u5976\uff09</p> <p>\u540e\u6765\u9003\u554a\u9003\uff0c\u770b\u5230\u4e86\u53f2\u6d69\u5b8f\u548c\u674e\u5f66\u5b8f\uff0c\u674e\u5f66\u5b8f\u8bf4\u4ed6\u521a\u4ece\u6cd5\u56fd\u7559\u5b66\u56de\u6765\uff0c\u4ed6\u6bcf\u6b21\u653e\u5047\u90fd\u4f1a\u56de\u6765\u3002\u7136\u540e\u4e0d\u77e5\u9053\u662f\u56e0\u4e3a\u6211\u4eec\u804a\u7684\u592a\u6295\u5165\u4e86\u8fd8\u662f\u600e\u4e48\u7684\uff0c\u6211\u4eec\u8e29\u5230\u4e86\u522b\u4eba\u5730\u91cc\u7684\u85af\u7247\uff08\uff1f\u53cd\u6b63\u662f\u8106\u8106\u7684\uff09\uff0c\u7acb\u9a6c\u5c31\u6709\u4e2a\u7537\u4eba\u8ffd\u8fc7\u6765\uff0c\u6211\u76f4\u63a5\u8df3\u5230\u4e86\u6cb3\u5bf9\u5cb8\uff0c\u7ed3\u679c\u90a3\u4e2a\u4eba\u6307\u5b9a\u6211\u662f\u7f6a\u9b41\u7978\u9996\u3002\u6ca1\u529e\u6cd5\uff0c\u6211\u5c31\u6284\u8d77\u9b54\u6cd5\u626b\u5e1a\uff08\uff1f\u4e0d\u77e5\u9053\u600e\u4e48\u79f0\u547c\uff0c\u5c31\u662f\u6070\u65af\u5361\u7528\u6765\u98de\u7684\u90a3\u628a\u67aa\uff09\uff0c\u7136\u540e\u5782\u76f4\u7684\u98de\u8dc3\u8fc7\u4e00\u680b\u9ad8\u697c\uff0c\u6446\u8131\u4e86\u90a3\u4e2a\u4eba\u7684\u8ffd\u6355\u3002</p> <p>\u6211\u964d\u843d\u5230\u4e86\u4e00\u4e2a\u6709\u5f88\u591a\u719f\u4eba\u5728\u7684\u57ce\u5e02\uff0c\u8857\u9053\u662f\u7a84\u7a84\u7684\u903c\u4ec4\u7684\uff0c\u5230\u5904\u90fd\u662f\u6b66\u4fa0\u5c0f\u8bf4/\u7535\u89c6\u5267\u7684\u6d77\u62a5\uff0c\u5728\u4e00\u6761\u5df7\u5b50\u91cc\uff0c\u6211\u9047\u5230\u4e86\u5f88\u591a\u719f\u4eba\uff0c\u4ed6\u4eec\u90fd\u60f3\u8981\u8ffd\u6740\u6211\uff0c\u4f46\u662f\u56e0\u4e3a\u8ddf\u6211\u5f88\u719f\uff0c\u90fd\u8ddf\u6211\u6253\u4e86\u4e2a\u62db\u547c\uff0c\u8bf4\u4e0d\u4f1a\u6740\u6211\u7684\uff0c\u5c31\u8d70\u4e86\u3002\u7ed3\u679c\u5df7\u5b50\u7684\u5c3d\u5934\u662f\u4e2a\u6b7b\u80e1\u540c\uff0c\u90a3\u91cc\u6709\u6700\u7ec8\u7684\u96c7\u4f63\u4ed6\u4eec\u7684\u96c7\u4e3b\uff0c\u60f3\u8981\u6740\u6211\u7684\u4eba\uff08\u4f46\u6211\u5fd8\u8bb0\u4e86\u4ed6\u662f\u8c01\uff09\uff0c\u8fd9\u65f6\u5019\uff0c\u5148\u524d\u7684\u719f\u4eba\u6089\u6570\u6765\u5230\u6211\u8eab\u8fb9\uff0c\u8bf4\uff0c\u201c\u5bf9\u4e0d\u8d77\uff0c\u4f46\u6211\u4e0d\u5f97\u4e0d\u6740\u4f60\uff08\u5927\u81f4\u662f\u8fd9\u4e2a\u610f\u601d\uff09\u201d\u3002\u6211\u4e5f\u8d70\u6295\u65e0\u8def\u4e86\uff0c\u8fd9\u65f6\u5019\uff0c\u6211\u9a97\u4ed6\u4eec\u8bf4\u8fd9\u91cc\u9762\u6709\u95f4\u8c0d\uff0c\u5176\u5b9e\u4e0a\u662f\u8981\u96c7\u4e3b\u7684\u547d\u7684\u3002\u96c7\u4e3b\u542c\u4fe1\u4e86\u6211\u7684\u8bdd\uff0c\u4e00\u4e2a\u4e00\u4e2a\u76d8\u95ee\uff0c\u7ed3\u679c\u5750\u5728\u6211\u5de6\u8fb9\u7684\u54e5\u4eec\u662f\u7b2c\u4e00\u4e2a\u63a5\u53d7\u76d8\u95ee\u7684\u4eba\uff0c\u4ed6\u56de\u7b54\u4e0d\u4e0a\u6765\u95ee\u9898\uff0c\u4ece\u5de6\u624b\u53e3\u888b\u91cc\u51c6\u5907\u638f\u51fa\u4e00\u628a\u67aa\u88ab\u770b\u5230\u4e86\uff0c\u7136\u540e\u5f15\u53d1\u4e86\u4e00\u573a\u9a9a\u4e71\uff0c\u6211\u597d\u50cf\u201c\u95ea\u73b0\u201d\u7a7f\u8fc7\u4e86\u5df7\u5b50\u4e24\u4fa7\u7684\u5899\u3002\u7136\u540e\u5230\u5904\u4e71\u901b\u3002</p>"},{"location":"diaries/2025/7%E6%9C%88/20250703/","title":"20250703","text":"<p> \u7ea6 57 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u597d\u4e45\u6ca1\u5199\u4e86\uff0c\u6700\u8fd1\u4e0d\u77e5\u9053\u5e72\u4ec0\u4e48\uff0c\u6ca1\u4ec0\u4e48\u52a8\u529b\u3002\u54ce\uff0c\u4e0d\u77e5\u9053\u81ea\u5df1\u7a76\u7adf\u60f3\u5e72\u4ec0\u4e48\u3002</p> <p>\u53ef\u80fd\u4eba\u9700\u8981\u653e\u677e\u4e00\u9635\u5b50\u5427\u3002</p> <p>\u4f46\u662f\u53c8\u5f88\u6015\u88ab\u522b\u4eba\u8d85\u8fc7\uff08\uff1f\uff09</p> <p>\u4e13\u6ce8\u81ea\u8eab\u53d1\u5c55</p>"},{"location":"diaries/2025/7%E6%9C%88/20250715/","title":"20250715","text":"<p> \u7ea6 76 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u66f4\u65b0\u4e00\u4e0b\u8fd9\u4e2a\u535a\u5ba2\u3002</p> <p>\u6700\u8fd1\u597d\u4e45\u6ca1\u5199\u4e86\uff0c\u770b\u4e86\u5f88\u591a\u522b\u4eba\u7684\u7f51\u7ad9\uff0c\u90fd\u5199\u7684\u5f88\u597d\uff0c\u611f\u89c9\u4ed6\u4eec\u90fd\u771f\u7684\u662f\u5728\u81ea\u613f\u7ef4\u62a4\u81ea\u5df1\u7684\u7f51\u7ad9\uff0c\u8f93\u51fa\u548c\u8868\u8fbe\u81ea\u5df1\u7684\u60f3\u6cd5\u3002\u4eca\u5929\u5b66\u5230\u4e86\u4ec0\u4e48\u5462\uff1f\u4e0d\u77e5\u9053\u3002\u4e0d\u8fc7\u6bcf\u5929\u90fd\u5728\u8fdb\u6b65\u3002</p>"},{"location":"essay/","title":"index","text":""},{"location":"essay/#_1","title":"\u6742\u8c08","text":"<p>\u8fd9\u91cc\u662f\u6211\u7684\u6742\u8c08\u677f\u5757\uff0c\u6536\u5f55\u4e00\u4e9b\u968f\u7b14\u548c\u60f3\u6cd5\u3002</p>"},{"location":"essay/%E4%BA%8C%E5%80%8D%E9%80%9F/","title":"\u4e8c\u500d\u901f","text":""},{"location":"essay/%E4%BA%8C%E5%80%8D%E9%80%9F/#_1","title":"\u4e8c\u500d\u901f","text":"<p> \u7ea6 285 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u6211\u611f\u89c9\u81ea\u5df1\u6d3b\u5728\u4e00\u4e2a\u4e8c\u500d\u901f\u7684\u4e16\u754c\u3002\u4e0d\u8bba\u662f\u6296\u97f3\uff0cB\u7ad9\u8fd8\u662f\u5c0f\u7ea2\u4e66\uff0c\u6211\u90fd\u4e60\u60ef\u4e86\u957f\u6309\u5c4f\u5e55\u5f00\u4e8c\u500d\u901f\uff0c\u6709\u4e9b\u65f6\u5019\u89c6\u9891\u8fd8\u6ca1\u70b9\u51fb\u64ad\u653e\uff0c\u5c31\u5148\u628a\u901f\u5ea6\u8bbe\u7f6e\u4e3a\u4e8c\u500d\u901f\u3002\u6211\u8fde\u770b\u7535\u5f71\u90fd\u8981\u4e8c\u500d\u901f\u4e86\u3002</p> <p>\u6211\u89c9\u5f97\u89c6\u9891\u4e2d\u8bf4\u8bdd\u901f\u5ea6\u90fd\u592a\u6162\u4e86\uff0c\u4f46\u90a3\u5b9e\u9645\u4e0a\u662f\u6b63\u5e38\u8bed\u901f\uff0c\u53ea\u662f\u6211\u6ca1\u6709\u8010\u5fc3\u542c\u4ed6\u4eec\u4e00\u5b57\u4e00\u53e5\u7684\u8bf4\uff0c\u6211\u53ea\u662f\u60f3\u4e86\u89e3\u4e2a\u5927\u6982\u3002\u751a\u81f3\u8fde\u77e5\u8bc6\u7c7b\u7684\u89c6\u9891\u6211\u4e5f\u4e60\u60ef\u4e86\u4e8c\u500d\u901f\u3002</p> <p>\u6628\u5929\u665a\u4e0a\u6211\u59b9\u5728\u6211\u65c1\u8fb9\uff0c\u6211\u5728\u957f\u6309\u5c4f\u5e55\uff0c\u7ed3\u679c\u5979\u4e5f\u5728\u6211\u7684\u5c4f\u5e55\u4e0a\u957f\u6309\uff0c\u53d1\u73b0\u901f\u5ea6\u52a0\u5feb\u4e86\uff0c\u5979\u53ef\u80fd\u4e5f\u7406\u89e3\u4e86\u957f\u6309\u7684\u76ee\u7684\uff0c\u4f46\u6211\u5f88\u6015\u628a\u5979\u5e26\u574f\u4e86\u3002</p> <p>\u6216\u8bb8\u6709\u7684\u89c6\u9891\u786e\u5b9e\u6ca1\u8425\u517b\uff0c\u4e8c\u500d\u901f\u53ef\u4ee5\u5269\u4e0b\u65f6\u95f4\uff0c\u4f46\u662f\u5f88\u591a\u65f6\u5019\u53d1\u73b0\u81ea\u5df1\u9519\u8fc7\u4e86\u5173\u952e\u4fe1\u606f\uff0c\u53c8\u8981\u5012\u56de\u53bb\u91cd\u65b0\u770b\uff0c\u4e0d\u662f\u4e5f\u4f1a\u6d6a\u8d39\u65f6\u95f4\u5417\uff1f\u6700\u540e\u82b1\u8d39\u7684\u65f6\u95f4\u53ef\u80fd\u548c\u6b63\u5e38\u901f\u5ea6\u89c2\u770b\u5dee\u4e0d\u592a\u591a\u3002</p> <p>\u4f46\u6211\u5e94\u8be5\u4e0d\u4f1a\u6539\u53d8\u8fd9\u4e2a\u4e60\u60ef\u3002</p>"},{"location":"essay/%E5%86%99%E7%BB%9918%E5%B2%81%E7%9A%84%E4%BF%A1/","title":"\u5199\u7ed918\u5c81\u7684\u4fe1","text":"<p> \u7ea6 2227 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 11 \u5206\u949f</p> <p>\u4eca\u5929\u662f\u6211\u519c\u538618\u5c81\u7684\u751f\u65e5\uff0c\u5728\u8fd9\u91cc\u5148\u795d\u81ea\u5df1\u751f\u65e5\u5feb\u4e50\uff01\u5929\u5929\u5f00\u5fc3\u3001\u5929\u5929\u5feb\u4e50\uff01</p> <p>\u521a\u597d\uff0c\u4eca\u5929\u4e5f\u662f\u6211\u6765\u5230\u4ea4\u5927\u6b63\u6b63\u597d\u4e00\u4e2a\u6708\u7684\u65e5\u5b50\u3002\u6211\u60f3\u501f\u6b64\u673a\u4f1a\uff0c\u8c08\u8c08\u8fd9\u4e00\u4e2a\u6708\u4ee5\u6765\u7684\u611f\u53d7\u3002</p> <p>\u4e0d\u5fc5\u8bf4\uff0c\u4ea4\u5927\u662f\u6211\u68a6\u5bd0\u4ee5\u6c42\u7684\u540d\u6821\u3002\u65e0\u8bba\u662fNeal\u5b66\u957f\u89c6\u9891\u91cc\u7ed9\u4e88\u4ed6\u65e0\u9650\u673a\u4f1a\u548c\u540d\u6821offer\u7684\u4ea4\u5927\uff0c\u8fd8\u662fMichael\u5b66\u957f\u89c6\u9891\u4e2d\u9633\u5149\u6d3b\u529b\u7684\u4ea4\u5927\uff0c\u90fd\u5728\u9ad8\u4e2d\u6df1\u6df1\u5438\u5f15\u7740\u6211\u3002\u4ece\u9ad8\u4e00\u5f00\u59cb\uff0c\u6211\u4fbf\u6697\u81ea\u4e0b\u5b9a\u51b3\u5fc3\uff0c\u8981\u8003\u4e0a\u4e0a\u6d77\u4ea4\u901a\u5927\u5b66\u3002\u4e0d\u4ec5\u5982\u6b64\uff0c\u6211\u628a\u4ea4\u5927\u5b9a\u4f4d\u76ee\u6807\u7684\u53e6\u4e00\u4e2a\u539f\u56e0\u662f\u8fd9\u6240\u5b66\u6821\u662f\u6211\u8db3\u591f\u52aa\u529b\u603b\u80fd\u78b0\u5230\u7684\uff0c\u800c\u4e0d\u662f\u553e\u624b\u53ef\u5f97\u4ea6\u6216\u8005\u9ad8\u6500\u4e0d\u8d77\u7684\u3002\u5728\u90a3\u4e4b\u540e\uff0c\u6211\u7684\u5347\u697c\u4eea\u5f0f\u7684\u4fe1\u4e0a\u5199\u4e0b\u4e86\u201cSJTU\u201d\uff0c\u5728\u767e\u65e5\u8a93\u5e08\u7684\u76ee\u6807\u4e2d\u5199\u4e0b\u201c\u4e0a\u6d77\u4ea4\u901a\u5927\u5b66\u201d\uff0cPCC\u5956\u52b1\u7684\u4fbf\u5229\u8d34\u4e5f\u662f\u201c\u4e0a\u6d77\u4ea4\u901a\u5927\u5b66\u201d\uff0c\u4eff\u4f5b\u4ea4\u5927\u4e00\u76f4\u966a\u4f34\u5728\u6211\u8eab\u8fb9\uff0c\u6210\u4e3a\u4e86\u6211\u7684\u7cbe\u795e\u652f\u67f1\u3002</p> <p>\u4f46\u6211\u60f3\u8bf4\uff0c\u4e0d\u8981\u89c9\u5f97\u8fd9\u662f\u723d\u6587\u5267\u60c5\uff0c\u4efb\u4f55\u5149\u9c9c\u4eae\u4e3d\u7684\u80cc\u540e\u603b\u662f\u56f0\u96be\u4e0e\u632b\u6298\u3002\u4e4b\u524d\u6211\u4e5f\u5bf9\u8fd9\u53e5\u8bdd\u55e4\u4e4b\u4ee5\u9f3b\uff0c\u89c9\u5f97\u90a3\u4e9b\u6210\u529f\u7684\u4eba\u53ea\u662f\u56e0\u4e3a\u4ed6\u4eec\u5bb6\u5883\u597d\uff0c\u8d77\u70b9\u9ad8\uff0c\u751a\u81f3\u4e0d\u9700\u8981\u989d\u5916\u7684\u52aa\u529b\u7167\u6837\u80fd\u540d\u5229\u53cc\u6536\u3002\u4e0d\u53ef\u5426\u8ba4\uff0c\u662f\u6709\u8fd9\u6837\u7684\u4eba\uff0c\u800c\u4e14\u8fd8\u4e0d\u5c11\u3002\u4f46\u4e5f\u662f\u6709\u5c11\u6570\u666e\u901a\u4eba\u9006\u5929\u6539\u547d\u7684\uff0c\u4ed6\u4eec\u6216\u8bb8\u662f\u6293\u4f4f\u4e86\u673a\u9047\uff0c\u6216\u8bb8\u662f\u62ff\u5230\u4e86\u597d\u7684\u6210\u7ee9\uff0c\u4f46\u4ed6\u4eec\u90fd\u662f\u4ed8\u51fa\u4e86\u52aa\u529b\u7684\u3002\u6bcf\u4e2a\u4eba\u90fd\u5728\u627f\u53d7\u7740\u5f88\u591a\uff0c\u6ca1\u6709\u8c01\u6bd4\u8c01\u66f4\u5bb9\u6613\uff0c\u800c\u4f60\u5982\u679c\u6709\u6539\u53d8\u4eba\u751f\u7684\u52c7\u6c14\u548c\u51b3\u5fc3\uff0c\u90a3\u5c31\u4fdd\u6301\u8fd9\u4efd\u5b9a\u529b\uff0c\u8ba9\u77a7\u4e0d\u8d77\u4f60\u7684\u4eba\u6700\u540e\u5bf9\u4f60\u522e\u76ee\u76f8\u770b\u3002</p> <p>\u524d\u51e0\u5929\u548c\u51af\u8bda\u8c08\u5230\u5bf9\u5b66\u9738\u795b\u9b45\uff0c\u679c\u771f\u5982\u6b64\u3002\u5f53\u90a3\u4e9b\u9ad8\u9ad8\u5728\u4e0a\u7684\u4e1c\u897f\u63a5\u8fd1\u4f60\u8eab\u8fb9\u65f6\uff0c\u4f60\u4f1a\u89c9\u5f97\u4e0d\u8fc7\u5982\u6b64\u3002\u5f53\u7136\uff0c\u8fd9\u5e76\u4e0d\u662f\u85d0\u89c6\u4ed6\u4eec\uff0c\u76f8\u53cd\uff0c\u73b0\u5728\u53d6\u5f97\u8fd9\u4e9b\u6210\u5c31\u7684\u4eba\u4e5f\u90fd\u662f\u666e\u901a\u4eba\uff0c\u4ed6\u4eec\u6b63\u53ef\u4ee5\u4f5c\u4e3a\u699c\u6837\u5b66\u4e60\uff0c\u4f46\u4e07\u4e0d\u53ef\u4f5c\u4e3a\u5076\u50cf\u6b7b\u5fc3\u584c\u5730\u7684\u5d07\u62dc\u3002\u4ea4\u5927\u6bd5\u7adf\u662fTop3\uff0c\u6765\u8fd9\u91cc\u7684\u4eba\u4e5f\u90fd\u5f88\u806a\u660e\uff0c\u81f3\u5c11\u5728\u9ad8\u8003\u8fd9\u65b9\u9762\u662f\u8d85\u8d8a\u4e86\u5f88\u591a\u4eba\u7684\u3002\u5f53\u5404\u5730\u7684\u9876\u5c16\u7684\u4eba\u805a\u96c6\u5728\u4e00\u8d77\uff0c\u53ea\u4f1a\u6709\u65e0\u5c3d\u7684\u6bd4\u8f83\u4e0e\u7ade\u4e89\u3002\u5c0f\u73ed\u957f\u7684\u81ea\u613f\u62a5\u540d\u4fbf\u662f\u7b2c\u4e00\u6b21\u7ade\u4e89\uff0c\u7d27\u63a5\u7740\u8fd8\u6709\u73ed\u59d4\u7ade\u9009\u3001\u6807\u5175\u7ade\u9009\u3001\u5165\u56e2\u79ef\u6781\u5206\u5b50\u62a5\u540d\u7b49\u7b49\u7b49\u7b49\u3002\u5927\u5b66\u5df2\u7ecf\u662f\u4e2a\u793e\u4f1a\u4e86\uff0c\u8fd9\u70b9\u771f\u771f\u5207\u5207\uff0c\u4e0d\u8fc7\u53c8\u6709\u591a\u5c11\u4eba\u80fd\u8f6c\u53d8\u7684\u8fc7\u6765\u5462\uff1f\u6211\u8fd8\u8bb0\u5f97\u73ed\u7ea7\u7ade\u9009\u73ed\u59d4\u65f6\uff0c\u6211\u62a5\u540d\u4e86\u5b66\u4e60\u59d4\u5458\uff0c\u5f53\u65f6\u6211\u89c9\u5f97\u8fd9\u4e2a\u5c97\u4f4d\u624b\u5230\u64d2\u6765\uff0c\u7ed3\u679c\u4e00\u7ade\u9009\u624d\u53d1\u73b0\u5176\u4ed6\u4eba\u539f\u6765\u540c\u6837\u4f18\u79c0\uff0c\u6211\u62ff\u4ec0\u4e48\u53bb\u6bd4\u5462\uff1f\u6211\u6709\u7684\u6210\u7ee9\u4ed6\u4eec\u90fd\u6709\uff0c\u4f46\u4ed6\u4eec\u6240\u62e5\u6709\u7684\u793e\u4f1a\u5b9e\u8df5\u7ecf\u5386\u6bd4\u6211\u591a\u5f97\u591a\u3002\u5230\u5934\u6765\u6211\u624d\u53d1\u73b0\uff0c\u4e4b\u524d\u521d\u9ad8\u4e2d\u603b\u662f\u5728\u73ed\u7ea7\u3001\u5e74\u7ea7\u4e4b\u5185\u6bd4\u8f83\uff0c\u518d\u5927\u4e00\u70b9\u5c31\u662f\u5b66\u6821\u3001\u5e02\u533a\uff0c\u80fd\u62ff\u5230\u56fd\u5bb6\u7ea7\u5956\u9879\u7684\u4eba\u90a3\u66f4\u662f\u5c11\u4e4b\u53c8\u5c11\uff0c\u8fd9\u5c31\u9020\u6210\u4e86\u4e00\u79cd\u8ff7\u4e4b\u81ea\u4fe1\u7684\u9519\u89c9\u3002\u6211\u4eec\u603b\u662f\u8bf4\u5e74\u7ea7\u524d\u51e0\uff0c\u5168\u5e02\u524d\u51e0\uff0c\u4f46\u9c9c\u6709\u4eba\u8bf4\u5168\u56fd\u524d\u51e0\u3002\u4f46\u5927\u5b66\u4e0d\u6b63\u662f\u5168\u56fd\u7684\u4eba\u6765\u5230\u540c\u4e00\u4e2a\u5730\u65b9\u5417\uff1f\u4f60\u7684\u5168\u5e02\u524d\u51e0\u5230\u5927\u5b66\u53c8\u6709\u4ec0\u4e48\u7528\u5462\uff1f\u5c31\u7b97\u4f60\u662f\u4e07\u91cc\u6311\u4e00\u7684\u5929\u624d\uff0c\u5728\u4e2d\u56fd\u4e5f\u4f1a\u670916\u4e07\u7684\u5929\u624d\uff0c\u5728\u5929\u624d\u4e91\u96c6\u7684\u5730\u65b9\u4e5f\u53ea\u4f1a\u6cef\u7136\u4f17\u4eba\u3002\u8bdd\u53c8\u8bf4\u56de\u6765\uff0c\u4f60\u8981\u771f\u8bf4\u667a\u5546\u7684\u8bdd\u53ef\u80fd\u5927\u5bb6\u5927\u5dee\u4e0d\u5dee\uff0c\u771f\u7684\u5dee\u8ddd\u5728\u5b9e\u8df5\u4e0e\u9605\u5386\u65b9\u9762\u3002\u6cbf\u6d77\u57ce\u5e02\u7684\u4eba\u5c31\u662f\u6d3b\u52a8\u7ecf\u5386\u66f4\u4e30\u5bcc\uff0c\u4e0a\u6d77\u672c\u5730\u7684\u4eba\u5c31\u662f\u82f1\u8bed\u66f4\u597d\u3001\u66f4\u81ea\u4fe1\uff0c\u4f46\u5176\u4ed6\u65b9\u9762\u5927\u5bb6\u771f\u7684\u5dee\u4e0d\u591a\u3002\u6240\u4ee5\u8bf4\u6211\u4eec\u8fd8\u6709\u65f6\u95f4\u53bb\u8d85\u8d8a\uff0c\u4ed6\u4eec\u4e5f\u53ea\u662f\u666e\u901a\u4eba\uff0c\u53ea\u4e0d\u8fc7\u751f\u6d3b\u5728\u4e86\u4e00\u4e2a\u66f4\u53d1\u8fbe\u7684\u57ce\u5e02\uff0c\u4e5f\u4e0d\u5fc5\u81ea\u5351\u6216\u8005\u81ea\u66b4\u81ea\u5f03\u3002\u4f8b\u5982\uff0c\u4e0a\u6d77\u7684\u540c\u5b66\u6765\u5230\u8fd9\u91cc\u5e76\u4e0d\u662f\u6210\u7ee9\u6709\u591a\u597d\uff0c\u53ea\u4e0d\u8fc7\u662f\u6cbe\u4e86\u672c\u5730\u7684\u5149\uff1b\u800c\u6211\u6ca1\u6709\u8fdb\u5165\u81f4\u8fdc\u6216\u8005\u7535\u9662\uff0c\u4e5f\u5e76\u4e0d\u662f\u6211\u80fd\u529b\u4e0d\u591f\uff0c\u53ea\u662f\u56e0\u4e3a\u5730\u533a\u5dee\u8ddd\u800c\u62db\u751f\u8ba1\u5212\u4e0d\u540c\u7f62\u4e86\u3002</p> <p>\u8bf4\u5230\u8fd9\uff0c\u6211\u5c31\u6765\u5199\u4e00\u5199\u540e\u671f\u7684\u89c4\u5212\u548c\u8981\u505a\u7684\u52aa\u529b\u5427\u3002\u5b66\u4e60\u65b9\u9762\u5462\uff0c\u6211\u51c6\u5907\u5148\u901a\u8fc7\u9009\u62d4\u8003\u8003\u8fdb\u6570\u5b66\u5206\u6790\uff08\u8363\u8a89\uff09(PASS)\uff0c\u518d\u901a\u8fc7\u8c03\u7ea7\u8003\u8003\u5165\u5927\u5b66\u82f1\u8bed\uff08\u56db\uff09(FAIL)\uff0c\u65c1\u542c\u7ebf\u6027\u4ee3\u6570\uff08\u8363\u8a89\uff09\uff0c\u4e89\u53d6\u8d76\u4e0a\u81f4\u8fdc\u7684\u8fdb\u5ea6\u3002\u9664\u6b64\u4e4b\u5916\uff0c\u6211\u8fd8\u5f97\u81ea\u5b66CS61A\u548cC++\uff0c\u5377\u5b66\u79ef\u5206\u5230\u524d3%\uff0c\u8f6c\u4e13\u4e1a\u5230\u81f4\u8fdc\u4eba\u5de5\u667a\u80fd\u6216\u8005\u7535\u9662CS\u3002\u56e0\u4e3a\u81f4\u8fdc\u4eba\u5de5\u667a\u80fd\u662f\u7b2c\u4e00\u5e74\u62db\u751f\uff0c\u6211\u4e0d\u786e\u5b9a\u9700\u8981\u4ec0\u4e48\u786c\u5b9e\u529b\uff0c\u4e0d\u8fc7CS\u6211\u54a8\u8be2\u4e86\u5b66\u957f\u4ed6\u8bf4\u53ea\u8981\u5b66\u79ef\u5206\u591f\u4e86\u90fd\u597d\u8bf4\u3002\u8fd0\u52a8\u65b9\u9762\uff0c\u6211\u575a\u6301\u6253\u7fbd\u6bdb\u7403\uff0c\u518d\u52a0\u4e0a\u5065\u8eab\uff0c\u4e89\u53d6\u53d8\u5f97\u5f3a\u58ee\u3002\u751f\u6d3b\u65b9\u9762\uff0c\u6211\u5e0c\u671b\u5076\u5c14\u53c2\u52a0\u4e00\u4e0b\u5b66\u6821\u7684\u5927\u578b\u6d3b\u52a8\u5427\uff0c\u60f3\u53bb\u9a91\u81ea\u884c\u8f66\u515c\u515c\u98ce\uff0c\u4e0d\u8fc7\u8fd9\u90fd\u662f\u540e\u8bdd\u4e86\u3002</p> <p>\u4eba\u5728\u52b3\u9038\u7ed3\u5408\u7684\u72b6\u6001\u4e0b\u771f\u7684\u80fd\u53d1\u6325\u51fa\u66f4\u597d\u7684\u6f5c\u529b\u3002\u5c31\u7b97\u662f\u5728\u9ad8\u8003\u524d\u5915\u6211\u4f9d\u65e7\u6bcf\u8282\u8bfe\u4e0b\u8bfe\u53bb\u9633\u53f0\u653e\u677e\uff0c\u6bcf\u5929\u665a\u4e0a\u7ed5\u6821\u56ed\u6563\u6b65\uff0c\u6bcf\u5929\u90fd\u542cEason\u7684\u6b4c\uff0c\u5377\u751f\u7269\u80cc\u4e66\u4ec0\u4e48\u7684\u6211\u5e76\u4e0d\u613f\u610f\u5728\u665a\u8bfe\u65f6\u5019\u8fdb\u884c\u3002\u5439\u5439\u98ce\uff0c\u6652\u6652\u592a\u9633\uff0c\u770b\u770b\u6821\u56ed\u91cc\u7684\u690d\u7269\uff0c\u90a3\u90fd\u662f\u5f88\u8212\u7545\u7684\u3002\u6211\u53c8\u4e0d\u5f97\u4e0d\u5728\u5938\u4e00\u4e0b\u5929\u5e9c\u4e03\u4e2d\u7684\u6821\u56ed\u73af\u5883\u4e86\uff0c\u81ea\u4ece\u642c\u5230\u884c\u653f\u697c\u4e4b\u540e\uff0c\u4e0d\u8bba\u5728\u90a3\u4e2a\u6559\u5ba4\uff0c\u90fd\u80fd\u6b23\u8d4f\u5230\u7edd\u4f73\u7684\u98ce\u666f\u3002\u8b6c\u5982\u5728\u56db\u73ed\u5916\u9762\u80fd\u770b\u5230\u7eda\u70c2\u7684\u665a\u971e\u4e0e\u5bc2\u9759\u7684\u591c\u666f\uff0c\u4e00\u73ed\u5916\u9762\u80fd\u770b\u5230\u8471\u7fe0\u7684\u9a6c\u978d\u5c71\uff0c\u4e8c\u73ed\u5916\u9762\u80fd\u770b\u5230\u5b66\u6821\u7684\u540e\u82b1\u56ed\u3002\u7f8e\u4e3d\u7684\u73af\u5883\u80fd\u591f\u8ba9\u6211\u5fc3\u60c5\u8212\u7545\uff0c\u4ece\u800c\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u3002\u5728\u5929\u4e03\u5446\u7684\u516d\u5e74\u65f6\u5149\u91cc\uff0c\u6216\u8bb8\u6709\u9057\u61be\uff0c\u4f46\u662f\u6765\u81ea\u8eab\u8fb9\u6bcf\u4e2a\u4eba\u7684\u5173\u7231\uff0c\u6765\u81ea\u5927\u81ea\u7136\u7684\u5475\u62a4\u662f\u80fd\u591f\u8fd9\u662f\u611f\u53d7\u5230\u7684\u3002</p> <p>\u800c\u4ea4\u5927\u7684\u6821\u56ed\u73af\u5883\u4e5f\u582a\u79f0\u4e00\u7edd\uff0c\u65e9\u6668\uff0c\u6210\u7fa4\u7ed3\u961f\u7684\u767d\u9e25\u5728\u6ce2\u5149\u7cbc\u7cbc\u7684\u601d\u6e90\u6e56\u65c1\u4eab\u53d7\u65e5\u5149\u6d74\uff1b\u508d\u665a\uff0c\u5915\u9633\u7684\u4f59\u6656\u5012\u6620\u5728\u6db5\u6cfd\u6e56\u4e2d\uff1b\u591c\u665a\uff0c\u9a91\u884c\u5728\u5ba3\u6000\u5927\u9053\uff0c\u7a7a\u65f7\u7684\u8857\u9053\u5f25\u6f2b\u6021\u4eba\u7684\u5fae\u98ce\uff0c\u81f4\u8fdc\u80e1\u6e56\u5fc3\u6c89\u7761\u7740\u4e00\u8f6e\u660e\u6708\u3002\u6bcf\u6b21\u6211\u89c9\u5f97\u538b\u529b\u5927\u7684\u65f6\u5019\uff0c\u6211\u5c31\u4f1a\u9a91\u81ea\u884c\u8f66\u5728\u6821\u56ed\u91cc\uff0c\u603b\u80fd\u627e\u5230\u4e00\u4e9b\u8eb2\u5728\u89d2\u843d\u5374\u53c8\u5f88\u6709\u8da3\u7684\u5730\u65b9\u3002</p> <p>\u5728\u8fd9\u91cc\uff0c\u6211\u4e5f\u9047\u5230\u4e86\u5f88\u591a\u5584\u826f\u4f18\u79c0\u7684\u4eba\u3002\u6bd4\u65b9\u8bf4\u6211\u7684\u5ba4\u53cb\u4eec\uff0c\u4ed6\u4eec\u4eba\u90fd\u5f88\u597d\uff0c\u4e92\u5e2e\u4e92\u52a9\uff0c\u6709\u65f6\u8fd8\u4f1a\u5e2e\u5fd9\u5e26\u996d\uff1b\u6211\u7684\u8001\u5e08\u4eec\uff0c\u4e0d\u7ba1\u662f\u521d\u6765\u4ea4\u5927\u8bf7\u6211\u5403\u7b2c\u4e00\u987f\u996d\u7684\u590f\u8001\u5e08\uff0c\u8fd8\u662f\u4ec5\u56e0\u4e3a\u6211\u4e00\u53e5\u201c\u6211\u4e5f\u60f3\u5b66\u4e60\u4e00\u4e0b\u6444\u5f71\u201d\u5c31\u8010\u5fc3\u6307\u5bfc\u6211\u7684\u8bb8\u8001\u5e08\uff0c\u53c8\u6216\u8005\u5e2e\u52a9\u6211\u5728\u5b66\u4e1a\u65b9\u9762\u7cbe\u8fdb\uff0c\u8ffd\u9010\u68a6\u60f3\u7684\u9648\u8001\u5e08\uff0c\u5f20\u8001\u5e08\uff0c\u5468\u8001\u5e08\uff1b\u5bbf\u7ba1\u963f\u59e8\u4eec\uff0c\u5979\u4eec\u4f1a\u5e2e\u6211\u4eec\u6536\u8863\u670d\uff0c\u63d0\u9192\u6211\u4eec\u6ce8\u610f\u5b89\u5168\uff1b\u8fd8\u6709\u5b66\u957f\u5b66\u59d0\u4eec\uff0c\u4ed6\u4eec\u613f\u610f\u628a\u81ea\u5df1\u7684\u7ecf\u9a8c\u5206\u4eab\u7ed9\u6211\uff0c\u5c3d\u7ba1\u4e92\u4e0d\u76f8\u8bc6\uff0c\u4f46\u4ed6\u4eec\u4ecd\u6beb\u65e0\u4fdd\u7559\u5730\u4e3a\u6211\u63d0\u4f9b\u5e2e\u52a9\u3002\u6216\u8bb8\u8fd9\u662f\u4e00\u79cd\u65b0\u9c9c\u611f\u7684\u6ee4\u955c\uff0c\u4f46\u81f3\u5c11\u8fd9\u4e2a\u6708\u6211\u8fc7\u5f97\u5f88\u5e78\u798f\uff0c\u5c31\u8db3\u591f\u4e86\u3002\u5927\u5b66\u662f\u5f88\u6b8b\u9177\uff0c\u4f46\u662f\u4e0d\u4ee3\u8868\u5c31\u6ca1\u6709\u6e29\u60c5\u3002\u53ea\u8981\u4f60\u613f\u610f\u53bb\u4e89\u53d6\u5e76\u4e14\u52aa\u529b\uff0c\u673a\u4f1a\u4f1a\u9752\u7750\u4f60\u7684\u3002\u5982\u679c\u4e00\u5f00\u59cb\u5c31\u6253\u9000\u5802\u9f13\uff0c\u90a3\u673a\u4f1a\u6839\u672c\u4e0d\u4f1a\u6572\u4f60\u7684\u95e8\u3002</p> <p>\u6700\u540e\u7684\u6700\u540e\uff0c\u8fd8\u662f\u717d\u60c5\u4e00\u4e0b\u5427\u3002\u611f\u8c22\u6211\u7684\u7236\u6bcd\u3001\u59b9\u59b9\u4ee5\u53ca\u5bb6\u4eba\u4eec\uff0c\u6ca1\u6709\u4f60\u4eec\u7684\u966a\u4f34\u6211\u5f88\u96be\u8d70\u5230\u4eca\u5929\uff1b\u611f\u8c22\u6211\u7684\u6bcd\u6821\uff0c\u6211\u6240\u9047\u8fc7\u7684\u3001\u6ca1\u9047\u8fc7\u7684\u8001\u5e08\u4eec\uff0c\u4f60\u4eec\u7684\u6559\u5bfc\u8ba9\u6211\u6709\u5e95\u6c14\u524d\u8fdb\uff1b\u611f\u8c22\u6211\u7684\u5144\u5f1f\u670b\u53cb\u4eec\uff0c\u6ca1\u6709\u4f60\u4eec\u7684\u652f\u6301\u6211\u5f88\u96be\u8d70\u8fdc\u3002\u611f\u8c22\u6211\u81ea\u5df1\u4e3a\u73b0\u5728\u505a\u51fa\u7684\u6240\u6709\u52aa\u529b\uff0c\u4e0d\u7ba1\u4ee5\u524d\u600e\u4e48\u6837\uff0c\u672a\u6765\u4f1a\u66f4\u597d\uff01</p> <p>Someone has to win,why not me\uff1f                                                                                                                                                                     6ch. \u200b                                           2024.9.28\u4e8e\u4e0a\u6d77\u4ea4\u901a\u5927\u5b66\u5305\u7389\u521a\u56fe\u4e66\u9986</p> <p>\u8865\uff1a2024.10.14 \u6700\u8fd1\u51e0\u5929\u4e00\u76f4\u5fd9\u7740\u5f53\u5fd7\u613f\u8005\uff0c\u867d\u7136\u8bf4\u5de5\u4f5c\u4e0d\u7b97\u591a\uff0c\u4f46\u662f\u6bcf\u5929\u51c6\u65f6\u8003\u52e4\u8fd8\u662f\u4e0d\u5bb9\u6613\u7684\u3002\u524d\u51e0\u5929\u6570\u5b66\u9009\u62d4\u8003\u7684\u7ed3\u679c\u4e5f\u51fa\u6765\u4e86\uff0c\u7ec8\u4e8e\u8003\u4e0a\u4e86\u6570\u5b66\u5206\u6790\u8363\u8a89\uff0c\u4e5f\u5c31\u662f\u8bf4\u7ebf\u4ee3\u548c\u6570\u5206\u6211\u90fd\u5728\u4e0a\u8363\u8a89\u8bfe\uff0c\u4e5f\u7b97\u662f\u5f25\u8865\u4e86\u81ea\u5df1\u5165\u5b66\u4ee5\u6765\u7684\u7f3a\u61be\u5427\uff01\u51a5\u51a5\u4e4b\u4e2d\u7684\u611f\u89c9\u5f80\u5f80\u5f88\u6709\u7528\uff0c\u90a3\u5c31\u7ee7\u7eed\u52aa\u529b\u5427\uff01</p>"},{"location":"essay/%E6%88%91%E7%9A%84%E5%A4%A7%E4%B8%80%E4%B8%8A%E5%AD%A6%E6%9C%9F/","title":"\u6211\u7684\u5927\u4e00\u4e0a\u5b66\u671f","text":"<p> \u7ea6 118 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p>"},{"location":"essay/%E6%88%91%E7%9A%84%E5%A4%A7%E4%B8%80%E4%B8%8A%E5%AD%A6%E6%9C%9F/#_1","title":"\u603b\u7ed3\u6211\u7684\u5927\u4e00\u4e0a\u5b66\u671f","text":"<p>\u8fd8\u662f\u8fc7\u5f97\u633a\u4e0d\u9519\u7684\uff0c\u8bf4\u5b9e\u8bdd\u3002\u4e3b\u8981\u662f\u8003\u7684\u786e\u5b9e\u8fd8\u4e0d\u9519\uff0c\u611f\u89c9\u6211\u8fd9\u4e2a\u4eba\u6267\u884c\u529b\u8fd8\u633a\u5f3a\u7684\uff0c\u5f00\u5b66\u951a\u5b9a\u4e86\u8981\u51b2\u5b66\u79ef\u5206\uff0c\u8f6c\u4e13\u4e1a\u5c31\u5230\u5904\u95ee\u5b66\u957f\uff0c\u4e5f\u597d\u597d\u5199\u4f5c\u4e1a\u542c\u8bfe\u3002\u7b97\u662f\u529f\u4e0d\u5510\u6350\u5427\u3002</p> <p>\u4f46\u662f\u758f\u4e8e\u953b\u70bc\uff0c\u8eab\u4f53\u53d8\u5f31\u4e86\uff0c\u4e5f\u53d8\u7626\u4e86\u3002\u5e76\u4e14\u8bfb\u4e66\u8fd8\u662f\u8bfb\u5c11\u4e86\u3002\u7434\u4e5f\u6709\u4e00\u4e2a\u5b66\u671f\u6ca1\u6709\u78b0\uff0c\u653e\u5728\u89d2\u843d\u91cc\u5403\u7070\u3002</p>"},{"location":"essay/%E7%9D%A1%E7%9C%A0%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7/","title":"\u7761\u7720","text":"<p> \u7ea6 961 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 5 \u5206\u949f</p> <p>\u628a\u4e4b\u524d\u6240\u6709\u5728\u8111\u5b50\u91cc\u9884\u6f14\u7684\u7a3f\u5b50\u68b3\u7406\u4e00\u4e0b~</p> <p>\u6211\u4e00\u76f4\u8ba4\u4e3a\u7761\u7720\u662f\u6781\u5176\u91cd\u8981\u7684\uff0c\u751a\u81f3\u662f\u6700\u91cd\u8981\u7684\u3002\u5bf9\u4e8e\u6211\u800c\u8a00\uff0c\u9ad8\u8003\u7684\u6210\u529f\u7684\u51b3\u5b9a\u6027\u56e0\u7d20\u5c31\u662f\u7761\u7720\u3002\u53ea\u6709\u7761\u7720\u8d28\u91cf\u4e0a\u53bb\u4e86\uff0c\u5c31\u80fd\u53d1\u6325\u597d\uff0c\u8fd9\u662f\u4e0d\u4e89\u7684\u4e8b\u5b9e\u3002</p> <p>\u4f46\u662f\u600e\u4e48\u624d\u80fd\u7761\u5f97\u597d\u662f\u4e00\u95e8\u6df1\u5965\u7684\u5b66\u95ee\u3002\u6211\u5bf9\u7761\u7720\u7684\u73af\u5883\u8981\u6c42\u5341\u5206\u82db\u523b\u3002\u9996\u5148\u7a97\u5e18\u5fc5\u987b\u5f97\u62c9\u4e0a\uff0c\u4e25\u4e1d\u5408\u7f1d\uff0c\u4e0d\u80fd\u900f\u5149\uff0c\u4e5f\u5c31\u662f\u623f\u95f4\u91cc\u9762\u4e0d\u80fd\u6709\u5149\u4eae\uff1b\u623f\u95f4\u5185\u4e0d\u80fd\u6709\u4eba\u4e3a\u7684\u58f0\u97f3\uff0c\u6bd4\u5982\u8bf4\u547c\u565c\u58f0\u3001\u78e8\u7259\u58f0\uff0c\u53ea\u5141\u8bb8\u6709\u91cd\u590d\u7684\u8749\u9e23\u6216\u8005\u7a7a\u8c03\u5916\u673a\u8fd0\u8f6c\u7684\u58f0\u97f3\uff1b\u88ab\u5b50\u8981\u76d6\u7684\u5f88\u4e25\u5b9e\uff0c\u80a9\u8180\u4e24\u8fb9\u7684\u88ab\u5b50\u5fc5\u987b\u538b\u4e0b\u53bb\u3002</p> <p>\u4e3a\u4e86\u6ee1\u8db3\u4e0a\u8ff0\u8981\u6c42\uff0c\u5c31\u5fc5\u987b\u8981\u4e70\u4e2a\u8d28\u91cf\u597d\u7684\u7a97\u5e18\uff0c\u900f\u5149\u7387\u8981\u4f4e\u3002\u4e3a\u4ec0\u4e48\u4e0d\u4e70\u773c\u7f69\u5462\uff1f\u56e0\u4e3a\u773c\u7f69\u52d2\u7740\u773c\u775b\uff0c\u6234\u4e45\u4e86\u4e0d\u8212\u670d\u3002\u7136\u540e\u8981\u4e70\u4e2a\u8d28\u91cf\u597d\u7684\u8033\u585e\u3002\u5343\u4e07\u4e0d\u8981\u9009\u6d77\u7ef5\u7684\uff0c\u692d\u7403\u67f1\u72b6\u7684\u8033\u585e\uff08\u70b9\u540d3M\u7684\uff09\uff0c\u90a3\u79cd\u4e00\u4e2a\u662f\u6781\u5176\u96be\u914d\u5e26\uff0c\u4f60\u5f97\u5148\u6413\u6210\u7ec6\u6761\u72b6\u7684\u624d\u80fd\u653e\u5728\u8033\u6735\u91cc\uff0c\u8fd8\u8981\u7b49\u5b83\u6162\u6162\u81a8\u80c0\uff0c\u4e8c\u4e00\u4e2a\u662f\u9694\u97f3\u6548\u679c\u4e0d\u597d\uff0c\u8fd8\u662f\u80fd\u542c\u5230\u5916\u9762\u7684\u58f0\u97f3\u3002\u6211\u5728\u4e70\u8033\u585e\u4e0a\u5df2\u7ecf\u82b1\u4e86\u516d\u4e03\u767e\u5757\u94b1\u4e86\uff0c\u90fd\u662fAlpine\u7684\u8033\u585e\uff08\u4e0d\u662f\u6253\u5e7f\u544a\uff09\uff0c\u975e\u5e38\u597d\u7528\u3002\u5b83\u7684\u5f62\u72b6\u662f\u7b26\u5408\u4eba\u8033\u5f62\u72b6\u7684\uff0c\u800c\u4e14\u662f\u6a61\u80f6\u7684\uff0c\u6234\u7740\u5f88\u8212\u670d\uff0c\u4e5f\u5f88\u7d27\uff0c\u80fd\u5b8c\u5168\u9694\u7edd\u5916\u754c\u58f0\u97f3\u3002\u4f46\u662f\u8fd9\u4e5f\u6709\u4e2a\u9700\u8981\u9002\u5e94\u7684\u5730\u65b9\uff0c\u5982\u679c\u8fc7\u4e8e\u5b89\u9759\u4e86\uff0c\u53cd\u800c\u4f1a\u6709\u8033\u9e23\u73b0\u8c61\uff0c\u8fd9\u4e2a\u9700\u8981\u514b\u670d\uff0c\u4e0d\u8fc7\u5bf9\u4e8e\u6211\u800c\u8a00\u662f\u4e60\u60ef\u4e86\u7684\u3002</p> <p>\u8fd8\u6709\u5c31\u662f\u5403\u4fdd\u5065\u54c1\uff08\u4e0d\u53ea\u662f\u5bf9\u7761\u7720\uff09\u3002\u5f88\u591a\u65f6\u5019\u5916\u529b\u4e5f\u5f88\u91cd\u8981\u3002\u6211\u5403\u7684\u4fdd\u5065\u54c1\u79cd\u7c7b\u4e5f\u7279\u522b\u591a\uff0c\u6709\u6bb5\u65f6\u95f4\u6211\u751a\u81f3\u8ff7\u4e0a\u5403\u4fdd\u5065\u54c1\u4e86\uff0c\u5bdd\u5ba4\u67dc\u5b50\u91cc\u6446\u6ee1\u4e86\u5404\u79cd\u5404\u6837\u7684\u5305\u88c5\uff0c\u670b\u53cb\u90fd\u53eb\u6211\u201c\u836f\u7f50\u5b50\u201d\u3002\u4e0d\u8fc7\u786e\u5b9e\u662f\u6709\u5e2e\u52a9\u7684\uff0c\u4f46\u662f\u9700\u8981\u6307\u660e\u7684\u662f\uff0c\u8fd9\u4e9b\u5e2e\u52a9\u65e0\u6cd5\u533a\u5206\u662f\u5fc3\u7406\u5c42\u9762\u4e0a\u7684\u8fd8\u662f\u5b9e\u9645\u7684\u4f5c\u7528\uff08\u6211\u66f4\u613f\u610f\u76f8\u4fe1\u662f\u5fc3\u7406\u4f5c\u7528\uff0c\u76f8\u5f53\u4e8e\u82b1\u94b1\u4e70\u4e2a\u5b89\u5fc3\uff0c\u5176\u5b9e\u662f\u975e\u5e38\u8d5a\u7684\u4e00\u7b14\u4e70\u5356\uff09\u3002\u4e0b\u9762\u5217\u4e3e\u4e00\u4e0b\u6211\u5403\u8fc7\u7684\uff1a1.\u53cc\u5fc3\u7684\u53f6\u9ec4\u7d20\uff0c\u7f13\u89e3\u773c\u775b\u7684\uff0c\u4e3b\u8981\u662f\u6211\u7684\u773c\u775b\u8fd1\u89c6\u5ea6\u6570\u4e00\u76f4\u6ca1\u600e\u4e48\u53d8\uff0c\u5403\u4e86\u4e5f\u8fd8\u53ef\u4ee5</p> <p>2.Losoki\u7684\u9c7c\u6cb9\uff08\u91cd\u4e2d\u4e4b\u91cd\uff09 \u975e\u5e38\u6709\u7528\uff01\u4e0d\u7ba1\u662f\u8c03\u8282\u5185\u5206\u6ccc\u8fd8\u662f\u5e2e\u52a9\u7761\u7720</p> <p>3.\u53cc\u5fc3\u7684\u7ef4\u751f\u7d20B-12\uff1a\u5f3a\u529b\u63a8\u8350\uff01\uff01\uff01\u975e\u5e38\u6709\u6548\u679c\uff0c\u56e0\u4e3a\u5496\u5561\u5bf9\u6211\u6765\u8bf4\u6ca1\u4ec0\u4e48\u4f5c\u7528\uff0c\u6211\u6709\u9700\u8981\u4e00\u4e2a\u63d0\u795e\u7684\u4e1c\u897f\uff0c\u8fd9\u4e2aB12\u66f4\u76f4\u63a5\u4e00\u4e9b\u3002\u9ad8\u8003\u4ee5\u53ca\u91cd\u5927\u8003\u8bd5\u5c31\u662f\u559d\u4e86\u5b83\u5934\u8111\u624d\u4e00\u76f4\u4fdd\u6301\u6e05\u9192\uff0c\u5fc3\u7406\u4f5c\u7528\u4e5f\u662f\u975e\u5e38\u91cd\u8981\uff0c\u559d\u4e86\u5b83\u5c31\u662f\u5b89\u5fc3\uff0c\u8003\u8bd5\u7684\u65f6\u5019\u90fd\u89c9\u5f97\u7a33\u4e86\u3002\u6211\u89c9\u5f97\u8fd9\u4e2a\u662f\u6211\u9ad8\u8003\u6210\u529f\u7684\u91cd\u8981\u529f\u81e3\u4e4b\u4e00\u3002</p> <p>4.\u94f6\u674f\u63d0\u53d6\u7269 \u4e3b\u8981\u662f\u592a\u8d35\u4e86\uff0c\u4e00\u677f\u6ca1\u591a\u5c11\uff0c\u5403\u4e86\u4f1a\u53d8\u806a\u660e\uff1f\u8fd9\u4e2a\u6211\u4e0d\u6e05\u695a</p> <p>5.\u5341\u4e8c\u70ef \u5fd8\u4e86\u5177\u4f53\u53eb\u4ec0\u4e48\u540d\u5b57\u4e86\uff0c\u4e5f\u7279\u522b\u8d35\uff0c\u4e00\u76d2\u4e09\u56db\u767e\uff0c\u662f\u6211\u7238\u5148\u7ed9\u6211\u4e70\u7684\uff0c\u8bf4\u662f\u53ef\u4ee5\u6539\u5584\u7761\u7720\u52a0\u4e0a\u63d0\u5347\u8bb0\u5fc6\u529b\u3002\u7238\u7238\u7ed9\u6211\u4e70\u4e86\u597d\u591a\u74f6\u3002\u6211\u611f\u89c9\u5403\u4e86\u4e4b\u540e\u80cc\u53e4\u8bd7\u786e\u5b9e\u8981\u597d\u591a\u4e86\uff0c\u8bb0\u5f97\u90fd\u8981\u7262\u4e00\u4e9b\uff08\u518d\u6b21\u53e0\u7532\uff1a\u4f60\u53ef\u4ee5\u8bf4\u662f\u5fc3\u7406\u4f5c\u7528\uff0c\u4f60\u53ef\u4ee5\u8bf4\u6211\u662f\u8ff7\u4fe1\uff0c\u4f46\u662f\u8fd9\u4e2a\u4e1c\u897f\u5c31\u662f\u6709\u6548\u679c\uff0c\u4f55\u5fc5\u592a\u8fc7\u4e8e\u7ea0\u7ed3\u5177\u4f53\u673a\u7406\u5462\uff1f\uff09</p> <p>\u5f85\u5c1d\u8bd5\u7684\uff1a\u8f85\u9176Q-10\uff0c\u770b\u7f51\u4e0a\u8bf4\u7279\u522b\u6709\u7528\uff0c\u4e0d\u8fc7\u6211\u67e5\u4e86\u4e00\u4e0b\u597d\u50cf\u662f\u7ed9\u7ecf\u5e38\u71ac\u591c\u7684\u4e2d\u5e74\u4eba\u5403\u7684\uff0c\u6211\u8fd8\u662f\u4e0d\u6562\u4e71\u5403\u3002</p>"},{"location":"essay/%E9%AB%98%E4%B8%AD%E5%9B%9E%E5%BF%86%E5%BD%95/","title":"\u6211\u7684\u9ad8\u4e2d","text":"<p> \u7ea6 38 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u5f85\u5b8c\u6210......</p> <p>\u9ad8\u4e2d\u771f\u7684\u5f88\u7f8e\u597d\uff0c\u90a3\u79cd\u9752\u6da9\u7eaf\u6d01\u7684\u604b\u7231\u4e00\u751f\u4e2d\u518d\u96be\u9047\u4e0a\u4e00\u6b21\u3002</p> <p>\u5148\u653e\u4e0a\u540c\u5b66\u4eec\u7684\u56de\u5fc6\u5427</p> <p></p>"},{"location":"notes/","title":"index","text":""},{"location":"notes/#notes","title":"Notes \ud83d\udcda","text":"<p>Abstract</p> <p>\u4e00\u4e9b\u6bd4\u8f83\u6210\u4f53\u7cfb\u7684\u7b14\u8bb0\u90fd\u505a\u5728\u8fd9\u91cc\uff0c\u65b9\u4fbf\u67e5\u9605\u3002</p> <p>\u672c\u90e8\u5206\u5185\u5bb9\uff08\u9664\u7279\u522b\u58f0\u660e\u5916\uff09\u91c7\u7528 \u7f72\u540d-\u975e\u5546\u4e1a\u6027\u4f7f\u7528-\u4fdd\u6301\u4e00\u81f4 4.0 \u56fd\u9645 (CC BY-NC-SA 4.0) \u8bb8\u53ef\u534f\u8bae\u8fdb\u884c\u8bb8\u53ef\u3002</p>"},{"location":"notes/Financial_Analysis/","title":"Python and Statistics for Financial Analysis","text":""},{"location":"notes/Financial_Analysis/#python-and-statistics-for-financial-analysis","title":"Python and Statistics for Financial Analysis","text":"<p> \u7ea6 96 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"notes/Financial_Analysis/#pandas-knowledge","title":"Pandas Knowledge","text":"<ol> <li> <p>What does shift() in <code>Pandas</code> mean? <code>shift(-1)</code> means to move upwards by one row.</p> </li> <li> <p>List Comprehension: <code>fb['Direction']=[1 if fb[ei,'PriceDiff'] &gt; 0 else -1 for ei in fb.index]</code></p> </li> <li> <p><code>fb['MovingAverage] = (fb + fb.shift(1) + fb.shift(2)) / 3</code> Move downwards to get the previous data.</p> </li> </ol>"},{"location":"notes/Financial_Analysis/#financial-knowledge","title":"Financial Knowledge","text":"<p>PriceDiff = Close_Price_Of_Tomorrow - Close_Price_Of_Today</p> <p>DailyReturn = PriceDiff / Close_Price_Of_Today</p> <p>Direction :=</p> <ul> <li>PriceDiff \\(&gt; 0  ====&gt;\\) Up 1</li> <li>PriceDiff \\(&lt;= 0  ====&gt;\\) Down -1</li> </ul> <p>MovingAverage = (Close_Price_Of_The_Day_Before_Yesterday + Close_Price_Of_Yesterday + Close_Price_Of_Today) / 3</p>"},{"location":"notes/Latex/","title":"Latex\u57fa\u672c\u6559\u7a0b","text":""},{"location":"notes/Latex/#latex","title":"Latex\u5b66\u4e60","text":"<p> \u7ea6 466 \u4e2a\u5b57  19 \u884c\u4ee3\u7801  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p>"},{"location":"notes/Latex/#_1","title":"\u6587\u4ef6\u7ed3\u6784","text":"TeX<pre><code>\\documentclass{sjtu}  %\u6587\u6863\u7c7b\u578b\n% \u8fd9\u91cc\u5f00\u59cb\u662f\u5bfc\u8a00\u533a\n\\usepackage{graphicx} % \u5f15\u7528\u5b8f\u5305\n\\graphicspath{{fig/}} % \u8bbe\u7f6e\u56fe\u7247\u76ee\u5f55\n\\def\\rawcmd#1{\\texttt{\\color{DarkBlue}\\footnotesize #1}}  % \u5b9a\u4e49\u65b0\u547d\u4ee4\n% \u5bfc\u8a00\u533a\u5230\u6b64\u4e3a\u6b62\n\\begin{document}\n\u8fd9\u91cc\u662f\u6b63\u6587\n\\end{document}\n</code></pre>"},{"location":"notes/Latex/#latex_1","title":"Latex \u201c\u547d\u4ee4\u201d(\u5b8f\u6216\u8005\u63a7\u5236\u7cfb\u5217)","text":"<ul> <li> <p>\u7b80\u5355\u547d\u4ee4</p> </li> <li> <p>\\\u547d\u4ee4   {\\heiti \u54c8\u54c8\u54c8}</p> </li> <li> <p>\\\u547d\u4ee4[\u53ef\u9009\u53c2\u6570]{\u5fc5\u9009\u53c2\u6570}</p> </li> <li> <p>\u73af\u5883\u547d\u4ee4</p> </li> </ul> TeX<pre><code>\\begin{equation*}\n  a^2-b^2=(a+b)(a-b)\n\\end{equation*}\n</code></pre>"},{"location":"notes/Latex/#_2","title":"\u8c0b\u7bc7\u5e03\u5c40","text":"<ul> <li>\u4e00\u7bc7\u5b66\u4f4d\u8bba\u6587\u5305\u62ec</li> <li>\u6807\u9898\uff1a <code>\\title,\\author,\\date -&gt; \\maketitle</code></li> <li>\u6458\u8981\uff1a<code>abstract</code> \u73af\u5883</li> <li>\u76ee\u5f55\uff1a<code>\\tableofcontents</code></li> <li>\u7ae0\u8282\uff1a<code>\\chapter,\\section,\\subsection\u7b49</code></li> <li>\u56fe\u8868\uff1a<code>table,figure</code>\u73af\u5883</li> <li>\u5f15\u7528\uff1a<code>\\label,\\cite,\\ref</code></li> <li>\u6587\u732e\uff1a<code>\\bibliograpghy</code></li> <li>\u9644\u5f55\uff1a<code>\\appendix</code></li> <li>\u81f4\u8c22\uff1a<code>acknowledgements</code>\u73af\u5883</li> <li>\u6587\u6863\u5212\u5206</li> <li>\u9875\u7801\u5212\u5206\uff1a<code>\\frontmatter,\\mainmatter,\\backmatter</code></li> <li>\u5206\u6587\u4ef6\u7f16\u8bd1\uff1a<code>\\include,\\input</code></li> </ul>"},{"location":"notes/Latex/#_3","title":"\u6587\u672c\u6807\u8bb0","text":"<ul> <li>\u52a0\u7c97\uff1a<code>{\\bfserires ...}</code> \u6216 <code>\\textbf{...}</code></li> <li>\u503e\u659c\uff1a<code>{\\itshape ...}</code> \u6216 <code>\\textit{...}</code></li> <li>\u5b57\u53f7\uff1a<code>\\tiny,\\small,\\normalsize,\\large,\\huge</code>\u7b49</li> <li>\u6362\u884c\uff1a<code>\\\\</code></li> <li>\u7f29\u8fdb: <code>\\indent,\\noindent</code></li> <li>\u5c45\u4e2d\uff1a<code>\\centering</code>\u6216<code>center</code>\u73af\u5883</li> </ul>"},{"location":"notes/Latex/#latex_2","title":"Latex\u5e38\u7528\u73af\u5883\u547d\u4ee4","text":"<ul> <li><code>table</code>: \u7528\u4e8e\u521b\u5efa\u4e00\u4e2a\u8868\u683c\u73af\u5883</li> <li><code>figure</code>: \u7528\u4e8e\u521b\u5efa\u4e00\u4e2a\u56fe\u7247\u73af\u5883</li> <li><code>itemize</code>: \u7528\u4e8e\u521b\u5efa\u4e00\u4e2a\u65e0\u7f16\u53f7\u5217\u8868\uff0c\u4f7f\u7528<code>\\item</code>\u8fdb\u884c\u5206\u5e97</li> <li><code>enumerate</code>: \u7528\u4e8e\u521b\u5efa\u4e00\u4e2a\u7f16\u53f7\u5217\u8868\uff0c\u4f7f\u7528<code>\\item</code>\u8fdb\u884c\u5206\u70b9</li> <li><code>equation</code>: \u7528\u4e8e\u521b\u5efa\u4e00\u4e2a\u516c\u5f0f\u73af\u5883\uff0c\u73af\u5883\u5185\u9002\u7528\u884c\u95f4\u516c\u5f0f\u8bed\u6cd5</li> </ul>"},{"location":"notes/Latex/#latex_3","title":"Latex\u6570\u5b66\u516c\u5f0f","text":"<ul> <li>\u7528\u5355\u4e2a\u7f8e\u5143\u7b26\u53f7<code>$\u6216\\( \\)</code> \u5305\u56f4\u8d77\u6765\u7684\u5185\u5bb9\u662f\u884c\u5185\u516c\u5f0f</li> <li>\u7528\u4e24\u4e2a\u7f8e\u5143\u7b26\u53f7<code>$$\u6216\\[ \\]</code>\u5305\u56f4\u8d77\u6765\u7684\u5185\u5bb9\u662f\u884c\u95f4\u516c\u5f0f</li> <li>\u4f7f\u7528\u6570\u5b66\u73af\u5883\uff0c\u4f8b\u5982<code>equation</code>\u73af\u5883\u5185\u7684\u516c\u5f0f\u4f1a\u81ea\u52a8\u52a0\u4e0a\u7f16\u53f7\uff0c<code>align</code>\u73af\u5883\u591a\u7528\u4e8e\u591a\u884c\u516c\u5f0f\uff08\u6bd4\u5982\u65b9\u7a0b\u7ec4\u3001\u591a\u4e2a\u5e76\u5217\u6761\u4ef6\u7b49\uff09</li> <li>\u5bfb\u627e\u7b26\u53f7</li> <li>\u8fd0\u884c<code>textdoc symbols</code>\u67e5\u770b\u7b26\u53f7\u8868</li> <li><code>https://ctan.org/pkg/comprehensive</code></li> <li>\u624b\u5199\u8bc6\u522b\uff08\u6709\u8da3\u4f46\u4e0d\u5168\uff09: Detexify</li> <li>Mathpix Snip \u8bc6\u522b\u56fe\u7247\u5bfc\u51fa</li> </ul>"},{"location":"notes/Latex/#_4","title":"\u4ea4\u53c9\u5f15\u7528\u4e0e\u63d2\u5165\u63d2\u56fe","text":"<ul> <li>\u7ed9\u5bf9\u8c61\u547d\u540d\uff1a\u56fe\u7247\u3001\u8868\u683c\u3001\u516c\u5f0f\u7b49</li> </ul> <p><code>\\label{name}</code></p> <ul> <li>\u5f15\u7528\u5bf9\u8c61</li> </ul> <p><code>\\ref{name}</code></p> TeX<pre><code>\\begin{figure}[htbp]\n\\centering\n\\includegraphics[height=.2\\textheight]{LOGO.png}\n\\caption{\u4ea4\u5927\u6821\u5fbd}\n\\label{fig:sjtu:LOGO}\n\\end{figure}\n\u4ea4\u5927\u6821\u5fbd\u8bf7\u53c2\u89c1\u56fe~\\ref{fig:sjtu:LOGO}\n</code></pre> <p></p>"},{"location":"notes/Latex/#_5","title":"\u4f5c\u56fe\u4e0e\u63d2\u56fe","text":"<ul> <li>\u5916\u90e8\u63d2\u5165</li> <li>Mathematica MATLAB</li> <li>PowerPoint</li> <li>Matplotlib\u5e93</li> <li>draw.io Processon</li> <li>\u63d2\u56fe\u683c\u5f0f</li> <li>.pdf\u6216.eps</li> <li>.jpg\u6216.png</li> <li>\u53c2\u8003\uff1a\u5982\u4f55\u5728\u8bba\u6587\u4e2d\u753b\u51fa\u6f02\u4eae\u7684\u63d2\u56fe\uff1f - \u77e5\u4e4e (zhihu.com)</li> </ul>"},{"location":"notes/Latex/#_6","title":"\u6587\u732e\u7ba1\u7406","text":"<ul> <li> <p>.bib\u6570\u636e\u5e93</p> </li> <li> <p>Google Scholar\u53ef\u76f4\u63a5\u590d\u5236\uff0c\u8981\u6ce8\u610f\u6821\u5bf9</p> </li> <li> <p>\u5e38\u7528\u65b9\u6cd5\uff08\u5927\u90e8\u5206\u4f1a\u8bae\uff0c\u671f\u520a\u6a21\u677f\uff09\uff1a BibTex\u540e\u7aef</p> </li> </ul>"},{"location":"notes/SeveralQ/","title":"\u4e00\u4e9b\u95ee\u9898","text":""},{"location":"notes/SeveralQ/#batchnormlayernorm","title":"\u6211\u4eec\u5230\u5e95\u5e94\u8be5\u5982\u4f55\u7406\u89e3BatchNorm\u548cLayerNorm?","text":"<p> \u7ea6 657 \u4e2a\u5b57  3 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> <p>Reference: 1.   machine learning - Why do transformers use layer norm instead of batch norm? - Cross Validated (stackexchange.com)</p> <ol> <li>BatchNorm\u548cLayerNorm\u2014\u2014\u901a\u4fd7\u6613\u61c2\u7684\u7406\u89e3_layernorm\u548cbatchnorm-CSDN\u535a\u5ba2</li> </ol> <p></p> <p>\u8bf4\u4eba\u8bdd\uff1a BN \u662f\u5bf9\u6bcf\u4e00\u4e2a\u901a\u9053\u8ba1\u7b97\u540c\u4e00\u6279\u6837\u672c\u6240\u6709\u5bf9\u5e94\u7279\u5f81\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee</p> <p>LN \u662f\u5bf9\u6bcf\u4e00\u4e2a\u6837\u672c\u8ba1\u7b97\u6240\u6709\u7279\u5f81\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee</p> <p>BN \u5e38\u7528\u4e8e CV(CNN),\u56e0\u4e3a\u6211\u4eec\u89c1\u8bc6\u4e0d\u540c\u7684\u6837\u672c\u6765\u4e86\u89e3\u201c\u732b\u201d\u201c\u72d7\u201d\u7684\u542b\u4e49\uff0c\u4e5f\u5c31\u662f\u8bf4\u4e0d\u540c\u6837\u672c\u5bf9\u540c\u4e00\u7279\u5f81\u8981\u6709\u53ef\u6bd4\u6027\u3002</p> <p>LN \u5e38\u7528\u4e8eNLP(Transformer),\u56e0\u4e3a\u6211\u4eec\u5e0c\u671b\u5b66\u4e60\u4e00\u4e2a\u8bcd\u662f\u901a\u8fc7\u8fd9\u4e00\u53e5\u8bdd\u7684\u4e0a\u4e0b\u6587\uff0c\u4e5f\u5c31\u662f\u540c\u4e00\u4e2a\u6837\u672c\u7684\u6240\u6709\u7279\u5f81\u3002</p> <p>BN\u793a\u610f\u56fe\uff1a</p> <p></p> <p>LN\u793a\u610f\u56fe\uff1a</p> <p></p>"},{"location":"notes/SeveralQ/#relu","title":"\u6211\u4eec\u4e3a\u4ec0\u4e48\u9700\u8981\u6fc0\u6d3b\u51fd\u6570(\u6bd4\u5982ReLU)?","text":"<p>The purpose of the activation function is to introduce non-linearity into the network</p> <p>in turn, this allows you to model a response variable (aka target variable, class label, or score) that varies non-linearly with its explanatory variables</p> <p>non-linear means that the output cannot be reproduced from a linear combination of the inputs (which is not the same as output that renders to a straight line--the word for this is affine).</p> <p>another way to think of it: without a non-linear activation function in the network, a NN, no matter how many layers it had, would behave just like a single-layer perceptron, because summing these layers would give you just another linear function (see definition just above).</p>"},{"location":"notes/SeveralQ/#_1","title":"\u6211\u4eec\u4e3a\u4ec0\u4e48\u9700\u8981\u5f52\u4e00\u5316\uff1f","text":"<p>Normalized data enhances model performance and improves the accuracy of a model. It aids algorithms that rely on distance metrics, such as k-nearest neighbors or support vector machines, by preventing features with larger scales from dominating the learning process.</p> <p>Normalization fosters stability in the optimization process, promoting faster convergence during gradient-based training. It mitigates issues related to vanishing or exploding gradients, allowing models to reach optimal solutions more efficiently.</p> <p>Normalized data is also easy to interpret and thus, easier to understand. When all the features of a dataset are on the same scale, it also becomes easier to identify and visualize the relationships between different features and make meaningful comparisons.</p> <p>1. With Unnormaized data:</p> <p>Since your network is tasked with learning how to combine inputs through a series of linear combinations and nonlinear activations, the parameters associated with each input will exist on different scales.</p> <p>Unfortunately, this can lead toward an awkward loss function topology which places more emphasis on certain parameter gradients.</p> <p>If the images are not normalized, the input pixels will range from [ 0 , 255 ]. These will produce huge activation values ( if you're using ReLU ). After the forward pass, you'll end up with a huge loss value and gradients.</p> <p>2. With Normalized data:</p> <p>By normalizing our inputs to a standard scale, we're allowing the network to more quickly learn the optimal parameters for each input node.</p> <p>Additionally, it's useful to ensure that our inputs are roughly in the range of -1 to 1 to avoid weird mathematical artifacts associated with floating-point number precision. In short, computers lose accuracy when performing math operations on really large or really small numbers. Moreover, if your inputs and target outputs are on a completely different scale than the typical -1 to 1 range, the default parameters for your neural network (ie. learning rates) will likely be ill-suited for your data. In the case of image the pixel intensity range is bound by 0 and 1(mean =0 and variance =1).</p>"},{"location":"notes/6.S091/Representation/","title":"Representation Learning","text":"<p> \u7ea6 2007 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 10 \u5206\u949f</p> <p>\u89c6\u9891\u4e2d\u56f4\u7ed5\u7ebf\u6027\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u548c\u56e0\u679c\u8868\u5f81\u5b66\u4e60\uff0c\u6d89\u53ca\u591a\u4e2a\u6838\u5fc3\u6570\u5b66\u516c\u5f0f\u7684\u63a8\u5bfc\uff0c\u4ee5\u4e0b\u7ed3\u5408\u89c6\u9891\u5185\u5bb9\u8be6\u7ec6\u62c6\u89e3\uff1a</p>"},{"location":"notes/6.S091/Representation/#scm","title":"\u4e00\u3001\u7ebf\u6027\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff08SCM\uff09\u7684\u57fa\u7840\u516c\u5f0f","text":""},{"location":"notes/6.S091/Representation/#1","title":"1. \u6f5c\u5728\u53d8\u91cf\u7684\u7ebf\u6027\u8868\u793a","text":"<p>\u89c6\u9891\u4e2d\u5b9a\u4e49\u6f5c\u5728\u53d8\u91cf \\( z \\) \u7531\u7ebf\u6027\u56e0\u679c\u673a\u5236\u751f\u6210\uff0c\u5f62\u5f0f\u4e3a\uff1a [ z = A^T z + \\Sigma^{\u00bd} \\epsilon ] - \u7b26\u53f7\u8bf4\u660e\uff1a   - \\( z \\in \\mathbb{R}^d \\) \u662f\u6f5c\u5728\u56e0\u679c\u53d8\u91cf\u5411\u91cf\uff08\\( d \\) \u4e3a\u7ef4\u5ea6\uff09\uff1b   - \\( A \\) \u662f\u6743\u91cd\u77e9\u9635\uff08\u4e0b\u4e09\u89d2\u77e9\u9635\uff0c\\( A_{ij} \\neq 0 \\) \u8868\u793a \\( z_i \\to z_j \\) \u5b58\u5728\u56e0\u679c\u8fb9\uff09\uff1b   - \\( \\Sigma^{1/2} \\) \u662f\u5916\u751f\u566a\u58f0\u7684\u6807\u51c6\u5dee\u77e9\u9635\uff08\u5bf9\u89d2\u7ebf\u77e9\u9635\uff0c\u63a7\u5236\u566a\u58f0\u5e45\u5ea6\uff09\uff1b   - \\( \\epsilon \\in \\mathbb{R}^d \\) \u662f\u5747\u503c\u4e3a0\u3001\u534f\u65b9\u5dee\u4e3a\u5355\u4f4d\u77e9\u9635 \\( I \\) \u7684\u566a\u58f0\u5411\u91cf\uff08\\( \\text{Cov}(\\epsilon) = I \\)\uff09\u3002  </p> <ul> <li>\u63a8\u5bfc\u903b\u8f91\uff1a   \u6bcf\u4e2a\u6f5c\u5728\u53d8\u91cf \\( z_j \\) \u662f\u5176\u7236\u53d8\u91cf\u7684\u7ebf\u6027\u7ec4\u5408\uff08\\( A^T z \\) \u9879\uff09\u52a0\u566a\u58f0\uff08\\( \\Sigma^{1/2} \\epsilon \\) \u9879\uff09\u3002\u901a\u8fc7\u79fb\u9879\u6574\u7406\u4e3a\uff1a   [ (I - A^T) z = \\Sigma^{\u00bd} \\epsilon ]   \u7531\u4e8e \\( A \\) \u662f\u4e0b\u4e09\u89d2\u77e9\u9635\uff0c\\( I - A^T \\) \u53ef\u9006\uff0c\u56e0\u6b64\uff1a   [ z = (I - A<sup>T)</sup> \\epsilon ]  } \\Sigma^{\u00bd</li> </ul>"},{"location":"notes/6.S091/Representation/#2","title":"2. \u89c2\u6d4b\u53d8\u91cf\u4e0e\u6f5c\u5728\u53d8\u91cf\u7684\u6620\u5c04","text":"<p>\u89c2\u6d4b\u53d8\u91cf \\( x \\) \u662f\u6f5c\u5728\u53d8\u91cf \\( z \\) \u7684\u7ebf\u6027\u6295\u5f71\uff0c\u516c\u5f0f\u4e3a\uff1a [ x = G z + \\nu ] - \u7b26\u53f7\u8bf4\u660e\uff1a   - \\( x \\in \\mathbb{R}^p \\) \u662f\u89c2\u6d4b\u53d8\u91cf\u5411\u91cf\uff08\\( p \\) \u4e3a\u89c2\u6d4b\u7ef4\u5ea6\uff0c\u901a\u5e38 \\( p \\geq d \\)\uff09\uff1b   - \\( G \\in \\mathbb{R}^{p \\times d} \\) \u662f\u6df7\u5408\u77e9\u9635\uff08\u5c06\u6f5c\u5728\u53d8\u91cf\u6620\u5c04\u5230\u89c2\u6d4b\u7a7a\u95f4\uff09\uff1b   - \\( \\nu \\) \u662f\u89c2\u6d4b\u566a\u58f0\uff08\u89c6\u9891\u4e2d\u6709\u65f6\u7b80\u5316\u4e3a \\( \\nu = 0 \\)\uff0c\u5373\u786e\u5b9a\u6027\u6620\u5c04\uff09\u3002  </p>"},{"location":"notes/6.S091/Representation/#_1","title":"\u4e8c\u3001\u534f\u65b9\u5dee\u77e9\u9635\u7684\u63a8\u5bfc","text":"<p>\u534f\u65b9\u5dee\u77e9\u9635\u662f\u5206\u6790\u53d8\u91cf\u5173\u7cfb\u7684\u6838\u5fc3\u5de5\u5177\uff0c\u89c6\u9891\u4e2d\u901a\u8fc7\u6f5c\u5728\u53d8\u91cf\u7684\u8868\u8fbe\u5f0f\u63a8\u5bfc\u5176\u534f\u65b9\u5dee\uff1a</p>"},{"location":"notes/6.S091/Representation/#1-z","title":"1. \u6f5c\u5728\u53d8\u91cf \\( z \\) \u7684\u534f\u65b9\u5dee","text":"<p>\u7531 \\( z = (I - A^T)^{-1} \\Sigma^{1/2} \\epsilon \\)\uff0c\u7ed3\u5408 \\( \\text{Cov}(\\epsilon) = I \\)\uff0c\u53ef\u5f97\uff1a [ \\text{Cov}(z) = (I - A<sup>T)</sup> \\Sigma \\left( (I - A<sup>T)</sup> \\right)^T ] - \u63a8\u5bfc\u903b\u8f91\uff1a   \u534f\u65b9\u5dee\u7684\u6027\u8d28\u4e3a \\( \\text{Cov}(Mz) = M \\text{Cov}(z) M^T \\)\uff08\\( M \\) \u4e3a\u5e38\u6570\u77e9\u9635\uff09\u3002\u6b64\u5904 \\( M = (I - A^T)^{-1} \\Sigma^{1/2} \\)\uff0c\u56e0\u6b64\uff1a   [ \\text{Cov}(z) = M \\cdot \\text{Cov}(\\epsilon) \\cdot M^T = (I - A<sup>T)</sup> \\left( (I - A} \\Sigma^{\u00bd} \\cdot I \\cdot \\Sigma^{\u00bd<sup>T)</sup> \\right)^T ]   \u7b80\u5316\u540e\u5f97\u5230\u4e0a\u8ff0\u516c\u5f0f\uff08\\( \\Sigma = (\\Sigma^{1/2})^2 \\)\uff09\u3002</p>"},{"location":"notes/6.S091/Representation/#2-x","title":"2. \u89c2\u6d4b\u53d8\u91cf \\( x \\) \u7684\u534f\u65b9\u5dee","text":"<p>\u82e5\u5ffd\u7565\u89c2\u6d4b\u566a\u58f0\uff08\\( \\nu = 0 \\)\uff09\uff0c\u5219 \\( x = G z \\)\uff0c\u5176\u534f\u65b9\u5dee\u4e3a\uff1a [ \\text{Cov}(x) = G \\cdot \\text{Cov}(z) \\cdot G^T ] - \u63a8\u5bfc\u903b\u8f91\uff1a   \u540c\u6837\u5229\u7528\u534f\u65b9\u5dee\u6027\u8d28\uff0c\u5c06 \\( M = G \\) \u4ee3\u5165\uff0c\u5f97\u5230\u89c2\u6d4b\u53d8\u91cf\u7684\u534f\u65b9\u5dee\u4e0e\u6f5c\u5728\u53d8\u91cf\u534f\u65b9\u5dee\u7684\u5173\u7cfb\u3002</p>"},{"location":"notes/6.S091/Representation/#_2","title":"\u4e09\u3001\u77e9\u9635\u9006\u4e0e\u8def\u5f84\u6743\u91cd\u7684\u5173\u7cfb","text":"<p>\u89c6\u9891\u4e2d\u63d0\u5230\uff0c\\( (I - A)^{-1} \\) \u77e9\u9635\u7684\u5143\u7d20\u4e0e\u56e0\u679c\u8def\u5f84\u6743\u91cd\u76f4\u63a5\u76f8\u5173\uff0c\u8fd9\u662f\u5206\u6790\u56e0\u679c\u5f71\u54cd\u7684\u5173\u952e\uff1a</p>"},{"location":"notes/6.S091/Representation/#1_1","title":"1. \u77e9\u9635\u9006\u7684\u8def\u5f84\u89e3\u91ca","text":"<p>\u5bf9\u4e8e\u4e0b\u4e09\u89d2\u77e9\u9635 \\( A \\)\uff0c\\( (I - A)^{-1} \\) \u53ef\u5c55\u5f00\u4e3a\u65e0\u7a77\u7ea7\u6570\uff08\u56e0 \\( A \\) \u662f\u4e0b\u4e09\u89d2\uff0c\u9ad8\u9636\u9879\u6700\u7ec8\u4e3a0\uff09\uff1a [ (I - A)^{-1} = I + A + A^2 + A^3 + \\dots + A^k \\quad (\\text{\u5f53 } k \\geq d \\text{ \u65f6\uff0c} A^k = 0) ] - \u7269\u7406\u610f\u4e49\uff1a   - \\( A^k \\) \u7684\u5143\u7d20 \\( (A^k)_{ij} \\) \u8868\u793a\u4ece \\( z_i \\) \u5230 \\( z_j \\) \u7684\u6240\u6709\u957f\u5ea6\u4e3a \\( k \\) \u7684\u6709\u5411\u8def\u5f84\u7684\u6743\u91cd\u4e4b\u548c\uff08\u8def\u5f84\u6743\u91cd\u4e3a\u5404\u8fb9\u6743\u91cd\u7684\u4e58\u79ef\uff09\uff1b   - \u56e0\u6b64 \\( (I - A)^{-1} \\) \u7684\u5143\u7d20 \\( (I - A)^{-1}_{ij} \\) \u8868\u793a\u4ece \\( z_i \\) \u5230 \\( z_j \\) \u7684\u6240\u6709\u53ef\u80fd\u957f\u5ea6\u7684\u6709\u5411\u8def\u5f84\u7684\u603b\u6743\u91cd\uff0c\u5373\u603b\u56e0\u679c\u5f71\u54cd\u3002</p>"},{"location":"notes/6.S091/Representation/#_3","title":"\u56db\u3001\u5e72\u9884\u6570\u636e\u4e0b\u7684\u77e9\u9635\u8bc6\u522b","text":"<p>\u5f53\u5f15\u5165\u5bf9\u6f5c\u5728\u53d8\u91cf\u7684\u5e72\u9884\u65f6\uff0c\u89c6\u9891\u901a\u8fc7\u9006\u534f\u65b9\u5dee\u77e9\u9635\u7684\u53d8\u5316\u63a8\u5bfc\u5e72\u9884\u76ee\u6807\u548c\u6df7\u5408\u77e9\u9635 \\( G \\) \u7684\u9006\uff08\u8bb0\u4e3a \\( H = G^{-1} \\)\uff09\uff1a</p>"},{"location":"notes/6.S091/Representation/#1_2","title":"1. \u5e72\u9884\u540e\u7684\u9006\u534f\u65b9\u5dee\u53d8\u5316","text":"<p>\u8bbe\u89c2\u6d4b\u6570\u636e\u7684\u9006\u534f\u65b9\u5dee\u77e9\u9635\u4e3a \\( \\Theta = \\text{Cov}(x)^{-1} \\)\uff0c\u5e72\u9884\u540e\u53d8\u4e3a \\( \\Theta' \\)\uff0c\u5219\uff1a [ \\Theta' - \\Theta = H \\cdot \\Delta B \\cdot H^T ] - \u7b26\u53f7\u8bf4\u660e\uff1a   - \\( \\Delta B \\) \u662f\u5e72\u9884\u5f15\u8d77\u7684\u6f5c\u5728\u53d8\u91cf\u9006\u534f\u65b9\u5dee\u53d8\u5316\uff08\u4ec5\u5e72\u9884\u76ee\u6807\u884c/\u5217\u975e\u96f6\uff0c\u79e9\u4e3a1\uff09\uff1b   - \\( H = G^{-1} \\) \u662f\u6df7\u5408\u77e9\u9635\u7684\u9006\uff08\u5c06\u89c2\u6d4b\u53d8\u91cf\u6620\u5c04\u56de\u6f5c\u5728\u53d8\u91cf\uff09\u3002  </p> <ul> <li>\u63a8\u5bfc\u903b\u8f91\uff1a   \u5e72\u9884\u4ec5\u6539\u53d8\u6f5c\u5728\u53d8\u91cf\u7684\u534f\u65b9\u5dee\u7ed3\u6784\uff08\\( \\Delta B \\)\uff09\uff0c\u800c\u89c2\u6d4b\u53d8\u91cf\u7684\u534f\u65b9\u5dee\u53d8\u5316\u7531 \\( G \\) \u4f20\u9012\uff0c\u56e0\u6b64\u9006\u534f\u65b9\u5dee\u7684\u53d8\u5316\u53ef\u8868\u793a\u4e3a \\( H \\cdot \\Delta B \\cdot H^T \\)\u3002\u7531\u4e8e \\( \\Delta B \\) \u79e9\u4e3a1\uff0c\\( \\Theta' - \\Theta \\) \u7684\u884c/\u5217\u7a7a\u95f4\u4e0e \\( H \\) \u7684\u884c\u7a7a\u95f4\u4e00\u81f4\uff0c\u4ece\u800c\u53ef\u901a\u8fc7\u6b64\u5173\u7cfb\u8bc6\u522b \\( H \\)\u3002</li> </ul>"},{"location":"notes/6.S091/Representation/#2-h","title":"2. \u6df7\u5408\u77e9\u9635\u9006 \\( H \\) \u7684\u6062\u590d","text":"<p>\u901a\u8fc7\u5bf9 \\( \\Theta' - \\Theta \\) \u8fdb\u884c\u7279\u5f81\u5206\u89e3\u6216\u6295\u5f71\uff0c\u53ef\u63d0\u53d6 \\( H \\) \u7684\u884c\u5411\u91cf\uff08\u4ec5\u5dee\u4e00\u4e2a\u7f29\u653e\u56e0\u5b50\uff09\u3002\u4f8b\u5982\uff0c\u82e5\u5e72\u9884\u76ee\u6807\u4e3a\u7b2c \\( i \\) \u4e2a\u6f5c\u5728\u53d8\u91cf\uff0c\u5219 \\( \\Theta' - \\Theta \\) \u7684\u884c\u7a7a\u95f4\u7531 \\( H \\) \u7684\u7b2c \\( i \\) \u884c\u5f20\u6210\uff0c\u4ece\u800c\u53ef\u6062\u590d\u8be5\u884c\u4f7f\u3002</p>"},{"location":"notes/6.S091/Representation/#_4","title":"\u4e94\u3001\u5173\u952e\u7ed3\u8bba\u603b\u7ed3","text":"<ol> <li>\u7ebf\u6027\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u4e2d\uff0c\u6f5c\u5728\u53d8\u91cf\u7684\u534f\u65b9\u5dee\u7531\u6743\u91cd\u77e9\u9635 \\( A \\) \u548c\u566a\u58f0\u65b9\u5dee \\( \\Sigma \\) \u51b3\u5b9a\uff0c\u4e14\u4e0e\u56e0\u679c\u8def\u5f84\u6743\u91cd\u76f4\u63a5\u76f8\u5173\uff1b  </li> <li>\u89c2\u6d4b\u53d8\u91cf\u7684\u534f\u65b9\u5dee\u662f\u6f5c\u5728\u53d8\u91cf\u534f\u65b9\u5dee\u7ecf\u6df7\u5408\u77e9\u9635 \\( G \\) \u6620\u5c04\u7684\u7ed3\u679c\uff1b  </li> <li>\u5f15\u5165\u5e72\u9884\u6570\u636e\u540e\uff0c\u901a\u8fc7\u9006\u534f\u65b9\u5dee\u77e9\u9635\u7684\u53d8\u5316\u53ef\u8bc6\u522b\u6df7\u5408\u77e9\u9635\u7684\u9006 \\( H \\)\uff0c\u8fdb\u800c\u6062\u590d\u6f5c\u5728\u53d8\u91cf\u7684\u56e0\u679c\u7ed3\u6784\u3002  </li> </ol> <p>\u8fd9\u4e9b\u63a8\u5bfc\u4e3a\u4ece\u9ad8\u7ef4\u89c2\u6d4b\u6570\u636e\u4e2d\u6316\u6398\u6f5c\u5728\u56e0\u679c\u5173\u7cfb\u63d0\u4f9b\u4e86\u6570\u5b66\u57fa\u7840\uff0c\u662f\u56e0\u679c\u8868\u5f81\u5b66\u4e60\u7684\u6838\u5fc3\u5de5\u5177\u3002</p>"},{"location":"notes/6.S091/Representation/#why-sumfrac12","title":"Why \\(\\sum^{\\frac{1}{2}}\\) ?","text":"<p>\u5728\u516c\u5f0f \\( z = A^T z + \\Sigma^{1/2} \\epsilon \\) \u4e2d\uff0c\\( \\Sigma^{1/2} \\) \u7684\u5f15\u5165\u4e0e\u566a\u58f0\u9879\u7684\u65b9\u5dee\u89c4\u8303\u5316\u76f4\u63a5\u76f8\u5173\uff0c\u5176\u6838\u5fc3\u4f5c\u7528\u662f\u5206\u79bb\u566a\u58f0\u7684\u201c\u7f29\u653e\u6548\u5e94\u201d\u4e0e\u201c\u72ec\u7acb\u6027\u5047\u8bbe\u201d\uff0c\u8ba9\u6a21\u578b\u66f4\u7b26\u5408\u56e0\u679c\u63a8\u65ad\u7684\u57fa\u672c\u8bbe\u5b9a\u3002\u4ee5\u4e0b\u4ece\u6570\u5b66\u539f\u7406\u548c\u56e0\u679c\u6a21\u578b\u9700\u6c42\u4e24\u65b9\u9762\u8be6\u7ec6\u89e3\u91ca\uff1a</p> <ol> <li> <p>\u566a\u58f0\u9879\u7684\u65b9\u5dee\u4e0e\u72ec\u7acb\u6027\u5047\u8bbe \u5728\u56e0\u679c\u7ed3\u6784\u6a21\u578b\uff08SCM\uff09\u4e2d\uff0c\u5916\u751f\u566a\u58f0 \\( \\epsilon \\) \u9700\u6ee1\u8db3\u4e24\u4e2a\u5173\u952e\u6027\u8d28\uff1a - \u72ec\u7acb\u6027\uff1a\u4e0d\u540c\u53d8\u91cf\u7684\u566a\u58f0\u76f8\u4e92\u72ec\u7acb\uff08\u65e0\u6df7\u6dc6\uff09\uff0c\u5373 \\( \\text{Cov}(\\epsilon) = I \\)\uff08\u5355\u4f4d\u77e9\u9635\uff09\u3002\u8fd9\u662f\u56e0\u679c\u6a21\u578b\u4e2d\u201c\u5916\u751f\u53d8\u91cf\u65e0\u7236\u8282\u70b9\u201d\u7684\u6570\u5b66\u4f53\u73b0\u2014\u2014\u566a\u58f0\u4e0d\u80fd\u88ab\u5176\u4ed6\u53d8\u91cf\uff08\u5305\u62ec\u5176\u4ed6\u566a\u58f0\uff09\u89e3\u91ca\u3002 - \u65b9\u5dee\u53ef\u63a7\uff1a\u6bcf\u4e2a\u566a\u58f0\u9879 \\( \\epsilon_j \\) \u53ef\u4ee5\u6709\u4e0d\u540c\u7684\u65b9\u5dee\uff08\u53cd\u6620\u53d8\u91cf \\( z_j \\) \u53d7\u4e0d\u53ef\u89c2\u6d4b\u56e0\u7d20\u5f71\u54cd\u7684\u7a0b\u5ea6\uff09\uff0c\u4f46\u9700\u901a\u8fc7\u4e00\u4e2a\u77e9\u9635\u7edf\u4e00\u8868\u793a\u3002  </p> </li> <li> <p>\\( \\Sigma^{1/2} \\) \u7684\u6570\u5b66\u610f\u4e49\uff1a\u65b9\u5dee\u7684\u201c\u5206\u89e3\u201d\u4e0e\u201c\u7f29\u653e\u201d - \\( \\Sigma \\) \u7684\u5b9a\u4e49\uff1a\\( \\Sigma \\) \u662f\u566a\u58f0\u9879 \\( \\Sigma^{1/2} \\epsilon \\) \u7684\u534f\u65b9\u5dee\u77e9\u9635\u3002   \u6839\u636e\u534f\u65b9\u5dee\u7684\u6027\u8d28 \\( \\text{Cov}(M \\epsilon) = M \\cdot \\text{Cov}(\\epsilon) \\cdot M^T \\)\uff08\\( M \\) \u4e3a\u5e38\u6570\u77e9\u9635\uff09\uff0c\u4ee3\u5165 \\( M = \\Sigma^{1/2} \\) \u548c \\( \\text{Cov}(\\epsilon) = I \\)\uff0c\u53ef\u5f97\uff1a   [   \\text{Cov}(\\Sigma^{\u00bd} \\epsilon) = \\Sigma^{\u00bd} \\cdot I \\cdot (\\Sigma<sup>{\u00bd})</sup>T = \\Sigma^{\u00bd} \\cdot \\Sigma^{\u00bd} = \\Sigma   ]   \u56e0\u6b64\uff0c\\( \\Sigma \\) \u76f4\u63a5\u8868\u793a\u4e86\u566a\u58f0\u9879 \\( \\Sigma^{1/2} \\epsilon \\) \u7684\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u5176\u5bf9\u89d2\u5143\u7d20 \\( \\Sigma_{jj} \\) \u5c31\u662f\u7b2c \\( j \\) \u4e2a\u566a\u58f0\u9879\u7684\u65b9\u5dee\u3002</p> </li> </ol> <ul> <li>\\( \\Sigma^{1/2} \\) \u7684\u4f5c\u7528\uff1a   \u5b83\u662f \\( \\Sigma \\) \u7684\u201c\u5e73\u65b9\u6839\u77e9\u9635\u201d\uff08\u901a\u5e38\u53d6\u5bf9\u79f0\u5e73\u65b9\u6839\uff09\uff0c\u7528\u4e8e\u5c06\u5355\u4f4d\u65b9\u5dee\u7684\u566a\u58f0 \\( \\epsilon \\) \u7f29\u653e\u4e3a\u6307\u5b9a\u65b9\u5dee\u7684\u566a\u58f0 \\( \\Sigma^{1/2} \\epsilon \\)\u3002   \u4f8b\u5982\uff0c\u82e5 \\( \\Sigma \\) \u662f\u5bf9\u89d2\u77e9\u9635 \\( \\text{diag}(\\sigma_1^2, \\sigma_2^2, ..., \\sigma_d^2) \\)\uff0c\u5219 \\( \\Sigma^{1/2} = \\text{diag}(\\sigma_1, \\sigma_2, ..., \\sigma_d) \\)\uff0c\u6b64\u65f6\uff1a   [   \\Sigma^{\u00bd} \\epsilon = (\\sigma_1 \\epsilon_1, \\sigma_2 \\epsilon_2, ..., \\sigma_d \\epsilon_d)^T   ]   \u6bcf\u4e2a\u566a\u58f0\u9879\u7684\u65b9\u5dee\u88ab\u7f29\u653e\u4e3a \\( \\sigma_j^2 \\)\uff0c\u540c\u65f6\u4fdd\u6301\u4e86 \\( \\epsilon \\) \u7684\u72ec\u7acb\u6027\uff08\u56e0 \\( \\Sigma^{1/2} \\) \u662f\u5bf9\u89d2\u77e9\u9635\uff0c\u4e0d\u5f15\u5165\u4ea4\u53c9\u9879\uff09\u3002  </li> </ul> <ol> <li>\u4e3a\u4ec0\u4e48\u4e0d\u76f4\u63a5\u7528 \\( \\epsilon \\) \u800c\u8981\u5f15\u5165 \\( \\Sigma^{1/2} \\) - \u5206\u79bb\u201c\u7ed3\u6784\u201d\u4e0e\u201c\u7f29\u653e\u201d\uff1a   \u516c\u5f0f \\( z = A^T z + \\Sigma^{1/2} \\epsilon \\) \u4e2d\uff0c\\( A^T \\) \u523b\u753b\u4e86\u53d8\u91cf\u95f4\u7684\u56e0\u679c\u7ed3\u6784\uff08\u7236\u8282\u70b9\u5bf9\u5b50\u5973\u7684\u5f71\u54cd\u6743\u91cd\uff09\uff0c\u800c \\( \\Sigma^{1/2} \\) \u5355\u72ec\u63a7\u5236\u566a\u58f0\u7684\u65b9\u5dee\u5927\u5c0f\u3002\u8fd9\u79cd\u5206\u79bb\u8ba9\u6a21\u578b\u66f4\u7075\u6d3b\u2014\u2014\u53ef\u4ee5\u5728\u4e0d\u6539\u53d8\u56e0\u679c\u7ed3\u6784\uff08\\( A \\) \u4e0d\u53d8\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u8c03\u6574\u566a\u58f0\u7684\u5f71\u54cd\u7a0b\u5ea6\uff08\\( \\Sigma \\) \u53d8\u5316\uff09\u3002  </li> </ol> <ul> <li>\u7b26\u5408\u56e0\u679c\u63a8\u65ad\u7684\u53ef\u8bc6\u522b\u6027\u9700\u6c42\uff1a   \u5728\u540e\u7eed\u7684\u534f\u65b9\u5dee\u77e9\u9635\u63a8\u5bfc\uff08\u5982 \\( \\text{Cov}(z) \\) \u7684\u8ba1\u7b97\uff09\u4e2d\uff0c\\( \\Sigma^{1/2} \\) \u7684\u5f15\u5165\u80fd\u8ba9\u566a\u58f0\u65b9\u5dee\u6e05\u6670\u5730\u4f53\u73b0\u5728\u7ed3\u679c\u4e2d\uff0c\u907f\u514d\u4e0e\u56e0\u679c\u7ed3\u6784\u53c2\u6570 \\( A \\) \u6df7\u6dc6\u3002\u4f8b\u5982\uff0c\u6f5c\u5728\u53d8\u91cf \\( z \\) \u7684\u534f\u65b9\u5dee\u516c\u5f0f\uff1a   [   \\text{Cov}(z) = (I - A<sup>T)</sup> \\Sigma \\left( (I - A<sup>T)</sup> \\right)^T   ]   \u5176\u4e2d \\( \\Sigma \\) \u76f4\u63a5\u5bf9\u5e94\u566a\u58f0\u7684\u603b\u65b9\u5dee\uff0c\u8fd9\u4e3a\u4ece\u89c2\u6d4b\u6570\u636e\u53cd\u63a8\u56e0\u679c\u7ed3\u6784\uff08\\( A \\)\uff09\u63d0\u4f9b\u4e86\u53ef\u8bc6\u522b\u7684\u6570\u5b66\u6761\u4ef6\u3002  </li> </ul>"},{"location":"notes/6.S091/Structural%20Causal%20Model/","title":"Structural Causal Model","text":""},{"location":"notes/6.S091/Structural%20Causal%20Model/#structural-causal-model","title":"Structural Causal Model","text":"<p> \u7ea6 725 \u4e2a\u5b57  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 4 \u5206\u949f</p> Known Model Known Variables Policy Evaluation \u2705 \u2705 Structure Learning \u274c \u2705 Representation Learning \u274c \u274c"},{"location":"notes/6.S091/Structural%20Causal%20Model/#def1","title":"Def1","text":"<p>A signature \\(\\mathcal{S}\\) consists of:</p> <ul> <li>\\(\\mathcal{X}\\) - a set of endogenous variables</li> <li>\\(\\epsilon\\) - a set of exogenous variables</li> <li>A range function \\(\\mathcal{R}\\) mapping \\(V \\in X \\epsilon\\) to its alphabet \\(\\mathcal{R}(V)\\)</li> </ul> <p>\\(R(\\mathbb{V})\\) = \\(X_{V \\in \\mathcal{V}} \\mathcal{R}(V)\\)</p> <p>\\(\\mathcal{G}\\) directed acyclic graph(DAG) over \\(\\mathcal{X}\\)</p> <ul> <li>\\(pa_{\\mathcal{G}}(X_i)\\) parents</li> <li>\\(ch_{\\mathcal{G}}(X_i)\\) children</li> <li>\\(an_{\\mathcal{G}}(X_i)\\) ancestors</li> <li>\\(de_{\\mathcal{G}}(X_i)\\) descendants</li> <li>\\(\\tilde{pa}_{\\mathcal{G}}(X_i)\\) inclusive parents &amp; \\(X_i\\)</li> </ul>"},{"location":"notes/6.S091/Structural%20Causal%20Model/#def2","title":"Def2","text":"<p>A DAG \\(\\tilde{\\mathcal{G}}\\) over nodes \\(\\mathcal{G} \\cup \\epsilon\\) is compatible with signature \\(S\\) if \\(pa_{\\mathcal{G}}(\\epsilon_i) = \\emptyset\\),\\(\\forall \\epsilon_i \\in \\epsilon\\).We call \\((\\tilde{\\mathcal{G}},S)\\) a template.</p>"},{"location":"notes/6.S091/Structural%20Causal%20Model/#def-3-admg","title":"Def 3 ADMG","text":"<p>the latent projection of G denoted G(X) is a mixed graph w/:</p> <p>\\(X_i-&gt;X_j\\) if \\(X_i-&gt;X_j\\) in G</p> <p>\\(X_i&lt;-&gt;X_j\\) if \\(\\exist \\epsilon_k \\in \\epsilon\\) s.t. \\(\\epsilon_k -&gt; X_i\\),\\(\\epsilon_k -&gt; X_j\\)</p> <p>We call \\(\\tilde{\\mathcal{G}}\\) Markovian if \\(|ch_{\\mathcal{G}}(\\epsilon)| \\leq 1\\),thus its latent projection is itself.</p> <p></p>"},{"location":"notes/6.S091/Structural%20Causal%20Model/#causal-mechanism","title":"\u56e0\u679c\u673a\u5236\uff08Causal Mechanism\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u9488\u5bf9\u7cfb\u7edf\u4e2d\u6bcf\u4e2a\u5185\u751f\u53d8\u91cf\u7684\u51fd\u6570\uff0c\u8f93\u5165\u4e3a\u8be5\u53d8\u91cf\u7236\u96c6\u8303\u56f4\u5185\u7684\u53d6\u503c\uff0c\u8f93\u51fa\u4e3a\u8be5\u53d8\u91cf\u7684\u53d6\u503c</li> <li>\u4f5c\u7528\uff1a\u5b9a\u91cf\u63cf\u8ff0\u5185\u751f\u53d8\u91cf\u4e0e\u5176\u4ed6\u53d8\u91cf\uff08\u7236\u53d8\u91cf\uff09\u7684\u5173\u7cfb</li> </ul>"},{"location":"notes/6.S091/Structural%20Causal%20Model/#structural-causal-model-scm","title":"\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff08Structural Causal Model, SCM\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u7531\u4e24\u90e8\u5206\u7ec4\u6210\u7684\u6a21\u578b</li> <li>\u5916\u751f\u53d8\u91cf\u7684\u8054\u5408\u5206\u5e03\uff1a\u5916\u751f\u53d8\u91cf\u4e4b\u95f4\u76f8\u4e92\u72ec\u7acb\u7684\u8054\u5408\u5206\u5e03</li> <li>\u7d22\u5f15\u7684\u56e0\u679c\u673a\u5236\u96c6\u5408\uff1a\u6bcf\u4e2a\u5185\u751f\u53d8\u91cf\u5bf9\u5e94\u7684\u56e0\u679c\u673a\u5236\u51fd\u6570</li> <li>\u7279\u6027\uff1a\u5916\u751f\u53d8\u91cf\u662f\u7cfb\u7edf\u968f\u673a\u6027\u7684\u6765\u6e90\uff0c\u5185\u751f\u53d8\u91cf\u662f\u5916\u751f\u53d8\u91cf\u548c\u5176\u7236\u53d8\u91cf\u7684\u786e\u5b9a\u6027\u51fd\u6570</li> </ul>"},{"location":"notes/6.S091/Structural%20Causal%20Model/#6-entailed-distribution","title":"6. \u7ee7\u627f\u5206\u5e03\uff08Entailed Distribution\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u7531\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u5bfc\u51fa\u7684\u3001\u5185\u751f\u53d8\u91cfX\u4e0a\u7684\u552f\u4e00\u5206\u5e03</li> <li>\u751f\u6210\u65b9\u5f0f\uff1a\u901a\u8fc7\u5916\u751f\u53d8\u91cf\u7684\u5206\u5e03\u548c\u56e0\u679c\u673a\u5236\u51fd\u6570\u5411\u524d\u63a8\u6f14\u5f97\u5230</li> </ul>"},{"location":"notes/6.S091/Structural%20Causal%20Model/#7-intervention","title":"7. \u5e72\u9884\uff08Intervention\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u7531\u5e72\u9884\u76ee\u6807\u548c\u5e72\u9884\u56e0\u679c\u673a\u5236\u7ec4\u6210\u7684\u64cd\u4f5c</li> <li>\u5e72\u9884\u76ee\u6807\uff1a\u4e00\u7ec4\u5185\u751f\u53d8\u91cf\uff08\u88ab\u5e72\u9884\u7684\u8282\u70b9\uff09</li> <li>\u5e72\u9884\u56e0\u679c\u673a\u5236\uff1a\u9488\u5bf9\u5e72\u9884\u76ee\u6807\u53d8\u91cf\u7684\u65b0\u56e0\u679c\u673a\u5236\u51fd\u6570</li> <li>\u4ecb\u5165\u5f0f\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff1a\u5e94\u7528\u5e72\u9884\u540e\u5f97\u5230\u7684\u65b0\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff0c\u5176\u4e2d\u672a\u88ab\u5e72\u9884\u7684\u53d8\u91cf\u4fdd\u6301\u539f\u56e0\u679c\u673a\u5236</li> </ul>"},{"location":"notes/6.S091/Structural%20Causal%20Model/#8-do-intervention","title":"8. \u5b8c\u7f8e\u5e72\u9884\uff08Do-Intervention\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u4e00\u79cd\u7279\u6b8a\u7684\u5e72\u9884\uff0c\u5c06\u5e72\u9884\u76ee\u6807\u53d8\u91cf\u7684\u56e0\u679c\u673a\u5236\u51fd\u6570\u66ff\u6362\u4e3a\u4e00\u4e2a\u786e\u5b9a\u503c</li> <li>\u7b26\u53f7\uff1a\u7528\u201cdo(X=a)\u201d\u8868\u793a\uff0c\u5176\u4e2dX\u4e3a\u5e72\u9884\u76ee\u6807\u53d8\u91cf\uff0ca\u4e3a\u8bbe\u5b9a\u7684\u786e\u5b9a\u503c</li> </ul>"},{"location":"notes/6.S091/Structural%20Causal%20Model/#9-counterfactual","title":"9. \u53cd\u4e8b\u5b9e\uff08Counterfactual\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u7528\u4e8e\u56de\u7b54\u201c\u82e5\u6539\u53d8\u67d0\u4ef6\u4e8b\u800c\u5176\u4ed6\u6761\u4ef6\u4e0d\u53d8\uff0c\u7ed3\u679c\u4f1a\u5982\u4f55\u201d\u7684\u6982\u5ff5\uff0c\u9488\u5bf9\u7279\u5b9a\u5df2\u89c2\u5bdf\u7ed3\u679c\u7684\u4f8b\u5b50</li> <li>\u5b9e\u73b0\u65b9\u5f0f\uff1a\u901a\u8fc7\u6539\u53d8\u5916\u751f\u53d8\u91cf\u7684\u5206\u5e03\uff08\u57fa\u4e8e\u89c2\u5bdf\u5230\u7684\u53d8\u91cf\u5b50\u96c6\u7684\u6761\u4ef6\u5206\u5e03\uff09\u6784\u5efa\u53cd\u4e8b\u5b9e\u7ed3\u6784\u56e0\u679c\u6a21\u578b</li> <li>\u4e0e\u5e72\u9884\u7684\u533a\u522b\uff1a\u5e72\u9884\u9762\u5411\u672a\u6765\uff08\u5982\u201c\u82e5\u672a\u6765\u5b9e\u65bd\u67d0\u63aa\u65bd\uff0c\u7ed3\u679c\u4f1a\u600e\u6837\u201d\uff09\uff0c\u53cd\u4e8b\u5b9e\u9488\u5bf9\u5df2\u53d1\u751f\u7684\u7279\u5b9a\u6848\u4f8b\uff08\u5982\u201c\u82e5\u8fc7\u53bb\u67d0\u56e0\u7d20\u4e0d\u540c\uff0c\u7ed3\u679c\u4f1a\u600e\u6837\u201d\uff09</li> </ul>"},{"location":"notes/CS0501H/%E6%9C%80%E8%BF%91%E5%85%AC%E5%85%B1%E7%A5%96%E5%85%88/","title":"\u6700\u8fd1\u516c\u5171\u7956\u5148","text":"<p>\u53c2\u8003\u6587\u7ae0\uff1a</p> <p>\u4e8c\u53c9\u6811\u4e2d\u7684\u6700\u4f4e\u516c\u5171\u7956\u5148 | GeeksforGeeks --- Lowest Common Ancestor in a Binary Tree | GeeksforGeeks</p>"},{"location":"notes/CS0501H/%E6%9C%80%E8%BF%91%E5%85%AC%E5%85%B1%E7%A5%96%E5%85%88/#_1","title":"\u6cd5\u4e00","text":"<p> \u7ea6 202 \u4e2a\u5b57  156 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> <p>\u7528\u4e24\u4e2a\u72ec\u7acb\u7684\u6570\u7ec4\u50a8\u5b58\u6839\u8282\u70b9\u5230\u8282\u70b9\u7684\u8def\u5f84\uff0c\u7136\u540e\u4ece0\u5f00\u59cb\u904d\u5386\u3002LCA\u662f\u8fd9\u4e24\u4e2a\u6570\u7ec4\u6700\u540e\u5339\u914d\u7684\u5143\u7d20\u3002</p> C++<pre><code>// C++ program to find LCA using Arrays to Store \n// Paths of Nodes from Root\n#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nclass Node {\npublic:\n    int data;\n    Node *left, *right;\n    Node(int x) {\n        data = x;\n        left = nullptr;\n        right = nullptr;\n    }\n};\n\n// Function to find path from root to given node.\nbool findPath(Node* root, vector&lt;Node*&gt;&amp; path, int k) {\n\n    // base case\n    if (root == nullptr)\n        return false;\n\n    // Store current node value in the path.\n    path.push_back(root);\n\n    // If node value is equal to k, or\n    // if node exist in left subtree or\n    // if node exist in right subtree return true\n    if (root-&gt;data == k || \n            findPath(root-&gt;left, path, k) ||\n                 findPath(root-&gt;right, path, k))\n        return true;\n\n    // else remove root from path and return false\n    path.pop_back();\n    return false;\n}\n\n// Returns LCA of two nodes.\nNode* lca(Node* root, int n1, int n2) {\n\n    // to store paths to n1 and n2 from the root\n    vector&lt;Node*&gt; path1, path2;\n\n    // Find paths from root to n1 and \n    // root to n2. If either\n    // n1 or n2 is not present, return nullptr\n    if (!findPath(root, path1, n1) || \n        !findPath(root, path2, n2))\n        return nullptr;\n\n    // Compare the paths to get the first\n    // different value\n    int i;\n    for (i = 0; i &lt; path1.size()\n                    &amp;&amp; i &lt; path2.size(); i++) {\n        if (path1[i] != path2[i])\n            return path1[i-1];\n    }\n\n    // if both the datas are same, return last node\n    return path1[i-1];\n}\n\nint main() {\n\n    // construct the binary tree\n    //             1\n    //           /   \\\n    //          2     3\n    //         / \\   / \\\n    //        4  5  6   7 \n    Node* root = new Node(1);\n    root-&gt;left = new Node(2);\n    root-&gt;right = new Node(3);\n    root-&gt;left-&gt;left = new Node(4);\n    root-&gt;left-&gt;right = new Node(5);\n    root-&gt;right-&gt;left = new Node(6);\n    root-&gt;right-&gt;right = new Node(7);\n\n    Node* ans = lca(root, 4, 5);\n    if(ans == nullptr)\n        cout&lt;&lt;\"No common ancestor found\";\n    else\n        cout&lt;&lt; ans-&gt;data;\n    return 0;\n}\n</code></pre>"},{"location":"notes/CS0501H/%E6%9C%80%E8%BF%91%E5%85%AC%E5%85%B1%E7%A5%96%E5%85%88/#_2","title":"\u6cd5\u4e8c","text":"<p>The idea is to traverse the tree starting from the root. If any of the given keys *(n1 and n2) matches* with the root, then the root is LCA (assuming that both keys are present). If the root *doesn\u2019t* *match* with any of the keys, we *recur* for the *left* and *right* subtree. The node which has *one key* present in its *left* subtree and the *other key* present in the *right* subtree is the LCA, else if, both keys lie in the *left* subtree, then the *left* *subtree* has LCA, else the *LCA* lies in the *right* subtree.*</p> C++<pre><code>// C++ program to find LCA using Single traversal\n#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nclass Node {\npublic:\n    Node *left, *right;\n    int data;\n    Node(int k) {\n        data = k;\n        left = nullptr;\n        right = nullptr;\n    }\n};\n\n// Function to find LCA of two keys.\nNode* lca(Node* root, int n1, int n2) {\n\n    if (!root)\n        return nullptr;\n\n    // If either key matches with root data, return root\n    if (root-&gt;data == n1 || root-&gt;data == n2)\n        return root;\n\n    // Look for datas in left and right subtrees\n    Node* leftLca = lca(root-&gt;left, n1, n2);\n    Node* rightLca = lca(root-&gt;right, n1, n2);\n\n    // If both of the above calls return Non-NULL, then one\n    // data is present in one subtree and the other is present\n    // in the other, so this node is the LCA\n    if (leftLca &amp;&amp; rightLca)\n        return root;\n\n    // Otherwise check if left subtree or right subtree is\n    // LCA\n    return leftLca ? leftLca : rightLca;\n}\n\nint main() {\n\n    // construct the binary tree\n    //             1\n    //           /   \\\n    //          2     3\n    //         / \\   / \\\n    //        4  5  6   7 \n\n    Node* root = new Node(1);\n    root-&gt;left = new Node(2);\n    root-&gt;right = new Node(3);\n    root-&gt;left-&gt;left = new Node(4);\n    root-&gt;left-&gt;right = new Node(5);\n    root-&gt;right-&gt;left = new Node(6);\n    root-&gt;right-&gt;right = new Node(7);\n\n    Node* ans = lca(root, 4, 5);\n    if(ans == nullptr){\n        cout&lt;&lt;\"No common ancestor found\";\n    }\n    else{\n        cout&lt;&lt;ans-&gt;data;\n    }\n\n    return 0;\n}\n</code></pre> <p>\u4e0a\u8ff0\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4e24\u4e2akey\u90fd\u5fc5\u987b\u5b58\u5728\u6811\u4e2d\uff0c\u800c\u5b9e\u9645\u60c5\u51b5\u4e0d\u540c\u3002\u9700\u8981\u5bfb\u627e\u662f\u5426\u5728\u6811\u4e2d\u3002</p>"},{"location":"notes/CS0501H/%E9%93%BE%E8%A1%A8/","title":"\u7ebf\u6027\u8868","text":"<p> \u7ea6 93 \u4e2a\u5b57  28 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u5143\u7d20\u7684\u5730\u5740\uff1a\u5143\u7d20\u7684\u9996\u5730\u5740\uff08\u56e0\u4e3a\u4e00\u4e2a\u5143\u7d20\u53ef\u80fd\u662f\u591a\u4e2a\u5b57\u8282\uff09</p> <p>\u6bd4\u5982int\u7c7b\u578b\uff084\u4e2a\u5b57\u8282\uff09 a1 :0,1,2,3  a2:4,5,6,7</p> <p>\u968f\u673a\u8bfb\u53d6 \\(~O(1)\\) a[i-1] = a[0] + (i-1)* d</p> C++<pre><code>#define LIST_INIT_SIZE 100 //\u521d\u59cb\u5bb9\u91cf\n#define LIST_INCREMENT 10  //\u8ffd\u52a0\u5185\u5b58\u65f6\u7684\u589e\u91cf \u5b8f=\u5168\u5c40\u53d8\u91cf+const\ntypedef int ElemType;\n\ntypedef struct{\n    ElemType *elem; //\u8fde\u7eed\u5185\u5b58\u9996\u5730\u5740\n    int length;\n    int size;\n} SqList;\nSqList L:\nL.elem;//\u9996\u5730\u5740 \nL.elem[0];// \u7b2c\u4e00\u4e2a\u5143\u7d20\nl.length;//\u8868\u957f\nL.size; //\u8868\u5bb9\u91cf\nL.elem[L.length-1] // \u53d6\u6700\u540e\u4e00\u4e2a\u6570\n\nvoid init(SqList &amp;L){\n    L.elem = (ElemType *)malloc(LIST_INIT_SIZE * sizeof(ElemType))\n}\n\nvoid getElem(SqList L,int i,ElemType &amp;e)\n{\n    if (i &lt; 1 || i &gt; L.length)\n    {\n        return;\n    }\n    e = L.elem[i-1];\n}\n</code></pre> <p>\u94fe\u8868\uff1a\u89e3\u51b3\u63d2\u5165\u5220\u9664</p> <p>\u4e0d\u662f\u968f\u673a\u8bfb\u53d6</p> <p>\u5faa\u73af\u94fe\u8868\u5143\u7d20\u4e2a\u6570\uff1a(front-rear+\u5bb9\u91cf) mod \u5bb9\u91cf \u5176\u4e2dfront\u662f\u5934\u6307\u9488\uff0crear\u662f\u5c3e\u6307\u9488</p>"},{"location":"notes/EECS498/2-layer-network/","title":"\u7b2c\u4e8c\u6b21\u4f5c\u4e1a(Two Layer Net)","text":"<p> \u7ea6 633 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> <p>\u4e3a\u4e86\u8bc1\u660e\u635f\u5931\u51fd\u6570 \\( L \\) \u5bf9\u6743\u91cd \\( W1 \\)\u3001\\( W2 \\) \u548c\u504f\u7f6e \\( b1 \\)\u3001\\( b2 \\) \u7684\u68af\u5ea6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u94fe\u5f0f\u6cd5\u5219\uff08Chain Rule\uff09\u548c\u7ebf\u6027\u4ee3\u6570\u7684\u77e5\u8bc6\u3002\u4ee5\u4e0b\u662f\u8be6\u7ec6\u7684\u63a8\u5bfc\u8fc7\u7a0b\u3002</p>"},{"location":"notes/EECS498/2-layer-network/#l-w1-w2-b1-b2","title":"\u7528\u7ebf\u6027\u4ee3\u6570\u7684\u77e5\u8bc6\u8bc1\u660e \\( L \\) \u5bf9 \\( W1 \\)\u3001\\( W2 \\)\u3001\\( b1 \\)\u3001\\( b2 \\) \u7684\u68af\u5ea6","text":""},{"location":"notes/EECS498/2-layer-network/#1","title":"1. \u5b9a\u4e49\u7b26\u53f7\u548c\u7f51\u7edc\u7ed3\u6784","text":"<p>\u5047\u8bbe\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\uff1a</p> <ol> <li>\u8f93\u5165\u5c42\uff1a\u8f93\u5165\u6570\u636e \\( X \\)\uff0c\u7ef4\u5ea6\u4e3a \\( N \\times D \\)\uff08\\( N \\) \u662f\u6837\u672c\u6570\u91cf\uff0c\\( D \\) \u662f\u7279\u5f81\u7ef4\u5ea6\uff09\u3002</li> <li>\u9690\u85cf\u5c42\uff1a<ul> <li>\u6743\u91cd \\( W1 \\)\uff0c\u7ef4\u5ea6\u4e3a \\( D \\times H \\)\uff08\\( H \\) \u662f\u9690\u85cf\u5c42\u795e\u7ecf\u5143\u6570\u91cf\uff09\u3002</li> <li>\u504f\u7f6e \\( b1 \\)\uff0c\u7ef4\u5ea6\u4e3a \\( H \\)\u3002</li> <li>\u6fc0\u6d3b\u51fd\u6570\u4e3a ReLU\uff1a\\( h1 = \\text{ReLU}(X \\cdot W1 + b1) \\)\uff0c\u7ef4\u5ea6\u4e3a \\( N \\times H \\)\u3002</li> </ul> </li> <li>\u8f93\u51fa\u5c42\uff1a<ul> <li>\u6743\u91cd \\( W2 \\)\uff0c\u7ef4\u5ea6\u4e3a \\( H \\times C \\)\uff08\\( C \\) \u662f\u7c7b\u522b\u6570\u91cf\uff09\u3002</li> <li>\u504f\u7f6e \\( b2 \\)\uff0c\u7ef4\u5ea6\u4e3a \\( C \\)\u3002</li> <li>\u8f93\u51fa logits\uff1a\\( scores = h1 \\cdot W2 + b2 \\)\uff0c\u7ef4\u5ea6\u4e3a \\( N $\\times$ C \\)\u3002</li> </ul> </li> <li>Softmax \u548c\u635f\u5931\u51fd\u6570\uff1a<ul> <li>Softmax \u8f93\u51fa\uff1a\\( probs = \\text{Softmax}(scores) \\)\u3002</li> <li>\u4ea4\u53c9\u71b5\u635f\u5931\uff1a\\( L = -\\frac{1}{N} \\sum_{i=1}^N \\log(probs_{i, y_i}) )\uff0c\u5176\u4e2d \\( y_i \\) \u662f\u7b2c \\( i \\) \u4e2a\u6837\u672c\u7684\u771f\u5b9e\u6807\u7b7e\u3002</li> </ul> </li> </ol> <p>### 2. \u8ba1\u7b97\u68af\u5ea6</p> <p>\u6211\u4eec\u9700\u8981\u8ba1\u7b97 \\( L \\) \u5bf9 \\( W1 \\)\u3001\\( W2 \\)\u3001\\( b1 \\)\u3001\\( b2 \\) \u7684\u68af\u5ea6\u3002</p>"},{"location":"notes/EECS498/2-layer-network/#1-fracpartial-lpartial-w2-fracpartial-lpartial-b2","title":"(1) \u68af\u5ea6 \\( \\frac{\\partial L}{\\partial W2} ) \u548c ( \\frac{\\partial L}{\\partial b2} \\)","text":"<ul> <li>\u6839\u636e\u94fe\u5f0f\u6cd5\u5219\uff1a     [ \\(\\frac{\\partial L}{\\partial W2} = \\frac{\\partial L}{\\partial scores} \\cdot \\frac{\\partial scores}{\\partial W2}\\)     ]<ul> <li>\\( \\frac{\\partial L}{\\partial scores} = probs - \\text{one-hot label} \\)\uff0c\u7ef4\u5ea6\u4e3a \\( N \\times C \\)\u3002</li> <li>\\($ \\frac{\\partial scores}{\\partial W2} = h1^T$ \\)\uff0c\u7ef4\u5ea6\u4e3a \\( H $\\times$ N \\)\u3002</li> <li>\u56e0\u6b64\uff1a   [ \\(\\frac{\\partial L}{\\partial W2} = h1^T \\cdot (probs - \\text{one-hot label})\\)   ]</li> </ul> </li> <li>\u5bf9\u4e8e \\( b2 \\)\uff1a     [ \\(\\frac{\\partial L}{\\partial b2} = \\sum_{i=1}^N (probs_i - \\text{one-hot label}_i)\\)     ]</li> </ul> <p>#### (2) \u68af\u5ea6 \\(( \\frac{\\partial L}{\\partial W1} ) \u548c ( \\frac{\\partial L}{\\partial b1} )\\)</p> <ul> <li>\u6839\u636e\u94fe\u5f0f\u6cd5\u5219\uff1a     [ \\(\\frac{\\partial L}{\\partial W1} = \\frac{\\partial L}{\\partial h1} \\cdot \\frac{\\partial h1}{\\partial (X \\cdot W1 + b1)} \\cdot \\frac{\\partial (X \\cdot W1 + b1)}{\\partial W1}\\)     ]<ul> <li>\\( \\frac{\\partial L}{\\partial h1} = (probs - \\text{one-hot label}) \\cdot W2^T \\)\uff0c\u7ef4\u5ea6\u4e3a \\( N \\times H \\)\u3002</li> <li>\\( \\frac{\\partial h1}{\\partial (X \\cdot W1 + b1)} = \\text{ReLU \u7684\u5bfc\u6570} \\)\uff0c\u5373 \\( 1 \\) \u5982\u679c \\( h1 &gt; 0 \\)\uff0c\u5426\u5219 \\( 0 \\)\u3002</li> <li>\\( \\frac{\\partial (X \\cdot W1 + b1)}{\\partial W1} = X^T )\uff0c\u7ef4\u5ea6\u4e3a \\( D \\times N \\)\u3002</li> <li>\u56e0\u6b64\uff1a   [ \\(\\frac{\\partial L}{\\partial W1} = X^T \\cdot \\left( (probs - \\text{one-hot label}) \\cdot W2^T \\odot \\text{ReLU \u7684\u5bfc\u6570} \\right)\\)   ]</li> </ul> </li> <li>\u5bf9\u4e8e \\( b1 \\)\uff1a     [ \\(\\frac{\\partial L}{\\partial b1} = \\sum_{i=1}^N \\left( (probs_i - \\text{one-hot label}_i) \\cdot W2^T \\odot \\text{ReLU \u7684\u5bfc\u6570} \\right)\\)     ]</li> </ul> <p>### 3. \u6b63\u5219\u5316\u9879\u7684\u68af\u5ea6</p> <p>\u5982\u679c\u635f\u5931\u51fd\u6570\u5305\u542b L2 \u6b63\u5219\u5316\u9879\uff08\u5982 \\( \\text{reg} \\cdot (\\|W1\\|^2 + \\|W2\\|^2) \\)\uff09\uff0c\u5219\u68af\u5ea6\u9700\u8981\u52a0\u4e0a\u6b63\u5219\u5316\u9879\u7684\u5bfc\u6570\uff1a</p> <ul> <li>\u5bf9\u4e8e \\( W1 \\)\uff1a     [ \\(\\frac{\\partial L}{\\partial W1} += 2 \\cdot \\text{reg} \\cdot W1\\)     ]</li> <li>\u5bf9\u4e8e \\( W2 \\)\uff1a     [ \\(\\frac{\\partial L}{\\partial W2} += 2 \\cdot \\text{reg} \\cdot W2\\)     ]</li> </ul>"},{"location":"notes/EECS498/2-layer-network/#4","title":"4. \u603b\u7ed3","text":"<p>\u901a\u8fc7\u94fe\u5f0f\u6cd5\u5219\u548c\u7ebf\u6027\u4ee3\u6570\u7684\u77e5\u8bc6\uff0c\u6211\u4eec\u63a8\u5bfc\u51fa\u4e86\u635f\u5931\u51fd\u6570 \\( L \\) \u5bf9 \\( W1 \\)\u3001\\( W2 \\)\u3001\\( b1 \\)\u3001\\( b2 \\) \u7684\u68af\u5ea6\u516c\u5f0f\u3002\u8fd9\u4e9b\u516c\u5f0f\u53ef\u4ee5\u76f4\u63a5\u7528\u4e8e\u5b9e\u73b0\u53cd\u5411\u4f20\u64ad\u3002</p>"},{"location":"notes/EECS498/A1/","title":"\u7b2c\u4e00\u6b21\u4f5c\u4e1a(pytorch & KNN)","text":"<p> \u7ea6 167 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>Deep Learning \\(\\in\\) Machine Learning</p> <p>Deep  Learning \\(\\cap\\) Computer Vision = EECS 498</p> <p>SIFT:\u8bc6\u522b\u56fe\u7247\u4e2d\u5c0f\u7684\u5339\u914d\u70b9\uff0c\u8ba1\u7b97\u7279\u5f81\u5411\u91cf\uff08\u4e0d\u4f1a\u56e0\u4e3a\u65cb\u8f6c\u4ee5\u53ca\u56fe\u7247\u7684\u4eae\u5ea6\u6539\u53d8\uff09</p> <p>\u79bb\u73b0\u5b9e\u751f\u6d3b\u8fd8\u6709\u4e00\u5b9a\u8ddd\u79bb\uff1a\u8ba1\u7b97\u673a\u53ea\u80fd\u770b\u5230\uff08\u8bc6\u522b\uff09\u4fe1\u606f\uff0c\u5374\u4e0d\u80fd\u7406\u89e3\u56fe\u7247\u80cc\u540e\u7684\u542b\u4e49\u3002\u4eba\u53ef\u4ee5\u901a\u8fc7\u5404\u79cd\u4fe1\u606f\u6765\u63a8\u7406\u5224\u65ad\uff0c\u4f46\u8ba1\u7b97\u673a\u5f88\u96be\u505a\u5230\u3002</p> <p>x.min(dim=0)\uff1a\u4f1a\u8fd4\u56de\u4e24\u4e2a\u503c\uff0c\u7b2c\u4e00\u4e2a\u5c31\u662f\u6700\u5c0f\u503c\uff0c\u7b2c\u4e8c\u4e2a\u662f\u6700\u5c0f\u503c\u7684\u4f4d\u7f6e\uff08\u7d22\u5f15\uff09</p> <p>\u5982\u679c\u53ea\u60f3\u83b7\u5f97\u7d22\u5f15\u7684\u8bdd\uff0c\u5c31\u7528x.argmin()</p> <p>\u4e0b\u8f7dpytorch\u6559\u7a0b\u6587\u4ef6</p> <p>\u4e0b\u8f7dKNN\u7b97\u6cd5\u6587\u4ef6</p> <p>\u67e5\u770b Pytorch \u4ea4\u4e92 Notebook</p> <p>\u67e5\u770b KNN \u4ea4\u4e92 Notebook</p>"},{"location":"notes/EECS498/A2/","title":"\u7b2c\u4e8c\u6b21\u4f5c\u4e1a(Linear Classifiers)","text":""},{"location":"notes/EECS498/A2/#svm","title":"SVM:","text":"<p> \u7ea6 1319 \u4e2a\u5b57  22 \u884c\u4ee3\u7801  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 7 \u5206\u949f</p> <p>\u200b   \\(W:(D,C)\\) \\(X:(N,D)\\) \\(y:(N,)\\)</p> <p>\u6ce8\uff1a1. (N,)\u8868\u793a\u4e00\u7ef4\u5411\u91cf\uff0c\u65e2\u4e0d\u662f\u884c\u5411\u91cf\u4e5f\u4e0d\u662f\u5217\u5411\u91cf\u3002\u5982\u679c\u8981\u663e\u5f0f\u7684\u8868\u793a\u884c\u5411\u91cf(1,N)\u6216\u8005\u5217\u5411\u91cf(N,1),\u5c31\u8981\u7528.view(1,-1)\u6216\u8005.view(-1,1)\u3002</p> <ol> <li>\\(f(x_i,W)=W^Tx_i\\) \u5176\u4e2d\\(x_i\\)\u8868\u793a\\(X[i]\\),\u5373\\(X\\)\u7684\u7b2c\\(i\\)\u884c\uff0c\u662f\u4e2a\u4e00\u7ef4\u5411\u91cf\\((D,)\\),\u4e0d\u662f\u884c\u5411\u91cf\uff01\uff08\u5373\u4f60\u53d6\u884c/\u5217\u90fd\u4f1a\u964d\u7ef4\uff09</li> <li>\u4e0d\u7ba1\u662f\u4ec0\u4e48\u4e58\u6cd5\uff08\u77e9\u9635\u548c\u77e9\u9635\uff0c\u77e9\u9635\u548c\u5411\u91cf\uff0c\u70b9\u4e58\u8fd8\u662f\u77e9\u9635\u4e58\u6cd5\uff09\uff0c\u90fd\u7528matmul()\u5c31\u597d\u4e86\uff0c\u514d\u5f97\u62a5\u9519</li> <li>\\(W\\) \u4e2d\u884c\u6570\\(D\\)\u4ee3\u8868\u7279\u5f81\u6570\uff0c\u4e00\u822c\u4e3aRGB\u901a\u9053+\u50cf\u7d20\u503c\uff0c\u53ef\u4ee5\u8ba4\u4e3a\u8fd9\u4e2a\u7279\u5f81\u6570\u6781\u5927\uff0c\u5305\u542b\u4e86\u50cf\u7d20\u7684\u6240\u6709\u4fe1\u606f\uff1b\u5217\u6570\\(C\\)\u8868\u793a\u79cd\u7c7b\u6570\u76ee\uff0c\u5982CIFR-10\u63d0\u4f9b\u4e8610\u79cd\u56fe\u7247\u7c7b\u522b\u3002\\(X\\)\u7684\u884c\u6570\\(N\\)\u8868\u793a\u6837\u672c\u7684\u6570\u91cf\uff0c\u56e0\u6570\u636e\u5e93\u7684\u5927\u5c0f\u4e0d\u540c\u800c\u4e0d\u540c\u3002</li> </ol> <p>\u8fd9\u91cc\u76f4\u63a5\u501f\u7528@z_z\u5927\u4f6c\u7684\u56fe\uff1a</p> <p></p> <p>\\(Loss\\)\u8bb0\u5f97\u8981\u5e73\u5747\uff0c\u800c\u4e14\u6bcf\u6b21\u90fd\u662f\u7d2f\u52a0\uff0c\u4e0d\u662f\u8d4b\u503c\uff0c\u5426\u5219\u90fd\u4f1a\u88ab\u5faa\u73af\u6700\u540e\u4e00\u6b21\u7684\u53d6\u503c\u7ed9\u8986\u76d6\u3002\u8fd8\u8981\u8bb0\u5f97\u6b63\u5219\u5316\uff0c\u4e00\u822c\u662f\\(L_2\\)norm\uff08\u4e0d\u7528\u5f00\u6839\u53f7\uff01\u53ea\u9700\u8981\u53d6\u6bcf\u4e2a\u5143\u7d20\u7684\u5e73\u65b9\u518d\u4e58\u4ee5\u6b63\u5219\u5316\u7cfb\u6570\uff09\uff0c\u5373\\(R(W)=R\\times \\abs{W^2}\\)</p> <p>\\(dW\\)\u7684\u8ba1\u7b97\u65b9\u6cd5: \u6ce8\u610f\uff0c\u6c42\u5bfc\u662f\u5bf9\\(W\\)\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u800c\u8a00\u7684\u3002\u5373\\(W\\)\u4e2d\u6bcf\u4e2a\u5143\u7d20\u53d8\u5316\u4e00\u70b9\uff0c\u6574\u4e2a\\(L\\)\u635f\u5931\u51fd\u6570\u7684\u53d6\u503c\u4f1a\u5982\u4f55\u53d8\u5316\u3002\u6211\u4eec\u5173\u6ce8\u7684\u662f\\(W\\)\u800c\u4e0d\u662f\\(X\\)\uff01\u56e0\u4e3a\\(W\\)\u624d\u662f\u6211\u4eec\u8bad\u7ec3\u51fa\u6765\u7684\u6a21\u578b\u3002</p> <p>\u5bf9\u4e8eSVM\u800c\u8a00\uff0c\\(L_i = \\sum_{j\\neq y_i}\\max(0,s_j-s_{y_i}+1)\\)</p>"},{"location":"notes/EECS498/A2/#_1","title":"\u5faa\u73af\u6cd5","text":"<p>\u8ba1\u7b97\\(\\frac{\\partial L_i}{dW}\\)\u9700\u8981\u5206\u4e24\u79cd\u60c5\u51b5\uff0c\u4f46\u662f\u603b\u4f53\u601d\u60f3\u90fd\u662f\u7528\u94fe\u5f0f\u6cd5\u5219</p> <p>\\(\\frac{\\partial L_i}{\\partial W} = \\frac{\\partial L_i}{\\partial s_i}\\frac{\\partial s_i}{dW}\\) \\(s_i\\)\u4ee3\u8868\u5bf9\u4e8e\u7b2c\\(i\\)\u4e2a\u6837\u672c\u6240\u5f97\u5230\u7684score\uff0c\u4f7f\u7528\\(W^Tx_i\\)\u8ba1\u7b97\u5f97\u5230\u7684\uff0c\u8fd9\u6837\u7684\u597d\u5904\u662f\u6211\u4eec\u5f88\u5bb9\u6613\u77e5\u9053\\(\\frac{\\partial s_i}{\\partial W}\\)\u7b49\u4e8e\\(x_i\\)</p> <p>\u63a8\u5bfc\uff1a\u5bf9\u4e8e\u67d0\u4e2a\u786e\u5b9a\u7684\\(i\\)\u800c\u8a00\uff0c\\(s_i=W^T x_i\\),\\(ds_i=d(W^T)x_i+W^Tdx_i=(dW)^Tx_i\\),\u4e24\u8fb9\u540c\u65f6\u53d6\u8ff9,\u6709\\(s_i=tr(s_i)=tr((dW)^Tx_i)=tr(x_i^TdW)\\),\u56e0\u6b64\\(\\frac{\\partial s_i}{\\partial W}=x_i\\)\u3002\u5f53\\(j=y[i]\\)\u65f6\uff0c\u8bf4\u660e\u662f\u6b63\u786e\u7684\u6807\u7b7e\uff0c\u5bf9\u635f\u5931\u51fd\u6570\u8d21\u732e\u4e3a0\uff0c\u81ea\u7136\u5bfc\u6570\u4e5f\u4e3a0.\u5f53\\(j\\neq y_i\\)\u4e14\\(L_i&gt;0\\)\u65f6\uff0c\u5bf9\u4e8e\u6b63\u786e\u7c7b\u522b\u800c\u8a00\uff0c\u7531\\(L_i = \\sum_{j\\neq y_i}\\max(0,s_j-s_{y_i}+1)\\)\u4e0d\u96be\u770b\u51fa\uff0c\\(\\frac{\\partial L}{\\partial s_{y_i}}=-1\\),\u56e0\u6b64\u6709\u94fe\u5f0f\u6cd5\u5219\u76f8\u4e58\uff0c\u68af\u5ea6\u51cf\u53bb\\(-X[i]\\)\u3002\u540c\u7406\uff0c\u5bf9\u4e8e\u9519\u8bef\u7c7b\u522b\uff0c\u5bfc\u6570\u4e3a1\uff0c\u90a3\u4e48\u68af\u5ea6\u5e94\u8be5\u52a0\u4e0a\\(X[i]\\)\u3002</p> <p>\u4ee3\u7801\u5b9e\u73b0:</p> Python<pre><code>def svm_loss_naive(W: torch.Tensor, X: torch.Tensor, y: torch.Tensor, reg: float):\n    dW = torch.zeros_like(W)  # initialize the gradient as zero\n    num_classes = W.shape[1]\n    num_train = X.shape[0]\n    loss = 0.0\n    for i in range(num_train):\n        scores = W.t().mv(X[i])\n        correct_class_score = scores[y[i]]\n        for j in range(num_classes):\n            if j == y[i]:\n                continue\n            margin = scores[j] - correct_class_score + 1  \n            if margin &gt; 0:\n                loss += margin\n                dW[:,y[i]] -= X[i]\n                dW[:,j] += X[i]\n    loss /= num_train\n    loss += reg * torch.sum(W * W)\n    dW_regular = 2 * reg * W\n    dW += dW_regular\n    return loss, dW\n</code></pre>"},{"location":"notes/EECS498/A2/#_2","title":"\u5411\u91cf\u5316\u6cd5","text":"<p>\u7279\u70b9\uff1a\u76f4\u63a5\u5bf9\u6574\u4e2a\u77e9\u9635\u8fdb\u884c\u64cd\u4f5c\uff0c\u800c\u4e0d\u662f\u62bd\u67d0\u4e00\u884c/\u5217\u3002\uff08\u7701\u65f6\uff0c\u5e76\u53d1\uff09</p> <p>\u4e3a\u4e86\u4e0d\u4f7f\u7528\u5faa\u73af\u800c\u9009\u51fa\u6bcf\u4e00\u4e2a\u6837\u672c\u6b63\u786e\u7c7b\u522b\u5bf9\u5e94\u7684\u5206\u6570\uff0c\u91c7\u7528\u4e00\u4e2a\u975e\u5e38\u5de7\u5999\u7684\u529e\u6cd5\u53d6\u51fa\u6570\u636e\uff0c\u90a3\u5c31\u662f\u8ba9\u884c\u6570\u548c\u5217\u6570\u4e00\u4e00\u5bf9\u5e94\uff0c\u5f62\u6210\u6709\u5e8f\u7684\u6570\u5bf9\uff08\u7c7b\u4f3czip\uff09\uff0c\u5373\u884c\u548c\u5217\u4e24\u4e2a\u4f4d\u7f6e\u4e0d\u653e\u6570\u5b57\uff0c\u653e\u4e24\u4e2a\u5f62\u72b6\u76f8\u540c\u7684tensor\u3002\u8fd9\u91cc\u6211\u4eec\u5e0c\u671b\u5728\u7b2c\u4e00\u4e2a\u6837\u672c\u53d6\u51fa\u6570\u636e\u540e\u81ea\u52a8\u5230\u7b2c\u4e8c\u4e2a\u6837\u672c\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u5efa\u7acb\u81ea\u7136\u6570(0~N-1)\u4e0e\u6b63\u786e\u6807\u7b7ey\u7684\u4e00\u4e00\u6620\u5c04\uff0c\u524d\u8005\u53ef\u4ee5\u7528torch.arange(N)\u5b9e\u73b0\u3002\u4f46\u662f\u53d6\u51fa\u6765\u4e4b\u540e\u662f\u4e2a\u4e00\u7ef4\u5f20\u91cf\uff0c\u6211\u4eec\u9700\u8981\u5c06\u5176reshape\u6210\u4e8c\u7ef4\u5217\u5411\u91cf(N,1)\u3002</p> <p>\u8ba1\u7b97\u635f\u5931\u77e9\u9635(\u4e0d\u59a8\u8bbe\u4e3amargin)\u65f6\u53ef\u4ee5\u5145\u5206\u5229\u7528\u5e7f\u64ad\u673a\u5236\u4ee3\u66ff\u5faa\u73af\uff0c\u5e7f\u64ad\u673a\u5236\u4f1a\u5c06(N,1)\u590d\u5236\u6210(N,C),\u6bcf\u4e00\u884c\u90fd\u662f\u76f8\u540c\u7684\u6570\u5b57\uff0c\u4e5f\u5c31\u662f\u6b63\u786e\u5e8f\u53f7\u5bf9\u5e94\u7684\u5206\u6570\u3002\u6211\u4eec\u9700\u8981\u5c06\u6700\u5c0f\u503c\u8bbe\u62100\uff0c\u5c0f\u4e8e0\u7684\u8bf4\u660e\u4e0d\u4f1a\u5bf9\u635f\u5931\u51fd\u6570\u9020\u6210\u5f71\u54cd\uff0c\u800c\u5927\u4e8e0\u7684\u6211\u4eec\u9700\u8981\u6ce8\u610f\uff1a\u6709\u4e24\u79cd\u60c5\u51b5\uff0c\u4e00\u79cd\u662f\u672c\u6765\u5c31\u662f\u5bf9\u7684\uff0c\u90a3\u4e48\u7ecf\u8fc7\\(L_i = \\sum_{j\\neq y_i}\\max(0,s_j-s_{y_i}+1)\\)\u540e\u4f1a\u5f97\u52301\uff0c\u8fd9\u79cd\u5f71\u54cd\u6211\u4eec\u9700\u8981\u624b\u52a8\u6392\u9664\uff0c\u56e0\u6b64\u9700\u8981\u76f4\u63a5\u8d4b\u503c\u4e3a0\uff08\u8fc7\u7a0b\u540c\u4e0a\u8ff0\u53d6\u6570\u636e\uff09\uff1b\u5982\u679c\u662f\u9519\u7684\u90a3\u5c31\u4f1a\u5bf9\u635f\u5931\u51fd\u6570\u9020\u6210\u5f71\u54cd\u3002\u6700\u540e\u522b\u5fd8\u4e86\u635f\u5931\u51fd\u6570\u662f\u4e2a\u6807\u91cf\uff0c\u9700\u8981\u5c06\u77e9\u9635\u5404\u5143\u7d20\u52a0\u548c\u6c42\u5e73\u5747\u518d\u6b63\u5219\u5316\u3002</p> <p>\u800c\u8ba1\u7b97\\(dW\\)\u662f\u4e00\u4e2a\u96be\u70b9\uff0c\u56e0\u4e3a\u6211\u4eec\u6ca1\u529e\u6cd5\u518d\u7528\u5faa\u73af\u7684\u64cd\u4f5c\u4e86\uff0c\u6240\u4ee5\u6211\u4eec\u53ea\u80fd\u60f3\u529e\u6cd5\u7528\u77e9\u9635\u4e58\u6cd5\u6765\u4ee3\u66ff\u5faa\u73af\uff08\u6bd4\u5982\u8bf4\u5982\u679c\u6211\u4eec\u60f3\u8981\u4ea4\u6362\u77e9\u9635\u7684\u76f8\u90bb\u4e24\u5217\uff0c\u6211\u4eec\u4e0d\u7528\u5faa\u73af\u7684\u8bdd\u53ef\u4ee5\u7528\u5355\u4f4d\u77e9\u9635\u8fdb\u884c\u76f8\u540c\u7684\u53d8\u6362\u540e\u53f3\u4e58\u5f97\u5230\uff09</p> <p>\u6211\u4eec\u5148\u660e\u786e\uff1a\u5bf9\u4e8emargin\u800c\u8a00\uff0c\u5927\u4e8e0\u7684\u8bf4\u660e\u662f\u9519\u7684\uff0c\u68af\u5ea6\u5e94\u8be5\u4e3a1\uff1b\u800c\u5bf9\u4e8e\u672c\u8eab\u6b63\u786e\u7684\u5e8f\u53f7\uff0c\u7531\u4e8e\u4e00\u884c\u91cc\u6709\u591a\u5c11\u6b21margin&gt;0\u5c31\u6709\u591a\u5c11\u6b21\\(-s_{y_i}\\),\u6240\u4ee5\u68af\u5ea6\u9700\u8981\u51cf\u53bb\u5927\u4e8e0\u7684\u5143\u7d20\u4e2a\u6570\uff08\u7528sum,\u4e14\u6307\u5b9adim=1\uff0cdim=1\u4ee3\u8868\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u6d88\u5931\uff0c\u53ea\u5269\u4e0b\u7b2c\u4e00\u7ef4\u5ea6\uff08\u5982\u679c\u7528\u4e86keepdim=True\u4ee3\u8868\u4fdd\u7559\u6c42\u548c\u7684\u90a3\u4e2a\u7ef4\u5ea6\uff0c\u53ea\u662f\u7ef4\u5ea6\u53d8\u62101\uff09\uff09</p> <p>\u540e\u9762\u6211\u81ea\u5df1\u6ca1\u641e\u61c2\uff0c\u5148\u8d34\u4e00\u4e2a\u652f\u6301\u5411\u91cf\u673a.pdf by z_z</p> <p>\u6211\u81ea\u5df1\u53c8\u60f3\u660e\u767d\u4e86\uff0c\u53ef\u80fd\u540e\u9762\u5f97\u591a\u56de\u987e\u3002SVM&amp;SOFTMAX by 6ch.</p>"},{"location":"notes/EECS498/AttnLSTM/","title":"AttnLSTM","text":"<p>\u5206\u4e3a\u4e24\u4e2a\u90e8\u5206\uff1a</p> <ul> <li>Attention\u6a21\u5757\uff08\u7c7b\uff09</li> <li>\u5e26Attention\u7684LSTM\u89e3\u7801\u5668</li> </ul>"},{"location":"notes/EECS498/AttnLSTM/#attn","title":"Attn \u6a21\u5757","text":"<p> \u7ea6 734 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 4 \u5206\u949f</p>"},{"location":"notes/EECS498/AttnLSTM/#_1","title":"\u5b9a\u4e49","text":"<p>__init__\u53c2\u6570\uff1afeature_dim\uff08\u56fe\u50cf\u7279\u5f81\u7684\u7ef4\u5ea6\uff0c\u7531\u9884\u8bad\u7ec3\u7684CNN\u56fe\u50cf\u7279\u5f81\u63d0\u53d6\u5668\u63d0\u4f9b\uff09\uff0chidden_dim(LSTM\u9690\u85cf\u72b6\u6001\u7684\u7ef4\u5ea6),attn_dim(\u81ea\u5df1\u8bbe\u5b9a\u7684Attn\u5185\u90e8\u8ba1\u7b97\u7a7a\u95f4\u7684\u7ef4\u5ea6)</p> <p><code>encoder_att</code>\uff1a\u628aCNN\u63d0\u53d6\u51fa\u6765\u7684\u56fe\u50cf\u7279\u5f81\u53d8\u6362\u5230attention\u7a7a\u95f4\u3002</p> <p><code>decoder_att</code>\uff1a\u628aLSTM\u5f53\u524d\u7684\u9690\u85cf\u72b6\u6001\u4e5f\u6620\u5c04\u5230attention\u7a7a\u95f4\u3002</p> <p>\u518d\u7ecf\u8fc7\u4e00\u4e2a\u7ebf\u6027\u5c42\uff0c\u628a\u6bcf\u4e2a\u4f4d\u7f6e\u7684attention\u5411\u91cf\u6620\u5c04\u6210\u4e00\u4e2a\u6807\u91cf\uff0c\u8868\u793a\u8fd9\u4e2a\u4f4d\u7f6e\u7684\u91cd\u8981\u6027\u5206\u6570\u3002</p>"},{"location":"notes/EECS498/AttnLSTM/#_2","title":"\u524d\u5411\u4f20\u64ad","text":"<p>\u53c2\u6570\uff1a<code>features</code>\uff1a\u56fe\u50cf\u7279\u5f81 (B, num_pixels, feature_dim)\uff0c\u6bd4\u5982(32, 196, 2048)</p> <p><code>hidden</code>\uff1a\u5f53\u524d\u65f6\u523bLSTM\u7684\u9690\u85cf\u72b6\u6001 (B, hidden_dim)</p> <p><code>att1</code>\uff1a\u6bcf\u4e2a\u56fe\u50cf\u4f4d\u7f6e\u7684\u7279\u5f81\u8f6c\u6210attention\u7a7a\u95f4\u3002</p> <p><code>att2</code>\uff1a\u628aLSTM\u9690\u85cf\u72b6\u6001\u8f6c\u6210attention\u7a7a\u95f4\uff0c\u5e76\u6269\u5c55\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u8ba9\u5b83\u53ef\u4ee5\u52a0\u5230\u6bcf\u4e2a\u4f4d\u7f6e\u4e0a\u3002</p> <p>att = F.relu(att1 + att2) \u89e3\u91ca\uff1a</p> <p>\u76f8\u52a0 \u2192 \u8868\u793a\u5f53\u524d\u8bed\u8a00\u4e0a\u4e0b\u6587\u548c\u56fe\u50cf\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u201c\u5339\u914d\u7a0b\u5ea6\u201d\u3002</p> <p>\u52a0ReLU \u2192 \u52a0\u4e00\u70b9\u975e\u7ebf\u6027\uff0c\u901a\u5e38\u80fd\u8ba9\u6a21\u578b\u8868\u73b0\u66f4\u597d\u3002</p> <p><code>self.full_att(att)</code>\uff1a\u6bcf\u4e2a\u4f4d\u7f6e\u5f97\u5230\u4e00\u4e2a\u6253\u5206\u3002</p> <p><code>softmax</code>\uff1a\u8ba9\u6253\u5206\u5f52\u4e00\u5316\u6210\u6982\u7387\u5206\u5e03\uff08\u6240\u6709\u4f4d\u7f6e\u7684\u6743\u91cd\u52a0\u8d77\u6765=1\uff09\uff0c\u8868\u793a\u6ce8\u610f\u529b\u6743\u91cd\u3002</p> <p><code>features * alpha</code>\uff1a\u5bf9\u56fe\u50cf\u7279\u5f81\u52a0\u6743\u6c42\u548c\uff0c\u5f97\u5230\u4e00\u4e2a\u4e0a\u4e0b\u6587\u5411\u91cf\uff08context vector\uff09\u3002</p> <p>\u8fd9\u4e2a\u4e0a\u4e0b\u6587\u662f\u5f53\u524d\u65f6\u95f4\u6b65 LSTM \u9700\u8981\u5173\u6ce8\u7684\u89c6\u89c9\u4fe1\u606f\u3002</p>"},{"location":"notes/EECS498/AttnLSTM/#decoder-with-attention","title":"Decoder With Attention\u6a21\u5757","text":""},{"location":"notes/EECS498/AttnLSTM/#_3","title":"\u5b9a\u4e49","text":"<p><code>embed_dim</code>\uff1a\u5355\u8bcd\u7684\u5d4c\u5165\u5411\u91cf\u7ef4\u5ea6\u3002</p> <p><code>hidden_dim</code>\uff1aLSTM\u9690\u85cf\u72b6\u6001\u7ef4\u5ea6\u3002</p> <p><code>vocab_size</code>\uff1a\u8bcd\u6c47\u8868\u5927\u5c0f\uff08\u6bd4\u598210000\uff09\u3002</p> <p><code>feature_dim</code>\u548c<code>attention_dim</code>\uff1a\u8ddfAttention\u6a21\u5757\u4e00\u6837\u3002</p> <p>\u628a\u5355\u8bcdID\u53d8\u6210\u8fde\u7eed\u5411\u91cf\u8868\u793a\u3002\u2192\u8f93\u5165\uff1a\u5355\u8bcdembedding \u548c \u4e0a\u4e0b\u6587\u5411\u91cf\uff08concatenate\u5728\u4e00\u8d77\uff09\u3002\u8f93\u51fa\uff1a\u65b0\u7684\u9690\u85cf\u72b6\u6001\u3002\u2192\u628a\u9690\u85cf\u72b6\u6001\u6620\u5c04\u5230\u6bcf\u4e2a\u5355\u8bcd\u7684\u6253\u5206\uff08\u672a\u5f52\u4e00\u5316\uff09\uff0c\u7528\u4e8e\u6700\u540e\u9009\u8bcd\u3002\u2192\u7528\u56fe\u50cf\u6574\u4f53\u4fe1\u606f\u6765\u521d\u59cb\u5316LSTM\u7684\u521d\u59cb\u9690\u85cf\u72b6\u6001<code>h0</code>\u548c\u8bb0\u5fc6\u5355\u5143<code>c0</code>\u3002</p>"},{"location":"notes/EECS498/AttnLSTM/#_4","title":"\u524d\u5411\u4f20\u64ad","text":"<p><code>features</code>\uff1a(B, num_pixels, feature_dim)  \u56fe\u50cf\u7279\u5f81\u3002</p> <p><code>captions</code>\uff1a(B, T)  \u5355\u8bcdID\u5e8f\u5217\u3002</p> <ul> <li>\u628a\u6bcf\u4e00\u4e2a\u5355\u8bcd\u7684ID\u53d8\u6210\u5411\u91cf\u3002\u2192\u7528\u56fe\u50cf\u6574\u4f53\u7279\u5f81\u521d\u59cb\u5316LSTM\u7684\u521d\u59cb\u72b6\u6001\u3002\u2192\u51c6\u5907\u6536\u96c6\u6bcf\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u51fa\u3002\u2192\u6bcf\u4e00\u6b65\u89e3\u7801\u4e00\u4e2a\u5355\u8bcd\uff08\u5faa\u73af\uff09:\u5f53\u524d\u7684\u9690\u85cf\u72b6\u6001h\uff0c\u6307\u5bfcAttention\u6a21\u5757\uff0c\u63d0\u53d6\u5230\u7684\u4e0a\u4e0b\u6587\u7279\u5f81context\u3002\u628a\u5f53\u524d\u5355\u8bcdembedding \u548c \u4e0a\u4e0b\u6587\u5411\u91cf\u62fc\u63a5\u8d77\u6765\uff0c\u4f5c\u4e3aLSTM\u7684\u8f93\u5165\u3002\u8f93\u5165\u5230LSTM\uff0c\u66f4\u65b0\u9690\u85cf\u72b6\u6001\u548c\u8bb0\u5fc6\u5355\u5143\u3002\u628aLSTM\u9690\u85cf\u72b6\u6001\u6620\u5c04\u5230\u8bcd\u8868\u4e0a\uff0c\u5f97\u5230\u6bcf\u4e2a\u5355\u8bcd\u7684\u6253\u5206\u3002\u4fdd\u5b58\u6bcf\u4e00\u6b65\u7684\u8f93\u51fa\u7ed3\u679c\u3002</li> </ul> <p>\u5faa\u73af\u7ed3\u675f\u540e\uff1a\u628a\u6bcf\u6b65\u7684\u8f93\u51fa\u6cbf\u7740\u65f6\u95f4\u8f74\u62fc\u63a5\u8d77\u6765\uff0c\u5f62\u6210\u5b8c\u6574\u7684\u9884\u6d4b\u5e8f\u5217\u3002</p>"},{"location":"notes/EECS498/AttnLSTM/#_5","title":"\u521d\u59cb\u5316\u9690\u85cf\u72b6\u6001","text":"<ul> <li>\u5bf9\u6240\u6709\u56fe\u50cf\u4f4d\u7f6e\u53d6\u5e73\u5747\uff0c\u5f97\u5230\u6574\u4f53\u7279\u5f81\u3002</li> <li>\u5206\u522b\u7ecf\u8fc7\u7ebf\u6027\u53d8\u6362\uff0c\u5f97\u5230LSTM\u7684\u521d\u59cb\u9690\u85cf\u6001\u548c\u8bb0\u5fc6\u6001\u3002</li> </ul>"},{"location":"notes/EECS498/Back%20Propagation/","title":"Back Propagation","text":"<p> \u7ea6 487 \u4e2a\u5b57  18 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> <p>Back Propagation:</p> <p>Simple Example:\\(f(x,y,z)=(x+y)z\\)</p> <p>1.Forward Pass: Compute outputs from left to right(from inputs to outputs)</p> <p>\\(q=x+y\\) \\(f=qz\\)</p> <p>2.Backward Pass: Compute derivatives </p> <p>Want: \\(\\frac{\\partial f}{\\partial x},\\frac{\\partial f}{\\partial y},\\frac{\\partial f}{\\partial z}\\)</p> <p>Order: \\(\\frac{\\partial f}{\\partial f}\\rightarrow \\frac{\\partial f}{\\partial z}\\rightarrow \\frac{\\partial f}{\\partial q}\\rightarrow \\frac{\\partial f}{\\partial y}=\\frac{\\partial f}{\\partial q}\\frac{\\partial q}{\\partial y}\\rightarrow \\frac{\\partial f}{\\partial x}=\\frac{\\partial f}{\\partial q}\\frac{\\partial q}{\\partial x}\\)</p> <p>[Downstream] = [Local]*[Upstream]</p> <p>sigmoid function:\\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\)</p> <p>\\(\\frac{d\\sigma(x)}{dx}=(1-\\sigma(x))\\sigma(x)\\)</p> <p>add: don\u2019t change derivatives so the elements linked by the \u201c+\u201d share the same gradient.</p> <p>copy: one side\u2019s derivatives add to the other side.</p> <p>multiply: swap multiplier</p> <p>max: gradient router,that reduces one element to \\(0\\) and another,full gradient the same with other side\u2019s element\u2019s.</p> <p>Flat: \u201cReverse Thinking Method\u201d:</p> Python<pre><code>#Forward\ndef f(w0,x0,w1,x1,w2):\n    s0 = w0 * x0\n    s1 = w1 * x1\n    s2 = s0 + s1\n    s3 = s2+ w2\n    L = sigmoid(s3)\n#Backward\n    grad_L = 1.0\n    grad_s3 = grad_L * (1-L) * L    #sigmoid function has a special form of derivatives\n    grad_w2 = grad_s3   #gradient copier\n    grad_s2 = grad_s3   #gradient copier\n    grad_s0 = grad_s2   #gradient copier\n    grad_s1 = grad_s2   #gradient copier\n    grad_w1 = grad_s1 * x1  #gradient multiplier\n    grad_x1 = grad_s1 * w1  #gradient multiplier\n    grad_w0 = grad_s0 * x0  #gradient multiplier\n    grad_x0 = grad_w0 * w0  #gradient multiplier\n</code></pre> <p>\\(y \\in \\mathbb{R},x \\in \\mathbb{R}^M,\\frac{dy}{dx}\\in \\mathbb{R}^M\\)</p> <p>\\(y \\in \\mathbb{R}^N,x \\in \\mathbb{R}^M,\\frac{dy}{dx}\\in \\mathbb{R}^{M\\times N}\\) :Jacobian Matrix</p> <p>4D INPUT \\(x\\):[1,-2,3,-3]  $\\rightarrow f(x)=\\max(0,x)(elementwise)\\rightarrow $  4D OUTPUT \\(y\\) = [1,0,3,0]</p> <p>4D \\(\\frac{dL}{dy}\\):[4,-1,5,9] $\\rightarrow $ \\(\\frac{dy}{dx}\\frac{dL}{dy}\\)</p> <p>\\(\\frac{dy}{dx}\\)=\\(\\begin{bmatrix}1&amp;0&amp;0&amp;0 \\\\0&amp;0&amp;0&amp;0 \\\\0&amp;0&amp;1&amp;0\\\\0&amp;0&amp;0&amp;0  \\end{bmatrix}\\)positive: 1 negative: 0</p> <p>Jacobian is sparse!: off-diagonal entries all zero! When doing a big Jacobian Matrix Multiply,it\u2019ll cause large resources waste because almost every element is zero!Never explicitly form Jacobian,instead use implicit multiplication.</p> <p>\\(y=xw\\)(\\(x:[N\\times D]\\) \\(w:[D\\times M]\\) \\(y:[N \\times M]\\))</p> <p>\\(\\frac{dL}{dx_{i,j}}=\\frac{dy}{dx_{i,j}}\\cdot\\frac{dL}{dy}=w_{j,:}\\cdot\\frac{dL}{dy_{i,:}}\\)</p> <p>\\(\\frac{dL}{dx}=\\frac{dL}{dy}w^T\\)(How to remember? Use the shape!)</p> <p>\\(\\frac{dL}{dw}=x^T\\frac{dL}{dy}\\)</p> <p>Hint:     \\(\\cdot\\)  means inner product while blank space means matrix multiply</p> <p>Backward-Mode: A vector input and a scalar output</p> <p>Forward-Mode: A scalar input and a vector output</p> <p>Compute Higher-Order Derivatives(Cool!):</p> <p>\\(x_0 --f1--&gt;x1--f2--&gt;L--f_2'--&gt;\\frac{dL}{dx_1}--f_1'--&gt;\\frac{dL}{dx_0}--\\cdot v--&gt;\\frac{dL}{dx_0}\\cdot v\\)</p> <p>we want to calculate \\(\\frac{\\partial^2L}{\\partial x_0^2}\\)  then we can calculate\\(\\frac{\\partial^2L}{\\partial x_0^2}\\cdot v\\) ,  and surprisingly,\\(\\frac{\\partial^2L}{\\partial x_0^2}\\cdot v=\\frac{\\partial}{\\partial x_0}[\\frac{\\partial L}{\\partial x_0}\\cdot v]\\)</p> <p>(\\(v\\) is independent from \\(x_0\\)) </p> <p>use backprop we will get the answer(remember: backprop gets the derivatives of output with regard to the input)</p> <p>\u518d\u5206\u6790\uff1a\u5012\u7740\u5199\u4e00\u904d</p> <p>\u53c2\u8003\u94fe\u63a5\uff1ahttps://zhuanlan.zhihu.com/p/21407711</p>"},{"location":"notes/EECS498/CNN/","title":"CNN","text":"<p> \u7ea6 77 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>Convolution Layer</p> <p>Without padding: Feature maps shrink with each layer.</p> <p>Input: W  Filter: K Output : W-K+1</p> <p>padding = 1,usually zero-padding.</p> <p>Why zero padding? it breaks the  translational equivalent(\u5e73\u79fb\u4e0d\u53d8\u6027)</p> <p>Output: W-K+1+2P</p> <p>Same padding: Set P = \\(\\frac{K-1}{2}\\) to make the out put same as input. </p> <p>Receptive Fields :</p> <p>Each successive convolution adds K-1 to the receptive field size </p> <p>With L layers the receptive field size is 1+L*\uff08K-1\uff09</p> <p>With Stride:(W-K+2P)/S + 1</p>"},{"location":"notes/EECS498/CNNArchiture/","title":"CNNArchitecture","text":"<p> \u7ea6 100 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p></p> <p>How to calculate?</p> <p>Output size: C = number of filters</p> <p>\\(H_{out}=W_{out}=(H_{in}-KernalSize+2\\times Padding)/Stride + 1\\)</p> <p>Memory:   Number of Elements=\\(C_{out}\\times H'\\times W'\\)</p> <p>\u200b   Bytes per element = 4(for 32-bit floating point)</p> <p>\u200b   KB =(number of elements)*(bytes per elem) / 1024</p> <p>params : \\(C_{out}\\times C_{in}\\times K \\times K+C_{out}\\)</p> <p>Float operations:(multiply + add) because hardware can perform a floating point per clock cycle.</p> <p>(number of output elements) * (ops per output elem)</p> <p>= \\((C_{out}\\times H' \\times W') \\times (C_{in} \\times K \\times K)\\)</p> <p>For pooling layer: W\u2019 = floor((W-K)/S + 1)</p>"},{"location":"notes/EECS498/Derivative%20of%20Matrix/","title":"\u77e9\u9635\u6c42\u5bfc","text":"<p> \u7ea6 228 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u4e00\u5143\u5fae\u79ef\u5206\u4e2d\u7684\u5bfc\u6570\u4e0e\u5fae\u5206\u7684\u5173\u7cfb: \\(df = f'(x)dx\\)</p> <p>\u591a\u5143\u5fae\u79ef\u5206\u4e2d\u7684\u68af\u5ea6(\u5217\u5411\u91cf)\u4e0e\u5fae\u5206\u7684\u5173\u7cfb: \\(df = \\sum_{i=1}^n \\frac{\\partial f}{\\partial x_i}dx_i=\\frac{\\partial f}{\\partial \\textbf{x}}^Td\\textbf{x}\\) \u7b2c\u4e00\u4e2a\u7b49\u53f7\u662f\u5168\u5fae\u5206\u516c\u5f0f\uff0c\u7b2c\u4e8c\u4e2a\u7b49\u53f7\u8868\u8fbe\u4e86\u68af\u5ea6\u5411\u91cf(\\(n \\times 1\\))\u4e0e\u5fae\u5206\u5411\u91cf(\\(n \\times 1\\))\u7684\u5185\u79ef\u662f\u5168\u5fae\u5206\u3002\u7531\u6b64\uff0c\u6211\u4eec\u77e5\u9053\\(df=\\sum_{i=1}^m\\sum_{j=1}^n\\frac{\\partial f}{\\partial X_{ij}}dX_{ij} = \\trace(\\frac{\\partial f}{\\partial X}^TdX)\\) </p> <p>\u7b2c\u4e00\u4e2a\u7b49\u53f7\u662f\u5168\u5fae\u5206\u516c\u5f0f\uff0c\u7b2c\u4e8c\u4e2a\u7b49\u53f7\u5efa\u8bae\u5728\u7eb8\u4e0a\u63a8\u5bfc\u4e00\u904d\uff0c\u56e0\u4e3a\\(\\trace(A^TB)=\\sum_{i,j}A_{ij}B_{ij}=\\sum_{i=1}^m\\sum_{j=1}^nA_{ij}B_{ij}\\) \u6240\u4ee5\u8bf4\u7167\u846b\u82a6\u753b\u74e2\u80fd\u591f\u5f97\u5230\u3002\uff08\u8fd9\u91cc\u53ef\u4ee5\u4fa7\u9762\u8bf4\u660e\u7ebf\u6027\u4ee3\u6570\u4e2d\u5b9a\u4e49\\(tr(A^TB)\\)\u4e3a\u77e9\u9635\u5185\u79ef\u7684\u5408\u7406\u6027\uff09</p> <p>\u521b\u5efa\u77e9\u9635\u5fae\u5206\u7684\u8fd0\u7b97\u6cd5\u5219\u77e9\u9635\u6c42\u5bfc.pdf by 6ch.</p>"},{"location":"notes/EECS498/Linear%20Classifiers/","title":"Linear Classifiers","text":"<p>Linear Classification: \\(f(x_i,W) = W \\cdot x\\)</p> <p>Matrix multiply: stretch x to a one-dimension vector,W is a matrix.</p>"},{"location":"notes/EECS498/Linear%20Classifiers/#multiclass-svm-loss","title":"Multiclass SVM Loss:","text":"<p> \u7ea6 366 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <p>Let \\(f(x_i,W)\\) be scores,then the SVM scores has the form: \\(L_i = \\sum_{j\\neq y_i}\\max(0,s_j-s_{y_i}+1)\\)</p> <p>\\(s_{y_i}\\) is the correct label\u2019s score,while \\(s_j\\) is the wrong label\u2019s scores. When \\(s_j\\) is larger than \\(s_{y_i} - 1\\)</p> <p>,that means it contributes to the loss,so that \\(L_i\\) is greater than \\(0\\).</p> <p>Characteristics: 1.When give the \\(s_{y_i}\\) a little bit change,the Loss function will not change. Because after change,\\(s_{y_i}\\) is still 1 more than the wrong label\u2019s scores.</p> <p>min possible : 0 max:\\(+\\infty\\)</p> <p>When all scores are small random values,loss is \\(C - 1\\)(\\(s_j \\approx s_{y_i}\\)) where C stands for the number of categories.</p>"},{"location":"notes/EECS498/Linear%20Classifiers/#regularization","title":"Regularization","text":"<p>\\(L(W)=\\frac{1}{N}\\sum_{i=1}^NL_i(f(x_i,W),y_i)+\\lambda R(W)\\) </p> <p>The most common regularization: L2-norm \\(\\sum_i\\sum_jW_{i,j}^2\\) </p> <p>Why we need that?:</p> <ul> <li> <p>Express preferences in among models beyond \u201cminimize training error\u201d,allow people to integrate their wisdom and knowledge they\u2019ve already obtained.</p> </li> <li> <p>Avoid overfitting </p> </li> </ul> <p>Example: \\(x = [1,1,1,1] \\newline w_1=[1,0,0,0] \\newline w_2=[0.25,0.25,0.25,0.25]\\)</p> <p>It\u2019s obvious that \\(w_1^\\mathrm T \\cdot x = w_2^\\mathrm T\\cdot x = 1\\)</p> <p>L2-norm regularization prefer more balanced matrix,which is \\(w_2\\) in this example. This implies that use as many functions as possible in this preference.\u201dspread out the weights\u201d</p> <p>prefer simple models: Occam's Razor reveals the truth that simplicity is much preferred.</p>"},{"location":"notes/EECS498/Linear%20Classifiers/#cross-entropy-loss","title":"Cross Entropy Loss","text":"<p>SoftMax function: </p> cat 3.2 24.5 0.13 car 5.1 164.0 0.87 frog -1.7 0.18 0.00 <p>\u200b               unnormalized log-prob/logits --exp\u2192 unnormalized prob --normalize\u2192probabilities</p> <p>\\(L_i = -\\ln P(Y = y_i |X = x_i)\\)  Maximum Likelihood Estimation</p> <p>min possible loss:0 (it can only approach to 0 but never truly reach)   max:\\(+\\infty\\)</p> <p>When all scores are small random values,loss is \\(-\\ln C\\) where C stands for the number of categories.</p>"},{"location":"notes/EECS498/Neural%20Network/","title":"Neural Network","text":"<p> \u7ea6 319 \u4e2a\u5b57  16 \u884c\u4ee3\u7801  5 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <p>Linear Classifiers cannot deal with non-linear boundaries.</p> <p>such as two circles with different radius but the same center point.</p> <p>\u2192 use polar coordinate to create a feature space. \\(r\\) is the x axis and the \\(\\theta\\) is the y axis.</p> <p>all points on the same circle is seated on the same vertical line that is parallel to the y axis.</p> <p>(Before) Linear score function: only a small part of Feature Extraction can adjust itself to better maximizing its ability.</p> <p>Learn only one template of one category.</p> <p>(After) Neural Network: raw picture pixel \u2192 classification scores</p> <p>Learn several templates of one category.</p> <p>Linear score function: \\(f = Wx\\)</p> <p>2-layer Neural Network:\\(f=W_2\\max(0,W_1x)\\)</p> <p>\u200b               \\(W_2 \\in \\mathbb{R}^{C\\times H} \\:  W_1 \\in \\mathbb{R}^{H\\times D}\\:  x \\in \\mathbb{R}^D\\)</p> <p>\\(h = W_1x = (\\alpha_1 ,\\alpha_2,\\cdots,\\alpha_H)^Tx\\)</p> <p>Element \\((i,j)\\) of \\(W_1\\) gives the effect on \\(h_i\\) from \\(x_j\\)</p> <p>Deep Neural Networks: Depth = number of layers = number of Matrix</p> <p>\u200b   Width = Size of each layer</p> <p>Activation Functions:</p> <p>Without the activation function,we will go back to \\(f=W_2W_1x=Wx\\) which is linear classifiers.</p> Activation Functions Expression Graph Sigmoid \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\) tanh tanh(x) ReLU(A good default choice for most problems) max(0,x) <p>A simple achievement:</p> Python<pre><code>import numpy as np\nfrom numpy.random import randn\n\nN,Din,H,Dout = 64,1000,100,10\nx,y = randn(N,Din),randn(N,Dout)\nw1,w2 = randn(Din,H),randn(H,Dout)\nfor t in range(10000):\n    h = 1.0 / (1.0 + np.exp(-x.dot(w1)))\n    y_pred = h.dot(w2)\n    loss = np.square(y_pred - y).sum()\n    dy_pred = 2.0 * (y_pred - y)\n    dw2 = h.T.dot(dy_pred)\n    dh = dy_pred.dot(w2.T)\n    dw1 = x.T.dot(dh*h*(1-h))\n    w1 -= 1e-4 * dw1\n    w2 -= 1e-4 * dw2\n</code></pre> <p>Space warping:</p> <p>Linear transform cannot linearly separate points even in feature space.</p> <p>but with ReLU function,</p> <p>Universal Approximation:</p> <p>\u200b   use layer bias to move the graph</p> <p></p> <p>use many ReLU to approach the function.</p> <p>to reach 0 or unchanged: slope should be opposite</p> <p>let coefficient of x be 1,only change the shaping factor of MAX.</p> <p>Convex Functions:</p> <p>\\(f:X \\subset \\mathbb{R}^N \\rightarrow \\mathbb{R}\\) is convex if for all \\(x_1,x_2 \\in X,t\\in[0,1],f(tx_1+(1-t)x_2)\\leq tf(x_1)+(1-t)f(x_2)\\)</p> <p>convex is easy to optimize</p>"},{"location":"notes/EECS498/ObjectDetection/","title":"Detect Multiple Objects","text":""},{"location":"notes/EECS498/ObjectDetection/#detect-multiple-objects","title":"Detect Multiple Objects","text":"<p> \u7ea6 1521 \u4e2a\u5b57  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 8 \u5206\u949f</p> <p>need four output numbers for each object: \\((x,y,w,h)\\) where w stands for width and h stands for height.</p>"},{"location":"notes/EECS498/ObjectDetection/#sliding-window-apply-a-cnn-to-many-different-crops-of-the-imagecnn-classifies-each-crop-and-object-or-background","title":"Sliding Window : Apply a CNN to many different crops of the image,CNN Classifies each crop and object or background.","text":"<p>Questions: We have lots of combinations of possible picture sizes, and it will be a large parameter!</p>"},{"location":"notes/EECS498/ObjectDetection/#region-proposals","title":"Region Proposals","text":"<p>e.g. Selective search</p> <p>Find a small set of boxes that are likely to cover all objects. Often based on heuristics: Look for \u201cblob-like\u201d image regions.</p> <p>R-CNN: Region-Based CNN</p> <p>Input Image ---&gt; Regions of Interest(ROI) from a proposal method \u2192 Warped Image Regions (224*224)</p> <p>\u2192 Forward each region through Convnet \u2192 Class Prediction &amp; Bounding box regression(Predict \u201ctransform\u201d to correct the ROI: 4 numbers (\\(t_x,t_y,t_h,t_w\\))</p> <p>Region proposal: (\\(p_x,p_y,p_h,p_w\\))   Transform:(\\(t_x,t_y,t_h,t_w\\)) Output box:(\\(b_x,b_y,b_h,b_w\\))</p> <p>Translate relative to box size: \\(b_x=p_x+p_wt_x \\quad b_y=p_y+p_ht_y\\)</p> <p>Log-space scale transform: \\(b_w=p_w\\exp{t_w}\\quad b_h=p_h\\exp{t_h}\\)</p> <p>mAP \u68c0\u6d4b\u6307\u6807 \u5168\u79f0 Mean Average Precision</p> <p>\u9996\u5148\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u7c7b\u522b\u8ba1\u7b97Average Precision</p> <p></p> <p>\u51c6\u786e\u7387\uff1a\u6309\u7167\u9884\u6d4b\u6982\u7387\u9ad8\u4f4e\u6392\u5e8f\uff0c\u4ece\u9ad8\u5230\u4f4e\uff0c\u5728\u68c0\u6d4b\u51fa\u6765\u7684\u5bf9\u8c61\u4e2d\uff0c\u6b63\u786e\u7684\u4e2a\u6570\u5360\u68c0\u6d4b\u51fa\u4e2a\u6570\u7684\u6bd4\u4f8b \u901a\u8fc7\u4e0e\u5b9e\u9645\u6846\u7684\u4ea4\u5e76\u6bd4(IOU)\u9608\u503c\uff0c\u4e00\u822c\u662f0.5\uff0c\u6765\u5224\u65ad\u662f\u5426\u6b63\u786e</p> <p>\u53ec\u56de\u7387\uff1a\u547d\u4e2d\u7684\u4e2a\u6570\u5360\u5b9e\u9645\u4e2a\u6570\u7684\u6bd4\u4f8b</p> <p>\u5982\u4f55\u8ba9AP=1.0\uff1f \u8ba9\u6240\u6709\u7684\u68c0\u6d4b\u6846\u4e0e\u5b9e\u9645\u6846\u7684\u4ea4\u5e76\u6bd4\u5927\u4e8e0.5\uff0c\u5e76\u4e14\u6392\u540d\u9760\u524d\u7684\u5168\u90e8\u90fd\u662f\u771f\u9633\u6027\uff0c\u5047\u9633\u6027\u6392\u5728\u771f\u9633\u6027\u4e4b\u540e</p> <p></p> <p>\u5728\u7c7b\u522b\u8fd9\u4e00\u7ef4\u5ea6\u4e0a\u8ba1\u7b97\u5e73\u5747\u503c\uff0c\u518d\u5728\u4e0d\u540cIOU\u9608\u503c\u4e0a\u8ba1\u7b97\u5e73\u5747\u503c</p> <p>\u8865\u5145\uff1a\u5728\u4e8c\u5206\u7c7b\u95ee\u9898\u4e2d\uff0c \u771f\u9633\u6027\uff08True Positive, TP\uff09\u3001\u5047\u9633\u6027\uff08False Positive, FP\uff09\u3001\u5047\u9634\u6027\uff08False Negative, FN\uff09\u3001\u771f\u9634\u6027\uff08True Negative, TN\uff09 \u662f\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u4e0e\u771f\u5b9e\u6807\u7b7e\u7684\u5bf9\u6bd4\u5b9a\u4e49\u7684\u56db\u4e2a\u57fa\u672c\u6982\u5ff5\u3002\u5b83\u4eec\u662f\u8bc4\u4f30\u5206\u7c7b\u6a21\u578b\u6027\u80fd\u7684\u57fa\u7840\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u533b\u5b66\u8bca\u65ad\u3001\u76ee\u6807\u68c0\u6d4b\u3001\u6d3b\u52a8\u8bc6\u522b\u7b49\u9886\u57df\u3002\u4ee5\u4e0b\u662f\u8be6\u7ec6\u533a\u5206\u548c\u8bf4\u660e\uff1a</p>"},{"location":"notes/EECS498/ObjectDetection/#_1","title":"\u4e00\u3001\u6838\u5fc3\u5b9a\u4e49\u4e0e\u7b26\u53f7\u8bf4\u660e","text":"\u9884\u6d4b\u7ed3\u679c  \u771f\u5b9e\u6807\u7b7e \u6b63\u4f8b\uff08Positive\uff09 \u8d1f\u4f8b\uff08Negative\uff09 \u9884\u6d4b\u4e3a\u6b63\u4f8b \u771f\u9633\u6027\uff08TP\uff09 \u5047\u9633\u6027\uff08FP\uff09 \u9884\u6d4b\u4e3a\u8d1f\u4f8b \u5047\u9634\u6027\uff08FN\uff09 \u771f\u9634\u6027\uff08TN\uff09 <ul> <li>\u6b63\u4f8b\uff08Positive\uff09\uff1a\u9700\u8981\u68c0\u6d4b\u6216\u8bc6\u522b\u7684\u76ee\u6807\u7c7b\u522b\uff08\u5982 \u201c\u60a3\u75c5\u201d\u201c\u5b58\u5728\u8f66\u8f86\u201d\u201c\u6325\u624b\u52a8\u4f5c\u201d\uff09\u3002</li> <li>\u8d1f\u4f8b\uff08Negative\uff09\uff1a\u975e\u76ee\u6807\u7c7b\u522b\uff08\u5982 \u201c\u5065\u5eb7\u201d\u201c\u65e0\u8f66\u8f86\u201d\u201c\u975e\u6325\u624b\u52a8\u4f5c\u201d\uff09\u3002</li> </ul>"},{"location":"notes/EECS498/ObjectDetection/#_2","title":"\u4e8c\u3001\u5177\u4f53\u542b\u4e49\u4e0e\u793a\u4f8b","text":""},{"location":"notes/EECS498/ObjectDetection/#1-tp","title":"1. \u771f\u9633\u6027\uff08TP\uff09","text":"<ul> <li> <p>\u5b9a\u4e49\uff1a\u6a21\u578b\u6b63\u786e\u9884\u6d4b\u4e3a\u6b63\u4f8b\u7684\u6837\u672c\u6570\u3002 \u516c\u5f0f\uff1aTP = \u5b9e\u9645\u4e3a\u6b63\u4f8b\u4e14\u9884\u6d4b\u4e3a\u6b63\u4f8b\u7684\u6837\u672c\u6570\u3002</p> </li> <li> <p>\u793a\u4f8b</p> </li> </ul> <p>\uff1a</p> <ul> <li>\u533b\u5b66\u68c0\u6d4b\uff1a\u67d0\u60a3\u8005\u5b9e\u9645\u60a3\u75c5\uff08\u771f\u5b9e\u6b63\u4f8b\uff09\uff0c\u6a21\u578b\u9884\u6d4b\u4e3a \u201c\u60a3\u75c5\u201d\uff08\u9884\u6d4b\u6b63\u4f8b\uff09\u2192 TP\u3002</li> <li>\u76ee\u6807\u68c0\u6d4b\uff1a\u56fe\u50cf\u4e2d\u771f\u5b9e\u5b58\u5728 \u201c\u884c\u4eba\u201d\uff08\u6b63\u4f8b\uff09\uff0c\u6a21\u578b\u68c0\u6d4b\u5230 \u201c\u884c\u4eba\u201d \u5e76\u6b63\u786e\u5206\u7c7b\u2192 TP\u3002</li> </ul>"},{"location":"notes/EECS498/ObjectDetection/#2-fp","title":"2. \u5047\u9633\u6027\uff08FP\uff09","text":"<ul> <li> <p>\u5b9a\u4e49\uff1a\u6a21\u578b\u9519\u8bef\u9884\u6d4b\u4e3a\u6b63\u4f8b\u7684\u6837\u672c\u6570\uff08\u201c\u8bef\u62a5\u201d\uff09\u3002 \u516c\u5f0f\uff1aFP = \u5b9e\u9645\u4e3a\u8d1f\u4f8b\u4f46\u9884\u6d4b\u4e3a\u6b63\u4f8b\u7684\u6837\u672c\u6570\u3002</p> </li> <li> <p>\u793a\u4f8b</p> </li> </ul> <p>\uff1a</p> <ul> <li>\u533b\u5b66\u68c0\u6d4b\uff1a\u5065\u5eb7\u4eba\uff08\u771f\u5b9e\u8d1f\u4f8b\uff09\u88ab\u6a21\u578b\u8bef\u8bca\u4e3a \u201c\u60a3\u75c5\u201d\uff08\u9884\u6d4b\u6b63\u4f8b\uff09\u2192 FP\u3002</li> <li>\u76ee\u6807\u68c0\u6d4b\uff1a\u56fe\u50cf\u4e2d\u65e0 \u201c\u81ea\u884c\u8f66\u201d\uff08\u8d1f\u4f8b\uff09\uff0c\u6a21\u578b\u9519\u8bef\u68c0\u6d4b\u5230 \u201c\u81ea\u884c\u8f66\u201d\u2192 FP\u3002</li> </ul>"},{"location":"notes/EECS498/ObjectDetection/#3-fn","title":"3. \u5047\u9634\u6027\uff08FN\uff09","text":"<ul> <li> <p>\u5b9a\u4e49\uff1a\u6a21\u578b\u9519\u8bef\u9884\u6d4b\u4e3a\u8d1f\u4f8b\u7684\u6837\u672c\u6570\uff08\u201c\u6f0f\u62a5\u201d\uff09\u3002 \u516c\u5f0f\uff1aFN = \u5b9e\u9645\u4e3a\u6b63\u4f8b\u4f46\u9884\u6d4b\u4e3a\u8d1f\u4f8b\u7684\u6837\u672c\u6570\u3002</p> </li> <li> <p>\u793a\u4f8b</p> </li> </ul> <p>\uff1a</p> <ul> <li>\u533b\u5b66\u68c0\u6d4b\uff1a\u60a3\u8005\u5b9e\u9645\u60a3\u75c5\uff08\u771f\u5b9e\u6b63\u4f8b\uff09\uff0c\u6a21\u578b\u9884\u6d4b\u4e3a \u201c\u5065\u5eb7\u201d\uff08\u9884\u6d4b\u8d1f\u4f8b\uff09\u2192 FN\u3002</li> <li>\u6d3b\u52a8\u8bc6\u522b\uff1a\u89c6\u9891\u4e2d\u4eba\u7269\u771f\u5b9e\u5728 \u201c\u8dd1\u6b65\u201d\uff08\u6b63\u4f8b\uff09\uff0c\u6a21\u578b\u672a\u68c0\u6d4b\u5230\u8be5\u52a8\u4f5c\u2192 FN\u3002</li> </ul>"},{"location":"notes/EECS498/ObjectDetection/#4-tn","title":"4. \u771f\u9634\u6027\uff08TN\uff09","text":"<ul> <li> <p>\u5b9a\u4e49\uff1a\u6a21\u578b\u6b63\u786e\u9884\u6d4b\u4e3a\u8d1f\u4f8b\u7684\u6837\u672c\u6570\u3002 \u516c\u5f0f\uff1aTN = \u5b9e\u9645\u4e3a\u8d1f\u4f8b\u4e14\u9884\u6d4b\u4e3a\u8d1f\u4f8b\u7684\u6837\u672c\u6570\u3002</p> </li> <li> <p>\u793a\u4f8b</p> </li> </ul> <p>\uff1a</p> <ul> <li>\u533b\u5b66\u68c0\u6d4b\uff1a\u5065\u5eb7\u4eba\uff08\u771f\u5b9e\u8d1f\u4f8b\uff09\uff0c\u6a21\u578b\u9884\u6d4b\u4e3a \u201c\u5065\u5eb7\u201d\uff08\u9884\u6d4b\u8d1f\u4f8b\uff09\u2192 TN\u3002</li> <li>\u76ee\u6807\u68c0\u6d4b\uff1a\u56fe\u50cf\u4e2d\u65e0 \u201c\u52a8\u7269\u201d\uff08\u8d1f\u4f8b\uff09\uff0c\u6a21\u578b\u6b63\u786e\u5224\u65ad\u4e3a \u201c\u65e0\u52a8\u7269\u201d\u2192 TN\u3002</li> </ul>"},{"location":"notes/EECS498/ObjectDetection/#_3","title":"\u4e09\u3001\u5173\u952e\u6307\u6807\u4e0e\u5e94\u7528","text":"<p>\u57fa\u4e8e\u8fd9\u56db\u4e2a\u6307\u6807\uff0c\u53ef\u4ee5\u63a8\u5bfc\u51fa\u591a\u79cd\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u7684\u5173\u952e\u6307\u6807\uff1a</p>"},{"location":"notes/EECS498/ObjectDetection/#1-accuracy","title":"1. \u51c6\u786e\u7387\uff08Accuracy\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u6a21\u578b\u6b63\u786e\u9884\u6d4b\u7684\u6837\u672c\u5360\u603b\u6837\u672c\u7684\u6bd4\u4f8b\u3002 \u516c\u5f0f\uff1aAccuracy=TP+FP+FN+TNTP+TN\u200b</li> <li>\u5c40\u9650\u6027\uff1a\u5f53\u6b63\u8d1f\u6837\u672c\u4e0d\u5e73\u8861\u65f6\uff08\u5982\u6b63\u4f8b\u5360\u6bd4\u6781\u4f4e\uff09\uff0c\u51c6\u786e\u7387\u53ef\u80fd\u8bef\u5bfc\u8bc4\u4f30\uff08\u4f8b\u5982 \u201c\u6c38\u8fdc\u9884\u6d4b\u8d1f\u4f8b\u201d \u4e5f\u53ef\u80fd\u83b7\u5f97\u9ad8\u51c6\u786e\u7387\uff09\u3002</li> </ul>"},{"location":"notes/EECS498/ObjectDetection/#2-precision","title":"2. \u7cbe\u5ea6\uff08Precision\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u9884\u6d4b\u4e3a\u6b63\u4f8b\u7684\u6837\u672c\u4e2d\uff0c\u5b9e\u9645\u4e3a\u6b63\u4f8b\u7684\u6bd4\u4f8b\uff08\u8861\u91cf \u201c\u9884\u6d4b\u6b63\u4f8b\u7684\u53ef\u9760\u6027\u201d\uff09\u3002 \u516c\u5f0f\uff1aPrecision=TP+FPTP\u200b</li> <li>\u573a\u666f\uff1a\u9002\u7528\u4e8e\u9700\u8981\u51cf\u5c11\u8bef\u62a5\u7684\u573a\u666f\uff08\u5982\u764c\u75c7\u8bca\u65ad\uff0c\u8bef\u62a5\u53ef\u80fd\u5bfc\u81f4\u8fc7\u5ea6\u6cbb\u7597\uff09\u3002</li> </ul>"},{"location":"notes/EECS498/ObjectDetection/#3-recall","title":"3. \u53ec\u56de\u7387\uff08Recall\uff0c\u7075\u654f\u5ea6\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u5b9e\u9645\u4e3a\u6b63\u4f8b\u7684\u6837\u672c\u4e2d\uff0c\u88ab\u6b63\u786e\u9884\u6d4b\u7684\u6bd4\u4f8b\uff08\u8861\u91cf \u201c\u68c0\u6d4b\u6b63\u4f8b\u7684\u80fd\u529b\u201d\uff09\u3002 \u516c\u5f0f\uff1aRecall=TP+FNTP\u200b</li> <li>\u573a\u666f\uff1a\u9002\u7528\u4e8e\u9700\u8981\u51cf\u5c11\u6f0f\u62a5\u7684\u573a\u666f\uff08\u5982\u5730\u9707\u9884\u8b66\uff0c\u6f0f\u62a5\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u540e\u679c\uff09\u3002</li> </ul>"},{"location":"notes/EECS498/ObjectDetection/#4-f1-f1-score","title":"4. F1 \u5206\u6570\uff08F1-Score\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u7684\u8c03\u548c\u5e73\u5747\u503c\uff0c\u5e73\u8861\u4e24\u8005\u7684\u7efc\u5408\u6307\u6807\u3002 \u516c\u5f0f\uff1aF1=2\u00d7Precision+RecallPrecision\u00d7Recall\u200b</li> <li>\u9002\u7528\u573a\u666f\uff1a\u6837\u672c\u4e0d\u5e73\u8861\u6216\u9700\u8981\u7efc\u5408\u8bc4\u4f30\u7cbe\u5ea6\u4e0e\u53ec\u56de\u7387\u65f6\uff08\u5982\u76ee\u6807\u68c0\u6d4b\u3001\u6d3b\u52a8\u8bc6\u522b\uff09\u3002</li> </ul>"},{"location":"notes/EECS498/ObjectDetection/#hake","title":"\u56db\u3001\u5728 HAKE \u4e2d\u7684\u5e94\u7528\u793a\u4f8b","text":"<p>\u4ee5 HAKE \u8bba\u6587\u4e2d\u7684 \u201c\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u201d \u4efb\u52a1\u4e3a\u4f8b\uff1a</p> <ul> <li>\u6b63\u4f8b\uff1a\u7279\u5b9a\u6d3b\u52a8\uff08\u5982 \u201c\u559d\u6c34\u201d\uff09\u3002</li> <li>\u8d1f\u4f8b\uff1a\u975e\u8be5\u6d3b\u52a8\uff08\u5982 \u201c\u884c\u8d70\u201d\u201c\u7ad9\u7acb\u201d\uff09\u3002</li> <li>TP\uff1a\u771f\u5b9e\u4e3a \u201c\u559d\u6c34\u201d \u4e14\u88ab\u6a21\u578b\u6b63\u786e\u8bc6\u522b\u4e3a \u201c\u559d\u6c34\u201d \u7684\u6837\u672c\u3002</li> <li>FP\uff1a\u771f\u5b9e\u4e3a \u201c\u975e\u559d\u6c34\u201d\uff08\u5982 \u201c\u62ff\u676f\u5b50\u201d\uff09\u4f46\u88ab\u6a21\u578b\u8bef\u5224\u4e3a \u201c\u559d\u6c34\u201d \u7684\u6837\u672c\u3002</li> <li>FN\uff1a\u771f\u5b9e\u4e3a \u201c\u559d\u6c34\u201d \u4f46\u88ab\u6a21\u578b\u6f0f\u68c0\uff08\u5982\u672a\u68c0\u6d4b\u5230 \u201c\u5934 - \u63a5\u89e6\u676f\u5b50\u201d \u539f\u8bed\uff09\u7684\u6837\u672c\u3002</li> <li>TN\uff1a\u771f\u5b9e\u4e3a \u201c\u975e\u559d\u6c34\u201d \u4e14\u88ab\u6a21\u578b\u6b63\u786e\u5224\u65ad\u4e3a \u201c\u975e\u559d\u6c34\u201d \u7684\u6837\u672c\u3002</li> </ul> <p>\u901a\u8fc7\u7edf\u8ba1 TP\u3001FP\u3001FN\u3001TN\uff0c\u53ef\u8ba1\u7b97 mAP \u7b49\u6307\u6807\uff08\u5982 HAKE \u5728 HICO-DET \u4e2d\u901a\u8fc7\u51cf\u5c11 FP \u548c FN\uff0c\u63d0\u5347\u4e86 TP \u6bd4\u4f8b\uff0c\u4ece\u800c\u63d0\u9ad8 mAP\uff09\u3002</p>"},{"location":"notes/EECS498/ObjectDetection/#_4","title":"\u4e94\u3001\u603b\u7ed3\uff1a\u5982\u4f55\u5feb\u901f\u533a\u5206\uff1f","text":"<ul> <li>\u771f\uff08T\uff09\uff1a\u9884\u6d4b\u4e0e\u771f\u5b9e\u4e00\u81f4\uff08TP\u3001TN\uff09\u3002</li> <li>\u5047\uff08F\uff09\uff1a\u9884\u6d4b\u4e0e\u771f\u5b9e\u4e0d\u4e00\u81f4\uff08FP\u3001FN\uff09\u3002</li> <li>\u9633\u6027\uff08P\uff09\uff1a\u9884\u6d4b\u4e3a\u6b63\u4f8b\uff08TP\u3001FP\uff09\u3002</li> <li>\u9634\u6027\uff08N\uff09\uff1a\u9884\u6d4b\u4e3a\u8d1f\u4f8b\uff08FN\u3001TN\uff09\u3002</li> </ul> <p>\u8bb0\u4f4f\u53e3\u8bc0\uff1a</p> <ul> <li>TP\uff1a\u771f\u7684\u662f\u6b63\u4f8b\uff08\u6a21\u578b\u8bf4\u6709\uff0c\u5b9e\u9645\u4e5f\u6709\uff09\u3002</li> <li>FP\uff1a\u5047\u7684\u662f\u6b63\u4f8b\uff08\u6a21\u578b\u8bf4\u6709\uff0c\u5b9e\u9645\u6ca1\u6709\uff09\u3002</li> <li>FN\uff1a\u5047\u7684\u662f\u8d1f\u4f8b\uff08\u6a21\u578b\u8bf4\u6ca1\u6709\uff0c\u5b9e\u9645\u6709\uff09\u3002</li> <li>TN\uff1a\u771f\u7684\u662f\u8d1f\u4f8b\uff08\u6a21\u578b\u8bf4\u6ca1\u6709\uff0c\u5b9e\u9645\u4e5f\u6ca1\u6709\uff09\u3002</li> </ul>"},{"location":"notes/EECS498/Optimization/","title":"Optimization","text":"<p>\\(w^* = \\arg \\min_wL(w)\\)</p> <p>Idea #1 :Random Search(Bad Idea!)</p> Python<pre><code>bestloss = float('inf')\nfor num in xrange(1000):\n    W = np.random.randn(10,3073) * 0.001\n    loss = L(X_train,Y_train,W) #L is the loss function\n    if loss &lt; bestloss:\n        bestloss = loss\n        bestW = W\n    print(f'in attempt {num} the loss was {loss},best {bestloss}')\n</code></pre> <p>Batch Gradient Descent</p> <p>\\(L(W) = \\frac{1}{N}\\sum_{i=1}^NL_i(x_i,y_i,W)+\\lambda R(W)\\)</p> <p>\\(\\nabla_WL(W)=\\frac{1}{N}\\sum_{i=1}^N\\nabla_WL_i(x_i,y_i,W)+\\lambda\\nabla_WR(W)\\)</p> <p>Idea #2 : Stochastic Gradient Descent</p> Python<pre><code>w = initialize_weights()\nfor t in range(num_steps):\n    minibatch = sample_data(data,batch_size)\n    dw = compute_gradient(loss_fn,minibatch,w)\n    w- = learning_rate * dw\n</code></pre> <p>SGD: \\(x_{t+1}=x_t - \\alpha \\nabla f(x_t)\\)</p> <p>Problems:1.overshoot and never get back</p> <p>\u200b       2.settle in local minimum and saddle point</p> <p>SGD+Momentum: \\(v_{t+1}=\\rho v_t -\\alpha \\nabla f (x_t)\\)</p> <p>\u200b               \\(x_{t+1}=x_t+v_{t+1}\\) </p> <p>Nesterov Momentum:\\(v_{t+1}=\\rho v_t-\\alpha \\nabla f(x_t+\\rho v_t)\\)</p> <p>\u200b               \\(x_{t+1}=x_t+v_{t+1}\\)   Not that good :Not intuitively clear,because it uses the data of future status</p> <p>\u200b       or            $\\tilde{x_t} =x_t + \\rho v_t $</p> <p>\u200b               \\(v_{t+1}=\\rho v_t -\\alpha \\nabla f (\\tilde{x_t})\\)</p> <p>\u200b               \\(\\widetilde{x_{t+1}}=\\tilde{x_t}-\\rho v_t + (1 + \\rho) v_{t+1}\\)</p> <p>\u200b                   \\(=\\tilde{x_t}+v_{t+1}+\\rho (v_{t+1}-v_t)\\)</p> <p>AdaGrad: Progress along \u201csteep\u201d directions is damped;</p> <p>\u200b       progress along \u201cflat\u201d directions is accelerated.</p> Python<pre><code>grad_squared = 0\nfor t in range(num_steps):\n    dw = compute_gradient(w)\n    grad_squared += dw*dw\n    w -= learning_rate * dw / (grad_squared.sqrt() + 1e-7)\n</code></pre> <p>Problem: grad_squared is accumulative so that it will stop before getting to the bottom.(it can get very big)</p> <p>RMSProp: a leaky version of Adaguard</p> Python<pre><code>grad_square = 0\nfor t in range(num_steps):\n    dw = compute_gradient(w)\n    grad_squared = decay_rate * grad_squared + (1 - decay_rate) * dw * dw\n    w -= learning_rate * dw / (grad_squared.sqrt() + 1e-7)\n</code></pre> <p>Adam: RMSProp + Momentum</p> Python<pre><code>moment1 = 0\nmoment2 = 0\nfor t in range(num_steps):\n    dw = compute_gradient(w)\n    moment1 = beta1 * moment1 + (1-beta1) * dw #Momentum\n    moment2 = beta2 * moment2 + (1-beta2) * dw * dw #RMSProp\n    moment1_unbias = moment1 / (1 - beta1 ** t)\n    moment2_unbias = moment2 / (1 - beta2 ** t)\n    w -= learning_rate * moment1_unbias / (moment2_unbias.sqrt() + 1e-7)\n    # Problem: when beta2 is approximately 1,momenent.sqrt() in the first several steps can be very small,thus leading to the */moment2.sqrt() very big.\n&lt;div markdown=\"1\" style=\"margin-top: -30px; font-size: 0.75em; opacity: 0.7;\"&gt;\n:material-circle-edit-outline: \u7ea6 265 \u4e2a\u5b57 :fontawesome-solid-code: 34 \u884c\u4ee3\u7801 :material-clock-time-two-outline: \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f\n&lt;/div&gt;\n    #We need to correct the bias.  \n</code></pre> <p>Adam with beta1 = 0.9,beta2 = 0.999,and learning_rate = 1e-3,5e-4,1e-4 is a great starting point for many models.</p> <p>AdamW:(W stands for weight decay) Only differs from Adam in the last step, \\(w_{t+1}=w_t-r\\frac{V_w^{correct}}{\\sqrt{S_w^{correct}}+\\epsilon}-r\\lambda w_t\\)</p>"},{"location":"notes/EECS498/RNN/","title":"RNN","text":"<p> \u7ea6 157 \u4e2a\u5b57  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>(Vanilla) Recurrent Neural Network</p> <p>\\(h_t = f_w(h_{t-1},x_t)\\)  \u2192  \\(h_t = \\tanh(W_{hh}h_{t-1}+W_{xh}x_t) \\\\ y_t = W_{hy}h_t\\)</p> <p>Sequence 2 Sequence :</p> <p>Many2One : Encode input sequence in a single vector</p> <p>One2Many: Produce output sequence from single input vector</p> <p></p> <p>Truncated Backpropagation Thru Time: Chunk the data and backprop in the every small chunk . They will remember the hidden weights.</p> <p>Vanilla RNN Gradient Flow</p> <p></p> <p>LSTM: \\(\\sigma\\) stands for sigmoid function</p> <p>\\(\\begin{aligned}\\left(\\begin{array}{l}i \\\\ f \\\\ o \\\\ g\\end{array}\\right) &amp; =\\left(\\begin{array}{c}\\sigma \\\\ \\sigma \\\\ \\sigma \\\\ \\tanh \\end{array}\\right) W\\binom{h_{t-1}}{x_t} \\\\ c_t &amp; =f \\odot c_{t-1}+i \\odot g \\\\ h_t &amp; =o \\odot \\tanh \\left(c_t\\right)\\end{aligned}\\)</p> <p>input gate: whether to write the cell</p> <p>forget gate: whether to erase the cell</p> <p>output gate: how much to reveal cell</p> <p>gate gate: how much to write to cell</p>"},{"location":"notes/EECS498/TrainingNN/","title":"TrainingNN","text":""},{"location":"notes/EECS498/TrainingNN/#one-time-setup","title":"One time setup","text":"<p> \u7ea6 861 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 4 \u5206\u949f</p>"},{"location":"notes/EECS498/TrainingNN/#activation-functions","title":"Activation functions","text":"<p>Don\u2019t use sigmoid or tanh because it will make gradients vanish.(they have flat region)</p> <p>Sigmoid: non-zero-symmetric, it will be all positive/negative for gradients on W(each input is the activation output from the previous layer) So it will have zigzag shape in order to achieve the final optimization goal. Exponential is expensive for CPUs.</p> <p>ReLU: converge very fast ; not zero-centered output; gradients are 0 if x is negative(dead ReLU: use a slightly positive biases ,say 0.01)</p> <p>Leaky ReLU: will not die \\(f(x)=\\max(0.01x,x)\\)</p>"},{"location":"notes/EECS498/TrainingNN/#data-preprocessing","title":"Data Preprocessing","text":"<p>we want zero-centered data.</p> <p>Common for images : - mean(per channel) / standard variation (per channel )</p> <p>for non-images : whitening  covariance matrix is identity matrix</p> <p>If we don\u2019t normalize the data, classification loss vert sensitive to changes in weight matrix.</p>"},{"location":"notes/EECS498/TrainingNN/#weight-initialization","title":"Weight Initialization","text":"<p>Initializing matrix to all 0 is very bad! The network will not learn anything.</p> <p>small random numbers(Gaussian with zero mean ) what about std?</p> <p>If activation collapses to 0, it will make the local gradient to 0 because local gradient equals to the output activation from the previous layer. </p> <p>If activation all center around 1 and we use tanh as activation function, it will make the upstream gradient to be 0 because 1 is in the flat region of tanh gradient.</p> <p>For tanh : Xavier initialization:\\(std = \\sqrt{\\frac{1}{Din}}\\)</p> <p>We want the variance of output = variance of input</p> <p>\\(y=Wx  \\\\ y_i = \\sum_{j=1}^{Din}x_jw_j\\)</p> <p>\\(Var(y_i)=Din\\times Var(x_iw_i) \\hfill \\ [Assume\\  x,w \\ are \\ iid] \\\\=Din\\times (E[x_i^2]E[w_i^2]-E[x_i]^2E[w_i]^2) \\hfill \\ [Assume\\ x,w\\ independent]\\\\=Din\\times Var(x_i)\\times Var(w_i) \\hfill  [Assume\\ x_i,w_i \\ are\\  zero-mean]\\) </p> <p>Note that \\(x_i,w_i\\) are zero-mean,so \\(Var(x_i)=E[x_i^2]-E[x_i]^2=E[x_i^2]\\)</p> <p>For ReLU: Kaiming initialization </p> <p>gain = \\(\\sqrt2\\)  that is \\(std = \\sqrt{\\frac{2}{Din}}\\)</p> <p>For residual networks, if we still use Kaiming initialization , we will double the variance every layer, because remember,</p> <p>\\(Var(F(x)+x)=Var(F(x))+Var(x)=Var(x)+Var(x)=2Var(x)\\)</p> <p>Solution: Initialize first conv with Kaiming, initialize second conv to zero.</p> <p></p>"},{"location":"notes/EECS498/TrainingNN/#regularization","title":"Regularization","text":"<p>L2 regularization(Weight decay);</p> <p>Dropout:</p> <p>Why? Forces the network to have a redundant representation ; Prevents co-adaptation of features.</p> <p>Dropout is training a large ensemble of models that share parameters. Each binary mask is one model.</p> <p>At test time we need accurate(fixed) dropout, so we need to multiply a dropout probability, which is expected output in training = output in testing</p> <p>Dropout only occurs in the fully-connected layers.</p> <p>Batch normalization : Training: Normalize using stats from random minibatches</p> <p>\u200b               Testing: Use fixed stats to normalize</p>"},{"location":"notes/EECS498/TrainingNN/#data-augmentation","title":"Data Augmentation","text":"<p>Transform image: Horizontal Flips, random crops and scales</p> <p>Cutout and mixup for small classification datasets.</p>"},{"location":"notes/EECS498/TrainingNN/#learning-rate","title":"Learning Rate","text":"<p>Set a high learning rate at the beginning end with a low lr.</p> <p>Step Decay: 0.10 \u2192 0.01 \u2192 0.001 ...</p> <p>Cosine Decay: \\(\\alpha_{t} = \\frac{1}{2}\\alpha_0(1+\\cos(t\\pi/T))\\)    No hyperparameters!   Usually for CV fields</p> <p>Linear Decay : \\(\\alpha_t=\\alpha_0(1-t/T)\\)   Usu. for NLP</p> <p>Inverse Sqrt Decay : \\(\\alpha_t=\\alpha_0/\\sqrt{t}\\)</p> <p>Constant: \\(\\alpha_t=\\alpha_0\\)</p> <p>Grid Search: [, , ,] * [, , ,]</p> <p>What DeepSeek does: AdamW optimizer \\(\\beta_1=0.9,\\beta_2=0.95,Weight Decay = 0.1\\)</p> <p>\u200b               Warm-up &amp; step decrease : At the beginning 2000 steps, learning rate increases to the maximum linearly. Then,after training about 80% tokens,learning rate times 0.316,90% tokens times 0.316,maximum is set to \\(4.2\\times 10^{-4}\\),gradient cut norm is set to 1.0</p>"},{"location":"notes/EECS498/TrainingNN/#choosing-hyperparameters","title":"Choosing Hyperparameters","text":"<p>Step 1 : Check initial loss</p> <p>Turn off weight decay , we have some expectation on our loss</p> <p>For example : lnC for softmax with C classes</p> <p>Step 2 : Overfit a small sample</p> <p>Try to train to 100% training accuracy on a small sample of training data\uff08~5-10 minibatches\uff09\uff1bfiddle with architecture,learning rate, weight initialization .Turn off regularization. Loss not going down\uff1fLR too low,bad initialization </p> <p>Loss explodes to Inf or NaN\uff1fLR too high,bad initialization</p> <p>Step 3 : Find LR that makes loss go down.</p> <p>Use the architecture from the previous step,use all training data, turn on small weight decay,find a learning rate that makes the loss drop significantly within ~100 iterations Good learning rates to try\uff1a1e-1,1e-2,1e-3,1e-4</p> <p>Step 4\uff1aCoarse grid,train for ~1-5 epochs </p> <p>Choose a few values of learning rate and weight decay around wha worked from Step 3\uff0ctrain a few models for ~1-5 epochs. Good weight decay to try\uff1a1e-4,1e-5,0</p> <p>Observe the graph:</p> <p>If train acc and val acc are nearly the same : underfitting train longer, use a bigger model</p> <p>If train acc goes up and val acc goes down : overfitting</p> <p>If there is smoe gap but they are all going up : good network!</p>"},{"location":"notes/EECS498/TrainingNN/#model-ensembles","title":"Model ensembles","text":"<p>Train multiple independent models \u2192 at the test time average their results.</p>"},{"location":"notes/EECS498/TrainingNN/#transfer-learning","title":"Transfer Learning","text":"<p>pretrained models</p> <ol> <li>Train on ImageNet</li> <li>Use CNN as a feature extractor</li> <li>Fine-tuning </li> </ol> <p>Some tricks\uff1a</p> <ul> <li> <p>Train with feature extraction first before fine-tuning</p> </li> <li> <p>Lower the learning rate\uff1a    use ~1/10 of LR used in original training</p> </li> <li> <p>Sometimes freeze lower layers to save computation</p> </li> </ul> <p>Paralleled: LR Warm-up</p>"},{"location":"notes/GPT/Attention%20is%20All%20You%20Need/","title":"Attention is All You Need","text":"<p>useful  reference: PPT</p>"},{"location":"notes/GPT/Attention%20is%20All%20You%20Need/#problems-with-rnnamong-others","title":"Problems with RNN(among others)","text":"<p> \u7ea6 471 \u4e2a\u5b57  3 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <p>RNN: Recurrent Neural Network</p> <ol> <li>Slow computation for long sequences</li> <li>Vanishing or exploding gradients</li> <li>Difficulty in accessing information from long time ago</li> </ol>"},{"location":"notes/GPT/Attention%20is%20All%20You%20Need/#intro-to-transformer","title":"Intro to Transformer","text":"<p>What do we have?</p>"},{"location":"notes/GPT/Attention%20is%20All%20You%20Need/#input-embedding","title":"Input Embedding:","text":"<p>Tokens ----&gt; Input IDs(Look up in the vocab table)  ------&gt; Embedding vectors(each is ,let\u2019s say,512 dimensions)</p> <p>\\(d_{model}=512\\)(dimension of embedding vectors)</p>"},{"location":"notes/GPT/Attention%20is%20All%20You%20Need/#positional-encoding","title":"Positional Encoding:","text":"<p>We want each word to carry some information about its  position in sentence. We want the model to  treat words that appear close to each other as \u201cclose\u201d and words that are distant as \u201cdistant\u201d.It\u2019s only computed once and reused for every sentence during training and inference.</p> <p>How to calculate?</p> <p>PE(pos,2i) = \\(\\sin(\\frac{pos}{10000^{\\frac{2i}{d_{model}}}})\\)</p> <p>PE(pos,2i+1) = \\(\\cos(\\frac{pos}{10000^{\\frac{2i}{d_{model}}}})\\)</p> <p>e.g. Sentence 1: </p> YOUR CAT IS PE(0,0) PE(1,0) PE(2,0) PE(0,1) PE(1,1) PE(2,1) ... ... ... PE(0,511) PE(1,511) PE(2,511) <p>The same position in different sentences has the same position embedding.</p>"},{"location":"notes/GPT/Attention%20is%20All%20You%20Need/#encoder-input-embedding-positional-embeddingboth-are-512-dimensions","title":"Encoder Input = Embedding + Positional Embedding(both are 512 dimensions)","text":""},{"location":"notes/GPT/Attention%20is%20All%20You%20Need/#what-is-self-attention","title":"What is Self-Attention?","text":"<p>Self-Attention allows the model to relate words to each other.</p> <p>In this simple case we consider the sequence length seq= 6 and \\(d_{model}=d_{k}=512\\)(single head)</p> <p>The matrices \\(Q,K\\) and \\(V\\) are just the input sentence.</p> <p>\\(Attention(Q,K,V)=softmax\\left(\\frac{QK^T}{\\sqrt{d_{k}}}\\right)V\\)</p> <p>\\(softmax(\\frac{(6,512)\\times(512,6)}{\\sqrt{512}})\\) All elements in a single row sum to 1.</p> <p>\\((6,6)\\times(6,512)\\)---&gt;\\((6,512)\\) </p> <p>Each row in this Matrix captures not only the meaning(given by the embedding) or the position in the sentence (represented by the positional encodings) but also each word\u2019s interaction with other words.</p>"},{"location":"notes/GPT/Attention%20is%20All%20You%20Need/#self-attention-in-detail","title":"Self-Attention in detail","text":"<ol> <li>Permutation Invariant (Change the order of two rows will not change the value of each row)</li> <li>Expect values along the diagonal to be the highest.</li> <li>If we don\u2019t want some positions to interact,we can always set their values to \\(-\\infty\\) before applying the softmax.</li> </ol>"},{"location":"notes/GPT/Attention%20is%20All%20You%20Need/#multi-head","title":"Multi-head","text":"<p>\\(Q,K,V\\) are just 3 copies of Input matrix.</p> <p>Different heads just concatenate together to form a bigger heads.</p> <p>Why we need different heads? These heads will see different aspects of possibilities of communication between raw words.</p>"},{"location":"notes/GPT/Attention%20is%20All%20You%20Need/#layer-normalization","title":"Layer Normalization","text":"<p>Difference compared to batch normalization:</p> <p></p> <p>Layer: All the values belonging to single batch&lt; independently &gt;</p> <p>Batch: Same features for all items in batch&lt; mixing together &gt;</p>"},{"location":"notes/GPT/Attention%20is%20All%20You%20Need/#what-is-masked-multi-head-attention","title":"What is Masked Multi-Head Attention?","text":"<p>Our goal is to make the model causal: it means the output at a certain position can only depend on the  words on the previous positions. The model must not be able to see future words.</p> <p></p> <p>Inference: Several timesteps,to predict the next word by the largest softmax probabilities.</p>"},{"location":"notes/GPT/ShakespeareGPT/","title":"ShakespeareGPT","text":"<p>\u8bad\u7ec3\u8bed\u6599\uff1a\u838e\u58eb\u6bd4\u4e9a\u6587\u9009</p> <p>\u542b\u6709Decoder\u7684Transformer\uff0c\u5229\u7528\u81ea\u6ce8\u610f\u529b\u673a\u5236\u3002\u8be6\u89c1\u8bba\u6587\u300aAttention is All You Need\u300b</p> <p>Jupyter Notebook\u6587\u4ef6: ShakespeareGPT.ipynb by 6ch.</p> <p>\u9644\u4e0a\u7528\u4e8e\u8bad\u7ec3\u7684python\u4ee3\u7801</p> Python<pre><code>import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\n# hyperparameters\n&lt;div markdown=\"1\" style=\"margin-top: -30px; font-size: 0.75em; opacity: 0.7;\"&gt;\n:material-circle-edit-outline: \u7ea6 49 \u4e2a\u5b57 :fontawesome-solid-code: 225 \u884c\u4ee3\u7801 :material-clock-time-two-outline: \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f\n&lt;/div&gt;\nbatch_size = 64 # how many independent sequences will we process in parallel?\nblock_size = 256 # what is the maximum context length for predictions?\nmax_iters = 5000\neval_interval = 500\nlearning_rate = 3e-4\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 200\nn_embd = 384\nn_head = 6\nn_layer = 6\ndropout = 0.2\n# ------------\n\ntorch.manual_seed(1337)\n\n# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\nwith open('g:/input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()\n\n# here are all the unique characters that occur in this text\nchars = sorted(list(set(text)))\nvocab_size = len(chars)\n# create a mapping from characters to integers\nstoi = { ch:i for i,ch in enumerate(chars) }\nitos = { i:ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\ndecode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n\n# Train and test splits\ndata = torch.tensor(encode(text), dtype=torch.long)\nn = int(0.9*len(data)) # first 90% will be train, rest val\ntrain_data = data[:n]\nval_data = data[n:]\n\n# data loading\ndef get_batch(split):\n    # generate a small batch of data of inputs x and targets y\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data) - block_size, (batch_size,))\n    x = torch.stack([data[i:i+block_size] for i in ix])\n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n    x, y = x.to(device), y.to(device)\n    return x, y\n\n@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for split in ['train', 'val']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            X, Y = get_batch(split)\n            logits, loss = model(X, Y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    model.train()\n    return out\n\nclass Head(nn.Module):\n    \"\"\" one head of self-attention \"\"\"\n\n    def __init__(self, head_size):\n        super().__init__()\n        self.key = nn.Linear(n_embd, head_size, bias=False)\n        self.query = nn.Linear(n_embd, head_size, bias=False)\n        self.value = nn.Linear(n_embd, head_size, bias=False)\n        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        # input of size (batch, time-step, channels)\n        # output of size (batch, time-step, head size)\n        B,T,C = x.shape\n        k = self.key(x)   # (B,T,hs)\n        q = self.query(x) # (B,T,hs)\n        # compute attention scores (\"affinities\")\n        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -&gt; (B, T, T)\n        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n        wei = F.softmax(wei, dim=-1) # (B, T, T)\n        wei = self.dropout(wei)\n        # perform the weighted aggregation of the values\n        v = self.value(x) # (B,T,hs)\n        out = wei @ v # (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)\n        return out\n\nclass MultiHeadAttention(nn.Module):\n    \"\"\" multiple heads of self-attention in parallel \"\"\"\n\n    def __init__(self, num_heads, head_size):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        self.proj = nn.Linear(head_size * num_heads, n_embd)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n        out = self.dropout(self.proj(out))\n        return out\n\nclass FeedFoward(nn.Module):\n    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n\n    def __init__(self, n_embd):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(n_embd, 4 * n_embd),\n            nn.ReLU(),\n            nn.Linear(4 * n_embd, n_embd),\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\nclass Block(nn.Module):\n    \"\"\" Transformer block: communication followed by computation \"\"\"\n\n    def __init__(self, n_embd, n_head):\n        # n_embd: embedding dimension, n_head: the number of heads we'd like\n        super().__init__()\n        head_size = n_embd // n_head\n        self.sa = MultiHeadAttention(n_head, head_size)\n        self.ffwd = FeedFoward(n_embd)\n        self.ln1 = nn.LayerNorm(n_embd)\n        self.ln2 = nn.LayerNorm(n_embd)\n\n    def forward(self, x):\n        x = x + self.sa(self.ln1(x))\n        x = x + self.ffwd(self.ln2(x))\n        return x\n\nclass GPTLanguageModel(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        # each token directly reads off the logits for the next token from a lookup table\n        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n        self.lm_head = nn.Linear(n_embd, vocab_size)\n\n        # better init, not covered in the original GPT video, but important, will cover in followup video\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Embedding):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n\n    def forward(self, idx, targets=None):\n        B, T = idx.shape\n\n        # idx and targets are both (B,T) tensor of integers\n        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n        x = tok_emb + pos_emb # (B,T,C)\n        x = self.blocks(x) # (B,T,C)\n        x = self.ln_f(x) # (B,T,C)\n        logits = self.lm_head(x) # (B,T,vocab_size)\n\n        if targets is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        # idx is (B, T) array of indices in the current context\n        for _ in range(max_new_tokens):\n            # crop idx to the last block_size tokens\n            idx_cond = idx[:, -block_size:]\n            # get the predictions\n            logits, loss = self(idx_cond)\n            # focus only on the last time step\n            logits = logits[:, -1, :] # becomes (B, C)\n            # apply softmax to get probabilities\n            probs = F.softmax(logits, dim=-1) # (B, C)\n            # sample from the distribution\n            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n            # append sampled index to the running sequence\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n        return idx\n\nmodel = GPTLanguageModel()\nm = model.to(device)\n# print the number of parameters in the model\nprint(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n\n# create a PyTorch optimizer\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n\nfor iter in range(max_iters):\n\n    # every once in a while evaluate the loss on train and val sets\n    if iter % eval_interval == 0 or iter == max_iters - 1:\n        losses = estimate_loss()\n        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n\n    # sample a batch of data\n    xb, yb = get_batch('train')\n\n    # evaluate the loss\n    logits, loss = model(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\n\n# generate from the model\ncontext = torch.zeros((1, 1), dtype=torch.long, device=device)\nprint(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n#open('more.txt', 'w').write(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))\n</code></pre>"},{"location":"notes/GPT/Tokenization/","title":"Tokenization","text":"<p>\u4e00\u4e2a\u56f0\u6270\u6211\u5f88\u4e45\u7684\u70b9\uff1aencode\u548cdecode\u5230\u5e95\u662f\u4ec0\u4e48\u610f\u601d\uff1f</p> Python<pre><code># \u539f\u59cb\u5b57\u7b26\u4e32\n&lt;div markdown=\"1\" style=\"margin-top: -30px; font-size: 0.75em; opacity: 0.7;\"&gt;\n:material-circle-edit-outline: \u7ea6 629 \u4e2a\u5b57 :fontawesome-solid-code: 26 \u884c\u4ee3\u7801 :material-clock-time-two-outline: \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f\n&lt;/div&gt;\noriginal_string = \"hello\"\n\n# \u7f16\u7801\u4e3a UTF-8 \u5b57\u8282\u5e8f\u5217\nencoded_bytes = original_string.encode('utf-8')\nprint(f\"\u7f16\u7801\u540e\u7684\u5b57\u8282\u5e8f\u5217: {encoded_bytes}\")   \nprint(f\"\u53d8\u4e3a\u5217\u8868\u5f62\u5f0f:{list(encoded_bytes)}\")\nprint(f\"\u7c7b\u578b: {type(encoded_bytes)}\")\n\n# \u89e3\u7801\u4e3a\u5b57\u7b26\u4e32\ndecoded_string = encoded_bytes.decode('utf-8')\nprint(f\"\u89e3\u7801\u540e\u7684\u5b57\u7b26\u4e32: {decoded_string}\")\nprint(f\"\u7c7b\u578b: {type(decoded_string)}\")\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <p>\u7f16\u7801\u540e\u7684\u5b57\u8282\u5e8f\u5217: b'hello' </p> <p>\u53d8\u4e3a\u5217\u8868\u5f62\u5f0f:[104, 101, 108, 108, 111] (\u539f\u7406\uff1a\u5341\u516d\u8fdb\u5236\u2192\u5341\u8fdb\u5236)</p> <p>\u7c7b\u578b: </p> <p>\u89e3\u7801\u540e\u7684\u5b57\u7b26\u4e32: hello </p> <p>\u7c7b\u578b: </p> <p>\u6211\u4eec\u770b\u5230encode\u4e4b\u540e\u8fd8\u662fhello\uff0c\u8fd9\u662f\u4e3a\u4ec0\u4e48\u5462\uff1f\u56e0\u4e3ahello\u662f\u82f1\u6587\u5b57\u7b26\uff0cutf-8\u548cASCII\u7f16\u7801\u76f8\u540c\uff0c\u56e0\u6b64\u7535\u8111\u4e0a\u4f1a\u76f4\u63a5\u663e\u793a\u82f1\u6587\u5b57\u7b26\u3002\u4f46\u662f\u5982\u679c\u6211\u4eec\u7528\u4e2d\u6587,\u6bd4\u5982text=\u201c\u4f60\u597d\u201d text.encode(\u201cutf-8\u201d) \u5c31\u4f1a\u663e\u793a\u7f16\u7801</p> Python<pre><code># \u539f\u59cb\u5b57\u7b26\u4e32\noriginal_string = \"\u4f60\u597d\"\n\n# \u7f16\u7801\u4e3a UTF-8 \u5b57\u8282\u5e8f\u5217\nencoded_bytes = original_string.encode('utf-8')\nprint(f\"\u7f16\u7801\u540e\u7684\u5b57\u8282\u5e8f\u5217: {encoded_bytes}\")\nprint(f\"\u53d8\u4e3a\u5217\u8868\u5f62\u5f0f:{list(encoded_bytes)}\")\nprint(f\"\u7c7b\u578b: {type(encoded_bytes)}\")\n\n# \u89e3\u7801\u4e3a\u5b57\u7b26\u4e32\ndecoded_string = encoded_bytes.decode('utf-8')\nprint(f\"\u89e3\u7801\u540e\u7684\u5b57\u7b26\u4e32: {decoded_string}\")\nprint(f\"\u7c7b\u578b: {type(decoded_string)}\")\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <p>\u7f16\u7801\u540e\u7684\u5b57\u8282\u5e8f\u5217: b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd' \u53d8\u4e3a\u5217\u8868\u5f62\u5f0f:[228, 189, 160, 229, 165, 189] \u7c7b\u578b:  \u89e3\u7801\u540e\u7684\u5b57\u7b26\u4e32: \u4f60\u597d \u7c7b\u578b: </p> <p>\u800cbytes\u5462\uff1f</p> <p>\u5728 Python \u4e2d\uff0c<code>bytes</code> \u7c7b\u7528\u4e8e\u8868\u793a\u4e0d\u53ef\u53d8\u7684\u5b57\u8282\u5e8f\u5217\u3002\u5b83\u662f\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u5904\u7406\u4e8c\u8fdb\u5236\u6570\u636e\u7684\u6570\u636e\u7c7b\u578b\u3002<code>bytes</code> \u5bf9\u8c61\u53ef\u4ee5\u901a\u8fc7\u591a\u79cd\u65b9\u5f0f\u521b\u5efa\uff0c\u6bd4\u5982\u76f4\u63a5\u8c03\u7528 <code>bytes()</code> \u6784\u9020\u51fd\u6570\u3001\u4f7f\u7528\u5b57\u8282\u5b57\u9762\u91cf\uff08\u5982 <code>b'hello'</code>\uff09\u6216\u4ece\u5176\u4ed6\u6570\u636e\u7c7b\u578b\uff08\u5982\u5217\u8868\u3001\u5b57\u7b26\u4e32\uff09\u8f6c\u6362\u800c\u6765\u3002</p> <p>1.\u5f53\u4f60\u4f7f\u7528 <code>bytes(n)</code> \u8fd9\u79cd\u65b9\u5f0f\u521b\u5efa <code>bytes</code> \u5bf9\u8c61\u65f6\uff0c\u5b83\u4f1a\u751f\u6210\u4e00\u4e2a\u957f\u5ea6\u4e3a <code>n</code> \u7684\u5b57\u8282\u5e8f\u5217\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5b57\u8282\u7684\u503c\u9ed8\u8ba4\u662f <code>0</code>\u3002</p> <ol> <li>\u4ece\u5217\u8868\u521b\u5efa</li> </ol> <p>\u901a\u8fc7\u4f20\u9012\u4e00\u4e2a\u6574\u6570\u5217\u8868\uff08\u6bcf\u4e2a\u6574\u6570\u8303\u56f4\u662f 0-255\uff09\u6765\u521b\u5efa <code>bytes</code> \u5bf9\u8c61\u3002</p> <p>\u6bd4\u5982bytes([104, 101, 108, 108, 111] )  \u4f1a\u8f93\u51fab\u2019hello\u2019</p> <p>\u90a3\u4e48decode\u5462\uff1f</p> <p>bytes([158] ).decode(\"utf-8\") \u4f1a\u62a5\u9519 </p> <p>\u5b57\u8282\u503c <code>158</code> \u4e0d\u662f\u4e00\u4e2a\u6709\u6548\u7684 UTF-8 \u7f16\u7801\u7684\u5b57\u8282\u3002</p> <p>UTF-8 \u662f\u4e00\u79cd\u53ef\u53d8\u957f\u5ea6\u7684\u5b57\u7b26\u7f16\u7801\u65b9\u5f0f\uff0c\u5b83\u5bf9\u5b57\u8282\u7684\u53d6\u503c\u6709\u4e25\u683c\u7684\u89c4\u5219\u3002\u5177\u4f53\u6765\u8bf4\uff1a</p> <ul> <li>\u5bf9\u4e8e\u5355\u5b57\u8282\u5b57\u7b26\uff08ASCII \u5b57\u7b26\uff09\uff0c\u5b57\u8282\u503c\u7684\u8303\u56f4\u662f <code>0x00</code> \u5230 <code>0x7F</code>\uff08\u5373 0 \u5230 127\uff09\u3002</li> <li>\u5bf9\u4e8e\u591a\u5b57\u8282\u5b57\u7b26\uff0cUTF-8 \u4f7f\u7528\u7279\u5b9a\u7684\u5b57\u8282\u6a21\u5f0f\u6765\u6807\u8bc6\u5b57\u7b26\u7684\u957f\u5ea6\u548c\u7f16\u7801\u3002</li> </ul> <p>\u5b57\u8282\u503c <code>158</code>\uff08\u5341\u516d\u8fdb\u5236\u4e3a <code>0x9E</code>\uff09\u8d85\u51fa\u4e86\u5355\u5b57\u8282\u5b57\u7b26\u7684\u8303\u56f4\uff0c\u4f46\u5b83\u4e5f\u4e0d\u7b26\u5408 UTF-8 \u7684\u591a\u5b57\u8282\u5b57\u7b26\u7684\u89c4\u5219\uff0c\u56e0\u6b64\u4f1a\u88ab\u8ba4\u4e3a\u662f\u65e0\u6548\u7684 UTF-8 \u7f16\u7801\u3002</p>"},{"location":"notes/GPT/Tokenization/#158","title":"\u4e3a\u4ec0\u4e48\u5b57\u8282\u503c <code>158</code> \u65e0\u6548\uff1f","text":"<p>\u5728 UTF-8 \u4e2d\uff1a</p> <ul> <li>\u591a\u5b57\u8282\u5b57\u7b26\u7684\u7b2c\u4e00\u4e2a\u5b57\u8282\uff08\u8d77\u59cb\u5b57\u8282\uff09\u5fc5\u987b\u4ee5 <code>110</code>\u3001<code>1110</code> \u6216 <code>11110</code> \u5f00\u5934\uff08\u4e8c\u8fdb\u5236\u8868\u793a\uff09\u3002</li> <li>\u540e\u7eed\u5b57\u8282\u5fc5\u987b\u4ee5 <code>10</code> \u5f00\u5934\uff08\u4e8c\u8fdb\u5236\u8868\u793a\uff09\u3002</li> </ul> <p>\u5b57\u8282\u503c <code>158</code> \u7684\u4e8c\u8fdb\u5236\u8868\u793a\u662f <code>10011110</code>\uff1a</p> <ul> <li>\u5b83\u4e0d\u7b26\u5408\u8d77\u59cb\u5b57\u8282\u7684\u89c4\u5219\uff08\u5fc5\u987b\u4ee5 <code>110</code>\u3001<code>1110</code> \u6216 <code>11110</code> \u5f00\u5934\uff09\u3002</li> <li>\u5b83\u4e5f\u4e0d\u7b26\u5408\u540e\u7eed\u5b57\u8282\u7684\u89c4\u5219\uff08\u5fc5\u987b\u4ee5 <code>10</code> \u5f00\u5934\uff09\u3002</li> </ul> <p>\u89e3\u51b3\u65b9\u6848:bytes([158] ).decode(\"utf-8\",errors=\"replace\") \u4f1a\u7528'\ufffd'\u66ff\u4ee3</p>"},{"location":"notes/GPT/diveintogpt/","title":"Dive into GPT","text":"<p> \u7ea6 4 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u601d\u7ef4\u5bfc\u56fe\uff1a</p> <p></p>"},{"location":"notes/GPT/makemore/","title":"Makemore(First Status)","text":"<p> \u7ea6 65 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u6839\u636e\u5e38\u89c1\u7684\u82f1\u6587\u540d\u5b57\u751f\u6210\u65b0\u7684\u82f1\u6587\u540d\u5b57</p> <p>torch.multinomial : \u6839\u636e\u6982\u7387\u5f20\u91cf\u968f\u673a\u62bd\u53d6\u6574\u6570\uff08\u6574\u6570\u8303\u56f4\u4e3arange(\u6982\u7387\u5f20\u91cf\u7684\u957f\u5ea6\uff09)</p> <p>\u8bb0\u5f97\u8981\u8bbe\u7f6ereplacement = True \u8fd9\u6837\u5c31\u662f\u6709\u653e\u56de\u7684\u62bd\u53d6</p> <p>\u8be6\u89c1makemore.ipynb by 6ch.</p>"},{"location":"notes/GPT/makemoreActivation/","title":"Makemore(Activation)","text":"<p> \u7ea6 16 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u6a21\u5757\u5316\uff08\u624b\u52a8\u5b9e\u73b0torch.nn.MLP\u529f\u80fd\uff09\u7248\u672cmakemore</p> <p>makemoreActivation.ipynb by 6ch.</p>"},{"location":"notes/GPT/makemoreComnet/","title":"Makemore(Convolution Layer)","text":"<p> \u7ea6 19 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u8fdb\u4e00\u6b65\u6a21\u5757\u5316\u5e76\u4e14\u80fd\u591f\u5904\u7406\u9ad8\u7ef4\u6570\u636e</p> <p>makemoreComnet.ipynb by 6ch.</p>"},{"location":"notes/GPT/makemoreMLP/","title":"Makemore(MLP)","text":"<p> \u7ea6 12 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u7248\u672cmakemore</p> <p>makemoreMLP.ipynb by 6ch.</p>"},{"location":"notes/GPT/makemoreNinja/","title":"Makemore(Become a Backprop Ninja)","text":"<p> \u7ea6 60 \u4e2a\u5b57  3 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u4e3a\u4ec0\u4e48\u5728\u8ba1\u7b97\u65b9\u5dee\u7684\u65f6\u5019\uff0c\u6211\u4eec\u8981\u4f7f\u7528/(n-1)\u800c\u4e0d\u662f/n\uff1f</p> <p>\u62d3\u5c55\u9605\u8bfb:  Bessel's Correction (emory.edu)</p> <p>\u9644\u6279\u91cf\u5f52\u4e00\u5316\u624b\u52a8\u53cd\u5411\u4f20\u64ad\u63a8\u5bfc by 6ch.\uff1a</p> <p></p> <p>\u9644\u4e0a\u77e9\u9635\u6c42\u5bfc\u624b\u5199\u63a8\u5bfc\uff08\u5f88\u6e05\u695a\uff09by Karpathy\uff1a</p> <p></p> <p></p>"},{"location":"notes/GPT/micrograd/","title":"Micrograd","text":"<p> \u7ea6 18 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u624b\u52a8\u5b9e\u73b0\u53cd\u5411\u4f20\u64ad\uff0c\u9644\u4e0a\u8ba1\u7b97\u56fe\u3002</p> <p>\u8be6\u89c1micrograd.ipynb by 6ch.</p>"},{"location":"notes/ML/KMeans/","title":"KMeans","text":""},{"location":"notes/ML/KMeans/#kmeans-kmeans","title":"\u624b\u6495KMeans &amp; Kmeans++","text":"<p> \u7ea6 848 \u4e2a\u5b57  180 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 6 \u5206\u949f</p>"},{"location":"notes/ML/KMeans/#kmeans","title":"KMeans\u539f\u7406","text":"<p>K-Means\u662f\u6700\u7ecf\u5178\u7684\u805a\u7c7b\u7b97\u6cd5\u4e4b\u4e00\uff0c\u5176\u6838\u5fc3\u601d\u60f3\u662f\u901a\u8fc7\u8fed\u4ee3\u8fc7\u7a0b\uff0c\u5c06\u6570\u636e\u96c6\u5212\u5206\u4e3aK\u4e2a\u7c07\uff0c\u4f7f\u5f97\u6bcf\u4e2a\u6570\u636e\u70b9\u90fd\u5c5e\u4e8e\u79bb\u5b83\u6700\u8fd1\u7684\u5747\u503c\uff08\u5373\u7c07\u4e2d\u5fc3\uff09\u5bf9\u5e94\u7684\u7c07\u3002</p>"},{"location":"notes/ML/KMeans/#_1","title":"\u7b97\u6cd5\u6b65\u9aa4","text":"<ol> <li> <p>\u8f93\u5165\uff1a</p> <ul> <li>\u6570\u636e\u96c6 \\(D = \\{x_1, x_2, ..., x_n\\}\\)</li> <li>\u9884\u8bbe\u7684\u7c07\u6570\u91cf \\(K\\)</li> </ul> </li> <li> <p>\u8f93\u51fa\uff1a</p> <ul> <li>\\(K\\) \u4e2a\u7c07 \\(C = \\{C_1, C_2, ..., C_K\\}\\)</li> <li>\\(K\\) \u4e2a\u7c07\u4e2d\u5fc3\u70b9 \\(\\mu = \\{\\mu_1, \\mu_2, ..., \\mu_K\\}\\)</li> </ul> </li> <li> <p>\u6b65\u9aa4\uff1a</p> <ol> <li>\u521d\u59cb\u5316\uff1a\u4ece\u6570\u636e\u96c6 \\(D\\) \u4e2d \u968f\u673a\u9009\u62e9 K \u4e2a\u6570\u636e\u70b9 \u4f5c\u4e3a\u521d\u59cb\u7684\u7c07\u4e2d\u5fc3\uff08\u8d28\u5fc3\uff09\\(\\mu_1^{(0)}, \\mu_2^{(0)}, ..., \\mu_K^{(0)}\\)\u3002</li> <li>\u8fed\u4ee3\u8fc7\u7a0b\uff1a\u91cd\u590d\u4ee5\u4e0b\u6b65\u9aa4\u76f4\u5230\u7c07\u4e2d\u5fc3\u4e0d\u518d\u53d1\u751f\u53d8\u5316\uff08\u6216\u53d8\u5316\u5f88\u5c0f\uff0c\u6216\u8fbe\u5230\u6700\u5927\u8fed\u4ee3\u6b21\u6570\uff09\u3002<ul> <li>\u5206\u914d\u6b65\u9aa4\uff1a\u5bf9\u4e8e\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e00\u4e2a\u6570\u636e\u70b9 \\(x_i\\)\uff1a<ul> <li>\u8ba1\u7b97\u5b83\u5230\u6240\u6709K\u4e2a\u7c07\u4e2d\u5fc3\u7684\u8ddd\u79bb\uff08\u901a\u5e38\u662f\u6b27\u6c0f\u8ddd\u79bb\uff09\u3002</li> <li>\u5c06\u5176\u5206\u914d\u7ed9 \u8ddd\u79bb\u6700\u8fd1 \u7684\u90a3\u4e2a\u7c07\u4e2d\u5fc3\u6240\u5bf9\u5e94\u7684\u7c07\u3002</li> <li>\u516c\u5f0f\u8868\u793a\uff1a\\(C^{(t)}_k = \\{ x_i : \\| x_i - \\mu^{(t)}_k \\|^2 \\le \\| x_i - \\mu^{(t)}_j \\|^2 \\, \\forall j, 1 \\le j \\le K \\}\\)</li> </ul> </li> <li>\u66f4\u65b0\u6b65\u9aa4\uff1a\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u7c07 \\(C_k\\)\uff1a<ul> <li>\u91cd\u65b0\u8ba1\u7b97\u8be5\u7c07\u7684\u8d28\u5fc3\uff0c\u5373\u53d6\u8be5\u7c07\u4e2d\u6240\u6709\u6570\u636e\u70b9\u7684\u5e73\u5747\u503c\u4f5c\u4e3a\u65b0\u7684\u7c07\u4e2d\u5fc3\u3002</li> <li>\u516c\u5f0f\u8868\u793a\uff1a\\(\\mu^{(t+1)}_k = \\frac{1}{|C^{(t)}_k|} \\sum_{x_i \\in C^{(t)}_k} x_i\\)</li> </ul> </li> </ul> </li> </ol> </li> </ol>"},{"location":"notes/ML/KMeans/#_2","title":"\u6d41\u7a0b\u56fe","text":"<pre><code>flowchart TD\n    A[\u5f00\u59cb] --&gt; B[\u8f93\u5165\u6570\u636e\u96c6D\u548c\u7c07\u6570K]\n    B --&gt; C[\u968f\u673a\u9009\u62e9K\u4e2a\u70b9\u4f5c\u4e3a\u521d\u59cb\u8d28\u5fc3]\n    C --&gt; D[\u5c06\u6bcf\u4e2a\u6570\u636e\u70b9\u5206\u914d\u5230\u6700\u8fd1\u7684\u8d28\u5fc3&lt;br&gt;\u5f62\u6210K\u4e2a\u7c07]\n    D --&gt; E[\u91cd\u65b0\u8ba1\u7b97\u6bcf\u4e2a\u7c07\u7684\u8d28\u5fc3]\n    E --&gt; F{\u8d28\u5fc3\u662f\u5426\u53d1\u751f\u53d8\u5316?}\n    F -- \u662f --&gt; D\n    F -- \u5426 --&gt; G[\u8f93\u51fa\u805a\u7c7b\u7ed3\u679c]\n    G --&gt; H[\u7ed3\u675f]</code></pre>"},{"location":"notes/ML/KMeans/#k-means","title":"K-Means++ \u7b97\u6cd5","text":"<p>K-Means++\u662fK-Means\u7684\u6539\u8fdb\u7b97\u6cd5\uff0c\u5176\u4e3b\u8981\u4f18\u5316\u5728\u4e8e \u521d\u59cb\u8d28\u5fc3\u7684\u9009\u62e9\u7b56\u7565\u3002\u5b83\u901a\u8fc7\u4e00\u4e2a\u6982\u7387\u65b9\u6cd5\uff0c\u4f7f\u5f97\u521d\u59cb\u7684\u7c07\u4e2d\u5fc3\u70b9\u5c3d\u53ef\u80fd\u5f7c\u6b64\u8fdc\u79bb\uff0c\u4ece\u800c\u6709\u6548\u89e3\u51b3K-Means\u5bf9\u521d\u59cb\u503c\u654f\u611f\u3001\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\u7684\u95ee\u9898\u3002</p>"},{"location":"notes/ML/KMeans/#_3","title":"\u7b97\u6cd5\u6b65\u9aa4","text":"<ol> <li> <p>\u8f93\u5165 \u548c \u8f93\u51fa \u4e0eK-Means\u5b8c\u5168\u76f8\u540c\u3002</p> </li> <li> <p>\u6b65\u9aa4\uff1a</p> <ol> <li>\u521d\u59cb\u5316\uff1a\u8c28\u614e\u5730\u9009\u62e9\u521d\u59cb\u8d28\u5fc3\u3002<ul> <li>a. \u4ece\u6570\u636e\u96c6 \\(D\\) \u4e2d \u968f\u673a\u5747\u5300\u5730\u9009\u62e9\u7b2c\u4e00\u4e2a\u7c07\u4e2d\u5fc3 \\(\\mu_1\\)\u3002</li> <li>b. \u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u6570\u636e\u70b9 \\(x_i\\)\uff0c\u8ba1\u7b97\u5b83\u5230 \u5df2\u9009\u5b9a\u7684\u6700\u8fd1\u7c07\u4e2d\u5fc3 \u7684\u8ddd\u79bb\uff0c\u8bb0\u4e3a \\(D(x_i)\\)\u3002</li> <li>c. \u6309\u7167\u6982\u7387 \\(\\frac{D(x_i)^2}{\\sum_{x_j \\in D} D(x_j)^2}\\) \u9009\u62e9\u4e00\u4e2a\u6570\u636e\u70b9\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u7c07\u4e2d\u5fc3\u3002\u8ddd\u79bb\u8d8a\u8fdc\u7684\u70b9\uff0c\u88ab\u9009\u4e2d\u7684\u6982\u7387\u8d8a\u5927\u3002</li> <li>d. \u91cd\u590d\u6b65\u9aa4 b \u548c c\uff0c\u76f4\u5230\u9009\u51fa K \u4e2a\u7c07\u4e2d\u5fc3\u3002</li> </ul> </li> <li>\u8fed\u4ee3\u8fc7\u7a0b\uff1a\u6b64\u540e\u7684\u6b65\u9aa4\u4e0e\u6807\u51c6K-Means\u5b8c\u5168\u4e00\u6837\u3002<ul> <li>\u5206\u914d\u6b65\u9aa4\uff1a\u5c06\u6bcf\u4e2a\u70b9\u5206\u914d\u5230\u6700\u8fd1\u7684\u8d28\u5fc3\u6240\u5728\u7684\u7c07\u3002</li> <li>\u66f4\u65b0\u6b65\u9aa4\uff1a\u6839\u636e\u5f53\u524d\u7c07\u7684\u5206\u914d\uff0c\u91cd\u65b0\u8ba1\u7b97\u6bcf\u4e2a\u7c07\u7684\u8d28\u5fc3\u3002</li> <li>\u91cd\u590d\u4ee5\u4e0a\u4e24\u6b65\u76f4\u5230\u6536\u655b\u3002</li> </ul> </li> </ol> </li> </ol>"},{"location":"notes/ML/KMeans/#_4","title":"\u6d41\u7a0b\u56fe","text":"<pre><code>flowchart TD\n    A[\u5f00\u59cb] --&gt; B[\u8f93\u5165\u6570\u636e\u96c6D\u548c\u7c07\u6570K]\n    B --&gt; C[K-Means++\u521d\u59cb\u5316\u8d28\u5fc3]\n    C --&gt; C1[\u968f\u673a\u9009\u62e9\u7b2c\u4e00\u4e2a\u8d28\u5fc3]\n    C1 --&gt; C2[\u8ba1\u7b97\u6bcf\u4e2a\u70b9\u5230\u6700\u8fd1\u5df2\u9009\u8d28\u5fc3\u7684\u8ddd\u79bbD]\n    C2 --&gt; C3[\u6839\u636eD\u00b2\u7684\u6982\u7387\u5206\u5e03\u9009\u62e9\u4e0b\u4e00\u4e2a\u8d28\u5fc3]\n    C3 --&gt; C4{\u5df2\u9009\u591fK\u4e2a\u8d28\u5fc3?}\n    C4 -- \u5426 --&gt; C2\n    C4 -- \u662f --&gt; D\n    D[\u5c06\u6bcf\u4e2a\u6570\u636e\u70b9\u5206\u914d\u5230\u6700\u8fd1\u7684\u8d28\u5fc3&lt;br&gt;\u5f62\u6210K\u4e2a\u7c07]\n    D --&gt; E[\u91cd\u65b0\u8ba1\u7b97\u6bcf\u4e2a\u7c07\u7684\u8d28\u5fc3]\n    E --&gt; F{\u8d28\u5fc3\u662f\u5426\u53d1\u751f\u53d8\u5316?}\n    F -- \u662f --&gt; D\n    F -- \u5426 --&gt; G[\u8f93\u51fa\u805a\u7c7b\u7ed3\u679c]\n    G --&gt; H[\u7ed3\u675f]</code></pre>"},{"location":"notes/ML/KMeans/#_5","title":"\u6838\u5fc3\u533a\u522b\u4e0e\u603b\u7ed3","text":"\u7279\u5f81 K-Means K-Means++ \u6838\u5fc3\u601d\u60f3 \u8fed\u4ee3\u91cd\u5b9a\u4f4d\uff0c\u6700\u5c0f\u5316\u7c07\u5185\u5e73\u65b9\u8bef\u5dee \u540cK-Means\uff0c\u4f46\u6539\u8fdb\u4e86\u521d\u59cb\u4e2d\u5fc3\u7684\u9009\u62e9 \u521d\u59cb\u5316 \u5b8c\u5168\u968f\u673a \u6982\u7387\u5316\u9009\u62e9\uff0c\u4f7f\u521d\u59cb\u4e2d\u5fc3\u70b9\u5c3d\u53ef\u80fd\u5206\u6563 \u4f18\u70b9 \u7b80\u5355\u3001\u9ad8\u6548\u3001\u9002\u7528\u4e8e\u5927\u6570\u636e\u96c6 \u6536\u655b\u901f\u5ea6\u66f4\u5feb\uff0c\u7ed3\u679c\u8d28\u91cf\u66f4\u9ad8\u4e14\u66f4\u7a33\u5b9a \u7f3a\u70b9 \u5bf9\u521d\u59cb\u503c\u654f\u611f\uff0c\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\u89e3 \u521d\u59cb\u5316\u8fc7\u7a0b\u6bd4K-Means\u7a0d\u6162\uff0c\u4f46\u6574\u4f53\u6548\u7387\u66f4\u9ad8 \u7ed3\u679c \u6bcf\u6b21\u8fd0\u884c\u7ed3\u679c\u53ef\u80fd\u5dee\u5f02\u5f88\u5927 \u7ed3\u679c\u66f4\u4e00\u81f4\uff0c\u5168\u5c40\u6700\u4f18\u89e3\u7684\u53ef\u80fd\u6027\u66f4\u9ad8 <p>\u7ed3\u8bba\uff1a\u5728\u5b9e\u8df5\u4e2d\uff0cK-Means++ \u51e0\u4e4e\u603b\u662f\u4f18\u4e8e\u6807\u51c6\u7684 K-Means \u7b97\u6cd5\uff0c\u56e0\u6b64\u5b83\u5df2\u6210\u4e3a\u8bb8\u591a\u673a\u5668\u5b66\u4e60\u5e93\uff08\u5982 Scikit-learn\uff09\u4e2dK-Means\u7b97\u6cd5\u7684\u9ed8\u8ba4\u521d\u59cb\u5316\u65b9\u6cd5\u3002</p>"},{"location":"notes/ML/KMeans/#kmeans_1","title":"KMeans\u4ee3\u7801","text":"Python<pre><code>import numpy as np\n\ndef calculate_distance(p1, p2):\n    \"\"\"\u8ba1\u7b97\u4e24\u4e2a\u70b9\u4e4b\u95f4\u7684\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u7684\u5e73\u65b9\uff0c\u4e0d\u5f00\u65b9\u53ef\u4ee5\u52a0\u901f\u8ba1\u7b97\"\"\"\n    return np.sum((p1 - p2) ** 2)\n\n# \u4e3b\u51fd\u6570\ndef my_kmeans(dataset: np.ndarray, K: int, max_iter: int = 100, tol: float = 1e-4):\n    \"\"\"\n    K-Means \u805a\u7c7b\u7b97\u6cd5\u5b9e\u73b0\n\n    Args:\n        dataset (np.ndarray): \u6570\u636e\u96c6 (N, D)\uff0cN\u4e2a\u6837\u672c\uff0cD\u4e2a\u7279\u5f81\n        K (int): \u805a\u7c7b\u7684\u7c07\u6570\n        max_iter (int): \u6700\u5927\u8fed\u4ee3\u6b21\u6570\n        tol (float): \u6536\u655b\u9608\u503c\uff0c\u8d28\u5fc3\u53d8\u5316\u7684\u8303\u6570\u5c0f\u4e8e\u6b64\u503c\u5219\u8ba4\u4e3a\u6536\u655b\n    \"\"\"\n\n    # --- \u7b2c\u4e00\u6b65\uff1a\u521d\u59cb\u5316\u8d28\u5fc3 ---\n    # \u4f60\u7684 random_init \u51fd\u6570\u5199\u5f97\u5f88\u597d\uff0c\u53ef\u4ee5\u76f4\u63a5\u7528\n    # \u4ece\u6570\u636e\u96c6\u4e2d\u968f\u673a\u9009\u62e9K\u4e2a\u70b9\u4f5c\u4e3a\u521d\u59cb\u8d28\u5fc3\n    random_indices = np.random.choice(len(dataset), size=K, replace=False)\n    centroids = dataset[random_indices]\n\n    # --- \u7b2c\u56db\u6b65\uff1a\u8fed\u4ee3\uff08\u628a\u5206\u914d\u548c\u66f4\u65b0\u5305\u8d77\u6765\uff09---\n    for i in range(max_iter):\n        print(f\"--- Iteration {i+1} ---\")\n\n        #\n        # \u5728\u8fd9\u91cc\u4fdd\u5b58\u65e7\u7684\u8d28\u5fc3\uff0c\u7528\u4e8e\u540e\u7eed\u6bd4\u8f83\u662f\u5426\u6536\u655b\n        #\n        old_centroids = centroids.copy() # \u975e\u5e38\u91cd\u8981\uff01\u9700\u8981\u7528copy()\u6df1\u62f7\u8d1d\n\n        # --- \u7b2c\u4e8c\u6b65\uff1a\u5206\u914d (Assignment) ---\n        # \u521b\u5efa\u4e00\u4e2a\u6570\u7ec4\uff0c\u7528\u6765\u5b58\u50a8\u6bcf\u4e2a\u6570\u636e\u70b9\u6240\u5c5e\u7684\u7c07\u7684\u7d22\u5f15 (0 \u5230 K-1)\n        clusters = np.zeros(len(dataset))\n\n        # \u904d\u5386\u6bcf\u4e00\u4e2a\u6570\u636e\u70b9\n        for point_idx, point in enumerate(dataset):\n            # \u8ba1\u7b97\u8be5\u70b9\u5230\u6240\u6709K\u4e2a\u8d28\u5fc3\u7684\u8ddd\u79bb\n            distances = [calculate_distance(point, centroid) for centroid in centroids]\n\n            # \u627e\u5230\u6700\u8fd1\u7684\u8d28\u5fc3\u7684\u7d22\u5f15\n            closest_centroid_idx = np.argmin(distances)\n\n            # \u5c06\u8be5\u6570\u636e\u70b9\u5206\u914d\u7ed9\u6700\u8fd1\u7684\u7c07\n            clusters[point_idx] = closest_centroid_idx\n\n        # --- \u7b2c\u4e09\u6b65\uff1a\u66f4\u65b0 (Update) ---\n        # \u904d\u5386\u6bcf\u4e00\u4e2a\u7c07 (0 \u5230 K-1)\n        for cluster_idx in range(K):\n            # \u7b5b\u9009\u51fa\u5c5e\u4e8e\u5f53\u524d\u7c07\u7684\u6240\u6709\u6570\u636e\u70b9\n            # !!! \u8fd9\u662f\u4f60\u9700\u8981\u91cd\u70b9\u4fee\u6539\u7684\u5730\u65b9\uff0c\u4f7f\u7528Numpy\u7684\u5e03\u5c14\u7d22\u5f15\n            points_in_cluster = dataset[clusters == cluster_idx]\n\n            # \u5982\u679c\u4e00\u4e2a\u7c07\u91cc\u6ca1\u6709\u4efb\u4f55\u70b9\uff08\u6781\u7aef\u60c5\u51b5\uff09\uff0c\u4fdd\u6301\u5176\u8d28\u5fc3\u4e0d\u53d8\n            if len(points_in_cluster) &gt; 0:\n                # \u8ba1\u7b97\u8fd9\u4e9b\u70b9\u7684\u5747\u503c\uff0c\u4f5c\u4e3a\u65b0\u7684\u8d28\u5fc3\n                # np.mean(..., axis=0) \u4f1a\u5bf9\u6240\u6709\u70b9\u7684\u6bcf\u4e00\u4e2a\u7ef4\u5ea6\uff08\u5217\uff09\u6c42\u5747\u503c\n                new_centroid = np.mean(points_in_cluster, axis=0)\n                centroids[cluster_idx] = new_centroid\n\n        # --- \u68c0\u67e5\u662f\u5426\u6536\u655b ---\n        # \u8ba1\u7b97\u65b0\u65e7\u8d28\u5fc3\u4e4b\u95f4\u7684\u53d8\u5316\u91cf\n        # np.linalg.norm \u8ba1\u7b97\u5411\u91cf\u7684\u8303\u6570\uff08\u53ef\u4ee5\u7406\u89e3\u4e3a\u8ddd\u79bb\uff09\n        change = np.linalg.norm(centroids - old_centroids)\n        print(f\"Centroid change: {change}\")\n\n        if change &lt; tol:\n            print(\"Converged!\")\n            break\n\n    # \u8fd4\u56de\u6700\u7ec8\u7684\u8d28\u5fc3\u548c\u6bcf\u4e2a\u70b9\u7684\u5206\u914d\u7ed3\u679c\n    return centroids, clusters\n</code></pre>"},{"location":"notes/ML/KMeans/#kmeans_2","title":"KMeans++\u4ee3\u7801","text":"Python<pre><code>import numpy as np\n\ndef kmeans_plusplus_optimized(dataset: np.ndarray, K: int, max_iter: int = 300, tol: float = 1e-4):\n    \"\"\"Perform K-Means clustering with the K-Means++ initialization scheme.\n\n    This function segments a dataset into K clusters using the K-Means algorithm.\n    It uses the K-Means++ method for initializing the cluster centroids, which\n    leads to better and more consistent results than random initialization.\n\n    Parameters\n    ----------\n    dataset : numpy.ndarray\n        The input data to cluster. A 2D array of shape (n_samples, n_features).\n    K : int\n        The number of clusters to form, as well as the number of centroids to generate.\n    max_iter : int, optional\n        The maximum number of iterations for the K-Means algorithm. \n        Defaults to 300.\n    tol : float, optional\n        The tolerance for convergence. If the Frobenius norm of the difference\n        between the old and new centroids is less than `tol`, the algorithm stops.\n        Defaults to 1e-4.\n\n    Returns\n    -------\n    centroids : numpy.ndarray\n        The final coordinates of the cluster centers. A 2D array of shape (K, n_features).\n    clusters : numpy.ndarray\n        An array of shape (n_samples,) where each element is the index of the\n        cluster that the corresponding sample in the dataset belongs to.\n\n    Notes\n    -----\n    The K-Means++ initialization algorithm was proposed by David Arthur and\n    Sergei Vassilvitskii to avoid the poor clusterings that can be found by\n    the standard K-Means algorithm with random initialization.\n\n    The initialization process is as follows:\n    1. Choose one center uniformly at random from the data points.\n    2. For each data point `x`, compute D(x), the distance between `x` and\n       the nearest center that has already been chosen.\n    3. Choose one new data point as a new center, using a weighted probability\n       distribution where a point `x` is chosen with probability proportional\n       to D(x)^2.\n    4. Repeat Steps 2 and 3 until K centers have been chosen.\n\n    This implementation is written purely in NumPy for efficiency.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from sklearn.datasets import make_blobs\n\n    &gt;&gt;&gt; # Generate sample data\n    &gt;&gt;&gt; X, _ = make_blobs(n_samples=150, centers=3, n_features=2,\n    ...                   random_state=42, cluster_std=1.0)\n\n    &gt;&gt;&gt; # Run K-Means++\n    &gt;&gt;&gt; n_clusters = 3\n    &gt;&gt;&gt; centroids, clusters = kmeans_plusplus_optimized(X, K=n_clusters)\n\n    &gt;&gt;&gt; print(\"Shape of final centroids:\", centroids.shape)\n    Shape of final centroids: (3, 2)\n\n    &gt;&gt;&gt; print(\"Shape of cluster assignments:\", clusters.shape)\n    Shape of cluster assignments: (150,)\n    \"\"\"\n\n\n    def calculate_L2_distance(p1,p2):\n        return np.sum((p1-p2)**2)\n\n    # \u539f\u6765\u7684KMeans: random_idx = np.random.choice(len(dataset),size=(K,),replace=False)\n    data_len = len(dataset)\n    first_centroid_idx = np.random.choice(data_len,size=(1,))\n    centroids = dataset[first_centroid_idx][None]    # (1,n_features)\n    for _ in range(1,K):\n        d = []\n        for point in dataset:\n            d.append(np.min([calculate_L2_distance(point,c) for c  in centroids]))\n        d = np.array(d)\n        d /= d.sum()\n        centroid_idx = np.random.choice(data_len, p=d)\n        cent = dataset[centroid_idx]\n        centroids = np.concatenate([centroids,cent[None]],axis = 0) #\u7c7b\u4f3c\u6570\u7ec4\u7684append\u65b9\u6cd5\n\n\n    for i in range(max_iter):\n        old_centroids = centroids.copy()\n        clusters = np.zeros((data_len,))\n\n        for point_idx , point in enumerate(dataset):\n            dist = [calculate_L2_distance(point,centroid) for centroid in centroids]\n            cluster_idx = np.argmin(dist)\n            clusters[point_idx] = cluster_idx\n\n        for cluster_idx in range(K):\n            point_in_cluster = dataset[clusters == cluster_idx]\n            if len(point_in_cluster) &gt; 0:\n                new_centroid = point_in_cluster.mean(axis=0)\n                centroids[cluster_idx] = new_centroid\n        diff = np.linalg.norm((old_centroids - centroids))\n        if diff &lt; tol:\n            break\n\n    return centroids,clusters\n</code></pre>"},{"location":"notes/Probability/%E8%AE%A8%E8%AE%BA2/","title":"\u7b2c\u4e8c\u6b21\u8ba8\u8bba","text":""},{"location":"notes/Probability/%E8%AE%A8%E8%AE%BA2/#_1","title":"\u95ee\u9898\u6982\u8ff0","text":"<p> \u7ea6 591 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> <p>\u5047\u8bbe\u67d0\u4eba\u611f\u67d3 COVID\uff0c\u8bb0\u4e3a\u4e8b\u4ef6\\(C\\), \\(A\\):\u201c\u6838\u9178\u68c0\u6d4b\u7ed3\u679c\u4e3a\u9633\u6027\u201d,\\(B\\):\u201c\u6297\u539f\u68c0\u6d4b\u5448\u9633\u6027\u201d\u3002 \u5219\\(P(AB|C)=P(A|C)P(B|C)\\) \u8bf7\u901a\u8fc7\u5b9e\u9645\u80cc\u666f\u89e3\u91ca\u4e0a\u8ff0\u7ed3\u679c\u4e3a\u4ec0\u4e48\u6210\u7acb\u3002</p>"},{"location":"notes/Probability/%E8%AE%A8%E8%AE%BA2/#_2","title":"\u95ee\u9898\u89e3\u51b3","text":"<p>\u6838\u9178\u68c0\u6d4b\u9633\u6027\uff08\\(A\\)\uff09\u548c\u6297\u539f\u68c0\u6d4b\u9633\u6027\uff08\\(B\\)\uff09\u867d\u7136\u662f\u4e24\u79cd\u4e0d\u540c\u7684\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4f46\u5728\u5df2\u77e5\u67d0\u4eba\u5df2\u7ecf\u611f\u67d3\u4e86 COVID \u540e\uff0c\u4e24\u8005\u68c0\u6d4b\u7ed3\u679c\u7684\u6982\u7387\u4e0d\u4f1a\u4e92\u76f8\u5e72\u6270\u3002 \u5728\u611f\u67d3\u4e86 COVID \u7684\u60c5\u51b5\u4e0b\uff0c\u6838\u9178\u68c0\u6d4b\u9633\u6027\u4e0e\u6297\u539f\u68c0\u6d4b\u9633\u6027\u5404\u81ea\u7684\u6982\u7387\u662f\u7531\u5404\u81ea\u7684\u68c0\u6d4b\u65b9\u6cd5\u51b3\u5b9a\u7684\u3002\u5047\u8bbe\u8fd9\u4e24\u79cd\u68c0\u6d4b\u65b9\u6cd5\u7684\u53ef\u9760\u6027\uff08\u6bd4\u5982\u7075\u654f\u5ea6\u548c\u7279\u5f02\u6027\uff09\u662f\u72ec\u7acb\u7684\uff0c\u4e14\u90fd\u53ea\u4e0e\u611f\u67d3\u72b6\u6001\u76f8\u5173\uff0c\u4e0d\u53d7\u5f7c\u6b64\u5f71\u54cd\u3002</p>"},{"location":"notes/Probability/%E8%AE%A8%E8%AE%BA2/#_3","title":"\u8fdb\u4e00\u6b65\u63a2\u7a76","text":"<p>\u89e3\u91ca\\(P(AB|\\overline{C}) = P(A|\\overline{C})\\cdot P(B|\\overline{C})\\)\u4ee5\u53ca \\(P(AB) = P(A)\\cdot P(B)\\) \u662f\u5426\u6210\u7acb\u3002 \u5148\u6765\u770b\u7b2c\u4e00\u4e2a\u5f0f\u5b50\u3002\u5bb9\u6613\u77e5\u9053\u5176\u8868\u793a\u7684\u610f\u601d\u662f\u5df2\u77e5\u67d0\u4eba\u6ca1\u6709\u611f\u67d3COVID\u65f6\uff0c\\(A\\)\u548c\\(B\\)\u662f\u5426\u6761\u4ef6\u72ec\u7acb\u3002\u7b54\u6848\u662f\u663e\u7136\u7684\uff0c\u7531\u4e0a\u8ff0\u539f\u56e0\uff0c\u8fd9\u4e24\u79cd\u68c0\u6d4b\u65b9\u6cd5\u5728\u5df2\u77e5\u662f\u5426\u611f\u67d3\u7684\u60c5\u51b5\u4e0b\u662f\u76f8\u4e92\u72ec\u7acb\u7684\u3002 \u518d\u6765\u770b\u7b2c\u4e8c\u4e2a\u5f0f\u5b50\u3002\u7b2c\u4e8c\u4e2a\u5f0f\u5b50\u662f\u4e0d\u6210\u7acb\u7684\uff0c\u5728\u672a\u77e5\u662f\u5426\u611f\u67d3\u65f6\uff0c\\(A\\)\u53d1\u751f\u4f1a\u4f7f\\(B\\)\u53d1\u751f\u7684\u53ef\u80fd\u6027\u4e0a\u5347\uff08\u5f71\u54cd\\(B\\)\u53d1\u751f\u7684\u53ef\u80fd\u6027\uff09\uff0c\u540c\u7406\uff0c\\(B\\)\u53d1\u751f\u4e5f\u4f1a\u5f71\u54cd\\(A\\)\u53d1\u751f\u7684\u53ef\u80fd\u6027\u3002\u56e0\u4e3a\u6211\u4eec\u6709\u7406\u7531\u76f8\u4fe1\uff0c\u5f53\u6838\u9178\u68c0\u6d4b\u4e3a\u9633\u6027\u65f6\uff0c\u6297\u539f\u68c0\u6d4b\u4e5f\u5927\u6982\u7387\u4e3a \u9633\u6027\uff08\u5f53\u7136\uff0c\u8fd9\u91cc\u5305\u62ec\u4e86\u5047\u9633\u6027\u7b49\u60c5\u51b5\uff09\u3002\u56e0\u6b64\\(A\\),\\(B\\)\u5e76\u4e0d\u662f\u76f8\u4e92\u72ec\u7acb\u7684\u3002</p>"},{"location":"notes/Probability/%E8%AE%A8%E8%AE%BA2/#2","title":"\u5bf9\u8865\u51452\u7684\u601d\u8003","text":"<p>\u8865\u51452\u4e2d\u5047\u9633\u6027\u3001\u5047\u9634\u6027\u7b49\u6761\u4ef6\u7684\u8865\u5145\u4f7f\u5f97\u7ed3\u679c\u66f4\u52a0\u7cbe\u786e\uff0c\u540c\u65f6\u4e5f\u7528\u5230\u4e86\u6761\u4ef6\u72ec\u7acb\uff0c\u56e0\u4e3a\u5728\u5df2\u77e5\u662f\u5426\u60a3\u75c5\u7684\u60c5\u51b5\u4e0b\uff0c\u8840\u6db2\u548c\u5c3f\u6db2\u68c0\u67e5\u7684\u7ed3\u679c\u662f\u76f8\u4e92\u72ec\u7acb\u7684\u3002\u4f46\u662f\u4e0d\u96be\u4ece\\(1)\\)\u548c\\(2)\\)\u7684\u7ed3\u679c\u4e2d\u770b\u51fa\uff0c\u5982\u679c\u5728\u672a\u77e5\u662f\u5426\u60a3\u75c5\u7684\u60c5\u51b5\u4e0b\uff0c\u4e24\u8005\u7684\u7ed3\u679c\u662f\u4f1a\u76f8\u4e92\u5f71\u54cd\u7684\u3002\u7b80\u8a00\u4e4b\uff0c\u5f53\u4e00\u5f00\u59cb\u53ea\u8fdb\u884c\u8840\u6db2\u68c0\u67e5\u65f6\uff0c\u7531\u4e8e\u4eba\u7fa4\u4e2d\u53d1\u75c5\u7387\u8f83\u4f4e\uff0c\u5373\u4f7f\u4e3a\u9633\u6027\uff0c\u60a3\u75c5\u51e0\u7387\u4e5f\u8f83\u4f4e\u3002\u4f46\u662f\u5f53\u5c3f\u6db2\u68c0\u67e5\u4e5f\u4e3a\u9633\u6027\u65f6\uff0c\u60a3\u75c5\u7684\u51e0\u7387\u4e5f\u4f1a\u63d0\u9ad8\u3002</p>"},{"location":"notes/Probability/%E8%AE%A8%E8%AE%BA3/","title":"\u7b2c\u4e09\u6b21\u8ba8\u8bba","text":"<p> \u7ea6 7 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u8be6\u89c1\u8ba8\u8bba3.pdf by 6ch.</p>"},{"location":"notes/Probability/%E8%AE%A8%E8%AE%BA4/","title":"\u7b2c\u56db\u6b21\u8ba8\u8bba","text":"<p> \u7ea6 0 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p></p>"},{"location":"notes/Python-Tutorial/ColdKnwoledge/","title":"Some Cold Knowledge","text":""},{"location":"notes/Python-Tutorial/ColdKnwoledge/#some-cold-knowledge","title":"Some Cold Knowledge","text":"<p> \u7ea6 32 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p><code>ast.literal_eval()</code> \u53ef\u4ee5\u5c06\u5f15\u53f7\u5185\u7684\u5b57\u7b26\u4e32\u3001\u6570\u5b57\u3001\u5143\u7ec4\u3001\u5217\u8868\u3001\u5b57\u5178\u3001\u5e03\u5c14\u503c\u3001None\u89e3\u5f15\u7528\u51fa\u6765\u3002</p>"},{"location":"notes/Python-Tutorial/Docstring/","title":"Docstring","text":""},{"location":"notes/Python-Tutorial/Docstring/#write-a-professional-docstring","title":"Write A Professional Docstring","text":"<p> \u7ea6 9 \u4e2a\u5b57  33 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"notes/Python-Tutorial/Docstring/#google-style-docstring","title":"Google Style Docstring","text":"Python<pre><code>def multiply(a, b):\n    \"\"\"\n    Multiply two numbers.\n\n    Args:\n        a (int): First number.\n        b (int): Second number.\n\n    Returns:\n        int: Product of a and b.\n    \"\"\"\n    return a * b\nprint(multiply(3, 5))\n</code></pre>"},{"location":"notes/Python-Tutorial/Docstring/#numpy-style-docstring","title":"Numpy-Style Docstring","text":"Python<pre><code>def divide(a, b):\n    \"\"\"\n    Divide two numbers.\n\n    Parameters\n    ----------\n    a : float\n        Dividend.\n    b : float\n        Divisor.\n\n    Returns\n    -------\n    float\n        Quotient of division.\n    \"\"\"\n    if b == 0:\n        raise ValueError(\"Division by zero not allowed.\")\n    return a / b\nprint(divide(6, 2))\n</code></pre>"},{"location":"notes/Python-Tutorial/For-Loop/","title":"\u51cf\u5c11For-Loop","text":""},{"location":"notes/Python-Tutorial/For-Loop/#pythonic","title":"Pythonic","text":"<p> \u7ea6 298 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p>"},{"location":"notes/Python-Tutorial/For-Loop/#for-loop","title":"\u539f\u6765\u6211\u53ef\u4ee5\u5c11\u4e9b\u8fd9\u4e48\u591aFor-Loop","text":"<p>List Comprehension: <code>lst = [i for i in range(100)]</code></p> <p>Generator: <code>(i for i in range(100))</code>,\u542b\u6709<code>yield()</code>\u65b9\u6cd5</p> <p>\u4f7f\u7528built-in\u51fd\u6570\u4f1a\u66f4\u65b9\u4fbf\uff0c\u540c\u65f6\uff0c\u53ef\u8bfb\u6027\u66f4\u5f3a</p> <p><code>any(i &gt; 10 for i in range(100))</code> : Syntax Sugar for <code>any((i &gt; 100 for i in range(100)))</code></p> <p><code>all()</code>\u540c\u7406</p> <p>\u6ce8\u610f\uff1a\u5982\u679c\u5199 <code>any([i &gt; 10 for i in range(100)])</code>\u4f1a\u6162\u4e0d\u5c11\uff0c\u56e0\u4e3aList Comprehension\u4f1a\u628a\u6240\u6709\u7684\u5217\u8868\u5143\u7d20\u5168\u90e8\u62ff\u51fa\u6765\uff0c\u800c\u5199\u6210Generator\u7684\u683c\u5f0f\u4f1a\u66f4\u5feb\uff0c\u56e0\u4e3aGenerator\u662f\u4e00\u4e2a\u4e00\u4e2a\u751f\u6210\u7684\uff08\u60f0\u6027\u7684\uff09\uff0c\u53ea\u8981\u627e\u5230\u4e00\u4e2a\u4e0d\u6ee1\u8db3\u7684\u7acb\u523b\u8fd4\u56deFalse\u3002</p> <p>\u5982\u679c\u8981\u5199\u4e00\u4e2a\u6ee1\u8db3<code>good()</code>\u51fd\u6570\u7684List Comprehension\uff0c\u9664\u4e86<code>[i for i in slt if good(i)]</code></p> <p>\u8fd8\u53ef\u4ee5\u7528\u5185\u7f6e\u51fd\u6570<code>filter(good,lst)</code>\uff0c\u4e0d\u8fc7\u8fd9\u4e2a\u4f1a\u8fd4\u56deGenerator\u800c\u4e0d\u662f\u4e00\u4e2aList\u3002\u6240\u4ee5\u8bf4\u8981\u5728\u5916\u9762\u5957\u4e00\u4e2a<code>list()</code></p> <p><code>map(Function,List)</code>\uff1a\u6309\u7167Function\u7684\u5bf9\u5e94\u6cd5\u5219\u6620\u5c04List\u4e2d\u7684\u6240\u6709\u5143\u7d20\u3002\u8fd4\u56de\u4e00\u4e2aGenerator\u3002\u8fd8\u6709\u4e00\u4e2a\u597d\u5904\uff1a\u5982\u679cFunction\u9700\u8981\u591a\u4e2a\u53c2\u6570\u65f6\uff0cmap\u53ef\u4ee5\u63a5\u53d7\u591a\u4e2a\u53c2\u6570\uff0c\u957f\u5ea6\u53d6\u7b2c\u4e00\u4e2aList\u7684\u957f\u5ea6\u3002</p> <p><code>zip(Lst1,Lst2)</code>\uff1a\u5c06Index\u76f8\u540c\u7684\u4e24\u4e2aLisat\u4e2d\u7684\u5143\u7d20\u6253\u5305\uff0c\u65b0\u7684\u751f\u6210\u5668\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u662f\u4e00\u4e2aTuple\u3002</p>"},{"location":"notes/Python-Tutorial/LearnRegex/","title":"Regex","text":""},{"location":"notes/Python-Tutorial/LearnRegex/#regex","title":"Regex","text":"<p> \u7ea6 1054 \u4e2a\u5b57  110 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 7 \u5206\u949f</p>"},{"location":"notes/Python-Tutorial/LearnRegex/#raw-strings","title":"\u6838\u5fc3\u6982\u5ff5\uff1a\u539f\u59cb\u5b57\u7b26\u4e32 (Raw Strings)","text":"<p>\u5728\u5b9a\u4e49\u6b63\u5219\u8868\u8fbe\u5f0f\u6a21\u5f0f\u65f6\uff0c\u5f3a\u70c8\u5efa\u8bae\u4f7f\u7528 Python \u7684\u539f\u59cb\u5b57\u7b26\u4e32\uff0c\u5373\u5728\u5b57\u7b26\u4e32\u524d\u52a0\u4e0a <code>r</code>\u3002</p> <p>\u4e3a\u4ec0\u4e48\uff1f \u56e0\u4e3a\u6b63\u5219\u8868\u8fbe\u5f0f\u4e2d\u5927\u91cf\u4f7f\u7528\u53cd\u659c\u6760 <code>\\</code> \u6765\u8868\u793a\u7279\u6b8a\u5b57\u7b26\uff08\u5982 <code>\\d</code> \u8868\u793a\u6570\u5b57\uff09\uff0c\u800c Python \u7684\u666e\u901a\u5b57\u7b26\u4e32\u4e5f\u4f7f\u7528 <code>\\</code> \u6765\u8fdb\u884c\u8f6c\u4e49\uff08\u5982 <code>\\n</code> \u8868\u793a\u6362\u884c\uff09\u3002\u8fd9\u5c31\u53ef\u80fd\u5bfc\u81f4\u51b2\u7a81\u3002</p> <ul> <li>\u666e\u901a\u5b57\u7b26\u4e32\uff1a<code>pattern = \"\\\\d\"</code> (\u4f60\u9700\u8981\u4e24\u4e2a\u53cd\u659c\u6760\u624d\u80fd\u8868\u793a\u4e00\u4e2a\u771f\u6b63\u7684\u53cd\u659c\u6760)</li> <li>\u539f\u59cb\u5b57\u7b26\u4e32\uff1a<code>pattern = r\"\\d\"</code> (\u6240\u89c1\u5373\u6240\u5f97\uff0c<code>\\</code> \u5c31\u662f <code>\\</code>)</li> </ul> <p>\u4f7f\u7528 <code>r</code> \u53ef\u4ee5\u8ba9\u4f60\u5199\u7684\u6a21\u5f0f\u66f4\u6e05\u6670\uff0c\u5e76\u907f\u514d\u5f88\u591a\u4e0d\u5fc5\u8981\u7684\u9519\u8bef\u3002</p>"},{"location":"notes/Python-Tutorial/LearnRegex/#re","title":"<code>re</code> \u5e93\u6700\u5e38\u7528\u7684\u51fd\u6570","text":""},{"location":"notes/Python-Tutorial/LearnRegex/#researchpattern-string-","title":"<code>re.search(pattern, string)</code> - \u67e5\u627e\u7b2c\u4e00\u4e2a\u5339\u914d\u9879","text":"<p>\u8be5\u51fd\u6570\u4f1a\u626b\u63cf\u6574\u4e2a\u5b57\u7b26\u4e32\uff0c\u627e\u5230\u7b2c\u4e00\u4e2a\u7b26\u5408\u6a21\u5f0f\u7684\u5339\u914d\u9879\u3002\u5982\u679c\u627e\u5230\uff0c\u5b83\u4f1a\u8fd4\u56de\u4e00\u4e2a\u201c\u5339\u914d\u5bf9\u8c61\u201d\uff08Match Object\uff09\uff1b\u5982\u679c\u627e\u4e0d\u5230\uff0c\u5219\u8fd4\u56de <code>None</code>\u3002</p> Python<pre><code>import re\n\ntext = \"My phone number is 415-555-1234, and my friend's is 415-555-9876.\"\npattern = r\"\\d{3}-\\d{3}-\\d{4}\" # \\d \u8868\u793a\u6570\u5b57, {3} \u8868\u793a\u91cd\u590d3\u6b21\n\nmatch = re.search(pattern, text)\n\nif match:\n    print(f\"\u627e\u5230\u4e86\u7535\u8bdd\u53f7\u7801: {match.group(0)}\")\nelse:\n    print(\"\u6ca1\u6709\u627e\u5230\u5339\u914d\u7684\u53f7\u7801\u3002\")\n\n# \u8f93\u51fa:\n# \u627e\u5230\u4e86\u7535\u8bdd\u53f7\u7801: 415-555-1234\n</code></pre> <ul> <li><code>match.group(0)</code> \u6216 <code>match.group()</code> \u8fd4\u56de\u5b8c\u6574\u5339\u914d\u7684\u5b57\u7b26\u4e32\u3002</li> </ul>"},{"location":"notes/Python-Tutorial/LearnRegex/#rematchpattern-string-","title":"<code>re.match(pattern, string)</code> - \u4ece\u5b57\u7b26\u4e32\u5f00\u5934\u5339\u914d","text":"<p><code>re.match()</code> \u4e0e <code>re.search()</code> \u975e\u5e38\u76f8\u4f3c\uff0c\u4f46\u5b83\u53ea\u5728\u5b57\u7b26\u4e32\u7684\u5f00\u5934\u8fdb\u884c\u5339\u914d\u3002\u5982\u679c\u5b57\u7b26\u4e32\u7684\u8d77\u59cb\u4f4d\u7f6e\u4e0d\u7b26\u5408\u6a21\u5f0f\uff0c\u5373\u4f7f\u540e\u9762\u6709\u5339\u914d\u7684\u5185\u5bb9\uff0c\u5b83\u4e5f\u4f1a\u8fd4\u56de <code>None</code>\u3002</p> Python<pre><code>import re\n\ntext1 = \"123 is a number.\"\ntext2 = \"A number is 123.\"\npattern = r\"\\d+\" # \\d+ \u8868\u793a\u4e00\u4e2a\u6216\u591a\u4e2a\u6570\u5b57\n\nmatch1 = re.match(pattern, text1)\nmatch2 = re.match(pattern, text2)\n\nprint(f\"\u5339\u914dtext1\u7684\u7ed3\u679c: {match1.group(0) if match1 else 'None'}\")\nprint(f\"\u5339\u914dtext2\u7684\u7ed3\u679c: {match2.group(0) if match2 else 'None'}\")\n\n# \u8f93\u51fa:\n# \u5339\u914dtext1\u7684\u7ed3\u679c: 123\n# \u5339\u914dtext2\u7684\u7ed3\u679c: None\n</code></pre>"},{"location":"notes/Python-Tutorial/LearnRegex/#3-refindallpattern-string-","title":"3. <code>re.findall(pattern, string)</code> - \u67e5\u627e\u6240\u6709\u5339\u914d\u9879","text":"<p>\u8fd9\u662f\u975e\u5e38\u6709\u7528\u7684\u4e00\u4e2a\u51fd\u6570\uff0c\u5b83\u4f1a\u627e\u5230\u5b57\u7b26\u4e32\u4e2d\u6240\u6709\u7b26\u5408\u6a21\u5f0f\u7684\u975e\u91cd\u53e0\u5339\u914d\u9879\uff0c\u5e76\u4ee5\u5217\u8868\uff08list\uff09 \u7684\u5f62\u5f0f\u8fd4\u56de\u3002</p> Python<pre><code>import re\n\ntext = \"Emails: user1@example.com, user2@test.com, user3@domain.org\"\npattern = r\"[\\w.-]+@[\\w.-]+\\.[\\w-]+\" # \u4e00\u4e2a\u7b80\u5355\u7684\u90ae\u4ef6\u6a21\u5f0f\n\nemails = re.findall(pattern, text)\nprint(emails)\n\n# \u8f93\u51fa:\n# ['user1@example.com', 'user2@test.com', 'user3@domain.org']\n</code></pre>"},{"location":"notes/Python-Tutorial/LearnRegex/#resubpattern-replacement-string-","title":"<code>re.sub(pattern, replacement, string)</code> - \u66ff\u6362\u5339\u914d","text":"<p>\u8be5\u51fd\u6570\u7528\u4e8e\u67e5\u627e\u5e76\u66ff\u6362\u3002\u5b83\u4f1a\u627e\u5230\u6240\u6709\u5339\u914d <code>pattern</code> \u7684\u5b50\u4e32\uff0c\u5e76\u5c06\u5b83\u4eec\u66ff\u6362\u4e3a <code>replacement</code>\u3002</p> Python<pre><code>import re\n\ntext = \"Hello, my name is John. Hello John!\"\n# \u5c06 \"John\" \u66ff\u6362\u4e3a \"Jane\"\nnew_text = re.sub(r\"John\", \"Jane\", text)\nprint(new_text)\n\n# \u8f93\u51fa:\n# Hello, my name is Jane. Hello Jane!\n\n# \u79fb\u9664\u6240\u6709\u6570\u5b57\ntext_no_digits = re.sub(r\"\\d\", \"\", \"My phone is 123-456-7890\")\nprint(text_no_digits)\n# \u8f93\u51fa: My phone is ---\n</code></pre>"},{"location":"notes/Python-Tutorial/LearnRegex/#resplitpattern-string-","title":"<code>re.split(pattern, string)</code> - \u5206\u5272\u5b57\u7b26\u4e32","text":"<p>\u6bd4 <code>string.split()</code> \u66f4\u5f3a\u5927\uff0c<code>re.split()</code> \u53ef\u4ee5\u4f7f\u7528\u590d\u6742\u7684\u6a21\u5f0f\u4f5c\u4e3a\u5206\u9694\u7b26\u6765\u5206\u5272\u5b57\u7b26\u4e32\u3002</p> Python<pre><code>import re\n\ntext = \"apple,banana;orange strawberry\"\n# \u6839\u636e\u9017\u53f7\u3001\u5206\u53f7\u6216\u7a7a\u683c\u8fdb\u884c\u5206\u5272\nparts = re.split(r\"[,;\\s]+\", text) # \\s \u8868\u793a\u7a7a\u767d\u5b57\u7b26, + \u8868\u793a\u4e00\u4e2a\u6216\u591a\u4e2a\nprint(parts)\n\n# \u8f93\u51fa:\n# ['apple', 'banana', 'orange', 'strawberry']\n</code></pre>"},{"location":"notes/Python-Tutorial/LearnRegex/#recompilepattern-","title":"<code>re.compile(pattern)</code> - \u7f16\u8bd1\u6b63\u5219\u8868\u8fbe\u5f0f","text":"<p>\u5982\u679c\u4e00\u4e2a\u6b63\u5219\u8868\u8fbe\u5f0f\u9700\u8981\u88ab\u91cd\u590d\u4f7f\u7528\u591a\u6b21\uff0c\u6700\u597d\u5148\u7528 <code>re.compile()</code> \u5c06\u5b83\u7f16\u8bd1\u6210\u4e00\u4e2a\u201c\u6a21\u5f0f\u5bf9\u8c61\u201d\uff08Pattern Object\uff09\u3002\u8fd9\u6837\u505a\u53ef\u4ee5\u5927\u5927\u63d0\u9ad8\u6267\u884c\u6548\u7387\uff0c\u56e0\u4e3a\u7f16\u8bd1\u53ea\u9700\u8981\u8fdb\u884c\u4e00\u6b21\u3002</p> Python<pre><code>import re\n\n# \u7f16\u8bd1\u4e00\u6b21\u6a21\u5f0f\nphone_pattern = re.compile(r\"\\d{3}-\\d{3}-\\d{4}\")\n\ntext1 = \"Call me at 415-555-1234.\"\ntext2 = \"His number is 212-555-9876.\"\n\n# \u591a\u6b21\u4f7f\u7528\u7f16\u8bd1\u597d\u7684\u6a21\u5f0f\u5bf9\u8c61\nmatch1 = phone_pattern.search(text1)\nmatch2 = phone_pattern.search(text2)\n\nif match1:\n    print(f\"Text1\u4e2d\u627e\u5230: {match1.group(0)}\")\nif match2:\n    print(f\"Text2\u4e2d\u627e\u5230: {match2.group(0)}\")\n\n# \u8f93\u51fa:\n# Text1\u4e2d\u627e\u5230: 415-555-1234\n# Text2\u4e2d\u627e\u5230: 212-555-9876\n</code></pre>"},{"location":"notes/Python-Tutorial/LearnRegex/#_1","title":"\u6b63\u5219\u8868\u8fbe\u5f0f\u57fa\u672c\u5143\u5b57\u7b26","text":"\u5b57\u7b26 \u63cf\u8ff0 \u793a\u4f8b \u5339\u914d . \u5339\u914d\u9664\u6362\u884c\u7b26\u5916\u7684\u4efb\u610f\u5355\u4e2a\u5b57\u7b26 a.c \"abc\", \"a_c\", \"a2c\" \\d \u5339\u914d\u4efb\u610f\u4e00\u4e2a\u6570\u5b57 (0-9) \\d+ \"123\", \"4\" \\D \u5339\u914d\u4efb\u610f\u4e00\u4e2a\u975e\u6570\u5b57 \\D \"a\", \"_\", \" \" \\w \u5339\u914d\u5b57\u6bcd\u3001\u6570\u5b57\u3001\u4e0b\u5212\u7ebf (word character) \\w+ \"hello\", \"user_123\" \\W \u5339\u914d\u975e\u5b57\u6bcd\u3001\u6570\u5b57\u3001\u4e0b\u5212\u7ebf \\W \"@\", \"!\", \" \" \\s \u5339\u914d\u4efb\u610f\u7a7a\u767d\u5b57\u7b26 (\u7a7a\u683c, tab, \u6362\u884c) \\s+ \" \", \" \\t\" \\S \u5339\u914d\u4efb\u610f\u975e\u7a7a\u767d\u5b57\u7b26 \\S+ \"word\", \"!\" ^ \u5339\u914d\u5b57\u7b26\u4e32\u7684\u5f00\u5934 ^Hello \"Hello world\" $ \u5339\u914d\u5b57\u7b26\u4e32\u7684\u7ed3\u5c3e world$ \"Hello world\" [] \u5b57\u7b26\u96c6\uff0c\u5339\u914d\u65b9\u62ec\u53f7\u4e2d\u7684\u4efb\u610f\u4e00\u4e2a\u5b57\u7b26 [aeiou] \"a\", \"e\", \"i\", \"o\", \"u\" [^] \u5426\u5b9a\u5b57\u7b26\u96c6\uff0c\u5339\u914d\u4e0d\u5728\u62ec\u53f7\u4e2d\u7684\u4efb\u610f\u5b57\u7b26 [^0-9] \"a\", \"b\", \"c\" (\u975e\u6570\u5b57) <code>|</code> \u6216\u8fd0\u7b97\u7b26 cat|dog () \u5206\u7ec4\uff0c\u6355\u83b7\u62ec\u53f7\u5185\u7684\u6a21\u5f0f (\\d{3})-(\\d{4}) \"555-1234\" <p>\u91cf\u8bcd (Quantifiers):</p> \u5b57\u7b26 \u63cf\u8ff0 * \u5339\u914d\u524d\u9762\u7684\u5143\u7d20 0 \u6b21\u6216\u591a\u6b21 + \u5339\u914d\u524d\u9762\u7684\u5143\u7d20 1 \u6b21\u6216\u591a\u6b21 ? \u5339\u914d\u524d\u9762\u7684\u5143\u7d20 0 \u6b21\u6216 1 \u6b21 {n} \u5339\u914d\u524d\u9762\u7684\u5143\u7d20\u6070\u597d n \u6b21 {n,} \u5339\u914d\u524d\u9762\u7684\u5143\u7d20\u81f3\u5c11 n \u6b21 {n,m} \u5339\u914d\u524d\u9762\u7684\u5143\u7d20 n \u5230 m"},{"location":"notes/Python-Tutorial/LearnRegex/#exercise","title":"Exercise","text":"Python<pre><code>pattern = r\"([\\w.-]+)@([\\w.-]+\\.[\\w-]+)\" # \u5728@\u524d\u540e\u52a0\u4e0a\u62ec\u53f7\n\ntext = \"Send your resume to careers@my-startup.com\"\nmatch = re.search(pattern, text)\n\nif match:\n    print(f\"\u5b8c\u6574\u90ae\u7bb1: {match.group(0)}\")\n    print(f\"\u7528\u6237\u540d: {match.group(1)}\")\n    print(f\"\u57df\u540d\u90e8\u5206: {match.group(2)}\")\n\n# \u8f93\u51fa\uff1a\n# \u5b8c\u6574\u90ae\u7bb1: careers@my-startup.com\n# \u7528\u6237\u540d: careers\n# \u57df\u540d\u90e8\u5206: my-startup.com\n</code></pre> <p>\u89e3\u6790\uff1a</p> \u90e8\u5206 \u542b\u4e49 \u8be6\u7ec6\u8bf4\u660e [\\w.-]+ \u7b2c\u4e00\u90e8\u5206\uff1a\u7528\u6237\u540d \u5339\u914d\u90ae\u7bb1\u7684 @ \u524d\u9762\u7684\u90e8\u5206\u3002 \\w \u5339\u914d\u4efb\u4f55\u201c\u5355\u8bcd\u5b57\u7b26\u201d\uff08\u5b57\u6bcd a-z, A-Z\uff0c\u6570\u5b57 0-9\uff0c\u4ee5\u53ca\u4e0b\u5212\u7ebf _\uff09\u3002 . \u548c - \u5339\u914d\u5b57\u9762\u4e0a\u7684\u70b9\u53f7\u548c\u8fde\u5b57\u7b26\u3002 [...] \u5c06\u4ee5\u4e0a\u7ec4\u5408\u6210\u5b57\u7b26\u96c6\u3002 + \u8868\u793a\u8fd9\u4e2a\u5b57\u7b26\u96c6\u91cc\u7684\u5b57\u7b26\u53ef\u4ee5\u51fa\u73b0\u4e00\u6b21\u6216\u591a\u6b21\u3002 @ \u5b57\u9762\u5b57\u7b26 \u7cbe\u786e\u5339\u914d @ \u7b26\u53f7\uff0c\u5b83\u662f\u7528\u6237\u540d\u548c\u57df\u540d\u7684\u5206\u754c\u7ebf\u3002 [\\w.-]+ \u7b2c\u4e8c\u90e8\u5206\uff1a\u57df\u540d \u5339\u914d @ \u4e4b\u540e\uff0c\u9876\u7ea7\u57df\u540d\uff08\u5982 .com\uff09\u4e4b\u524d\u7684\u90e8\u5206\u3002\u89c4\u5219\u548c\u7528\u6237\u540d\u90e8\u5206\u4e00\u6837\uff0c\u53ef\u4ee5\u5339\u914d gmail \u6216 sub-domain.example \u8fd9\u6837\u7684\u57df\u540d\u3002 . \u8f6c\u4e49\u7684\u70b9 \u8fd9\u662f\u5173\u952e\uff01 . \u5728\u6b63\u5219\u8868\u8fbe\u5f0f\u4e2d\u662f\u5143\u5b57\u7b26\uff0c\u4ee3\u8868\u201c\u4efb\u4f55\u5b57\u7b26\u201d\u3002\u4e3a\u4e86\u5339\u914d\u4e00\u4e2a\u771f\u6b63\u7684\u70b9\uff0c\u6211\u4eec\u5fc5\u987b\u7528\u53cd\u659c\u6760  \u5bf9\u5b83\u8fdb\u884c\u8f6c\u4e49\u3002 [\\w-]+ \u7b2c\u4e09\u90e8\u5206\uff1a\u9876\u7ea7\u57df\u540d \u5339\u914d\u6700\u540e\u7684\u90e8\u5206\uff0c\u5982 com, org, co-uk\u3002 [\\w-] \u6ce8\u610f\uff0c\u8fd9\u91cc\u901a\u5e38\u4e0d\u5305\u542b\u70b9 .\uff0c\u56e0\u4e3a\u9876\u7ea7\u57df\u540d\u672c\u8eab\u4e00\u822c\u4e0d\u5e26\u70b9\u3002 + \u51fa\u73b0\u4e00\u6b21\u6216\u591a\u6b21\u3002 Python<pre><code># \u6a21\u5f0f\uff1ahttp(s)://(\u57df\u540d\u548c\u8def\u5f84)\nurl_pattern = r\"https?://[\\w./-]+\"\n# \u89e3\u6790\uff1a\n# http  -&gt; \u5339\u914d\u5b57\u9762\u4e0a\u7684 \"http\"\n# s?    -&gt; \"s\" \u662f\u53ef\u9009\u7684\uff08? \u4ee3\u88680\u6b21\u62161\u6b21\uff09\uff0c\u6240\u4ee5 http \u548c https \u90fd\u80fd\u5339\u914d\n# ://   -&gt; \u5339\u914d\u5b57\u9762\u4e0a\u7684 \"://\"\n# [\\w./-]+ -&gt; \u5339\u914d\u7531\u5355\u8bcd\u5b57\u7b26\u3001\u70b9\u3001\u659c\u6760\u3001\u8fde\u5b57\u7b26\u7ec4\u6210\u7684\u4efb\u610f\u957f\u5e8f\u5217\n\nweb_text = \"Visit our site at http://example.com/home or the secure portal https://portal.my-company.com/login.\"\nurls = re.findall(url_pattern, web_text)\nprint(urls)\n\n# \u8f93\u51fa\uff1a\n# ['http://example.com/home', 'https://portal.my-company.com/login']\n</code></pre>"},{"location":"notes/Python-Tutorial/Logging/","title":"Logging","text":""},{"location":"notes/Python-Tutorial/Logging/#logging","title":"Logging","text":"<p> \u7ea6 61 \u4e2a\u5b57  14 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> Python<pre><code>import logging\n\nlogging.basicConfig(level=logging.INFO) #\u53ea\u6709\u5f53\u65e5\u5fd7\u7b49\u7ea7\u9ad8\u4e8e\u6b64\u65f6\u624d\u4f1a\u6253\u5370\u51fa\u6765\n\nlogging.debug(\"debug msg\")\nlogging.info(\"info msg\")\nlogging.warning(\"warning msg\")\nlogging.error(\"error msg\")\nlogging.critical(\"critical msg\")\n</code></pre> <p>\u9ed8\u8ba4\u8f93\u51fa\uff1a\u65e5\u5fd7\u7b49\u7ea7+\u65e5\u5fd7\u540d\u79f0+\u65e5\u5fd7\u5185\u5bb9</p>"},{"location":"notes/Python-Tutorial/Logging/#_1","title":"\u53c2\u8003","text":"<p>Logging format: https://docs.python.org/3/library/logging.html#logrecord-attributes</p> <p>Logging handler: https://docs.python.org/3/howto/logging.html#useful-handlers</p> <p><code>logging.basicConfig(level=logging.INFO,format='%(asctime)s - %(name)s - %(levelname)s - %(message)s)</code></p> <p>\u6dfb\u52a0filename='?.txt'</p> <p>filemode = 'w' / 'a'</p> <p><code>logger = logging.getLogger('test_logger')</code>  or <code>logging.getlogger(__name__) #\u53ef\u80fd\u662f__main__\u6216\u8005module.py</code></p>"},{"location":"notes/Python-Tutorial/Logging/#_2","title":"\u5f02\u5e38\u5904\u7406","text":"Python<pre><code>try:\n    1 / 0\nexcept:\n    test_logger.exception(\"Get exception\")\n</code></pre>"},{"location":"notes/Python-Tutorial/Pyplot/","title":"Matplotlib","text":""},{"location":"notes/Python-Tutorial/Pyplot/#pyplot","title":"Pyplot","text":"<p> \u7ea6 679 \u4e2a\u5b57  20 \u884c\u4ee3\u7801  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 4 \u5206\u949f</p>"},{"location":"notes/Python-Tutorial/Pyplot/#xy","title":"\u7ed8\u5236x\u548cy\u70b9","text":"<p><code>plot()</code>\u51fd\u6570\u9ed8\u8ba4\u4ece\u70b9\u5230\u70b9\u7ed8\u5236\u4e00\u6761\u76f4\u7ebf\uff0c\u53c2\u65701\u662f\u5305\u542bx\u8f74\u4e0a\u7684\u70b9\u7684\u6570\u7ec4\uff0c\u53c2\u65702\u662f\u5305\u542by\u8f74\u4e0a\u7684\u70b9\u7684\u6570\u7ec4\u3002</p> <p>\u6bd4\u5982\u6211\u4eec\u60f3\u7ed8\u5236(1,3)-&gt;(8,10)\u7684\u7ebf\uff0c\u5c31\u8981\u4f20\u5165[1,8]\u548c[3,10]\u3002</p> <p>\u5982\u679c\u53ea\u60f3\u7ed8\u5236\u6807\u8bb0\u70b9\u800c\u4e0d\u7ed8\u5236\u76f4\u7ebf\uff0c\u53ef\u4ee5\u4f20\u5165\u53c2\u6570<code>'o'</code> <code>plt.plot(xpoints, ypoints,'o')</code></p> <p>\u5982\u679c\u6211\u4eec\u4e0d\u6307\u5b9ax\u8f74\u4e0a\u7684\u70b9\uff0c\u5b83\u4eec\u5c06\u83b7\u5f97\u9ed8\u8ba4\u503c0,1,2,3,...(\u53d6\u51b3\u4e8ey\u7684\u957f\u5ea6)</p>"},{"location":"notes/Python-Tutorial/Pyplot/#_1","title":"\u6807\u8bb0","text":"<p>\u7ebf\u6bb5\u7684\u7aef\u70b9\u7528marker\u505a\u6807\u8bb0\uff0c\u663e\u5f0f\u7684\u4f20\u5165<code>marker='*'</code>or<code>marker='o'</code></p> <p><code>plt.plot(xpoints, ypoints,marker='o')</code> \u6ce8\u610f\u4e0e\u4e0a\u8ff0\u53ea\u7ed8\u5236\u70b9\u7684\u533a\u522b</p> <p>\u539f\u56e0\uff1afmt='o' \u8fd9\u4e2a\u7b80\u5199\u5b57\u7b26\u4e32\u5df2\u7ecf\u9690\u542b\u4e86 marker='o' \u4e14 linestyle='None'\uff0c \u6240\u4ee5\u4f60\u770b\u5230\u7684\u662f \u7eaf\u6563\u70b9\u3002 marker='o' \u53ea\u8bbe\u7f6e\u4e86 marker\uff0c\u6ca1\u52a8 linestyle\uff0c \u4e8e\u662f\u9ed8\u8ba4\u7684 linestyle='-' \u4ecd\u7136\u6709\u6548\uff0c \u7ed3\u679c marker \u4e4b\u95f4\u88ab\u76f4\u7ebf\u8fde\u8d77\u6765\u4e86\u3002 </p> <p>\u683c\u5f0f\u5316\u5b57\u7b26\u4e32\u4f20\u53c2: <code>fmt='color|marker|line</code></p> \u5206\u7c7b \u5b57\u7b26 \u6548\u679c \u989c\u8272 (color) <code>b</code> blue \u84dd\u8272 <code>g</code> green \u7eff\u8272 <code>r</code> red \u7ea2\u8272 <code>c</code> cyan \u9752\u8272 <code>m</code> magenta \u6d0b\u7ea2 <code>y</code> yellow \u9ec4\u8272 <code>k</code> black \u9ed1\u8272 <code>w</code> white \u767d\u8272 \u6807\u8bb0 (marker) <code>.</code> point marker <code>,</code> pixel marker <code>o</code> circle marker <code>v</code> triangle_down marker <code>^</code> triangle_up marker <code>&lt;</code> triangle_left marker <code>&gt;</code> triangle_right marker <code>1</code> tri_down marker <code>2</code> tri_up marker <code>3</code> tri_left marker <code>4</code> tri_right marker <code>s</code> square marker <code>p</code> pentagon marker <code>*</code> star marker <code>h</code> hexagon1 marker <code>H</code> hexagon2 marker <code>+</code> plus marker <code>x</code> x marker <code>D</code> diamond marker <code>d</code> thin_diamond marker <code>&amp;#124;</code> vertical line marker <code>_</code> horizontal line marker \u7ebf\u578b (line) <code>-</code> solid line \u5b9e\u7ebf <code>--</code> dashed line \u865a\u7ebf <code>-.</code> dash-dot line \u70b9\u5212\u7ebf <code>:</code> dotted line \u70b9\u7ebf <code>None</code> / <code>' '</code> / <code>''</code> \u65e0\u7ebf\u6bb5 <p>marker\u76f8\u5173\u53c2\u6570:</p> <ul> <li>ms(markersize)</li> <li>mec(markeredgecolor): marker\u8fb9\u7f18\u989c\u8272</li> <li>mfc(markerfacecolor): marker\u5185\u90e8\u989c\u8272</li> </ul> <p>\u8bbe\u7f6e\u4e2d\u6587\u5b57\u4f53\uff1a <code>matplotlib.rcParams['font.sans-serif'] = ['KaiTi']</code></p>"},{"location":"notes/Python-Tutorial/Pyplot/#_2","title":"\u6807\u7b7e","text":"<p><code>xlabel()</code>\u548c<code>ylabel()</code>\u8bbe\u7f6e\u6a2a\u7eb5\u5750\u6807\u7684\u6807\u7b7e</p> <p><code>title()</code>\u8bbe\u7f6e\u6807\u9898</p> <p>\u8bbe\u7f6e\u5b57\u4f53:</p> Python<pre><code>   font1 = {'family':'serif','color':'blue','size':20}\n   font2 = {'family':'serif','color':'red','size':50}\n\n   plt.title(\"\u8fd0\u52a8\u5065\u5eb7\u6570\u636e\",fontdict=font1)\n   plt.xlabel(\"\u5e73\u5747\u8109\u640f\",fontdict=font2)\n   plt.ylabel(\"\u5361\u8def\u91cc\u6d88\u8017\u91cf\",fontdict=font2)\n\n   plt.plot(x,y)\n   plt.show()\n</code></pre> <p><code>loc()</code>\u53c2\u6570\u8868\u660e\u6807\u9898\u4f4d\u7f6e <code>left,right,center</code></p>"},{"location":"notes/Python-Tutorial/Pyplot/#_3","title":"\u7f51\u683c","text":"<p><code>plt.grid()</code> \u7ed8\u5236x,y\u7f51\u683c</p> <p><code>plt.grid(axis='x')</code> \u7ed8\u5236x\u7684\u7f51\u683c\uff08\u5e73\u884c\u4e8ey\u8f74\uff09</p> <p><code>color,linestyle,linewidth</code></p>"},{"location":"notes/Python-Tutorial/Pyplot/#_4","title":"\u591a\u56fe","text":"<p>\u5728\u7ed8\u5236\u4e4b\u524d\u8bbe\u7f6e<code>plt.subplot(row,col,index)</code>\uff0crow,col\u8868\u793a\u8fd9\u4e2a\u56fe\u50cf\u4e00\u5171\u6709row\u884c\uff0ccol\u5217\uff0c\u5f53\u524d\u5b50\u56fe\u662f\u7b2cindex\u4e2a(0-base)\u3002index\u8ba1\u6570\uff1a\u4ece\u5de6\u5230\u53f3\uff0c\u4ece\u4e0a\u5230\u4e0b\u3002</p> <p><code>title()</code>\u4e3a\u6bcf\u4e2a\u5b50\u56fe\u8bbe\u7f6e\u6807\u9898</p> <p><code>suptitle()</code>\u4e3a\u6574\u5f20\u56fe\u7247\u8bbe\u7f6e\u6807\u9898</p>"},{"location":"notes/Python-Tutorial/Pyplot/#_5","title":"\u6563\u70b9\u56fe","text":"<p><code>plt.scatter()</code></p> <p><code>color=</code>\u4e3a\u6574\u4f53\u4e0a\u8272</p> <p><code>colors = [\"red\",\"blue\",\"...\"]</code>\u6b64\u65f6\u662f\u4e3a\u6bcf\u4e2a\u70b9\u4e0a\u8272\uff08\u6309\u7167\u4f20\u5165\u7684\u987a\u5e8f\uff09\uff0c\u6ce8\u610f\u6b64\u65f6\u53ea\u80fd\u7528<code>c=</code>\u4f20\u53c2</p> <p>\u989c\u8272\u56fe\uff1a <code>cmap</code> + <code>plt.colorbar()</code></p> <p>\u6bd4\u65b9\u8bf4\u4f7f\u7528<code>viridis</code>\uff0c\u4ece0\uff08\u7d2b\u8272\uff09\u5230100\uff08\u9ec4\u8272\uff09</p> <p></p>Python<pre><code>x=np.array([5,7,8,7,2,17,2,9,4,11,12,9,6])\ny=np.array([99,86,87,88,111,86,103,87,94,78,77,85,86])\ncolors=np.array([0,10,20,30,40,45,50,55,60,70,80,90,100])\nplt.scatter(x,y, c=colors, cmap='viridis')\nplt.colorbar()\nplt.show()\n</code></pre> <p></p> <p><code>s</code>: \u70b9\u7684\u5927\u5c0f</p> <p><code>alpha</code>: \u900f\u660e\u5ea6</p>"},{"location":"notes/Python-Tutorial/Pyplot/#_6","title":"\u67f1\u72b6\u56fe","text":"<p><code>bar()</code>\u7ed8\u5236\u5782\u76f4\u67f1\u72b6\u56fe\uff0c<code>width()</code>\u6761\u5bbd</p> <p><code>barh()</code>\u7ed8\u5236\u6c34\u5e73\u67f1\u72b6\u56fe\uff0c<code>height()</code>\u6761\u9ad8</p>"},{"location":"notes/Python-Tutorial/Pyplot/#_7","title":"\u76f4\u65b9\u56fe","text":"<p><code>hist()</code></p>"},{"location":"notes/Python-Tutorial/Pyplot/#_8","title":"\u997c\u56fe","text":"<p><code>pie()</code></p> <p><code>labels=</code>\u63a5\u53d7\u6807\u7b7e</p> <p><code>startangle=</code>\u8d77\u59cb\u89d2\u5ea6\uff0c\u9ed8\u8ba4\u662f0\uff0c\u53ef\u4ee5\u662f\u4ece\\([a, b)\\)\u4e2d\u6539\u53d8</p> <p><code>explode</code>\u8ba9\u5176\u4e2d\u4e00\u4e2a\u6954\u5b50\u8131\u9896\u800c\u51fa</p> <p><code>shadow=True</code>\u6dfb\u52a0\u9634\u5f71</p> <p><code>legend()</code>\u6dfb\u52a0\u56fe\u4f8b <code>legend(title=\"xxx\")</code></p>"},{"location":"notes/Python-Tutorial/Python-Basics/","title":"Python Basics","text":""},{"location":"notes/Python-Tutorial/Python-Basics/#python-basic-knowledge","title":"Python Basic Knowledge","text":"<p> \u7ea6 35 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"notes/Python-Tutorial/Python-Basics/#-1","title":"[::-1]","text":"<p>When an object is indexable,we can use a[::-1],-1 means it will do operation from end to start. So [A:B:-1]</p>"},{"location":"notes/Python-Tutorial/Python-Basics/#bytewise-operation","title":"Bytewise Operation","text":"<p><code>&gt;&gt;</code> \u53f3\u79fb</p> <p><code>&lt;&lt;</code> \u5de6\u79fb \u76f8\u5f53\u4e8e\u4e58\\(2^n\\)</p> <p>&amp; , | ,</p>"},{"location":"notes/Python-Tutorial/Tensorboard/","title":"Tensorboard","text":""},{"location":"notes/Python-Tutorial/Tensorboard/#tensorboard","title":"\ud83e\udded TensorBoard \u5168\u9762\u5b66\u4e60\u8def\u7ebf","text":"<p> \u7ea6 728 \u4e2a\u5b57  76 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 5 \u5206\u949f</p> <p>\u6211\u4eec\u4f1a\u5206\u6a21\u5757\u8fdb\u884c\u8bb2\u89e3\uff0c\u6bcf\u4e2a\u6a21\u5757\u5305\u62ec\uff1a</p> <ul> <li>\ud83d\udcd8 \u529f\u80fd\u4ecb\u7ecd</li> <li>\ud83e\uddea \u4ee3\u7801\u793a\u4f8b</li> <li>\ud83d\udd0d TensorBoard \u9875\u9762\u5c55\u793a</li> <li>\ud83e\udde0 \u5178\u578b\u5e94\u7528\u573a\u666f</li> </ul>"},{"location":"notes/Python-Tutorial/Tensorboard/#1","title":"\u2705 \u7b2c1\u8bfe\uff1a\u57fa\u672c\u4f7f\u7528\uff08\u6807\u91cf\u6307\u6807\u7684\u8bb0\u5f55\uff09","text":""},{"location":"notes/Python-Tutorial/Tensorboard/#_1","title":"\ud83d\udcd8 \u529f\u80fd\u4ecb\u7ecd\uff1a","text":"<p>\u6700\u57fa\u7840\u7684\u529f\u80fd\u662f\u8bb0\u5f55\u6807\u91cf\uff0c\u6bd4\u5982\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684 <code>loss</code>\u3001<code>accuracy</code>\uff0c\u65b9\u4fbf\u4f60\u67e5\u770b\u8bad\u7ec3\u662f\u5426\u6536\u655b\u3002</p>"},{"location":"notes/Python-Tutorial/Tensorboard/#_2","title":"\ud83e\uddea \u4ee3\u7801\u793a\u4f8b\uff1a","text":"<p>\u4ee5 PyTorch \u4e3a\u4f8b\uff1a</p> Python<pre><code>from torch.utils.tensorboard import SummaryWriter\nimport torch\nimport random\n\nwriter = SummaryWriter(\"runs/basic_scalars\")\n\nfor epoch in range(100):\n    loss = random.random()\n    accuracy = 1 - loss\n    writer.add_scalar(\"Loss/train\", loss, epoch)\n    writer.add_scalar(\"Accuracy/train\", accuracy, epoch)\n\nwriter.close()\n</code></pre>"},{"location":"notes/Python-Tutorial/Tensorboard/#tensorboard_1","title":"\ud83d\udd0d TensorBoard \u9875\u9762\u5c55\u793a\uff1a","text":"<ul> <li> <p>\u6253\u5f00 Scalar \u9762\u677f\uff0c\u4f60\u4f1a\u770b\u5230\u4e24\u4e2a\u56fe\u7ebf\uff1a</p> </li> <li> <p>Loss/train</p> </li> <li>Accuracy/train</li> </ul>"},{"location":"notes/Python-Tutorial/Tensorboard/#_3","title":"\ud83e\udde0 \u5e94\u7528\u573a\u666f\uff1a","text":"<ul> <li>\u8ddf\u8e2a\u6a21\u578b\u8bad\u7ec3\u6548\u679c\uff08Loss/Accuracy/\u5b66\u4e60\u7387\uff09</li> <li>\u6bd4\u8f83\u4e0d\u540c\u5b9e\u9a8c\uff08\u591a\u4e2a runs\uff09</li> </ul>"},{"location":"notes/Python-Tutorial/Tensorboard/#2","title":"\u2705 \u7b2c2\u8bfe\uff1a\u8bb0\u5f55\u8ba1\u7b97\u56fe\uff08\u6a21\u578b\u7ed3\u6784\u53ef\u89c6\u5316\uff09","text":""},{"location":"notes/Python-Tutorial/Tensorboard/#_4","title":"\ud83d\udcd8 \u529f\u80fd\u4ecb\u7ecd\uff1a","text":"<p>\u4f60\u53ef\u4ee5\u5c06\u6a21\u578b\u7684\u524d\u5411\u4f20\u64ad\u56fe\u53ef\u89c6\u5316\uff0c\u4fbf\u4e8e\u7406\u89e3\u7ed3\u6784\u3002</p>"},{"location":"notes/Python-Tutorial/Tensorboard/#_5","title":"\ud83e\uddea \u4ee3\u7801\u793a\u4f8b\uff1a","text":"Python<pre><code>import torch.nn as nn\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(10, 32),\n            nn.ReLU(),\n            nn.Linear(32, 2)\n        )\n    def forward(self, x):\n        return self.net(x)\n\nmodel = MyModel()\ndummy_input = torch.randn(1, 10)\n\nwriter = SummaryWriter(\"runs/graph_example\")\nwriter.add_graph(model, dummy_input)\nwriter.close()\n</code></pre>"},{"location":"notes/Python-Tutorial/Tensorboard/#tensorboard_2","title":"\ud83d\udd0d TensorBoard \u9875\u9762\u5c55\u793a\uff1a","text":"<ul> <li>\u6253\u5f00 Graph \u9762\u677f\uff0c\u4f1a\u770b\u5230\u5b8c\u6574\u7684\u6a21\u578b\u56fe\u3002</li> </ul>"},{"location":"notes/Python-Tutorial/Tensorboard/#_6","title":"\ud83e\udde0 \u5e94\u7528\u573a\u666f\uff1a","text":"<ul> <li>\u5feb\u901f\u9a8c\u8bc1\u6a21\u578b\u7ed3\u6784</li> <li>\u7ed9\u56e2\u961f\u6210\u5458\u5c55\u793a\u6a21\u578b\u6784\u6210</li> </ul>"},{"location":"notes/Python-Tutorial/Tensorboard/#3","title":"\u2705 \u7b2c3\u8bfe\uff1a\u8bb0\u5f55\u6a21\u578b\u53c2\u6570\uff08\u6743\u91cd\u5206\u5e03\u76f4\u65b9\u56fe\uff09","text":""},{"location":"notes/Python-Tutorial/Tensorboard/#_7","title":"\ud83d\udcd8 \u529f\u80fd\u4ecb\u7ecd\uff1a","text":"<p>\u4f60\u53ef\u4ee5\u8bb0\u5f55\u6bcf\u4e00\u5c42\u7684\u53c2\u6570\u5206\u5e03\uff0c\u67e5\u770b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u53c2\u6570\u662f\u5426\u5408\u7406\u3002</p>"},{"location":"notes/Python-Tutorial/Tensorboard/#_8","title":"\ud83e\uddea \u4ee3\u7801\u793a\u4f8b\uff1a","text":"Python<pre><code>model = nn.Linear(10, 2)\nwriter = SummaryWriter(\"runs/param_hist\")\n\nfor epoch in range(100):\n    for name, param in model.named_parameters():\n        writer.add_histogram(name, param, epoch)\n\nwriter.close()\n</code></pre>"},{"location":"notes/Python-Tutorial/Tensorboard/#tensorboard_3","title":"\ud83d\udd0d TensorBoard \u9875\u9762\u5c55\u793a\uff1a","text":"<ul> <li>\u6253\u5f00 Histograms \u9762\u677f\uff0c\u53ef\u4ee5\u770b\u5230\u968f\u8bad\u7ec3\u8fc7\u7a0b\u6a21\u578b\u53c2\u6570\u5206\u5e03\u7684\u6f14\u53d8\u3002</li> </ul>"},{"location":"notes/Python-Tutorial/Tensorboard/#_9","title":"\ud83e\udde0 \u5e94\u7528\u573a\u666f\uff1a","text":"<ul> <li>\u76d1\u63a7\u8bad\u7ec3\u662f\u5426\u51fa\u73b0\u68af\u5ea6\u7206\u70b8/\u6d88\u5931</li> <li>\u89c2\u5bdf\u6a21\u578b\u6536\u655b\u8d8b\u52bf</li> </ul>"},{"location":"notes/Python-Tutorial/Tensorboard/#4","title":"\u2705 \u7b2c4\u8bfe\uff1a\u8bb0\u5f55\u56fe\u50cf\uff08\u8bad\u7ec3\u6837\u672c\u3001\u53ef\u89c6\u5316\u7ed3\u679c\uff09","text":""},{"location":"notes/Python-Tutorial/Tensorboard/#_10","title":"\ud83d\udcd8 \u529f\u80fd\u4ecb\u7ecd\uff1a","text":"<p>\u5c06\u56fe\u50cf\u8f93\u5165\u3001\u9884\u6d4b\u7ed3\u679c\u53ef\u89c6\u5316\uff0c\u53ef\u4ee5\u5e2e\u52a9\u4f60 debug \u6216\u5c55\u793a\u6548\u679c\u3002</p>"},{"location":"notes/Python-Tutorial/Tensorboard/#_11","title":"\ud83e\uddea \u4ee3\u7801\u793a\u4f8b\uff1a","text":"Python<pre><code>import torchvision\nimport torchvision.transforms as transforms\n\ntransform = transforms.Compose([transforms.ToTensor()])\ndataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n\nimages, labels = next(iter(dataloader))\nimg_grid = torchvision.utils.make_grid(images)\n\nwriter = SummaryWriter(\"runs/images\")\nwriter.add_image(\"mnist_images\", img_grid)\nwriter.close()\n</code></pre>"},{"location":"notes/Python-Tutorial/Tensorboard/#tensorboard_4","title":"\ud83d\udd0d TensorBoard \u9875\u9762\u5c55\u793a\uff1a","text":"<ul> <li>\u6253\u5f00 Images \u9762\u677f\uff0c\u663e\u793a\u91c7\u6837\u56fe\u50cf\uff08\u5982 MNIST\uff09</li> </ul>"},{"location":"notes/Python-Tutorial/Tensorboard/#_12","title":"\ud83e\udde0 \u5e94\u7528\u573a\u666f\uff1a","text":"<ul> <li>\u9a8c\u8bc1\u6570\u636e\u9884\u5904\u7406\u7ed3\u679c</li> <li>\u5bf9\u6bd4\u9884\u6d4b\u7ed3\u679c\u4e0e\u771f\u5b9e\u6807\u7b7e\uff08\u8bed\u4e49\u5206\u5272\u3001\u751f\u6210\u56fe\u50cf\uff09</li> </ul>"},{"location":"notes/Python-Tutorial/Tensorboard/#5-embeddings","title":"\u2705 \u7b2c5\u8bfe\uff1a\u9ad8\u9636\u529f\u80fd\uff08\u6295\u5f71\u5d4c\u5165 Embeddings\uff09","text":""},{"location":"notes/Python-Tutorial/Tensorboard/#_13","title":"\ud83d\udcd8 \u529f\u80fd\u4ecb\u7ecd\uff1a","text":"<p>\u4f60\u53ef\u4ee5\u7528 TensorBoard \u7684 Projector \u67e5\u770b\u9ad8\u7ef4\u5d4c\u5165\u7684\u6295\u5f71\uff0c\u6bd4\u5982 Word Embedding\u3001Image Embedding\u3002</p>"},{"location":"notes/Python-Tutorial/Tensorboard/#_14","title":"\ud83e\uddea \u4ee3\u7801\u793a\u4f8b\uff1a","text":"Python<pre><code>import numpy as np\nfrom torch.utils.tensorboard import SummaryWriter\n\nfeatures = torch.randn(100, 64)  # 100\u4e2a\u6837\u672c\uff0c64\u7ef4\u7279\u5f81\nlabels = [str(i % 10) for i in range(100)]  # \u5047\u8bbe\u662f0-9\u7684\u6807\u7b7e\n\nwriter = SummaryWriter(\"runs/embeddings\")\nwriter.add_embedding(features, metadata=labels)\nwriter.close()\n</code></pre>"},{"location":"notes/Python-Tutorial/Tensorboard/#tensorboard_5","title":"\ud83d\udd0d TensorBoard \u9875\u9762\u5c55\u793a\uff1a","text":"<ul> <li>\u6253\u5f00 Projector \u9762\u677f\uff0c\u53ef\u4ee5\u67e5\u770b2D/3D\u5d4c\u5165\u6295\u5f71\u56fe\u3002</li> </ul>"},{"location":"notes/Python-Tutorial/Tensorboard/#_15","title":"\ud83e\udde0 \u5e94\u7528\u573a\u666f\uff1a","text":"<ul> <li>\u53ef\u89c6\u5316\u5206\u7c7b\u5668\u8f93\u51fa\u3001\u8bcd\u5411\u91cf\u5206\u5e03</li> <li>\u68c0\u67e5\u6837\u672c\u805a\u7c7b\u3001\u6a21\u578b\u5206\u79bb\u80fd\u529b</li> </ul>"},{"location":"notes/Python-Tutorial/Tensorboard/#6-runs","title":"\u2705 \u7b2c6\u8bfe\uff1a\u591a\u5b9e\u9a8c\u5bf9\u6bd4\uff08\u547d\u540d\u4e0d\u540c runs\uff09","text":""},{"location":"notes/Python-Tutorial/Tensorboard/#_16","title":"\ud83d\udcd8 \u529f\u80fd\u4ecb\u7ecd\uff1a","text":"<p>\u4f60\u53ef\u4ee5\u8bb0\u5f55\u591a\u4e2a\u5b9e\u9a8c\u5230\u4e0d\u540c\u5b50\u76ee\u5f55\uff0c\u7136\u540e\u540c\u65f6\u5728 TensorBoard \u4e2d\u6bd4\u8f83\u5b83\u4eec\u3002</p>"},{"location":"notes/Python-Tutorial/Tensorboard/#_17","title":"\ud83e\uddea \u4ee3\u7801\u793a\u4f8b\uff1a","text":"Python<pre><code>writer1 = SummaryWriter(\"runs/exp1\")\nwriter2 = SummaryWriter(\"runs/exp2\")\n\nfor epoch in range(100):\n    writer1.add_scalar(\"Loss/train\", 1 / (epoch+1), epoch)\n    writer2.add_scalar(\"Loss/train\", 0.8 / (epoch+1), epoch)\n\nwriter1.close()\nwriter2.close()\n</code></pre> <p>\u7136\u540e\uff1a</p> Python<pre><code>from tensorboard import program\n\ntb = program.TensorBoard()\ntb.configure(argv=[None, '--logdir=runs'])\ntb.launch()\n</code></pre>"},{"location":"notes/Python-Tutorial/Tensorboard/#tensorboard_6","title":"\ud83d\udd0d TensorBoard \u9875\u9762\u5c55\u793a\uff1a","text":"<ul> <li>\u4f60\u4f1a\u770b\u5230 Loss/train \u6709\u4e24\u6761\u7ebf\uff0c\u4e00\u6761\u6765\u81ea <code>exp1</code>\uff0c\u4e00\u6761\u6765\u81ea <code>exp2</code></li> </ul>"},{"location":"notes/Python-Tutorial/Tensorboard/#_18","title":"\ud83e\udde0 \u5e94\u7528\u573a\u666f\uff1a","text":"<ul> <li>\u5bf9\u6bd4\u4e0d\u540c\u8d85\u53c2\u6570</li> <li>\u5bf9\u6bd4\u4e0d\u540c\u6a21\u578b\u7ed3\u6784</li> <li>\u6c47\u603b\u5b9e\u9a8c\u7ed3\u679c</li> </ul>"},{"location":"notes/Python-Tutorial/Tensorboard/#_19","title":"\ud83d\ude80 \u5b9e\u7528\u6280\u5de7 &amp; \u5efa\u8bae","text":"\u6280\u5de7 \u8bf4\u660e \u4f7f\u7528 <code>runs/\u5b9e\u9a8c\u540d</code> \u505a\u76ee\u5f55\u7ba1\u7406 \u65b9\u4fbf\u540e\u671f\u5bf9\u6bd4\u591a\u4e2a\u5b9e\u9a8c \u5199\u65e5\u5fd7\u7684\u65f6\u5019\u5c3d\u91cf\u7528\u8bed\u4e49\u6e05\u6670\u7684 tag\uff0c\u5982 <code>train/loss</code>\u3001<code>val/accuracy</code> \u65b9\u4fbf\u5728 TensorBoard \u4e2d\u5206\u7ec4 \u6bcf\u6b21\u8bad\u7ec3\u5f00\u59cb\u524d\u6e05\u7406\u65e7\u65e5\u5fd7\uff08<code>shutil.rmtree('runs')</code>\uff09 \u907f\u514d\u65e7\u65e5\u5fd7\u6df7\u6dc6 TensorBoard \u65e5\u5fd7\u8bb0\u5f55\u4e0d\u5e94\u592a\u9891\u7e41 \u6bcf\u51e0\u4e2a step \u6216\u6bcf\u4e2a epoch \u8bb0\u5f55\u4e00\u6b21\u5373\u53ef\uff0c\u907f\u514d\u6587\u4ef6\u81a8\u80c0"},{"location":"notes/Python-Tutorial/WhatIsPickle/","title":"Pickle","text":""},{"location":"notes/Python-Tutorial/WhatIsPickle/#pickle","title":"Pickle","text":"<p> \u7ea6 257 \u4e2a\u5b57  5 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>pickle\u5b9e\u9645\u4e0a\u662f\u4e00\u4e2a\u5b57\u5178\uff0c\u5e76\u4e14\u53ef\u4ee5\u591a\u5c42\u5d4c\u5957\u3002</p>"},{"location":"notes/Python-Tutorial/WhatIsPickle/#pickle_1","title":"\u901a\u8fc7\u7c7b\u522b\u8f6c\u6362\u6df1\u523b\u8ba4\u8bc6Pickle\u6587\u4ef6","text":""},{"location":"notes/Python-Tutorial/WhatIsPickle/#pickle_2","title":"\u56fe\u7247\u8f6cpickle","text":"<p>\u5982\u679c\u76f4\u63a5\u5c06\u4e00\u4e2a\u56fe\u50cf\u6587\u4ef6\u91c7\u7528Python\u5185\u7f6e\u7684read()\u65b9\u6cd5\uff0c\u5982\u4ee5\u4e8c\u8fdb\u5236\u5f62\u5f0f\u8bfb\u53d6\uff1a</p> Python<pre><code>with open('image.jpg', 'rb') as f:\n    raw_data = f.read()\n</code></pre> <p>raw_data\u662f\u4e00\u4e2a\u5305\u542b\u56fe\u50cf\u6587\u4ef6\u539f\u59cb\u5b57\u8282\u7684bytes\u5bf9\u8c61</p> <p>\u6ce8\uff1a\u4ec0\u4e48\u662fbytes\u5bf9\u8c61\uff1f</p> <p>\u4e0d\u53ef\u4fee\u6539\uff01\u6bcf\u4e2abyte\u5b58\u50a80~255\u7684\u6574\u6570\u3002\u53ef\u4ee5\u76f4\u63a5\u7528<code>b'hello'</code>(Ascii\u7f16\u7801)\u6216<code>b'\\x41\\x42'</code>(\u5341\u516d\u8fdb\u5236\uff0c\u76f8\u5f53\u4e8e<code>b'AB'</code>)\u6216\u4ece\u6574\u6570\u6570\u7ec4\u751f\u6210</p> <p>\u53ef\u4ee5\u5c06\u5b57\u7b26\u4e32\u7f16\u7801\u4e3abytes\u5bf9\u8c61\uff1a<code>text=\"\u4f60\u597d\"  b_text = text.encode('utf-8')</code></p> <p>\u5c06bytes\u5bf9\u8c61\u8f6c\u6362\u6210\u5b57\u7b26\u4e32: <code>b = b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd'  text = b.decode('utf-8')  # \"\u4f60\u597d\"</code></p> <p>\u4e00\u4e9b\u7528\u6cd5\uff1a\u7d22\u5f15\u548c\u5207\u7247</p> Python<pre><code>b = b'ABCD'\nprint(b[0])    # 65\uff08\u8fd4\u56de\u6574\u6570\u5b57\u8282\u503c\uff09\nprint(b[1:3])  # b'BC'\uff08\u8fd4\u56de\u65b0\u7684 bytes \u5bf9\u8c61\uff09\n</code></pre> <p>\u5982\u679c\u76f4\u63a5print\u51fa\u6765\uff0c\u662f\u4ee5b\u5f00\u5934\u7684\uff0c\u5e76\u4e0d\u76f4\u63a5\u63cf\u8ff0\u56fe\u7247\u50cf\u7d20\uff0c\u800c\u8fd8\u5305\u62ec\u4e86\u4e00\u4e9b\u4fe1\u606f\uff0c\u6bd4\u5982\u521b\u5efa\u8fd9\u5f20\u56fe\u7684\u4f5c\u8005\u662f\u8c01</p> <p>PIL: (\u884c\uff0c\u5217)</p> <p>Numpy\uff1a\uff08\u5217\uff0c\u884c\uff09</p> <p>\u53ef\u4ee5\u5199\u4e00\u4e2a\u7b80\u5355\u7684Image2Pickle\u51fd\u6570\u6765\u6d4b\u8bd5\u5bf9\u4e0a\u8ff0\u77e5\u8bc6\u7684\u7406\u89e3\u3002</p>"},{"location":"notes/Python-Tutorial/pandas/","title":"Pandas","text":""},{"location":"notes/Python-Tutorial/pandas/#pandas","title":"Pandas\u5e93","text":"<p> \u7ea6 563 \u4e2a\u5b57  91 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 4 \u5206\u949f</p>"},{"location":"notes/Python-Tutorial/pandas/#series","title":"Series\uff1a\u5e26\u6807\u7b7e\u7684\u4e00\u7ef4\u6570\u7ec4","text":"<p>Series \u7c7b\u4f3c\u4e8e NumPy \u7684\u4e00\u7ef4\u6570\u7ec4\uff0c\u4f46\u6709\u7d22\u5f15\uff08\u6807\u7b7e\uff09\u3002</p> Python<pre><code>s = pd.Series([10,20,30],index=['a','b','c'])\nprint(s)\nprint(s['a']) #\u7c7b\u4f3c\u5b57\u5178\u4e00\u6837\u8bbf\u95ee\u503c\n</code></pre>"},{"location":"notes/Python-Tutorial/pandas/#dataframe","title":"DataFrame","text":"<p>DataFrame \u662f Pandas \u6700\u6838\u5fc3\u7684\u6570\u636e\u7ed3\u6784\uff0c\u53ef\u4ee5\u7c7b\u6bd4\u4e3a\u4e00\u4e2a\u5e26\u884c\u5217\u6807\u7b7e\u7684\u4e8c\u7ef4\u8868\u683c\uff08\u5c31\u50cf Excel \u8868\uff09\u3002\u4f60\u53ef\u4ee5\u628a\u5b83\u60f3\u6210\u662f\u591a\u4e2a Series \u6309\u5217\u7ec4\u5408\u800c\u6210\u3002</p> Python<pre><code>data = {\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'age': [25, 30, 35],\n    'Score': [85.5, 90.0, 95.5]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n</code></pre> <p>\u4f60\u53ef\u4ee5\u50cf\u5b57\u5178\u4e00\u6837\u53d6\u5217\uff1a</p> Python<pre><code>print(df['Name'])  # \u8f93\u51fa Name \u5217\uff08\u4e00\u4e2a Series\uff09\n</code></pre> <p>\u4e5f\u53ef\u4ee5\u6309\u884c\u7d22\u5f15\uff1a</p> Python<pre><code>print(df.loc[1])  # \u6309\u6807\u7b7e\u7d22\u5f15\u7b2c 1 \u884c\n\"\"\"\nname      Bob\nage        30\nScore    90.0\nName: 1, dtype: object\n\"\"\"\nprint(df.iloc[2])  # \u6309\u4f4d\u7f6e\u7d22\u5f15\u7b2c 2 \u884c\n</code></pre> <p>Info</p> <p>loc \u7528\u540d\u5b57\uff08\u50cf\u5b57\u5178\uff09</p> <p>iloc \u7528\u6570\u5b57\uff08\u50cf\u6570\u7ec4\uff09</p> <p>loc[a:b] \u4f1a\u5305\u542b b\uff0ciloc[a:b] \u4e0d\u4f1a\u5305\u542b b</p> <p>\u63d0\u793a - <code>loc</code> \u7528\u540d\u5b57\uff08\u50cf\u5b57\u5178\uff09 - <code>iloc</code> \u7528\u6570\u5b57\uff08\u50cf\u6570\u7ec4\uff09 - <code>loc[a:b]</code> \u5305\u542b <code>b</code>\uff0c<code>iloc[a:b]</code> \u4e0d\u5305\u542b <code>b</code></p> Python<pre><code>import pandas as pd\n\ndata = {\n    'Name': ['Tom', 'Lily', 'Jack'],\n    'Math': [88, 95, 70],\n    'English': [78, 85, 90]\n}\ndf = pd.DataFrame(data, index=['s1', 's2', 's3'])\n# \u8bbf\u95ee\u6807\u7b7e\u8303\u56f4\uff08\u5305\u62ec\u672b\u5c3e\uff09\nprint(df.loc['s1':'s2'])\n\n# \u8bbf\u95ee\u7b2c 0~1 \u884c\uff08\u4e0d\u542b\u7b2c 2 \u884c\uff09\nprint(df.iloc[0:2])\n</code></pre> \u5c5e\u6027 / \u65b9\u6cd5 \u4f5c\u7528 <code>.shape</code> \u8fd4\u56de\u5f62\u72b6\uff08\u884c\u6570\uff0c\u5217\u6570\uff09 <code>.columns</code> \u8fd4\u56de\u6240\u6709\u5217\u540d\uff08Index \u5bf9\u8c61\uff09 <code>.index</code> \u8fd4\u56de\u6240\u6709\u884c\u7d22\u5f15 <code>.dtypes</code> \u8fd4\u56de\u6bcf\u4e00\u5217\u7684\u6570\u636e\u7c7b\u578b <code>.head(n)</code> \u67e5\u770b\u524d n \u884c\u6570\u636e\uff08\u9ed8\u8ba4\u524d 5 \u884c\uff09 <code>.tail(n)</code> \u67e5\u770b\u540e n \u884c\u6570\u636e <code>.info()</code> \u67e5\u770b\u603b\u4f53\u7ed3\u6784\uff08\u975e\u7a7a\u6570\u3001\u7c7b\u578b\u3001\u5185\u5b58\uff09 <code>.describe()</code> \u6570\u503c\u5217\u7684\u6c47\u603b\u7edf\u8ba1\uff08\u5747\u503c\u3001\u6807\u51c6\u5dee\u3001\u6700\u5927\u6700\u5c0f\uff09"},{"location":"notes/Python-Tutorial/pandas/#dataframe_1","title":"\u6309\u6761\u4ef6\u7b5b\u9009DataFrame\u7684\u884c","text":"Python<pre><code>import pandas as pd\n\ndata = {\n    'Name': ['Tom', 'Lily', 'Jack', 'Lucy', 'Eric'],\n    'Math': [88, 95, 70, 82, 91],\n    'English': [78, 85, 90, 88, 76],\n    'Age': [20, 22, 21, 23, 21],\n    'Gender': ['M', 'F', 'M', 'F', 'M']\n}\ndf = pd.DataFrame(data)\n</code></pre> <p>\u6211\u4eec\u8981\u7b5b\u9009Math \u6210\u7ee9\u5927\u4e8e 80 \u4e14 Age \u5c0f\u4e8e 23 \u7684\u5b66\u751f\uff1a</p> Python<pre><code># \u7b5b\u9009 Math &gt; 80 \u4e14 Age &lt; 23\nfiltered_df = df[(df['Math'] &gt; 80) &amp; (df['Age'] &lt; 23)]\nprint(filtered_df)\n</code></pre> JavaScript<pre><code>    Name  Math  English  Age Gender\n1   Lily    95       85   22      F\n4   Eric    91       76   21      M\n</code></pre> <p>\u6ce8\u610f\uff1a</p> <ul> <li> <p>\u6761\u4ef6\u4e4b\u95f4\u8981\u7528 &amp;\uff08\u4e0e\uff09\u548c |\uff08\u6216\uff09\u8fde\u63a5\u3002</p> </li> <li> <p>\u6bcf\u4e2a\u6761\u4ef6\u8981\u7528\u5706\u62ec\u53f7\u62ec\u8d77\u6765\u3002</p> </li> <li> <p>\u6bd4\u8f83\u65f6\uff0c\u53ef\u4ee5\u4f7f\u7528\u5e38\u89c1\u7684\u8fd0\u7b97\u7b26\uff1a==, !=, &lt;, &gt;, &lt;=, &gt;=\u3002</p> </li> </ul>"},{"location":"notes/Python-Tutorial/pandas/#_1","title":"\u9009\u62e9\u7279\u5b9a\u5217\uff0c\u6dfb\u52a0\uff0c\u5220\u9664\u5217","text":"Text Only<pre><code>- \u5355\u5217\u9009\u62e9\uff1adf['column_name']\n- \u591a\u5217\u9009\u62e9\uff1adf[['col1', 'col2']]\n- \u6dfb\u52a0\u5217\uff1adf['new_column'] = value\n- \u5220\u9664\u5217\uff0c\u8fd4\u56de\u526f\u672c\uff1adf.drop('column_name', axis=1)\n- \u5220\u9664\u5217\uff0c\u5728\u539f\u59cb\u6570\u636e\u4e0a\u4fee\u6539\uff1adf.drop('column_name', axis=1,inplace=True)\n</code></pre>"},{"location":"notes/Python-Tutorial/pandas/#dataframe_2","title":"DataFrame \u7684\u6392\u5e8f\uff08\u6309\u503c\u6216\u6309\u7d22\u5f15\u6392\u5e8f\uff09","text":"\u65b9\u6cd5\u540d \u4f5c\u7528\u8bf4\u660e <code>sort_values()</code> \u6309\u5217\u7684\u503c\u6392\u5e8f\uff08\u6700\u5e38\u7528\uff09 <code>sort_index()</code> \u6309\u884c\u6216\u5217\u7684\u7d22\u5f15\u6392\u5e8f Python<pre><code>import pandas as pd\n\ndata = {\n    'Name': ['Tom', 'Lily', 'Jack', 'Lucy', 'Eric'],\n    'Math': [88, 95, 70, 82, 91],\n    'English': [78, 85, 90, 88, 76],\n    'Age': [20, 22, 21, 23, 21]\n}\n\ndf = pd.DataFrame(data)\n</code></pre> <p>\u6309\u5217\u503c\u6392\u5e8f\uff08<code>sort_values</code>\uff09</p>"},{"location":"notes/Python-Tutorial/pandas/#_2","title":"\u5355\u5217\u6392\u5e8f","text":"Python<pre><code># \u6309 Math \u5347\u5e8f\u6392\u5e8f\ndf.sort_values(by='Math')\n</code></pre> Python<pre><code># \u6309 Age \u964d\u5e8f\u6392\u5e8f\ndf.sort_values(by='Age', ascending=False)\n</code></pre>"},{"location":"notes/Python-Tutorial/pandas/#_3","title":"\u591a\u5217\u6392\u5e8f","text":"Python<pre><code># \u5148\u6309 Age \u5347\u5e8f\uff0c\u518d\u6309 English \u964d\u5e8f\n# \u5982\u679c\u540c Age \u624d\u6309\u7167 English \u964d\u5e8f\ndf.sort_values(by=['Age', 'English'], ascending=[True, False])\n</code></pre> <p>\u6309\u7d22\u5f15\u6392\u5e8f\uff08<code>sort_index</code>\uff09</p>"},{"location":"notes/Python-Tutorial/pandas/#_4","title":"\u6309\u884c\u7d22\u5f15\u6392\u5e8f","text":"Python<pre><code>df.sort_index()\n</code></pre>"},{"location":"notes/Python-Tutorial/pandas/#_5","title":"\u6309\u5217\u540d\u6392\u5e8f\uff08\u6a2a\u5411\uff09","text":"Python<pre><code>df.sort_index(axis=1)\n</code></pre>"},{"location":"notes/Python-Tutorial/pandas/#_6","title":"\u7f3a\u7701\u503c\u5904\u7406","text":"<ul> <li>isna() / isnull()\uff1a\u68c0\u67e5\u7f3a\u5931\u503c</li> <li>dropna()\uff1a\u5220\u9664\u542b NaN \u7684\u884c\u6216\u5217</li> <li>fillna()\uff1a\u586b\u5145\u7f3a\u5931\u503c\uff080\u3001\u524d\u503c\u3001\u540e\u503c\u3001\u7279\u5b9a\u503c\u7b49\uff09</li> <li>dropna(thresh=...)\uff1a\u6839\u636e\u975e NaN \u503c\u7684\u4e2a\u6570\u5220\u9664\u884c\u6216\u5217</li> <li>fillna(method='ffill'/'bfill')\uff1a\u524d\u540e\u503c\u586b\u5145</li> <li>\u6309\u5217\u4f7f\u7528\u4e0d\u540c\u7684\u586b\u5145\u503c\uff1a df_filled_col = df.fillna({'Math': 80, 'English': 85})</li> </ul>"},{"location":"notes/Python-Tutorial/pandas/#_7","title":"\u5206\u7ec4\u64cd\u4f5c","text":"\u65b9\u6cd5\u540d \u4f5c\u7528\u8bf4\u660e <code>groupby()</code> \u5c06\u6570\u636e\u6309\u67d0\u4e9b\u5217\u8fdb\u884c\u5206\u7ec4 <code>agg()</code> \u805a\u5408\u64cd\u4f5c\uff0c\u53ef\u4ee5\u5bf9\u6bcf\u4e2a\u7ec4\u5e94\u7528\u591a\u4e2a\u805a\u5408\u51fd\u6570 <code>sum()</code> \u6309\u7ec4\u6c42\u548c <code>mean()</code> \u6309\u7ec4\u8ba1\u7b97\u5747\u503c <code>count()</code> \u6309\u7ec4\u8ba1\u7b97\u975e NaN \u503c\u7684\u4e2a\u6570 <code>transform()</code> \u5bf9\u6bcf\u4e2a\u7ec4\u8fdb\u884c\u53d8\u6362\uff0c\u8fd4\u56de\u4e0e\u539f\u6570\u636e\u7ed3\u6784\u76f8\u540c\u7684 DataFrame Python<pre><code># \u6309 Gender \u5217\u5206\u7ec4\ngrouped = df.groupby('Gender')\n\n# \u67e5\u770b\u6bcf\u4e2a\u7ec4\u7684\u5185\u5bb9\nfor name, group in grouped:\n    print(name)\n    print(group)\n#\u805a\u5408\u64cd\u4f5c\uff08agg()\uff09\n#\u8ba1\u7b97\u6bcf\u4e2a\u6027\u522b\u7ec4\u7684\u6570\u5b66\u6210\u7ee9\u5e73\u5747\u503c\u548c\u603b\u548c\n\n# \u6309 Gender \u5206\u7ec4\uff0c\u805a\u5408 Math \u548c English \u5217\ngrouped_agg = grouped.agg({\n    'Math': ['mean', 'sum'],\n    'English': 'mean'\n})\nprint(grouped_agg)\n</code></pre>"},{"location":"notes/Pytorch-Tutorial/Einsum/","title":"Einsum","text":""},{"location":"notes/Pytorch-Tutorial/Einsum/#torcheinsum","title":"torch.einsum","text":"<p> \u7ea6 337 \u4e2a\u5b57  46 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <p>torch.einsum(equation, *operands) \u2192 Tensor</p> <p>Einsum \u53ef\u4ee5\u901a\u8fc7\u57fa\u4e8e\u7231\u56e0\u65af\u5766\u6c42\u548c\u7ea6\u5b9a\u6cd5\u7684\u7b80\u5199\u683c\u5f0f\u6765\u8ba1\u7b97\u8bb8\u591a\u5e38\u89c1\u7684\u591a\u7ef4\u7ebf\u6027\u4ee3\u6570\u6570\u7ec4\u64cd\u4f5c\uff0c\u683c\u5f0f\u4e3a equation \u3002\u57fa\u672c\u601d\u60f3\u662f\u4e3a\u8f93\u5165 operands \u7684\u6bcf\u4e2a\u7ef4\u5ea6\u6807\u8bb0\u4e0b\u6807\uff0c\u5e76\u5b9a\u4e49\u54ea\u4e9b\u4e0b\u6807\u662f\u8f93\u51fa\u7684\u4e00\u90e8\u5206\u3002\u7136\u540e\u901a\u8fc7\u6cbf\u7740\u90a3\u4e9b\u4e0b\u6807\u4e0d\u5c5e\u4e8e\u8f93\u51fa\u7684\u7ef4\u5ea6\u5bf9 operands \u7684\u5143\u7d20\u6c42\u548c\u6765\u8ba1\u7b97\u8f93\u51fa\u3002\u4f8b\u5982\uff0c\u77e9\u9635\u4e58\u6cd5\u53ef\u4ee5\u4f7f\u7528 einsum \u8ba1\u7b97\uff0c\u5982 torch.einsum(\"ij,jk-&gt;ik\", A, B)\u3002\u8fd9\u91cc\uff0cj \u662f\u6c42\u548c\u4e0b\u6807\uff0c\u800c i \u548c k \u662f\u8f93\u51fa\u4e0b\u6807</p> Python<pre><code># trace\ntorch.einsum('ii', torch.randn(4, 4))\n\n# diagonal\ntorch.einsum('ii-&gt;i', torch.randn(4, 4))\n\n# outer product\nx = torch.randn(5)\ny = torch.randn(4)\ntorch.einsum('i,j-&gt;ij', x, y)\n\n# batch matrix multiplication\nAs = torch.randn(3, 2, 5)\nBs = torch.randn(3, 5, 4)\ntorch.einsum('bij,bjk-&gt;bik', As, Bs)\n\n\n\n# with sublist format and ellipsis\ntorch.einsum(As, [..., 0, 1], Bs, [..., 1, 2], [..., 0, 2])\n\n\n\n# batch permute\nA = torch.randn(2, 3, 4, 5)\ntorch.einsum('...ij-&gt;...ji', A).shape\n\n# equivalent to torch.nn.functional.bilinear\nA = torch.randn(3, 5, 4)\nl = torch.randn(2, 5)\nr = torch.randn(2, 4)\ntorch.einsum('bn,anm,bm-&gt;ba', l, A, r)\n</code></pre> <p>For example: x = torch.einsum('...ij, ijk -&gt; ...ik', x, self.__weight)</p> <p>\u53c2\u6570\u5206\u89e3\uff1a</p> <p>\u7b2c\u4e00\u4e2a\u5f20\u91cf x \u7684\u7ef4\u5ea6\u6a21\u5f0f\u662f ...ij</p> <p>... \u8868\u793a\u4efb\u610f\u6570\u91cf\u7684\u989d\u5916\u7ef4\u5ea6\uff08\u53ef\u80fd\u6ca1\u6709\uff09</p> <p>ij \u8868\u793a\u6700\u540e\u4e24\u4e2a\u7ef4\u5ea6</p> <p>\u7b2c\u4e8c\u4e2a\u5f20\u91cf self.__weight \u7684\u7ef4\u5ea6\u6a21\u5f0f\u662f ijk</p> <p>\u8f93\u51fa\u5f20\u91cf\u7684\u7ef4\u5ea6\u6a21\u5f0f\u662f ...ik</p> <p>\u8fd0\u7b97\u542b\u4e49\uff1a</p> <p>\u5bf9\u7b2c\u4e8c\u4e2a\u5f20\u91cfj\u7ef4\u5ea6\u4e2d\u7684\u6bcf\u4e2a\u503c\u548c\u7b2c\u4e00\u4e2a\u5f20\u91cf\u540e\u4e24\u4e2a\u7ef4\u5ea6\u6784\u6210\u7684\u77e9\u9635\u6cbfj\u65b9\u5411\u9010\u9879\u76f8\u4e58\u7136\u540e\u6c42\u548c\u3002</p> <p>\u7b49\u4ef7\u4e8e\u5148\u5e7f\u64ad\u518d\u4e58\u3002</p> <p>\\(C_{*ik} = A_{*ij}B_{ijk}\\)</p> <p>\\(C_{*ik} = \\sum_j A_{*ij}B_{ijk}\\)</p> <p>(i,j) -&gt; broadcast -&gt; (i,j,1)  -&gt; \u5728\u7b2c\u4e09\u7ef4\u5ea6\u590d\u5236k\u6b21 (i,j,k) -&gt; \\(\\odot\\)\uff08\u9010\u5143\u7d20\u76f8\u4e58\uff09(i,j,k) -&gt; \u5728j\u7ef4\u5ea6\u6c42\u548c -&gt; (i,k)</p> <p>A simple test:</p> Python<pre><code>A = torch.Tensor(range(1*2*3*4)).view(1, 2, 3 , 4)\nB = torch.Tensor(range(3*4*5)).view(3,4,5)\nC = torch.einsum('...ij,ijk-&gt;...ik',A , B)\nC_ = torch.zeros((1,2,3,5))\np , q , i , j , k = A.shape[0], A.shape[1], A.shape[2], A.shape[3], B.shape[2]\nfor p_ in range(p):\n    for q_ in range(q):\n        for i_ in range(i):\n            for j_ in range(j):\n                for k_ in range(k):\n                    C_[p_, q_, i_, k_] += A[p_, q_, i_, j_] * B[i_, j_, k_]\nassert C == C_\n</code></pre> <p>\u535a\u5ba2\u53c2\u8003</p> <p>einsum is all you need</p>"},{"location":"notes/Pytorch-Tutorial/addmm/","title":"addmm","text":""},{"location":"notes/Pytorch-Tutorial/addmm/#torchaddmm","title":"torch.addmm","text":"<p> \u7ea6 70 \u4e2a\u5b57  9 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\\(out = \\beta \\times mat + \\alpha \\times (mat1 @ mat2)\\)</p> <p>\u6362\u53e5\u8bdd\u8bf4\uff0c\u5c31\u662f\u9700\u8981\u4f20\u51655\u4e2a\u53c2\u6570\uff0cmat\u91cc\u7684\u6bcf\u4e2a\u5143\u7d20\u4e58\u4ee5beta\uff0cmat1\u548cmat2\u8fdb\u884c\u77e9\u9635\u4e58\u6cd5\uff08\u5de6\u884c\u4e58\u53f3\u5217\uff09\u540e\u518d\u4e58\u4ee5alpha\uff0c\u6700\u540e\u5c06\u8fd92\u4e2a\u7ed3\u679c\u52a0\u5728\u4e00\u8d77\u3002</p> <p>\\(\\beta,\\alpha\\)\u9ed8\u8ba4\u4e3a1</p> Python<pre><code>a = torch.addmm(input,mat1,mat2)\nb = input.addmm(mat1,mat2)\n\n# In-place\ninputs.addmm_(1,-2,mat1,mat2)\n# inputs =  1 * inputs - 2 * (mat1 @ mat2)\n</code></pre>"},{"location":"notes/Pytorch-Tutorial/where/","title":"where","text":""},{"location":"notes/Pytorch-Tutorial/where/#torchwhere","title":"torch.where","text":"<p> \u7ea6 304 \u4e2a\u5b57  39 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p>"},{"location":"notes/Pytorch-Tutorial/where/#1","title":"1. \u57fa\u672c\u8bed\u6cd5","text":"Python<pre><code>torch.where(condition, x, y)\n</code></pre> - <code>condition</code>\uff1a\u5e03\u5c14\u6761\u4ef6\uff08<code>torch.BoolTensor</code>\uff09\uff0c\u51b3\u5b9a\u9009\u62e9 <code>x</code> \u8fd8\u662f <code>y</code>\u3002 - <code>x</code>\uff1a\u5982\u679c <code>condition</code> \u4e3a <code>True</code>\uff0c\u5219\u9009\u62e9 <code>x</code> \u5bf9\u5e94\u4f4d\u7f6e\u7684\u5143\u7d20\u3002 - <code>y</code>\uff1a\u5982\u679c <code>condition</code> \u4e3a <code>False</code>\uff0c\u5219\u9009\u62e9 <code>y</code> \u5bf9\u5e94\u4f4d\u7f6e\u7684\u5143\u7d20\u3002 <p>\u8fd4\u56de\u503c\uff1a - \u4e00\u4e2a\u65b0\u7684\u5f20\u91cf\uff0c\u5176\u5143\u7d20\u6765\u81ea <code>x</code> \u6216 <code>y</code>\uff0c\u53d6\u51b3\u4e8e <code>condition</code>\u3002</p>"},{"location":"notes/Pytorch-Tutorial/where/#2","title":"2. \u4f7f\u7528\u793a\u4f8b","text":""},{"location":"notes/Pytorch-Tutorial/where/#1_1","title":"\u793a\u4f8b 1\uff1a\u57fa\u672c\u6761\u4ef6\u9009\u62e9","text":"Python<pre><code>import torch\n\na = torch.tensor([1, 2, 3, 4])\nb = torch.tensor([10, 20, 30, 40])\n\ncondition = torch.tensor([True, False, True, False])\n\nresult = torch.where(condition, a, b)\nprint(result)  # \u8f93\u51fa: tensor([ 1, 20,  3, 40])\n</code></pre> \u89e3\u91ca\uff1a - <code>condition</code> \u4e3a <code>True</code> \u7684\u4f4d\u7f6e\u9009\u62e9 <code>a</code> \u7684\u503c\uff08<code>1</code> \u548c <code>3</code>\uff09\u3002 - <code>condition</code> \u4e3a <code>False</code> \u7684\u4f4d\u7f6e\u9009\u62e9 <code>b</code> \u7684\u503c\uff08<code>20</code> \u548c <code>40</code>\uff09\u3002"},{"location":"notes/Pytorch-Tutorial/where/#2_1","title":"\u793a\u4f8b 2\uff1a\u57fa\u4e8e\u5f20\u91cf\u7684\u6761\u4ef6","text":"Python<pre><code>x = torch.tensor([[1, 2], [3, 4]])\ny = torch.tensor([[10, 20], [30, 40]])\n\ncondition = x &gt; 2  # \u8fd4\u56de\u5e03\u5c14\u5f20\u91cf\nprint(condition)\n# tensor([[False, False],\n#         [ True,  True]])\n\nresult = torch.where(condition, x, y)\nprint(result)\n# tensor([[10, 20],\n#         [ 3,  4]])\n</code></pre> \u89e3\u91ca\uff1a - <code>x &gt; 2</code> \u7684\u4f4d\u7f6e\u9009\u62e9 <code>x</code> \u7684\u503c\uff08<code>3</code> \u548c <code>4</code>\uff09\u3002 - \u5176\u4f59\u4f4d\u7f6e\u9009\u62e9 <code>y</code> \u7684\u503c\uff08<code>10</code> \u548c <code>20</code>\uff09\u3002"},{"location":"notes/Pytorch-Tutorial/where/#3-condition-npwherecondition","title":"\u793a\u4f8b 3\uff1a\u4ec5\u7528 <code>condition</code>\uff08\u7c7b\u4f3c <code>np.where(condition)</code>\uff09","text":"<p>\u5982\u679c\u53ea\u4f20\u5165 <code>condition</code>\uff0c<code>torch.where()</code> \u4f1a\u8fd4\u56de\u6ee1\u8db3\u6761\u4ef6\u7684 \u7d22\u5f15\uff08\u7c7b\u4f3c\u4e8e <code>np.where(condition)</code>\uff09\uff1a </p>Python<pre><code>a = torch.tensor([1, 2, 3, 4, 5])\nindices = torch.where(a &gt; 3)\nprint(indices)  # \u8f93\u51fa: (tensor([3, 4]),)\n</code></pre> \u89e3\u91ca\uff1a - \u8fd4\u56de <code>a &gt; 3</code> \u7684\u7d22\u5f15\u4f4d\u7f6e\uff08<code>3</code> \u548c <code>4</code>\uff09\u3002<p></p>"},{"location":"notes/Pytorch-Tutorial/where/#4","title":"\u793a\u4f8b 4\uff1a\u7528\u4e8e\u66ff\u6362\u7279\u5b9a\u503c","text":"Python<pre><code>x = torch.tensor([1, -2, 3, -4])\n# \u5c06\u8d1f\u6570\u66ff\u6362\u4e3a 0\nresult = torch.where(x &lt; 0, torch.tensor(0), x)\nprint(result)  # \u8f93\u51fa: tensor([1, 0, 3, 0])\n</code></pre> \u89e3\u91ca\uff1a - <code>x &lt; 0</code> \u7684\u4f4d\u7f6e\u66ff\u6362\u4e3a <code>0</code>\uff0c\u5426\u5219\u4fdd\u7559\u539f\u503c\u3002"},{"location":"notes/Pytorch-Tutorial/where/#3","title":"3. \u5b9e\u9645\u5e94\u7528\u573a\u666f","text":""},{"location":"notes/Pytorch-Tutorial/where/#1-triplet-loss","title":"(1) \u4e09\u5143\u7ec4\u635f\u5931\uff08Triplet Loss\uff09\u4e2d\u7684\u96be\u6837\u672c\u6316\u6398","text":"<p>\u5728 <code>TripletLoss</code> \u4e2d\uff0c\u53ef\u4ee5\u7528 <code>torch.where</code> \u66ff\u4ee3 <code>mask</code> \u64cd\u4f5c\uff1a </p>Python<pre><code># \u539f\u59cb\u4ee3\u7801\uff1a\ndist_ap = dist[i][mask[i]].max()\ndist_an = dist[i][mask[i] == 0].min()\n\n# \u7528 torch.where \u5b9e\u73b0\uff1a\ndist_ap = torch.where(mask[i], dist[i], -torch.inf).max()  # \u4ec5\u8ba1\u7b97\u6b63\u6837\u672c\ndist_an = torch.where(~mask[i], dist[i], torch.inf).min()  # \u4ec5\u8ba1\u7b97\u8d1f\u6837\u672c\n</code></pre><p></p>"},{"location":"notes/Pytorch-Tutorial/where/#2_2","title":"(2) \u68af\u5ea6\u88c1\u526a","text":"Python<pre><code>grad = torch.randn(5)\nclipped_grad = torch.where(grad &gt; 1.0, torch.tensor(1.0), grad)\n</code></pre>"},{"location":"notes/Pytorch-Tutorial/where/#3_1","title":"(3) \u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387","text":"Python<pre><code>lr = torch.where(epoch &lt; 10, 0.1, 0.01)  # \u524d 10 \u8f6e lr=0.1\uff0c\u4e4b\u540e lr=0.01\n</code></pre>"},{"location":"notes/Pytorch-Tutorial/where/#4_1","title":"4. \u6ce8\u610f\u4e8b\u9879","text":"<ol> <li><code>x</code> \u548c <code>y</code> \u7684\u5f62\u72b6\u5fc5\u987b\u76f8\u540c\uff08\u6216\u53ef\u5e7f\u64ad\uff09\u3002</li> <li><code>condition</code> \u5fc5\u987b\u662f <code>torch.BoolTensor</code>\uff08\u53ef\u4ee5\u7528 <code>&gt;</code>, <code>&lt;</code>, <code>==</code> \u7b49\u751f\u6210\uff09\u3002</li> <li><code>torch.where(condition)</code> \u8fd4\u56de\u7684\u662f\u7d22\u5f15\uff0c\u800c\u4e0d\u662f\u503c\u3002</li> </ol>"},{"location":"notes/Pytorch-Tutorial/where/#_1","title":"\u603b\u7ed3","text":"\u7528\u6cd5 \u8bf4\u660e <code>torch.where(cond, x, y)</code> \u7c7b\u4f3c <code>if-else</code>\uff0c\u9009\u62e9 <code>x</code> \u6216 <code>y</code> <code>torch.where(cond)</code> \u8fd4\u56de <code>cond</code> \u4e3a <code>True</code> \u7684\u7d22\u5f15 \u9002\u7528\u573a\u666f \u6761\u4ef6\u9009\u62e9\u3001\u63a9\u7801\u64cd\u4f5c\u3001\u52a8\u6001\u8c03\u6574\u53c2\u6570 <p><code>torch.where()</code> \u5728 PyTorch \u4e2d\u975e\u5e38\u7075\u6d3b\uff0c\u53ef\u4ee5\u7528\u4e8e \u6761\u4ef6\u8ba1\u7b97\u3001\u7d22\u5f15\u67e5\u627e\u3001\u52a8\u6001\u8c03\u6574\u5f20\u91cf\u503c \u7b49\u4efb\u52a1\u3002</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/","title":"\u6982\u8ff0","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#loss-function","title":"Loss Function","text":"<p> \u7ea6 3582 \u4e2a\u5b57  451 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 24 \u5206\u949f</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#positivebceloss","title":"PositiveBCELoss","text":"<p>PositiveBCELoss \u662f\u4e00\u79cd \u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\uff08Binary Cross-Entropy Loss, BCE Loss\uff09\u7684\u53d8\u4f53\uff0c\u4e13\u95e8\u7528\u4e8e \u4ec5\u8ba1\u7b97\u6b63\u6837\u672c\uff08Positive Samples\uff09\u7684\u635f\u5931\u3002 \u5b83\u7684\u6838\u5fc3\u601d\u60f3\u662f\uff1a\u53ea\u5173\u6ce8\u6b63\u7c7b\uff08target=1\uff09\u7684\u9884\u6d4b\u6982\u7387\uff0c\u5ffd\u7565\u8d1f\u7c7b\uff08target=0\uff09\u7684\u8d21\u732e\u3002</p> <p>\u9002\u7528\u573a\u666f:</p> <ul> <li> <p>\u5f53\u6570\u636e\u4e2d \u8d1f\u6837\u672c\u8fdc\u591a\u4e8e\u6b63\u6837\u672c\uff08\u7c7b\u522b\u4e0d\u5e73\u8861\uff09\u65f6\uff0c\u4f20\u7edf BCE Loss \u53ef\u80fd\u88ab\u8d1f\u6837\u672c\u4e3b\u5bfc\uff0c\u5bfc\u81f4\u6a21\u578b\u5bf9\u6b63\u6837\u672c\u5b66\u4e60\u4e0d\u8db3\u3002</p> </li> <li> <p>\u5e0c\u671b \u66f4\u805a\u7126\u6b63\u6837\u672c\u7684\u4f18\u5316\uff08\u5982\u533b\u5b66\u68c0\u6d4b\u4e2d\u7684\u7f55\u89c1\u75c5\u4f8b\u3001\u5f02\u5e38\u68c0\u6d4b\u7b49\uff09\u3002</p> </li> </ul> Python<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass PositiveBCELoss(nn.Module):\n    def __init__(self, class_weight=None):\n        super().__init__()\n        self.register_buffer(\"class_weight\", class_weight)\n\n    def forward(self, logit, target):\n        x = F.logsigmoid(logit) * target  # \u5173\u952e\u6b65\u9aa4\uff1a\u4ec5\u6b63\u6837\u672c\u53c2\u4e0e\u8ba1\u7b97\n        if self.class_weight is not None:\n            x = x * self.class_weight   # \u53ef\u9009\uff1a\u6b63\u6837\u672c\u7684\u7c7b\u522b\u6743\u91cd\n        loss = -(x.mean())              # \u53d6\u5e73\u5747\u5e76\u53d6\u8d1f\uff08\u6700\u5927\u5316\u5bf9\u6570\u6982\u7387 = \u6700\u5c0f\u5316\u635f\u5931\uff09\n        return loss\n</code></pre> <p>\u4ee3\u7801\u8bb2\u89e3\uff1a</p> <ul> <li>F.logsigmoid(logit)</li> </ul> <p>\u5bf9\u6a21\u578b\u7684\u539f\u59cb\u8f93\u51fa logit \u8ba1\u7b97\u5bf9\u6570 Sigmoid\uff08\u5373 log(\u03c3(logit))\uff09\uff0c\u7b49\u4ef7\u4e8e log(1 / (1 + exp(-logit)))\u3002</p> <p>\u8fd9\u8868\u793a \u9884\u6d4b\u6b63\u7c7b\u7684\u5bf9\u6570\u6982\u7387\uff08\u56e0\u4e3a \u03c3(logit) \u662f\u9884\u6d4b\u6b63\u7c7b\u7684\u6982\u7387\uff09\u3002</p> <p>\u5728\u4e8c\u5143\u5206\u7c7b\u95ee\u9898\u4e2d\uff0c\u03c3(logit)\uff08\u5373 Sigmoid \u51fd\u6570\uff09\u7684\u8f93\u51fa\u88ab\u89e3\u91ca\u4e3a \u9884\u6d4b\u6b63\u7c7b\u7684\u6982\u7387\uff0c\u8fd9\u662f\u7531\u903b\u8f91\u56de\u5f52\uff08Logistic Regression\uff09\u7684\u6570\u5b66\u539f\u7406\u51b3\u5b9a\u7684\u3002\u4e0b\u9762\u8be6\u7ec6\u89e3\u91ca\u4e3a\u4ec0\u4e48\uff1a</p> <p>Sigmoid \u51fd\u6570\u7684\u4f5c\u7528:Sigmoid \u51fd\u6570\u5b9a\u4e49\u4e3a\uff1a \\(\\sigma(x) = \\frac{1}{1+e^{-x}}\\) \u5b83\u5c06\u4efb\u610f\u5b9e\u6570x\uff08\u5373 logit\uff09\u6620\u5c04\u5230 (0,1) \u533a\u95f4\uff0c\u8f93\u51fa\u53ef\u4ee5\u76f4\u89c2\u7406\u89e3\u4e3a\u6982\u7387\u3002</p> <p>\u4ece Logit \u5230\u6982\u7387\u7684\u63a8\u5bfc \u5728\u4e8c\u5143\u5206\u7c7b\u4e2d\uff1a \u6a21\u578b\u7684\u539f\u59cb\u8f93\u51fa\u662f logit\uff08\u4e5f\u79f0\u4e3a\u201c\u5bf9\u6570\u51e0\u7387\u201d\uff09\uff0c\u8303\u56f4\u662f \\((-\\infty,+\\infty)\\)\u3002 \u901a\u8fc7 Sigmoid \u5c06 logit \u8f6c\u6362\u4e3a\u6982\u7387\uff1a \\(P(y=1\u2223x)=\u03c3(logit)\\) \u200b\u5982\u679c logit \u5f88\u5927\uff08\u5982 +\u221e\uff09\uff0cP(y=1)\u21921\u3002 \u5982\u679c logit \u5f88\u5c0f\uff08\u5982 -\u221e\uff09, P(y=1)\u21920\u3002</p> <p>\u4e3a\u4ec0\u4e48\u662f\u201c\u6b63\u7c7b\u201d\u7684\u6982\u7387\uff1f \u5bf9\u6570\u51e0\u7387\u7684\u89e3\u91ca\uff1a logit \u7684\u672c\u8d28\u662f \u6b63\u7c7b\u6982\u7387\u7684\u5bf9\u6570\u51e0\u7387\uff08log-odds\uff09\uff1a \\(logit=log(\\frac{P(y=1)}{P(y=0)})\\) \u901a\u8fc7 Sigmoid \u7684\u53cd\u5411\u63a8\u5bfc\uff1a \\(\\sigma(logit)=\\frac{P(y=1)}{P(y=0)+P(y=1)}=P(y=1)\\) \u56e0\u6b64\uff0c\u03c3(logit) \u76f4\u63a5\u8868\u793a\u6b63\u7c7b\u7684\u6982\u7387\u3002</p> <ul> <li>* target</li> </ul> <p>\u901a\u8fc7 target\uff080 \u6216 1 \u7684\u63a9\u7801\uff09\u8fc7\u6ee4\uff0c\u4ec5\u4fdd\u7559\u6b63\u6837\u672c\u7684\u635f\u5931\uff08target=1 \u7684\u4f4d\u7f6e\u4fdd\u7559\u503c\uff0ctarget=0 \u7684\u4f4d\u7f6e\u5f52\u96f6\uff09\u3002</p> <ul> <li>class_weight\uff08\u53ef\u9009\uff09</li> </ul> <p>\u5982\u679c\u63d0\u4f9b class_weight\uff0c\u4f1a\u5bf9\u6b63\u6837\u672c\u7684\u635f\u5931\u52a0\u6743\uff08\u5e38\u7528\u4e8e\u8fdb\u4e00\u6b65\u5e73\u8861\u7c7b\u522b\uff09\u3002</p> <ul> <li>-(x.mean())</li> </ul> <p>\u5bf9\u5269\u4f59\u7684\u6b63\u6837\u672c\u635f\u5931\u53d6\u5e73\u5747\uff0c\u5e76\u53d6\u8d1f\u53f7\uff08\u56e0\u4e3a log(p) \u662f\u8d1f\u6570\uff0c\u53d6\u8d1f\u540e\u5f97\u5230\u6b63\u635f\u5931\u503c\uff09\u3002</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#l1-loss-mean-absolute-error-mae","title":"L1 Loss (Mean Absolute Error - MAE)","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_1","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = \\frac{1}{n}\\sum_{i=1}^{n} |x_i - y_i| $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u503c\uff08\u6a21\u578b\u8f93\u51fa\uff09 - \\( y \\) \u662f\u76ee\u6807\u503c\uff08\u771f\u5b9e\u6807\u7b7e\uff09 - \\( n \\) \u662f\u6837\u672c\u6570\u91cf</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_2","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u56de\u5f52\u4efb\u52a1\uff1a\u5f53\u9700\u8981\u9884\u6d4b\u8fde\u7eed\u503c\u4e14\u5bf9\u5f02\u5e38\u503c\u4e0d\u654f\u611f\u65f6</li> <li>\u9c81\u68d2\u6027\u8981\u6c42\u9ad8\uff1a\u76f8\u6bd4L2 Loss\u66f4\u4e0d\u6613\u53d7\u5f02\u5e38\u503c\u5f71\u54cd</li> <li>\u7a00\u758f\u68af\u5ea6\u9700\u6c42\uff1a\u5728\u9700\u8981\u68af\u5ea6\u5927\u5c0f\u6052\u5b9a\u7684\u573a\u666f</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_3","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>\u5728PyTorch\u4e2d\u901a\u8fc7<code>torch.nn.L1Loss</code>\u5b9e\u73b0\uff0c\u4e3b\u8981\u53c2\u6570\uff1a</p> <p></p>Python<pre><code>torch.nn.L1Loss(\n    size_average=None,  # \u5df2\u5e9f\u5f03\uff08\u9ed8\u8ba4\u53d6mean\uff09\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean'    # \u53ef\u9009\uff1a'none'|'mean'|'sum'\n)\n\"\"\"\nreduction:\n\n'none'\uff1a\u8fd4\u56de\u9010\u5143\u7d20\u635f\u5931 The same shape as Input\n\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c  (1,)\n\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c  (1,)\n\"\"\"\n</code></pre> L1 Loss\u5b98\u65b9\u6587\u6863<p></p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#negative-log-likelihood-loss-nll-loss","title":"Negative Log Likelihood Loss (NLL Loss)","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_4","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = -\\frac{1}{n}\\sum_{i=1}^{n} x_{i,y_i} $$ \u6216\u66f4\u4e00\u822c\u7684\u5f62\u5f0f\uff1a $$ \\mathcal{L}(x, y) = -\\sum_{i=1}^{n} \\log(p_{y_i}) $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u7684\u5bf9\u6570\u6982\u7387\uff08log-probabilities\uff09\uff0c\u5f62\u72b6\u4e3a (N, C) - \\( y \\) \u662f\u76ee\u6807\u7c7b\u522b\u7d22\u5f15\uff0c\u5f62\u72b6\u4e3a (N) - \\( p_{y_i} \\) \u662f\u5bf9\u5e94\u771f\u5b9e\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387 - \\( n \\) \u662f batch size - \\( C \\) \u662f\u7c7b\u522b\u6570</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_5","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u591a\u5206\u7c7b\u95ee\u9898\uff1a\u5e38\u4e0eLogSoftmax\u914d\u5408\u4f7f\u7528</li> <li>\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u6982\u7387\u5206\u5e03\uff1a\u8981\u6c42\u8f93\u5165\u5df2\u7ecf\u662f\u5bf9\u6570\u6982\u7387</li> <li>\u8bed\u8a00\u6a21\u578b/\u6587\u672c\u5206\u7c7b\uff1a\u5728NLP\u4efb\u52a1\u4e2d\u5e7f\u6cdb\u4f7f\u7528</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_6","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.NLLLoss</code></p> Python<pre><code>torch.nn.NLLLoss(\n    weight=None,        # \u5404\u7c7b\u522b\u7684\u6743\u91cd\uff081D Tensor\uff09\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    ignore_index=-100,  # \u5ffd\u7565\u7684\u76ee\u6807\u7c7b\u522b\u7d22\u5f15\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean'    # 'none'|'mean'|'sum'\n)\n\"\"\"\nignore_index\uff1a\u6307\u5b9a\u5ffd\u7565\u7684\u7c7b\u522b\uff08\u4e0d\u8d21\u732e\u68af\u5ea6\uff09\n\nweight\uff1a\u7c7b\u522b\u4e0d\u5e73\u8861\u65f6\u53ef\u901a\u8fc7\u6b64\u53c2\u6570\u8c03\u6574\u6743\u91cd\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8f93\u5165\u9700\u8981\u5148\u7ecf\u8fc7LogSoftmax</li> <li>\u4e0eCrossEntropyLoss\u7684\u5173\u7cfb\uff1aCrossEntropy = LogSoftmax + NLLLoss</li> <li>\u6700\u5c0f\u5316\u8d1f\u5bf9\u6570\u4f3c\u7136\u7b49\u4ef7\u4e8e\u6700\u5927\u5316\u4f3c\u7136\u51fd\u6570</li> </ul> <p>\u793a\u4f8b\uff1a</p> Python<pre><code>m = nn.LogSoftmax(dim=1)\nloss = nn.NLLLoss()\ninput = m(torch.randn(3, 5))\ntarget = torch.tensor([1, 0, 4])\noutput = loss(input, target)\n</code></pre> <p>NLLLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#poisson-negative-log-likelihood-loss-poissonnllloss","title":"Poisson Negative Log Likelihood Loss (PoissonNLLLoss)","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_7","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"\\[ \\mathcal{L}(x, y) = \\frac{1}{n}\\sum_{i=1}^{n} (x_i - y_i \\log(x_i)) $$ \u5f53\u8bbe\u7f6e `log_input=False`\uff08\u9ed8\u8ba4\uff09\u65f6\u8ba1\u7b97\u4e0a\u5f0f\u3002   \u5f53 `log_input=True` \u65f6\uff08\u8f93\u5165\u5df2\u53d6\u5bf9\u6570\uff09\uff1a $$ \\mathcal{L}(x, y) = \\frac{1}{n}\\sum_{i=1}^{n} (\\exp(x_i) - y_i x_i) \\]"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_8","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u8ba1\u6570\u6570\u636e\u5efa\u6a21\uff1a\u4e8b\u4ef6\u53d1\u751f\u6b21\u6570\u7684\u9884\u6d4b\uff08\u6cca\u677e\u5206\u5e03\uff09</li> <li>\u975e\u8d1f\u8fde\u7eed\u503c\u9884\u6d4b\uff1a\u5982\u6d41\u91cf\u9884\u6d4b\u3001\u75be\u75c5\u53d1\u75c5\u7387</li> <li>\u8f93\u5165\u8f93\u51fa\u5448\u6cca\u677e\u5206\u5e03\u5173\u7cfb\uff1a\u65b9\u5dee\u7b49\u4e8e\u5747\u503c\u7684\u60c5\u51b5</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_9","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.PoissonNLLLoss</code></p> Python<pre><code>torch.nn.PoissonNLLLoss(\n    log_input=True,      # \u8f93\u5165\u662f\u5426\u4e3a\u5bf9\u6570\u5f62\u5f0f\uff08\u9ed8\u8ba4True\uff09\n    full=False,          # \u662f\u5426\u8ba1\u7b97\u5b8c\u6574\u635f\u5931\uff08\u5e26\u65af\u7279\u6797\u8fd1\u4f3c\u9879\uff09\n    size_average=None,   # \u5df2\u5e9f\u5f03\n    eps=1e-8,            # \u9632\u6b62log(0)\u7684\u5c0f\u6570\u503c\n    reduce=None,         # \u5df2\u5e9f\u5f03\n    reduction='mean'     # 'none'|'mean'|'sum'\n)\n\"\"\"\nlog_input\uff1a\n\nTrue\uff1a\u8f93\u5165\u9700\u5148\u53d6\u5bf9\u6570\uff08\u66f4\u6570\u503c\u7a33\u5b9a\uff09\n\nFalse\uff1a\u76f4\u63a5\u4f7f\u7528\u539f\u59cb\u8f93\u5165\n\nfull\uff1a\n\nTrue\uff1a\u589e\u52a0\u65af\u7279\u6797\u8fd1\u4f3c\u9879 y*log(y) - y + 0.5*log(2\u03c0y)\n\nFalse\uff08\u9ed8\u8ba4\uff09\uff1a\u4ec5\u8ba1\u7b97\u57fa\u672c\u9879\n\neps\uff1a\u9632\u6b62\u6570\u503c\u4e0d\u7a33\u5b9a\uff08\u5f53 log_input=False \u4e14\u8f93\u5165\u63a5\u8fd10\u65f6\uff09\n\"\"\"\n</code></pre> <p>PoissonNLLLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#gaussian-negative-log-likelihood-loss-gaussiannllloss","title":"Gaussian Negative Log Likelihood Loss (GaussianNLLLoss)","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_10","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y, \\sigma) = \\frac{1}{n}\\sum_{i=1}^{n} \\left( \\frac{(x_i - y_i)<sup>2}{2\\sigma_i</sup>2} + \\log(\\sigma_i) \\right) $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u503c\uff08\u6a21\u578b\u8f93\u51fa\uff09 - \\( y \\) \u662f\u76ee\u6807\u503c\uff08\u771f\u5b9e\u6807\u7b7e\uff09 - \\( \\sigma \\) \u662f\u9884\u6d4b\u7684\u6807\u51c6\u5dee\uff08\u4e0d\u786e\u5b9a\u6027\uff09 - \\( n \\) \u662f\u6837\u672c\u6570\u91cf</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_11","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\uff1a\u9700\u8981\u540c\u65f6\u9884\u6d4b\u503c\u548c\u4e0d\u786e\u5b9a\u6027</li> <li>\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\uff1a\u8f93\u51fa\u6982\u7387\u5206\u5e03\u800c\u975e\u5355\u70b9\u9884\u6d4b</li> <li>\u5f02\u65b9\u5dee\u56de\u5f52\uff1a\u65b9\u5dee\u968f\u8f93\u5165\u53d8\u5316\u7684\u56de\u5f52\u4efb\u52a1</li> <li>\u5b89\u5168\u5173\u952e\u5e94\u7528\uff1a\u5982\u81ea\u52a8\u9a7e\u9a76\u3001\u533b\u7597\u8bca\u65ad\u7b49\u9700\u8981\u77e5\u9053\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u7684\u573a\u666f</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_12","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.GaussianNLLLoss</code></p> Python<pre><code>torch.nn.GaussianNLLLoss(\n    full=False,          # \u662f\u5426\u8ba1\u7b97\u5b8c\u6574\u635f\u5931\uff08\u5e26\u5e38\u6570\u9879\uff09\n    eps=1e-6,            # \u9632\u6b62\u65b9\u5dee\u4e3a\u96f6\u7684\u5c0f\u6570\u503c\n    reduction='mean'     # 'none'|'mean'|'sum'\n)\n\"\"\"\nfull\uff1a\nTrue\uff1a\u589e\u52a0\u5e38\u6570\u9879 0.5*log(2\u03c0)\nFalse\uff08\u9ed8\u8ba4\uff09\uff1a\u4e0d\u5305\u542b\u5e38\u6570\u9879\n\neps\uff1a\u9632\u6b62\u6570\u503c\u4e0d\u7a33\u5b9a\uff08\u5f53\u65b9\u5dee\u63a5\u8fd10\u65f6\uff09\n\"\"\"\n</code></pre> <p>GaussianNLLLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#kullback-leibler-divergence-loss-kldivloss","title":"Kullback-Leibler Divergence Loss (KLDivLoss)","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_13","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = \\frac{1}{n}\\sum_{i=1}^{n} \\sum_{j=1}^{C} y_{i,j} \\left( \\log(y_{i,j}) - x_{i,j} \\right) $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u7684\u5bf9\u6570\u6982\u7387\uff08log-probabilities\uff09\uff0c\u5f62\u72b6\u4e3a (N, C) - \\( y \\) \u662f\u76ee\u6807\u6982\u7387\u5206\u5e03\uff0c\u5f62\u72b6\u4e3a (N, C) - \\( n \\) \u662f batch size - \\( C \\) \u662f\u7c7b\u522b\u6570</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_14","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u5206\u5e03\u5339\u914d\uff1a\u8861\u91cf\u4e24\u4e2a\u6982\u7387\u5206\u5e03\u7684\u5dee\u5f02</li> <li>\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\uff1a\u4f5c\u4e3a\u6b63\u5219\u5316\u9879</li> <li>\u77e5\u8bc6\u84b8\u998f\uff1a\u8ba9\u5b66\u751f\u6a21\u578b\u5b66\u4e60\u6559\u5e08\u6a21\u578b\u7684\u6982\u7387\u5206\u5e03</li> <li>\u751f\u6210\u6a21\u578b\uff1a\u8bad\u7ec3\u6a21\u578b\u751f\u6210\u63a5\u8fd1\u76ee\u6807\u5206\u5e03\u7684\u6570\u636e</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_15","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.KLDivLoss</code></p> Python<pre><code>torch.nn.KLDivLoss(\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean',   # 'none'|'batchmean'|'mean'|'sum'\n    log_target=False    # \u76ee\u6807\u662f\u5426\u4e3a\u5bf9\u6570\u6982\u7387\n)\n\"\"\"\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u5143\u7d20\u635f\u5931\n'batchmean'\uff1a\u8fd4\u56debatch\u7684\u635f\u5931\u548c\uff08\u63a8\u8350\u7528\u4e8eKL\u6563\u5ea6\uff09\n'mean'\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\nlog_target\uff1a\nTrue\uff1a\u76ee\u6807\u5df2\u7ecf\u662f\u5bf9\u6570\u6982\u7387\nFalse\uff08\u9ed8\u8ba4\uff09\uff1a\u76ee\u6807\u662f\u666e\u901a\u6982\u7387\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - \u8f93\u5165x\u9700\u8981\u662f\u5bf9\u6570\u6982\u7387\uff08log-probabilities\uff09 - \u76ee\u6807y\u9700\u8981\u662f\u6982\u7387\u5206\u5e03\uff08sum to 1\uff09 - KL\u6563\u5ea6\u662f\u975e\u5bf9\u79f0\u7684\uff1aKL(P||Q) \u2260 KL(Q||P)</p> <p>\u793a\u4f8b\uff1a</p> Python<pre><code># \u8f93\u5165\u9700\u8981\u662f\u5bf9\u6570\u6982\u7387\ninput = F.log_softmax(torch.randn(3, 5), dim=1)\n# \u76ee\u6807\u9700\u8981\u662f\u6982\u7387\u5206\u5e03\ntarget = F.softmax(torch.randn(3, 5), dim=1)\nloss = nn.KLDivLoss(reduction='batchmean')\noutput = loss(input, target)\n</code></pre> <p>KLDivLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#mean-squared-error-loss-mseloss","title":"Mean Squared Error Loss (MSELoss)","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_16","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = \\frac{1}{n}\\sum_{i=1}^{n} (x_i - y_i)^2 $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u503c\uff08\u6a21\u578b\u8f93\u51fa\uff09 - \\( y \\) \u662f\u76ee\u6807\u503c\uff08\u771f\u5b9e\u6807\u7b7e\uff09 - \\( n \\) \u662f\u6837\u672c\u6570\u91cf</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_17","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u56de\u5f52\u4efb\u52a1\uff1a\u9884\u6d4b\u8fde\u7eed\u503c\u7684\u6807\u51c6\u635f\u5931\u51fd\u6570</li> <li>\u56fe\u50cf\u91cd\u5efa\uff1a\u5982\u81ea\u7f16\u7801\u5668\u3001\u56fe\u50cf\u53bb\u566a\u7b49</li> <li>\u5e73\u6ed1\u6570\u636e\uff1a\u5f53\u6570\u636e\u566a\u58f0\u8f83\u5c0f\u4e14\u9700\u8981\u7cbe\u786e\u9884\u6d4b\u65f6</li> <li>\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\uff1a\u63d0\u4f9b\u5e73\u6ed1\u7684\u68af\u5ea6\u4fe1\u53f7</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_18","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.MSELoss</code></p> Python<pre><code>torch.nn.MSELoss(\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean'    # 'none'|'mean'|'sum'\n)\n\"\"\"\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u5143\u7d20\u635f\u5931 The same shape as Input\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c (1,)\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c (1,)\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - MSE\u5bf9\u5f02\u5e38\u503c\u654f\u611f\uff0c\u56e0\u4e3a\u8bef\u5dee\u88ab\u5e73\u65b9 - \u76f8\u6bd4L1 Loss\uff0cMSE\u5728\u63a5\u8fd1\u6700\u4f18\u70b9\u65f6\u68af\u5ea6\u66f4\u5c0f\uff0c\u6709\u52a9\u4e8e\u7cbe\u7ec6\u8c03\u6574 - \u6700\u5c0f\u5316MSE\u7b49\u4ef7\u4e8e\u6700\u5927\u5316\u9ad8\u65af\u5206\u5e03\u4e0b\u7684\u4f3c\u7136\u51fd\u6570</p> <p>MSELoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#binary-cross-entropy-loss-bceloss","title":"Binary Cross Entropy Loss (BCELoss)","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_19","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = -\\frac{1}{n}\\sum_{i=1}^{n} \\left[ y_i \\log(x_i) + (1 - y_i) \\log(1 - x_i) \\right] $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u6982\u7387\uff0c\u8303\u56f4\u5728 [0, 1] - \\( y \\) \u662f\u76ee\u6807\u503c\uff080 \u6216 1\uff09 - \\( n \\) \u662f\u6837\u672c\u6570\u91cf</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_20","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1\uff1a\u5224\u65ad\u6837\u672c\u5c5e\u4e8e\u4e24\u4e2a\u7c7b\u522b\u4e2d\u7684\u54ea\u4e00\u4e2a</li> <li>\u6982\u7387\u9884\u6d4b\uff1a\u8f93\u51fa\u6837\u672c\u5c5e\u4e8e\u6b63\u7c7b\u7684\u6982\u7387</li> <li>\u591a\u6807\u7b7e\u5206\u7c7b\uff1a\u6bcf\u4e2a\u6837\u672c\u53ef\u4ee5\u5c5e\u4e8e\u591a\u4e2a\u7c7b\u522b</li> <li>\u533b\u5b66\u8bca\u65ad\uff1a\u5982\u75be\u75c5\u68c0\u6d4b\u3001\u98ce\u9669\u9884\u6d4b\u7b49</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_21","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.BCELoss</code></p> Python<pre><code>torch.nn.BCELoss(\n    weight=None,        # \u5404\u6837\u672c\u7684\u6743\u91cd\uff081D Tensor\uff09\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean'    # 'none'|'mean'|'sum'\n)\n\"\"\"\nweight\uff1a\u53ef\u7528\u4e8e\u6837\u672c\u4e0d\u5e73\u8861\u65f6\u7684\u52a0\u6743\n\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u5143\u7d20\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - \u8f93\u5165\u9700\u8981\u7ecf\u8fc7Sigmoid\u51fd\u6570\uff0c\u786e\u4fdd\u5728[0,1]\u8303\u56f4\u5185 - \u5982\u679c\u8f93\u5165\u63a5\u8fd10\u62161\uff0c\u53ef\u80fd\u5bfc\u81f4\u6570\u503c\u4e0d\u7a33\u5b9a - \u5bf9\u4e8e\u6570\u503c\u7a33\u5b9a\u6027\u66f4\u597d\u7684\u5b9e\u73b0\uff0c\u63a8\u8350\u4f7f\u7528BCEWithLogitsLoss</p> <p>\u793a\u4f8b\uff1a</p> Python<pre><code>m = nn.Sigmoid()\nloss = nn.BCELoss()\ninput = m(torch.randn(3))\ntarget = torch.empty(3).random_(2)\noutput = loss(input, target)\n</code></pre> <p>BCELoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#binary-cross-entropy-with-logits-loss-bcewithlogitsloss","title":"Binary Cross Entropy with Logits Loss (BCEWithLogitsLoss)","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_22","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = -\\frac{1}{n}\\sum_{i=1}^{n} \\left[ y_i \\log(\\sigma(x_i)) + (1 - y_i) \\log(1 - \\sigma(x_i)) \\right] $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u7684\u539f\u59cb\u8f93\u51fa\uff08logits\uff09 - \\( y \\) \u662f\u76ee\u6807\u503c\uff080 \u6216 1\uff09 - \\( \\sigma \\) \u662fSigmoid\u51fd\u6570\uff1a\\(\\sigma(x) = \\frac{1}{1+e^{-x}}\\) - \\( n \\) \u662f\u6837\u672c\u6570\u91cf</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_23","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1\uff1a\u4e0eBCELoss\u76f8\u540c\u7684\u5e94\u7528\u573a\u666f</li> <li>\u6570\u503c\u7a33\u5b9a\u6027\u8981\u6c42\u9ad8\uff1a\u76f8\u6bd4BCELoss + Sigmoid\u66f4\u7a33\u5b9a</li> <li>\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff1a\u907f\u514d\u68af\u5ea6\u6d88\u5931/\u7206\u70b8\u95ee\u9898</li> <li>\u5927\u89c4\u6a21\u8bad\u7ec3\uff1a\u66f4\u9002\u5408\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8bad\u7ec3</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_24","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.BCEWithLogitsLoss</code></p> Python<pre><code>torch.nn.BCEWithLogitsLoss(\n    weight=None,        # \u5404\u6837\u672c\u7684\u6743\u91cd\uff081D Tensor\uff09\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean',   # 'none'|'mean'|'sum'\n    pos_weight=None     # \u6b63\u6837\u672c\u7684\u6743\u91cd\uff08\u7528\u4e8e\u7c7b\u522b\u4e0d\u5e73\u8861\uff09\n)\n\"\"\"\nweight\uff1a\u6837\u672c\u7ea7\u522b\u7684\u6743\u91cd\n\npos_weight\uff1a\u6b63\u6837\u672c\u7684\u6743\u91cd\uff0c\u53ef\u7528\u4e8e\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\n\u5982\u679c\u8bbe\u7f6e\uff0c\u6b63\u6837\u672c\u7684\u635f\u5931\u5c06\u4e58\u4ee5\u8be5\u503c\n\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u5143\u7d20\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - \u7ed3\u5408\u4e86Sigmoid\u548cBCELoss\uff0c\u6570\u503c\u66f4\u7a33\u5b9a - \u4f7f\u7528log-sum-exp\u6280\u5de7\u907f\u514d\u6570\u503c\u6ea2\u51fa - \u63a8\u8350\u4f7f\u7528BCEWithLogitsLoss\u800c\u975e\u5355\u72ec\u7684Sigmoid + BCELoss - pos_weight\u53c2\u6570\u5bf9\u4e8e\u6b63\u8d1f\u6837\u672c\u4e0d\u5e73\u8861\u7684\u60c5\u51b5\u5f88\u6709\u7528</p> <p>BCEWithLogitsLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#hinge-embedding-loss","title":"Hinge Embedding Loss","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_25","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = \\frac{1}{n}\\sum_{i=1}^{n} \\begin{cases} x_i, &amp; \\text{if } y_i = 1 \\ \\max(0, \\text{margin} - x_i), &amp; \\text{if } y_i = -1 \\end{cases} $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u503c\uff08\u901a\u5e38\u662f\u76f8\u4f3c\u5ea6\u5f97\u5206\uff09 - \\( y \\) \u662f\u76ee\u6807\u503c\uff081 \u6216 -1\uff09 - \\( n \\) \u662f\u6837\u672c\u6570\u91cf - margin \u662f\u8fb9\u754c\u53c2\u6570\uff08\u9ed8\u8ba4\u4e3a1.0\uff09</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_26","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u5ea6\u91cf\u5b66\u4e60\uff1a\u5b66\u4e60\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u76f8\u4f3c\u6027</li> <li>\u4eba\u8138\u8bc6\u522b/\u9a8c\u8bc1\uff1a\u5224\u65ad\u4e24\u5f20\u4eba\u8138\u662f\u5426\u4e3a\u540c\u4e00\u4e2a\u4eba</li> <li>\u76f8\u4f3c\u6027\u5b66\u4e60\uff1a\u5b66\u4e60\u6837\u672c\u95f4\u7684\u76f8\u4f3c\u5ea6\u5ea6\u91cf</li> <li>\u534a\u76d1\u7763\u5b66\u4e60\uff1a\u5229\u7528\u76f8\u4f3c\u6027\u4fe1\u606f\u8fdb\u884c\u5b66\u4e60</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_27","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.HingeEmbeddingLoss</code></p> Python<pre><code>torch.nn.HingeEmbeddingLoss(\n    margin=1.0,         # \u8fb9\u754c\u53c2\u6570\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean'    # 'none'|'mean'|'sum'\n)\n\"\"\"\nmargin\uff1a\n\u5f53y=-1\u65f6\uff0c\u5982\u679cx &lt; margin\uff0c\u5219\u8ba1\u7b97margin - x\n\u5426\u5219\u635f\u5931\u4e3a0\n\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u5143\u7d20\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - \u76ee\u6807\u6807\u7b7e\u5e94\u4e3a1\uff08\u76f8\u4f3c\uff09\u6216-1\uff08\u4e0d\u76f8\u4f3c\uff09 - \u5bf9\u4e8e\u76f8\u4f3c\u6837\u672c\uff08y=1\uff09\uff0c\u76f4\u63a5\u4f7f\u7528\u9884\u6d4b\u503c\u4f5c\u4e3a\u635f\u5931 - \u5bf9\u4e8e\u4e0d\u76f8\u4f3c\u6837\u672c\uff08y=-1\uff09\uff0c\u53ea\u6709\u5f53\u9884\u6d4b\u503c\u5c0f\u4e8emargin\u65f6\u624d\u6709\u635f\u5931</p> <p>HingeEmbeddingLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#multi-label-margin-loss","title":"Multi Label Margin Loss","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_28","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = \\frac{1}{n}\\sum_{i=1}^{n} \\sum_{j} \\max(0, \\text{margin} - (x_{i,y_i} - x_{i,j})) $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u503c\uff08\u901a\u5e38\u662f\u76f8\u4f3c\u5ea6\u5f97\u5206\uff09 - \\( y \\) \u662f\u76ee\u6807\u503c\uff08\u5305\u542b\u6b63\u6837\u672c\u7c7b\u522b\u7684\u7d22\u5f15\uff09 - \\( n \\) \u662f\u6837\u672c\u6570\u91cf - \\( j \\) \u904d\u5386\u6240\u6709\u4e0d\u5c5e\u4e8e \\( y_i \\) \u7684\u7c7b\u522b - margin \u662f\u8fb9\u754c\u53c2\u6570\uff08\u9ed8\u8ba4\u4e3a1.0\uff09</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_29","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u591a\u6807\u7b7e\u5206\u7c7b\uff1a\u6bcf\u4e2a\u6837\u672c\u53ef\u4ee5\u5c5e\u4e8e\u591a\u4e2a\u7c7b\u522b</li> <li>\u56fe\u50cf\u6807\u6ce8\uff1a\u4e00\u5f20\u56fe\u50cf\u53ef\u4ee5\u6709\u591a\u4e2a\u6807\u7b7e</li> <li>\u6587\u672c\u5206\u7c7b\uff1a\u4e00\u7bc7\u6587\u7ae0\u53ef\u4ee5\u5c5e\u4e8e\u591a\u4e2a\u4e3b\u9898</li> <li>\u63a8\u8350\u7cfb\u7edf\uff1a\u4e00\u4e2a\u7528\u6237\u53ef\u80fd\u559c\u6b22\u591a\u4e2a\u7c7b\u522b</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_30","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.MultiLabelMarginLoss</code></p> Python<pre><code>torch.nn.MultiLabelMarginLoss(\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean'    # 'none'|'mean'|'sum'\n)\n\"\"\"\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u6837\u672c\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - \u76ee\u6807\u6807\u7b7e\u5e94\u5305\u542b\u6240\u6709\u6b63\u6837\u672c\u7c7b\u522b\u7684\u7d22\u5f15 - \u5bf9\u4e8e\u6bcf\u4e2a\u6837\u672c\uff0c\u635f\u5931\u8ba1\u7b97\u6b63\u7c7b\u522b\u4e0e\u6240\u6709\u8d1f\u7c7b\u522b\u4e4b\u95f4\u7684margin - \u76ee\u6807\u6807\u7b7e\u7684\u7ef4\u5ea6\u5e94\u4e3a (N, C)\uff0c\u5176\u4e2dC\u662f\u7c7b\u522b\u6570 - \u76ee\u6807\u4e2d\uff0c\u6b63\u6837\u672c\u4f4d\u7f6e\u7684\u503c\u5e94\u4e3a1\uff0c\u8d1f\u6837\u672c\u4f4d\u7f6e\u7684\u503c\u5e94\u4e3a0</p> <p>\u793a\u4f8b\uff1a</p> Python<pre><code>loss = nn.MultiLabelMarginLoss()\ninput = torch.randn(3, 5)\n# \u76ee\u6807\uff1a\u7b2c\u4e00\u4e2a\u6837\u672c\u5c5e\u4e8e\u7c7b\u522b0\u548c2\uff0c\u7b2c\u4e8c\u4e2a\u6837\u672c\u5c5e\u4e8e\u7c7b\u522b1\u548c3\uff0c\u7b2c\u4e09\u4e2a\u6837\u672c\u5c5e\u4e8e\u7c7b\u522b0\u548c4\ntarget = torch.tensor([[1, 0, 1, 0, 0], [0, 1, 0, 1, 0], [1, 0, 0, 0, 1]])\noutput = loss(input, target)\n</code></pre> <p>MultiLabelMarginLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#smooth-l1-loss","title":"Smooth L1 Loss","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_31","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = \\frac{1}{n}\\sum_{i=1}^{n} \\begin{cases} 0.5 (x_i - y_i)^2 / \\beta, &amp; \\text{if } |x_i - y_i| &lt; \\beta \\ |x_i - y_i| - 0.5 \\beta, &amp; \\text{otherwise} \\end{cases} $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u503c\uff08\u6a21\u578b\u8f93\u51fa\uff09 - \\( y \\) \u662f\u76ee\u6807\u503c\uff08\u771f\u5b9e\u6807\u7b7e\uff09 - \\( n \\) \u662f\u6837\u672c\u6570\u91cf - \\( \\beta \\) \u662f\u5e73\u6ed1\u53c2\u6570\uff08\u9ed8\u8ba4\u4e3a1.0\uff09</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_32","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u76ee\u6807\u68c0\u6d4b\uff1a\u5982Faster R-CNN\u4e2d\u7684\u8fb9\u754c\u6846\u56de\u5f52</li> <li>\u9c81\u68d2\u56de\u5f52\uff1a\u5bf9\u5f02\u5e38\u503c\u4e0d\u654f\u611f\u7684\u56de\u5f52\u4efb\u52a1</li> <li>\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\uff1a\u4f5c\u4e3aL1\u548cL2\u635f\u5931\u7684\u6298\u4e2d\u65b9\u6848</li> <li>\u8ba1\u7b97\u673a\u89c6\u89c9\uff1a\u9700\u8981\u65e2\u5e73\u6ed1\u53c8\u9c81\u68d2\u7684\u635f\u5931\u51fd\u6570</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_33","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.SmoothL1Loss</code></p> Python<pre><code>torch.nn.SmoothL1Loss(\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean',   # 'none'|'mean'|'sum'\n    beta=1.0            # \u5e73\u6ed1\u53c2\u6570\n)\n\"\"\"\nbeta\uff1a\n\u6307\u5b9a\u4ece\u4e8c\u6b21\u635f\u5931\u8f6c\u4e3a\u7ebf\u6027\u635f\u5931\u7684\u9608\u503c\u70b9\n\u9ed8\u8ba4\u503c\u4e3a1.0\n\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u5143\u7d20\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - \u5f53\u8bef\u5dee\u5c0f\u4e8ebeta\u65f6\uff0c\u4f7f\u7528\u4e8c\u6b21\u635f\u5931\uff08\u7c7b\u4f3cMSE\uff09 - \u5f53\u8bef\u5dee\u5927\u4e8ebeta\u65f6\uff0c\u4f7f\u7528\u7ebf\u6027\u635f\u5931\uff08\u7c7b\u4f3cMAE\uff09 - \u8fd9\u79cd\u8bbe\u8ba1\u4f7f\u5f97\u635f\u5931\u51fd\u6570\u5bf9\u5f02\u5e38\u503c\u4e0d\u654f\u611f\uff0c\u540c\u65f6\u5728\u5c0f\u8bef\u5dee\u5904\u4fdd\u6301\u5e73\u6ed1 - \u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u5e38\u7528\u4e8e\u8fb9\u754c\u6846\u56de\u5f52\uff0c\u56e0\u4e3a\u5bf9\u5f02\u5e38\u503c\u4e0d\u654f\u611f</p> <p>SmoothL1Loss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#huber-loss","title":"Huber Loss","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_34","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = \\frac{1}{n}\\sum_{i=1}^{n} \\begin{cases} 0.5 (x_i - y_i)^2, &amp; \\text{if } |x_i - y_i| &lt; \\delta \\ \\delta (|x_i - y_i| - 0.5 \\delta), &amp; \\text{otherwise} \\end{cases} $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u503c\uff08\u6a21\u578b\u8f93\u51fa\uff09 - \\( y \\) \u662f\u76ee\u6807\u503c\uff08\u771f\u5b9e\u6807\u7b7e\uff09 - \\( n \\) \u662f\u6837\u672c\u6570\u91cf - \\( \\delta \\) \u662f\u9608\u503c\u53c2\u6570\uff08\u9ed8\u8ba4\u4e3a1.0\uff09</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_35","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u9c81\u68d2\u56de\u5f52\uff1a\u5bf9\u5f02\u5e38\u503c\u4e0d\u654f\u611f\u7684\u56de\u5f52\u4efb\u52a1</li> <li>\u5f3a\u5316\u5b66\u4e60\uff1a\u4f5c\u4e3aQ-learning\u7684\u635f\u5931\u51fd\u6570</li> <li>\u63a7\u5236\u7406\u8bba\uff1a\u7cfb\u7edf\u63a7\u5236\u4e2d\u7684\u8bef\u5dee\u5ea6\u91cf</li> <li>\u91d1\u878d\u9884\u6d4b\uff1a\u5bf9\u6781\u7aef\u503c\u4e0d\u654f\u611f\u7684\u9884\u6d4b\u4efb\u52a1</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_36","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.HuberLoss</code></p> Python<pre><code>torch.nn.HuberLoss(\n    reduction='mean',   # 'none'|'mean'|'sum'\n    delta=1.0           # \u9608\u503c\u53c2\u6570\n)\n\"\"\"\ndelta\uff1a\n\u6307\u5b9a\u4ece\u4e8c\u6b21\u635f\u5931\u8f6c\u4e3a\u7ebf\u6027\u635f\u5931\u7684\u9608\u503c\u70b9\n\u9ed8\u8ba4\u503c\u4e3a1.0\n\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u5143\u7d20\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - \u5f53\u8bef\u5dee\u5c0f\u4e8edelta\u65f6\uff0c\u4f7f\u7528\u4e8c\u6b21\u635f\u5931\uff08\u7c7b\u4f3cMSE\uff09 - \u5f53\u8bef\u5dee\u5927\u4e8edelta\u65f6\uff0c\u4f7f\u7528\u7ebf\u6027\u635f\u5931\uff08\u7c7b\u4f3cMAE\uff09 - Huber Loss\u662fSmoothL1Loss\u7684\u6cdb\u5316\u5f62\u5f0f\uff0c\u5f53delta=1.0\u65f6\u4e24\u8005\u7b49\u4ef7 - \u5bf9\u5f02\u5e38\u503c\u4e0d\u654f\u611f\uff0c\u540c\u65f6\u5728\u5c0f\u8bef\u5dee\u5904\u4fdd\u6301\u5e73\u6ed1\u7684\u68af\u5ea6</p> <p>HuberLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#soft-margin-loss","title":"Soft Margin Loss","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_37","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = \\frac{1}{n}\\sum_{i=1}^{n} \\log(1 + \\exp(-y_i x_i)) $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u503c\uff08\u6a21\u578b\u8f93\u51fa\uff09 - \\( y \\) \u662f\u76ee\u6807\u503c\uff081 \u6216 -1\uff09 - \\( n \\) \u662f\u6837\u672c\u6570\u91cf</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_38","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u4e8c\u5143\u5206\u7c7b\uff1a\u4e0eHinge Loss\u7c7b\u4f3c\u7684\u5e94\u7528\u573a\u666f</li> <li>\u6982\u7387\u8f93\u51fa\u9700\u6c42\uff1a\u9700\u8981\u6982\u7387\u89e3\u91ca\u7684\u5206\u7c7b\u4efb\u52a1</li> <li>SVM\u66ff\u4ee3\uff1a\u4f5c\u4e3aSVM\u7684\u5e73\u6ed1\u66ff\u4ee3\u65b9\u6848</li> <li>\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\uff1a\u63d0\u4f9b\u5e73\u6ed1\u7684\u68af\u5ea6\u4fe1\u53f7</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_39","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.SoftMarginLoss</code></p> Python<pre><code>torch.nn.SoftMarginLoss(\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean'    # 'none'|'mean'|'sum'\n)\n\"\"\"\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u5143\u7d20\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - \u76ee\u6807\u6807\u7b7e\u5e94\u4e3a1\uff08\u6b63\u7c7b\uff09\u6216-1\uff08\u8d1f\u7c7b\uff09 - Soft Margin Loss\u662fHinge Loss\u7684\u5e73\u6ed1\u7248\u672c - \u76f8\u6bd4Hinge Loss\uff0cSoft Margin Loss\u5904\u5904\u53ef\u5bfc\uff0c\u66f4\u9002\u5408\u68af\u5ea6\u4e0b\u964d - \u635f\u5931\u503c\u8303\u56f4\u5728[0, +\u221e)\uff0c\u5f53\u9884\u6d4b\u6b63\u786e\u4e14\u7f6e\u4fe1\u5ea6\u9ad8\u65f6\u63a5\u8fd10</p> <p>\u793a\u4f8b\uff1a</p> Python<pre><code>loss = nn.SoftMarginLoss()\ninput = torch.randn(3, requires_grad=True)\ntarget = torch.tensor([-1, 1, 1], dtype=torch.float)\noutput = loss(input, target)\n</code></pre> <p>SoftMarginLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#cross-entropy-loss","title":"Cross Entropy Loss","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_40","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = -\\frac{1}{n}\\sum_{i=1}^{n} \\log\\left(\\frac{\\exp(x_{i,y_i})}{\\sum_{j=1}^{C} \\exp(x_{i,j})}\\right) $$ \u6216\u7b49\u4ef7\u5f62\u5f0f\uff1a $$ \\mathcal{L}(x, y) = -\\frac{1}{n}\\sum_{i=1}^{n} \\left[ x_{i,y_i} - \\log\\left(\\sum_{j=1}^{C} \\exp(x_{i,j})\\right) \\right] $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u7684\u539f\u59cb\u8f93\u51fa\uff08logits\uff09\uff0c\u5f62\u72b6\u4e3a (N, C) - \\( y \\) \u662f\u76ee\u6807\u7c7b\u522b\u7d22\u5f15\uff0c\u5f62\u72b6\u4e3a (N) - \\( n \\) \u662f batch size - \\( C \\) \u662f\u7c7b\u522b\u6570</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_41","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u591a\u5206\u7c7b\u4efb\u52a1\uff1a\u6807\u51c6\u7684\u591a\u7c7b\u522b\u5206\u7c7b\u95ee\u9898</li> <li>\u56fe\u50cf\u5206\u7c7b\uff1a\u5982MNIST\u3001CIFAR\u3001ImageNet\u7b49</li> <li>\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff1a\u6587\u672c\u5206\u7c7b\u3001\u60c5\u611f\u5206\u6790\u7b49</li> <li>\u8bed\u97f3\u8bc6\u522b\uff1a\u97f3\u9891\u5206\u7c7b\u4efb\u52a1</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_42","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.CrossEntropyLoss</code></p> Python<pre><code>torch.nn.CrossEntropyLoss(\n    weight=None,        # \u5404\u7c7b\u522b\u7684\u6743\u91cd\uff081D Tensor\uff09\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    ignore_index=-100,  # \u5ffd\u7565\u7684\u76ee\u6807\u7c7b\u522b\u7d22\u5f15\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean',   # 'none'|'mean'|'sum'\n    label_smoothing=0.0 # \u6807\u7b7e\u5e73\u6ed1\u53c2\u6570\n)\n\"\"\"\nweight\uff1a\u7c7b\u522b\u4e0d\u5e73\u8861\u65f6\u53ef\u901a\u8fc7\u6b64\u53c2\u6570\u8c03\u6574\u6743\u91cd\n\nignore_index\uff1a\u6307\u5b9a\u5ffd\u7565\u7684\u7c7b\u522b\uff08\u4e0d\u8d21\u732e\u68af\u5ea6\uff09\n\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u6837\u672c\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\nlabel_smoothing\uff1a\n\u6807\u7b7e\u5e73\u6ed1\u7cfb\u6570\uff0c\u8303\u56f4[0,1]\n0\u8868\u793a\u4e0d\u8fdb\u884c\u5e73\u6ed1\uff0c1\u8868\u793a\u5b8c\u5168\u5e73\u6ed1\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - CrossEntropyLoss = LogSoftmax + NLLLoss - \u8f93\u5165\u4e0d\u9700\u8981\u7ecf\u8fc7Softmax\uff0c\u5185\u90e8\u4f1a\u81ea\u52a8\u5904\u7406 - \u5bf9\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u53ef\u4ee5\u901a\u8fc7weight\u53c2\u6570\u8c03\u6574 - label_smoothing\u6709\u52a9\u4e8e\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027</p> <p>\u793a\u4f8b\uff1a</p> Python<pre><code>loss = nn.CrossEntropyLoss()\ninput = torch.randn(3, 5, requires_grad=True)\ntarget = torch.empty(3, dtype=torch.long).random_(5)\noutput = loss(input, target)\n</code></pre> <p>CrossEntropyLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#multi-label-soft-margin-loss","title":"Multi Label Soft Margin Loss","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_43","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = -\\frac{1}{n}\\sum_{i=1}^{n} \\frac{1}{C} \\sum_{j=1}^{C} \\left[ y_{i,j} \\log(\\sigma(x_{i,j})) + (1 - y_{i,j}) \\log(1 - \\sigma(x_{i,j})) \\right] $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u7684\u539f\u59cb\u8f93\u51fa\uff08logits\uff09\uff0c\u5f62\u72b6\u4e3a (N, C) - \\( y \\) \u662f\u76ee\u6807\u503c\uff080 \u6216 1\uff09\uff0c\u5f62\u72b6\u4e3a (N, C) - \\( \\sigma \\) \u662fSigmoid\u51fd\u6570\uff1a\\(\\sigma(x) = \\frac{1}{1+e^{-x}}\\) - \\( n \\) \u662f batch size - \\( C \\) \u662f\u7c7b\u522b\u6570</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_44","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u591a\u6807\u7b7e\u5206\u7c7b\uff1a\u6bcf\u4e2a\u6837\u672c\u53ef\u4ee5\u5c5e\u4e8e\u591a\u4e2a\u7c7b\u522b</li> <li>\u56fe\u50cf\u6807\u6ce8\uff1a\u4e00\u5f20\u56fe\u50cf\u53ef\u4ee5\u6709\u591a\u4e2a\u6807\u7b7e</li> <li>\u6587\u672c\u5206\u7c7b\uff1a\u4e00\u7bc7\u6587\u7ae0\u53ef\u4ee5\u5c5e\u4e8e\u591a\u4e2a\u4e3b\u9898</li> <li>\u63a8\u8350\u7cfb\u7edf\uff1a\u4e00\u4e2a\u7528\u6237\u53ef\u80fd\u559c\u6b22\u591a\u4e2a\u7c7b\u522b</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_45","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.MultiLabelSoftMarginLoss</code></p> Python<pre><code>torch.nn.MultiLabelSoftMarginLoss(\n    weight=None,        # \u5404\u7c7b\u522b\u7684\u6743\u91cd\uff081D Tensor\uff09\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean'    # 'none'|'mean'|'sum'\n)\n\"\"\"\nweight\uff1a\u7c7b\u522b\u4e0d\u5e73\u8861\u65f6\u53ef\u901a\u8fc7\u6b64\u53c2\u6570\u8c03\u6574\u6743\u91cd\n\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u6837\u672c\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - \u76ee\u6807\u6807\u7b7e\u5e94\u4e3a0\u62161\uff0c\u8868\u793a\u6837\u672c\u662f\u5426\u5c5e\u4e8e\u8be5\u7c7b\u522b - \u5185\u90e8\u4f7f\u7528Sigmoid\u51fd\u6570\u5c06logits\u8f6c\u6362\u4e3a\u6982\u7387 - \u76f8\u6bd4\u4f7f\u7528\u591a\u4e2aBCEWithLogitsLoss\uff0c\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u5bf9\u591a\u6807\u7b7e\u4efb\u52a1\u8fdb\u884c\u4e86\u4f18\u5316 - \u9002\u7528\u4e8e\u6807\u7b7e\u4e4b\u95f4\u53ef\u80fd\u5b58\u5728\u76f8\u5173\u6027\u7684\u591a\u6807\u7b7e\u4efb\u52a1</p> <p>\u793a\u4f8b\uff1a</p> Python<pre><code>loss = nn.MultiLabelSoftMarginLoss()\ninput = torch.randn(3, 5, requires_grad=True)\ntarget = torch.empty(3, 5).random_(2)\noutput = loss(input, target)\n</code></pre> <p>MultiLabelSoftMarginLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#cosine-embedding-loss","title":"Cosine Embedding Loss","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_46","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = \\frac{1}{n}\\sum_{i=1}^{n} \\begin{cases} 1 - \\cos(x_{i1}, x_{i2}), &amp; \\text{if } y_i = 1 \\ \\max(0, \\cos(x_{i1}, x_{i2}) - \\text{margin}), &amp; \\text{if } y_i = -1 \\end{cases} $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u8f93\u5165\u5f20\u91cf\u5bf9\uff0c\u5f62\u72b6\u4e3a (N, *) - \\( y \\) \u662f\u76ee\u6807\u503c\uff081 \u6216 -1\uff09\uff0c\u5f62\u72b6\u4e3a (N) - \\( \\cos(x_{i1}, x_{i2}) \\) \u662f\u4f59\u5f26\u76f8\u4f3c\u5ea6 - \\( n \\) \u662f\u6837\u672c\u6570\u91cf - margin \u662f\u8fb9\u754c\u53c2\u6570\uff08\u9ed8\u8ba4\u4e3a0.0\uff09</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_47","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u5ea6\u91cf\u5b66\u4e60\uff1a\u5b66\u4e60\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u76f8\u4f3c\u6027</li> <li>\u4eba\u8138\u8bc6\u522b/\u9a8c\u8bc1\uff1a\u5224\u65ad\u4e24\u5f20\u4eba\u8138\u662f\u5426\u4e3a\u540c\u4e00\u4e2a\u4eba</li> <li>\u76f8\u4f3c\u6027\u5b66\u4e60\uff1a\u5b66\u4e60\u6837\u672c\u95f4\u7684\u76f8\u4f3c\u5ea6\u5ea6\u91cf</li> <li>\u5b6a\u751f\u7f51\u7edc\uff1a\u8bad\u7ec3\u5b6a\u751f\u795e\u7ecf\u7f51\u7edc</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_48","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.CosineEmbeddingLoss</code></p> Python<pre><code>torch.nn.CosineEmbeddingLoss(\n    margin=0.0,         # \u8fb9\u754c\u53c2\u6570\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean'    # 'none'|'mean'|'sum'\n)\n\"\"\"\nmargin\uff1a\n\u5f53y=-1\u65f6\uff0c\u5982\u679c\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5927\u4e8emargin\uff0c\u5219\u8ba1\u7b97\u4f59\u5f26\u76f8\u4f3c\u5ea6-margin\n\u5426\u5219\u635f\u5931\u4e3a0\n\u9ed8\u8ba4\u503c\u4e3a0.0\n\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u6837\u672c\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - \u8f93\u5165\u5e94\u4e3a\u4e24\u4e2a\u5f62\u72b6\u76f8\u540c\u7684\u5f20\u91cf\uff08input1, input2\uff09 - \u76ee\u6807\u6807\u7b7e\u5e94\u4e3a1\uff08\u76f8\u4f3c\uff09\u6216-1\uff08\u4e0d\u76f8\u4f3c\uff09 - \u4f59\u5f26\u76f8\u4f3c\u5ea6\u8ba1\u7b97\uff1a\\(\\cos(a, b) = \\frac{a \\cdot b}{||a|| \\cdot ||b||}\\) - \u5bf9\u4e8e\u76f8\u4f3c\u6837\u672c\uff08y=1\uff09\uff0c\u6700\u5927\u5316\u4f59\u5f26\u76f8\u4f3c\u5ea6 - \u5bf9\u4e8e\u4e0d\u76f8\u4f3c\u6837\u672c\uff08y=-1\uff09\uff0c\u6700\u5c0f\u5316\u4f59\u5f26\u76f8\u4f3c\u5ea6</p> <p>\u793a\u4f8b\uff1a</p> Python<pre><code>loss = nn.CosineEmbeddingLoss()\ninput1 = torch.randn(3, 5, requires_grad=True)\ninput2 = torch.randn(3, 5, requires_grad=True)\ntarget = torch.tensor([1, -1, 1], dtype=torch.float)\noutput = loss(input1, input2, target)\n</code></pre> <p>CosineEmbeddingLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#margin-ranking-loss","title":"Margin Ranking Loss","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_49","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x_1, x_2, y) = \\frac{1}{n}\\sum_{i=1}^{n} \\max(0, -y_i (x_{1i} - x_{2i}) + \\text{margin}) $$ \u5176\u4e2d\uff1a - \\( x_1 \\) \u662f\u7b2c\u4e00\u4e2a\u8f93\u5165\u5f20\u91cf\uff0c\u5f62\u72b6\u4e3a (N, ) - \\( x_2 \\) \u662f\u7b2c\u4e8c\u4e2a\u8f93\u5165\u5f20\u91cf\uff0c\u5f62\u72b6\u4e3a (N, ) - \\( y \\) \u662f\u76ee\u6807\u503c\uff081 \u6216 -1\uff09\uff0c\u5f62\u72b6\u4e3a (N) - \\( n \\) \u662f\u6837\u672c\u6570\u91cf - margin \u662f\u8fb9\u754c\u53c2\u6570\uff08\u9ed8\u8ba4\u4e3a0.0\uff09</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_50","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u5b66\u4e60\u6392\u5e8f\uff1a\u8bad\u7ec3\u6a21\u578b\u5b66\u4e60\u6b63\u786e\u7684\u6392\u5e8f\u5173\u7cfb</li> <li>\u63a8\u8350\u7cfb\u7edf\uff1a\u5b66\u4e60\u7528\u6237\u504f\u597d\u6392\u5e8f</li> <li>\u4fe1\u606f\u68c0\u7d22\uff1a\u6587\u6863\u76f8\u5173\u6027\u6392\u5e8f</li> <li>\u5ea6\u91cf\u5b66\u4e60\uff1a\u5b66\u4e60\u6837\u672c\u95f4\u7684\u76f8\u5bf9\u8ddd\u79bb</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_51","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.MarginRankingLoss</code></p> Python<pre><code>torch.nn.MarginRankingLoss(\n    margin=0.0,         # \u8fb9\u754c\u53c2\u6570\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean'    # 'none'|'mean'|'sum'\n)\n\"\"\"\nmargin\uff1a\n\u6307\u5b9a\u671f\u671b\u7684\u8fb9\u754c\u5927\u5c0f\n\u9ed8\u8ba4\u503c\u4e3a0.0\n\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u5143\u7d20\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - \u76ee\u6807\u6807\u7b7e\u5e94\u4e3a1\uff08x1\u5e94\u6392\u540d\u9ad8\u4e8ex2\uff09\u6216-1\uff08x2\u5e94\u6392\u540d\u9ad8\u4e8ex1\uff09 - \u5f53y=1\u65f6\uff0c\u5e0c\u671bx1 &gt; x2 + margin - \u5f53y=-1\u65f6\uff0c\u5e0c\u671bx2 &gt; x1 + margin - \u5982\u679c\u6761\u4ef6\u6ee1\u8db3\uff0c\u635f\u5931\u4e3a0\uff1b\u5426\u5219\u635f\u5931\u4e3a\u5dee\u8ddd\u7684\u7edd\u5bf9\u503c</p> <p>\u793a\u4f8b\uff1a</p> Python<pre><code>loss = nn.MarginRankingLoss()\ninput1 = torch.randn(3, requires_grad=True)\ninput2 = torch.randn(3, requires_grad=True)\ntarget = torch.tensor([1, -1, 1], dtype=torch.float)\noutput = loss(input1, input2, target)\n</code></pre> <p>MarginRankingLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#multi-margin-loss","title":"Multi Margin Loss","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_52","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y) = \\frac{1}{n}\\sum_{i=1}^{n} \\frac{1}{C} \\sum_{j \\neq y_i} \\max(0, \\text{margin} - (x_{i,y_i} - x_{i,j}) + p_j) $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u9884\u6d4b\u503c\uff08\u6a21\u578b\u8f93\u51fa\uff09\uff0c\u5f62\u72b6\u4e3a (N, C) - \\( y \\) \u662f\u76ee\u6807\u7c7b\u522b\u7d22\u5f15\uff0c\u5f62\u72b6\u4e3a (N) - \\( n \\) \u662f batch size - \\( C \\) \u662f\u7c7b\u522b\u6570 - margin \u662f\u8fb9\u754c\u53c2\u6570\uff08\u9ed8\u8ba4\u4e3a1.0\uff09 - \\( p_j \\) \u662f\u7b2cj\u7c7b\u7684\u5c3a\u5ea6\u56e0\u5b50\uff08\u7531weight\u53c2\u6570\u51b3\u5b9a\uff09</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_53","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u591a\u5206\u7c7b\u4efb\u52a1\uff1a\u7279\u522b\u662f\u9700\u8981\u533a\u5206\u76f8\u4f3c\u7c7b\u522b\u7684\u60c5\u51b5</li> <li>\u56fe\u50cf\u5206\u7c7b\uff1a\u5982\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1</li> <li>\u6587\u672c\u5206\u7c7b\uff1a\u533a\u5206\u8bed\u4e49\u76f8\u8fd1\u7684\u7c7b\u522b</li> <li>\u8bed\u97f3\u8bc6\u522b\uff1a\u533a\u5206\u53d1\u97f3\u76f8\u4f3c\u7684\u8bcd</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_54","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.MultiMarginLoss</code></p> Python<pre><code>torch.nn.MultiMarginLoss(\n    p=1,                # \u8303\u6570\u53c2\u6570\uff08\u4ec5\u652f\u63011\u62162\uff09\n    margin=1.0,         # \u8fb9\u754c\u53c2\u6570\n    weight=None,        # \u5404\u7c7b\u522b\u7684\u6743\u91cd\uff081D Tensor\uff09\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean'    # 'none'|'mean'|'sum'\n)\n\"\"\"\np\uff1a\n\u8303\u6570\u53c2\u6570\uff0c\u4ec5\u652f\u63011\u62162\n\u9ed8\u8ba4\u503c\u4e3a1\uff08L1\u8303\u6570\uff09\n\nmargin\uff1a\n\u6307\u5b9a\u671f\u671b\u7684\u8fb9\u754c\u5927\u5c0f\n\u9ed8\u8ba4\u503c\u4e3a1.0\n\nweight\uff1a\u7c7b\u522b\u4e0d\u5e73\u8861\u65f6\u53ef\u901a\u8fc7\u6b64\u53c2\u6570\u8c03\u6574\u6743\u91cd\n\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u6837\u672c\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - \u5bf9\u4e8e\u6bcf\u4e2a\u6837\u672c\uff0c\u8ba1\u7b97\u6b63\u786e\u7c7b\u522b\u4e0e\u5176\u4ed6\u6240\u6709\u7c7b\u522b\u4e4b\u95f4\u7684\u8fb9\u754c - \u5f53p=1\u65f6\uff0c\u4f7f\u7528L1\u8303\u6570\uff1b\u5f53p=2\u65f6\uff0c\u4f7f\u7528L2\u8303\u6570 - \u5982\u679c\u6b63\u786e\u7c7b\u522b\u7684\u5206\u6570\u4e0e\u5176\u4ed6\u7c7b\u522b\u7684\u5206\u6570\u5dee\u8ddd\u5927\u4e8emargin\uff0c\u5219\u635f\u5931\u4e3a0 - \u9002\u7528\u4e8e\u9700\u8981\u5f3a\u5236\u6a21\u578b\u533a\u5206\u76f8\u4f3c\u7c7b\u522b\u7684\u4efb\u52a1</p> <p>\u793a\u4f8b\uff1a</p> Python<pre><code>loss = nn.MultiMarginLoss()\ninput = torch.randn(3, 5, requires_grad=True)\ntarget = torch.tensor([1, 0, 4])\noutput = loss(input, target)\n</code></pre> <p>MultiMarginLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#triplet-margin-loss","title":"Triplet Margin Loss","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_55","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(a, p, n) = \\frac{1}{n}\\sum_{i=1}^{n} \\max(0, d(a_i, p_i) - d(a_i, n_i) + \\text{margin}) $$ \u5176\u4e2d\uff1a - \\( a \\) \u662f\u951a\u70b9\u6837\u672c\uff08anchor\uff09\uff0c\u5f62\u72b6\u4e3a (N, ) - \\( p \\) \u662f\u6b63\u6837\u672c\uff08positive\uff09\uff0c\u5f62\u72b6\u4e3a (N, ) - \\( n \\) \u662f\u8d1f\u6837\u672c\uff08negative\uff09\uff0c\u5f62\u72b6\u4e3a (N, *) - \\( d(x, y) \\) \u662f\u8ddd\u79bb\u51fd\u6570\uff08\u9ed8\u8ba4\u4e3a\u6b27\u6c0f\u8ddd\u79bb\uff09 - \\( n \\) \u662f\u6837\u672c\u6570\u91cf - margin \u662f\u8fb9\u754c\u53c2\u6570\uff08\u9ed8\u8ba4\u4e3a1.0\uff09</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_56","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u5ea6\u91cf\u5b66\u4e60\uff1a\u5b66\u4e60\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u8ddd\u79bb\u5ea6\u91cf</li> <li>\u4eba\u8138\u8bc6\u522b\uff1a\u5b66\u4e60\u4eba\u8138\u7279\u5f81\u5d4c\u5165</li> <li>\u56fe\u50cf\u68c0\u7d22\uff1a\u5b66\u4e60\u56fe\u50cf\u7279\u5f81\u8868\u793a</li> <li>\u63a8\u8350\u7cfb\u7edf\uff1a\u5b66\u4e60\u7528\u6237\u548c\u7269\u54c1\u7684\u5d4c\u5165\u8868\u793a</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_57","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.TripletMarginLoss</code></p> Python<pre><code>torch.nn.TripletMarginLoss(\n    margin=1.0,         # \u8fb9\u754c\u53c2\u6570\n    p=2.0,              # \u8303\u6570\u53c2\u6570\uff08\u8ddd\u79bb\u51fd\u6570\u7684\u9636\u6570\uff09\n    eps=1e-6,           # \u6570\u503c\u7a33\u5b9a\u6027\u5c0f\u91cf\n    swap=False,         # \u662f\u5426\u4f7f\u7528swap\n    size_average=None,  # \u5df2\u5e9f\u5f03\n    reduce=None,        # \u5df2\u5e9f\u5f03\n    reduction='mean'    # 'none'|'mean'|'sum'\n)\n\"\"\"\nmargin\uff1a\n\u6307\u5b9a\u671f\u671b\u7684\u8fb9\u754c\u5927\u5c0f\n\u9ed8\u8ba4\u503c\u4e3a1.0\n\np\uff1a\n\u8303\u6570\u53c2\u6570\uff0c\u7528\u4e8e\u8ba1\u7b97\u8ddd\u79bb\n\u9ed8\u8ba4\u503c\u4e3a2.0\uff08\u6b27\u6c0f\u8ddd\u79bb\uff09\n\neps\uff1a\n\u9632\u6b62\u9664\u4ee5\u96f6\u7684\u5c0f\u6570\u503c\n\u9ed8\u8ba4\u503c\u4e3a1e-6\n\nswap\uff1a\n\u5982\u679c\u4e3aTrue\uff0c\u5f53d(a,n) &lt; d(a,p)\u65f6\uff0c\u8ba1\u7b97d(p,n) - d(a,p) + margin\n\u9ed8\u8ba4\u503c\u4e3aFalse\n\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u6837\u672c\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - \u76ee\u6807\u662f\u4f7f\u951a\u70b9\u4e0e\u6b63\u6837\u672c\u7684\u8ddd\u79bb\u5c0f\u4e8e\u951a\u70b9\u4e0e\u8d1f\u6837\u672c\u7684\u8ddd\u79bb\uff0c\u4e14\u5dee\u8ddd\u81f3\u5c11\u4e3amargin - \u5982\u679c\u6761\u4ef6\u6ee1\u8db3\uff0c\u635f\u5931\u4e3a0\uff1b\u5426\u5219\u635f\u5931\u4e3a\u5dee\u8ddd\u7684\u7edd\u5bf9\u503c - \u5e38\u7528\u4e8e\u8bad\u7ec3\u5b6a\u751f\u7f51\u7edc\u6216\u4e09\u5143\u7ec4\u7f51\u7edc - swap\u53c2\u6570\u6709\u52a9\u4e8e\u5904\u7406\u56f0\u96be\u8d1f\u6837\u672c\u7684\u60c5\u51b5</p> <p>\u793a\u4f8b\uff1a</p> Python<pre><code>loss = nn.TripletMarginLoss()\nanchor = torch.randn(100, 128, requires_grad=True)\npositive = torch.randn(100, 128, requires_grad=True)\nnegative = torch.randn(100, 128, requires_grad=True)\noutput = loss(anchor, positive, negative)\n</code></pre> <p>TripletMarginLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#triplet-margin-with-distance-loss","title":"Triplet Margin with Distance Loss","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_58","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(a, p, n) = \\frac{1}{n}\\sum_{i=1}^{n} \\max(0, \\text{distance_function}(a_i, p_i) - \\text{distance_function}(a_i, n_i) + \\text{margin}) $$ \u5176\u4e2d\uff1a - \\( a \\) \u662f\u951a\u70b9\u6837\u672c\uff08anchor\uff09\uff0c\u5f62\u72b6\u4e3a (N, ) - \\( p \\) \u662f\u6b63\u6837\u672c\uff08positive\uff09\uff0c\u5f62\u72b6\u4e3a (N, ) - \\( n \\) \u662f\u8d1f\u6837\u672c\uff08negative\uff09\uff0c\u5f62\u72b6\u4e3a (N, *) - \\( \\text{distance\\_function} \\) \u662f\u81ea\u5b9a\u4e49\u7684\u8ddd\u79bb\u51fd\u6570 - \\( n \\) \u662f\u6837\u672c\u6570\u91cf - margin \u662f\u8fb9\u754c\u53c2\u6570\uff08\u9ed8\u8ba4\u4e3a1.0\uff09</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_59","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u5ea6\u91cf\u5b66\u4e60\uff1a\u9700\u8981\u81ea\u5b9a\u4e49\u8ddd\u79bb\u51fd\u6570\u7684\u5ea6\u91cf\u5b66\u4e60</li> <li>\u4eba\u8138\u8bc6\u522b\uff1a\u4f7f\u7528\u7279\u5b9a\u8ddd\u79bb\u5ea6\u91cf\u7684\u4eba\u8138\u7279\u5f81\u5d4c\u5165</li> <li>\u56fe\u50cf\u68c0\u7d22\uff1a\u4f7f\u7528\u7279\u5b9a\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u7684\u56fe\u50cf\u7279\u5f81\u8868\u793a</li> <li>\u63a8\u8350\u7cfb\u7edf\uff1a\u4f7f\u7528\u7279\u5b9a\u8ddd\u79bb\u5ea6\u91cf\u7684\u7528\u6237\u548c\u7269\u54c1\u5d4c\u5165</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_60","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.TripletMarginWithDistanceLoss</code></p> Python<pre><code>torch.nn.TripletMarginWithDistanceLoss(\n    distance_function=None,  # \u81ea\u5b9a\u4e49\u8ddd\u79bb\u51fd\u6570\n    margin=1.0,             # \u8fb9\u754c\u53c2\u6570\n    reduction='mean'         # 'none'|'mean'|'sum'\n)\n\"\"\"\ndistance_function\uff1a\n\u81ea\u5b9a\u4e49\u8ddd\u79bb\u51fd\u6570\uff0c\u7b7e\u540d\u4e3a(Tensor, Tensor) -&gt; Tensor\n\u5982\u679c\u4e3aNone\uff0c\u9ed8\u8ba4\u4f7f\u7528p=2\u7684\u8303\u6570\u8ddd\u79bb\n\u9ed8\u8ba4\u503c\u4e3aNone\n\nmargin\uff1a\n\u6307\u5b9a\u671f\u671b\u7684\u8fb9\u754c\u5927\u5c0f\n\u9ed8\u8ba4\u503c\u4e3a1.0\n\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u6837\u672c\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - \u8fd9\u662fTripletMarginLoss\u7684\u6cdb\u5316\u7248\u672c\uff0c\u5141\u8bb8\u4f7f\u7528\u81ea\u5b9a\u4e49\u8ddd\u79bb\u51fd\u6570 - \u8ddd\u79bb\u51fd\u6570\u5e94\u63a5\u53d7\u4e24\u4e2a\u76f8\u540c\u5f62\u72b6\u7684\u5f20\u91cf\u5e76\u8fd4\u56de\u4e00\u4e2a\u6807\u91cf\u5f20\u91cf - \u76ee\u6807\u662f\u4f7f\u951a\u70b9\u4e0e\u6b63\u6837\u672c\u7684\u8ddd\u79bb\u5c0f\u4e8e\u951a\u70b9\u4e0e\u8d1f\u6837\u672c\u7684\u8ddd\u79bb\uff0c\u4e14\u5dee\u8ddd\u81f3\u5c11\u4e3amargin - \u5e38\u7528\u4e8e\u9700\u8981\u7279\u5b9a\u8ddd\u79bb\u5ea6\u91cf\u7684\u573a\u666f\uff0c\u5982\u4f59\u5f26\u8ddd\u79bb\u3001\u9a6c\u6c0f\u8ddd\u79bb\u7b49</p> <p>\u793a\u4f8b\uff1a</p> Python<pre><code># \u4f7f\u7528\u6b27\u6c0f\u8ddd\u79bb\nloss = nn.TripletMarginWithDistanceLoss()\nanchor = torch.randn(100, 128, requires_grad=True)\npositive = torch.randn(100, 128, requires_grad=True)\nnegative = torch.randn(100, 128, requires_grad=True)\noutput = loss(anchor, positive, negative)\n\n# \u4f7f\u7528\u81ea\u5b9a\u4e49\u8ddd\u79bb\u51fd\u6570\uff08\u5982\u4f59\u5f26\u8ddd\u79bb\uff09\ndef cosine_distance(x1, x2):\n    return 1 - F.cosine_similarity(x1, x2, dim=1)\n\nloss = nn.TripletMarginWithDistanceLoss(distance_function=cosine_distance)\noutput = loss(anchor, positive, negative)\n</code></pre> <p>TripletMarginWithDistanceLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#connectionist-temporal-classification-loss-ctcloss","title":"Connectionist Temporal Classification Loss (CTCLoss)","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_61","title":"\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>$$ \\mathcal{L}(x, y, l) = -\\log(p(l|x)) $$ \u5176\u4e2d\uff1a - \\( x \\) \u662f\u8f93\u5165\u5e8f\u5217\uff08\u901a\u5e38\u662fRNN\u7684\u8f93\u51fa\uff09\uff0c\u5f62\u72b6\u4e3a (T, N, C) - \\( y \\) \u662f\u76ee\u6807\u5e8f\u5217\uff0c\u5f62\u72b6\u4e3a (N, S) \u6216\u76ee\u6807\u548c\u957f\u5ea6\u7684\u5143\u7ec4 - \\( l \\) \u662f\u8f93\u5165\u957f\u5ea6\u548c\u76ee\u6807\u957f\u5ea6 - \\( p(l|x) \\) \u662f\u7ed9\u5b9a\u8f93\u5165\u5e8f\u5217x\u65f6\uff0c\u76ee\u6807\u5e8f\u5217l\u7684\u6761\u4ef6\u6982\u7387</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_62","title":"\u9002\u7528\u573a\u666f","text":"<ol> <li>\u5e8f\u5217\u6807\u6ce8\uff1a\u8f93\u5165\u548c\u8f93\u51fa\u957f\u5ea6\u4e0d\u540c\u7684\u5e8f\u5217\u4efb\u52a1</li> <li>\u8bed\u97f3\u8bc6\u522b\uff1a\u5c06\u97f3\u9891\u4fe1\u53f7\u8f6c\u6362\u4e3a\u6587\u672c</li> <li>\u624b\u5199\u8bc6\u522b\uff1a\u5c06\u624b\u5199\u56fe\u50cf\u8f6c\u6362\u4e3a\u6587\u672c</li> <li>\u89c6\u9891\u5206\u6790\uff1a\u89c6\u9891\u5e8f\u5217\u5230\u6807\u7b7e\u5e8f\u5217\u7684\u8f6c\u6362</li> </ol>"},{"location":"notes/Pytorch-Tutorial/LossFunction/LossFunction/#_63","title":"\u53c2\u6570\u8bf4\u660e","text":"<p>PyTorch\u5b9e\u73b0\uff1a<code>torch.nn.CTCLoss</code></p> Python<pre><code>torch.nn.CTCLoss(\n    blank=0,            # \u7a7a\u767d\u6807\u7b7e\u7d22\u5f15\n    reduction='mean',   # 'none'|'mean'|'sum'\n    zero_infinity=False # \u662f\u5426\u5c06\u65e0\u9650\u635f\u5931\u8bbe\u4e3a\u96f6\n)\n\"\"\"\nblank\uff1a\n\u7a7a\u767d\u6807\u7b7e\u7684\u7d22\u5f15\n\u9ed8\u8ba4\u503c\u4e3a0\n\nreduction\uff1a\n'none'\uff1a\u8fd4\u56de\u9010\u6837\u672c\u635f\u5931\n'mean'\uff08\u9ed8\u8ba4\uff09\uff1a\u8fd4\u56de\u635f\u5931\u5747\u503c\n'sum'\uff1a\u8fd4\u56de\u635f\u5931\u603b\u548c\n\nzero_infinity\uff1a\n\u5982\u679c\u4e3aTrue\uff0c\u5c06\u65e0\u9650\u635f\u5931\u8bbe\u4e3a\u96f6\uff08\u7528\u4e8e\u5904\u7406\u5f02\u5e38\u60c5\u51b5\uff09\n\u9ed8\u8ba4\u503c\u4e3aFalse\n\"\"\"\n</code></pre> <p>\u6ce8\u610f\uff1a - CTC\u5141\u8bb8\u8f93\u5165\u548c\u8f93\u51fa\u5e8f\u5217\u957f\u5ea6\u4e0d\u540c - \u8f93\u5165\u901a\u5e38\u9700\u8981\u7ecf\u8fc7log_softmax\u5904\u7406 - \u9700\u8981\u63d0\u4f9b\u8f93\u5165\u957f\u5ea6\u548c\u76ee\u6807\u957f\u5ea6 - \u7a7a\u767d\u6807\u7b7e\u7528\u4e8e\u5bf9\u9f50\u4e0d\u540c\u957f\u5ea6\u7684\u5e8f\u5217 - \u9002\u7528\u4e8e\u4e0d\u9700\u8981\u5148\u9a8c\u5bf9\u9f50\u4fe1\u606f\u7684\u5e8f\u5217\u5230\u5e8f\u5217\u4efb\u52a1</p> <p>\u793a\u4f8b\uff1a</p> Python<pre><code>T = 50      # \u8f93\u5165\u5e8f\u5217\u957f\u5ea6\nC = 20      # \u7c7b\u522b\u6570\uff08\u5305\u62ec\u7a7a\u767d\u6807\u7b7e\uff09\nN = 16      # batch size\nS = 30      # \u76ee\u6807\u5e8f\u5217\u957f\u5ea6\nS_min = 10  # \u6700\u5c0f\u76ee\u6807\u957f\u5ea6\n\n# \u968f\u673a\u751f\u6210\u6570\u636e\ninput = torch.randn(T, N, C).log_softmax(2)\ntarget = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n\n# \u751f\u6210\u968f\u673a\u957f\u5ea6\ninput_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\ntarget_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)\n\nloss = nn.CTCLoss()\noutput = loss(input, target, input_lengths, target_lengths)\n</code></pre> <p>CTCLoss\u5b98\u65b9\u6587\u6863</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/TripletLoss/","title":"Triplet Loss","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/TripletLoss/#triplet-loss","title":"Triplet Loss","text":"<p> \u7ea6 1173 \u4e2a\u5b57  67 \u884c\u4ee3\u7801  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 7 \u5206\u949f</p> <p></p> <p>\u5982\u4e0a\u56fe\u6240\u793a\uff0cTriplet Loss \u662f\u6709\u4e00\u4e2a\u4e09\u5143\u7ec4\u6784\u6210\uff0c\u5176\u4e2d</p> <p>a: anchor \u8868\u793a\u8bad\u7ec3\u6837\u672c\u3002</p> <p>p: positive \u8868\u793a\u9884\u6d4b\u4e3a\u6b63\u6837\u672c\u3002</p> <p>n: negative \u8868\u793a\u9884\u6d4b\u4e3a\u8d1f\u6837\u672c\u3002</p> <p>triplet loss\u7684\u4f5c\u7528\uff1a\u7528\u4e8e\u51cf\u5c11positive\uff08\u6b63\u6837\u672c\uff09\u4e0eanchor\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u6269\u5927negative\uff08\u8d1f\u6837\u672c\uff09\u4e0eanchor\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002\u57fa\u4e8e\u4e0a\u8ff0\u4e09\u5143\u7ec4\uff0c\u53ef\u4ee5\u6784\u5efa\u4e00\u4e2apositive pair \u548c\u4e00\u4e2anegative pair \u3002triplet loss\u7684\u76ee\u7684\u662f\u5728\u4e00\u5b9a\u8ddd\u79bb\uff08margin\uff09\u4e0a\u628apositive pair\u548cnegative pair\u5206\u5f00\u3002</p> <p>\u6240\u4ee5\u6211\u4eec\u5e0c\u671b\uff1aD(a, p) &lt; D(a, n)\u3002\u8fdb\u4e00\u6b65\u5e0c\u671b\u5728\u4e00\u5b9a\u8ddd\u79bb\u4e0a\uff08margin\uff09 \u6ee1\u8db3\u8fd9\u4e2a\u60c5\u51b5\uff1aD(a, p)  + margin  &lt;  D(a, n)</p> <p>\uff08a\uff09easy triplets\uff1aloss = 0\uff0cD(a, p) + margin &lt; D(a, n)\uff0cpositive pair \u7684\u8ddd\u79bb\u8fdc\u8fdc\u5c0f\u4e8e\u4e8enegative pair\u7684\u8ddd\u79bb\u3002\u5373\uff0c\u7c7b\u5185\u8ddd\u79bb\u5f88\u5c0f\uff0c\u7c7b\u95f4\u5f88\u5927\u8ddd\u79bb\uff0c\u8fd9\u79cd\u60c5\u51b5\u4e0d\u9700\u8981\u4f18\u5316\u3002</p> <p>\uff08b\uff09hard triplets\uff1aD(a, n)   &lt;  D(a, p) \uff0cpositive pair \u7684\u8ddd\u79bb\u5927\u4e8e\u4e8enegative pair\u7684\u8ddd\u79bb\uff0c\u5373\u7c7b\u5185\u8ddd\u79bb\u5927\u4e8e\u7c7b\u95f4\u8ddd\u79bb\u3002\u8fd9\u79cd\u60c5\u51b5\u6bd4\u8f83\u96be\u4f18\u5316\u3002</p> <p>\uff08c\uff09semi-hard triplets\uff1aD(a, p) &lt; D(a, n) &lt; D(a, p) + margin\u3002positive pair\u7684\u8ddd\u79bb\u548cnegative pair\u7684\u8ddd\u79bb\u6bd4\u8f83\u9ad8\u8fd1\u3002\u5373\uff0c\u548c\u5f88\u8fd1\uff0c\u4f46\u90fd\u5728\u4e00\u4e2amargin\u5185\u3002\u6bd4\u8f83\u5bb9\u6613\u4f18\u5316\u3002</p> <p>\u5f53\u4e3a semi-hard triplets \u65f6\uff0c D(a, p) + margin -  D(a, n) &gt; 0\u4ea7\u751floss.</p> <p>\u8bad\u7ec3\u65f6\uff0c\u65e9\u671f\u4e3a\u4e86\u7f51\u7edcloss\u5e73\u7a33\uff0c\u4e00\u822c\u9009\u62e9easy triplets\u8fdb\u884c\u4f18\u5316\uff0c\u540e\u671f\u4e3a\u4e86\u4f18\u5316\u8bad\u7ec3\u5173\u952e\u662f\u8981\u9009\u62e9hard triplets\u3002</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/TripletLoss/#_1","title":"\u5b9e\u73b0\u539f\u7406","text":""},{"location":"notes/Pytorch-Tutorial/LossFunction/TripletLoss/#pytorch","title":"Pytorch\u6e90\u7801\u5b9e\u73b0","text":"Python<pre><code>class TripletLoss(nn.Module):\n    \"\"\"Triplet loss with hard positive/negative mining.\n\n    Reference:\n        Hermans et al. In Defense of the Triplet Loss for Person Re-Identification. arXiv:1703.07737.\n\n    Imported from `&lt;https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py&gt;`_.\n\n    Args:\n        margin (float, optional): margin for triplet. Default is 0.3.\n    \"\"\"\n\n    def __init__(self, margin=0.3,global_feat, labels):\n        super(TripletLoss, self).__init__()\n        self.margin = margin\n        self.ranking_loss = nn.MarginRankingLoss(margin=margin)\n\n    def forward(self, inputs, targets):\n        \"\"\"\n        Args:\n            inputs (torch.Tensor): feature matrix with shape (batch_size, feat_dim).\n            targets (torch.LongTensor): ground truth labels with shape (num_classes).\n        \"\"\"\n        n = inputs.size(0)\n\n        # Compute pairwise distance, replace by the official when merged\n        dist = torch.pow(inputs, 2).sum(dim=1, keepdim=True).expand(n, n)\n        dist = dist + dist.t()\n        dist.addmm_(1, -2, inputs, inputs.t())\n        dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n\n        # For each anchor, find the hardest positive and negative\n        mask = targets.expand(n, n).eq(targets.expand(n, n).t())\n        dist_ap, dist_an = [], []\n        for i in range(n):\n            dist_ap.append(dist[i][mask[i]].max().unsqueeze(0))\n            dist_an.append(dist[i][mask[i] == 0].min().unsqueeze(0))\n        dist_ap = torch.cat(dist_ap)\n        dist_an = torch.cat(dist_an)\n\n        # Compute ranking hinge loss\n        y = torch.ones_like(dist_an)\n        return self.ranking_loss(dist_an, dist_ap, y)\n</code></pre> <p>\u597d\u7684\uff01\u6211\u5c06\u901a\u8fc7\u4e00\u4e2a\u5177\u4f53\u7684\u4f8b\u5b50\uff0c\u8be6\u7ec6\u89e3\u91ca <code>TripletLoss</code> \u7684\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u5305\u62ec \u8f93\u5165\u6570\u636e\u3001\u8ddd\u79bb\u77e9\u9635\u8ba1\u7b97\u3001\u96be\u6837\u672c\u6316\u6398\u548c\u635f\u5931\u8ba1\u7b97 \u7684\u6bcf\u4e00\u6b65\u3002</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/TripletLoss/#1","title":"1. \u8f93\u5165\u6570\u636e","text":"<p>\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a batch \u5305\u542b 4 \u4e2a\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u7684\u7279\u5f81\u7ef4\u5ea6\u662f 2\uff08\u7b80\u5316\u8ba1\u7b97\uff09\uff0c\u5e76\u4e14\u5b83\u4eec\u7684\u6807\u7b7e\u5982\u4e0b\uff1a</p> <ul> <li>\u8f93\u5165\u7279\u5f81 <code>inputs</code>\uff084\u00d72 \u7684\u5f20\u91cf\uff09\uff1a Python<pre><code>inputs = torch.tensor([\n    [1.0, 2.0],   # \u6837\u672c 0\uff0c\u6807\u7b7e 1\n    [2.0, 3.0],   # \u6837\u672c 1\uff0c\u6807\u7b7e 1\n    [4.0, 5.0],   # \u6837\u672c 2\uff0c\u6807\u7b7e 2\n    [5.0, 6.0]    # \u6837\u672c 3\uff0c\u6807\u7b7e 2\n])\n</code></pre></li> <li>\u6807\u7b7e <code>targets</code>\uff1a Python<pre><code>targets = torch.tensor([1, 1, 2, 2])\n</code></pre></li> </ul>"},{"location":"notes/Pytorch-Tutorial/LossFunction/TripletLoss/#2","title":"2. \u8ba1\u7b97\u6240\u6709\u6837\u672c\u4e4b\u95f4\u7684\u6b27\u6c0f\u8ddd\u79bb\u77e9\u9635","text":"<p>\u4e09\u5143\u7ec4\u635f\u5931\u7684\u5173\u952e\u662f\u8ba1\u7b97 \u6240\u6709\u6837\u672c\u5bf9\u7684\u8ddd\u79bb\uff0c\u5f97\u5230\u4e00\u4e2a <code>4\u00d74</code> \u7684\u8ddd\u79bb\u77e9\u9635 <code>dist</code>\u3002</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/TripletLoss/#1-dist","title":"(1) \u8ba1\u7b97 <code>dist</code>","text":"<p>\u4ee3\u7801\uff1a </p>Python<pre><code>dist = torch.pow(inputs, 2).sum(dim=1, keepdim=True).expand(n, n)\ndist = dist + dist.t()\ndist.addmm_(1, -2, inputs, inputs.t())\ndist = dist.clamp(min=1e-12).sqrt()\n</code></pre> \u6b65\u9aa4\u5206\u89e3\uff1a 1. \u8ba1\u7b97\u6bcf\u4e2a\u6837\u672c\u7684 L2 \u8303\u6570\u5e73\u65b9\uff1a    - <code>torch.pow(inputs, 2)</code> \u2192 \u6bcf\u4e2a\u5143\u7d20\u5e73\u65b9\uff1a Text Only<pre><code>[[1, 4], [4, 9], [16, 25], [25, 36]]\n</code></pre>    - <code>.sum(dim=1, keepdim=True)</code> \u2192 \u5bf9\u6bcf\u884c\u6c42\u548c\uff08\u5373 <code>x_i^2 + y_i^2</code>\uff09\uff1a Text Only<pre><code>[[5], [13], [41], [61]]\n</code></pre>    - <code>.expand(4, 4)</code> \u2192 \u6269\u5c55\u6210 <code>4\u00d74</code> \u77e9\u9635\uff1a Text Only<pre><code>[[5, 5, 5, 5],\n [13, 13, 13, 13],\n [41, 41, 41, 41],\n [61, 61, 61, 61]]\n</code></pre><p></p> <ol> <li> <p>\u52a0\u4e0a\u5176\u8f6c\u7f6e\u77e9\u9635\uff1a </p>Python<pre><code>dist = dist + dist.t()\n</code></pre>    - \u7ed3\u679c\uff1a Text Only<pre><code>[[10, 18, 46, 66],\n [18, 26, 54, 74],\n [46, 54, 82, 102],\n [66, 74, 102, 122]]\n</code></pre><p></p> </li> <li> <p>\u8ba1\u7b97 <code>-2 * (inputs @ inputs.T)</code> \u5e76\u52a0\u5230 <code>dist</code>\uff1a </p>Python<pre><code>dist.addmm_(1, -2, inputs, inputs.t())\n</code></pre>    - <code>inputs @ inputs.T</code>\uff08\u77e9\u9635\u4e58\u6cd5\uff09\uff1a Text Only<pre><code>[[5, 8, 14, 17],\n [8, 13, 23, 28],\n [14, 23, 41, 50],\n [17, 28, 50, 61]]\n</code></pre>    - <code>-2 * (inputs @ inputs.T)</code>\uff1a Text Only<pre><code>[[-10, -16, -28, -34],\n [-16, -26, -46, -56],\n [-28, -46, -82, -100],\n [-34, -56, -100, -122]]\n</code></pre>    - \u6700\u7ec8 <code>dist</code>\uff08<code>dist += -2 * (inputs @ inputs.T)</code>\uff09\uff1a Text Only<pre><code>[[0, 2, 18, 32],\n [2, 0, 8, 18],\n [18, 8, 0, 2],\n [32, 18, 2, 0]]\n</code></pre><p></p> </li> <li> <p>\u6570\u503c\u7a33\u5b9a\u5316 + \u5f00\u5e73\u65b9\uff1a </p>Python<pre><code>dist = dist.clamp(min=1e-12).sqrt()\n</code></pre>    - \u7531\u4e8e <code>dist</code> \u5df2\u7ecf\u662f\u975e\u8d1f\u6570\uff0c\u5f00\u5e73\u65b9\u540e\u4ecd\u7136\u662f\uff1a Text Only<pre><code>[[0.0, 1.414, 4.242, 5.656],\n [1.414, 0.0, 2.828, 4.242],\n [4.242, 2.828, 0.0, 1.414],\n [5.656, 4.242, 1.414, 0.0]]\n</code></pre><p></p> </li> </ol> <p>\u2705 \u6700\u7ec8 <code>dist</code> \u77e9\u9635\uff08<code>dist[i][j]</code> = \u6837\u672c <code>i</code> \u548c <code>j</code> \u7684\u8ddd\u79bb\uff09\uff1a |       | \u6837\u672c 0 | \u6837\u672c 1 | \u6837\u672c 2 | \u6837\u672c 3 | |-------|-------|-------|-------|-------| | \u6837\u672c 0 | 0.0   | 1.414 | 4.242 | 5.656 | | \u6837\u672c 1 | 1.414 | 0.0   | 2.828 | 4.242 | | \u6837\u672c 2 | 4.242 | 2.828 | 0.0   | 1.414 | | \u6837\u672c 3 | 5.656 | 4.242 | 1.414 | 0.0   |</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/TripletLoss/#3-hard-mining","title":"3. \u96be\u6837\u672c\u6316\u6398\uff08Hard Mining\uff09","text":"<p>\u4e09\u5143\u7ec4\u635f\u5931\u7684\u6838\u5fc3\u662f\uff1a - \u6b63\u6837\u672c\u8ddd\u79bb\uff08<code>dist_ap</code>\uff09\uff1a\u4e0e <code>anchor</code> \u540c\u7c7b\u7684\u6700\u8fdc\u6837\u672c\uff08\u6700\u96be\u6b63\u6837\u672c\uff09\u3002 - \u8d1f\u6837\u672c\u8ddd\u79bb\uff08<code>dist_an</code>\uff09\uff1a\u4e0e <code>anchor</code> \u4e0d\u540c\u7c7b\u7684\u6700\u8fd1\u6837\u672c\uff08\u6700\u96be\u8d1f\u6837\u672c\uff09\u3002</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/TripletLoss/#1-mask","title":"(1) \u6784\u5efa <code>mask</code> \u77e9\u9635","text":"Python<pre><code>mask = targets.expand(n, n).eq(targets.expand(n, n).t())\n</code></pre> - <code>targets.expand(4, 4)</code>\uff1a Text Only<pre><code>[[1, 1, 2, 2],\n [1, 1, 2, 2],\n [2, 2, 2, 2],\n [2, 2, 2, 2]]\n</code></pre> - <code>targets.expand(4, 4).t()</code>\uff08\u8f6c\u7f6e\uff09\uff1a Text Only<pre><code>[[1, 1, 2, 2],\n [1, 1, 2, 2],\n [2, 2, 2, 2],\n [2, 2, 2, 2]]\n</code></pre> - <code>mask</code>\uff08<code>True</code> \u8868\u793a\u540c\u7c7b\uff09\uff1a Text Only<pre><code>[[True, True, False, False],\n [True, True, False, False],\n [False, False, True, True],\n [False, False, True, True]]\n</code></pre>"},{"location":"notes/Pytorch-Tutorial/LossFunction/TripletLoss/#2-dist_ap-dist_an","title":"(2) \u8ba1\u7b97 <code>dist_ap</code> \u548c <code>dist_an</code>","text":"Python<pre><code>dist_ap, dist_an = [], []\nfor i in range(n):\n    dist_ap.append(dist[i][mask[i]].max().unsqueeze(0))  # \u540c\u7c7b\u6700\u8fdc\n    dist_an.append(dist[i][mask[i] == 0].min().unsqueeze(0))  # \u4e0d\u540c\u7c7b\u6700\u8fd1\n</code></pre> \u9010\u6837\u672c\u5206\u6790\uff1a 1. \u6837\u672c 0\uff08\u6807\u7b7e 1\uff09\uff1a    - <code>mask[0] = [True, True, False, False]</code>\uff08\u540c\u7c7b\uff1a\u6837\u672c 0, 1\uff09    - <code>dist_ap</code>\uff1a<code>dist[0][mask[0]] = [0.0, 1.414]</code> \u2192 <code>max = 1.414</code>    - <code>dist_an</code>\uff1a<code>dist[0][mask[0]==False] = [4.242, 5.656]</code> \u2192 <code>min = 4.242</code> <ol> <li> <p>\u6837\u672c 1\uff08\u6807\u7b7e 1\uff09\uff1a    - <code>mask[1] = [True, True, False, False]</code>\uff08\u540c\u7c7b\uff1a\u6837\u672c 0, 1\uff09    - <code>dist_ap</code>\uff1a<code>dist[1][mask[1]] = [1.414, 0.0]</code> \u2192 <code>max = 1.414</code>    - <code>dist_an</code>\uff1a<code>dist[1][mask[1]==False] = [2.828, 4.242]</code> \u2192 <code>min = 2.828</code></p> </li> <li> <p>\u6837\u672c 2\uff08\u6807\u7b7e 2\uff09\uff1a    - <code>mask[2] = [False, False, True, True]</code>\uff08\u540c\u7c7b\uff1a\u6837\u672c 2, 3\uff09    - <code>dist_ap</code>\uff1a<code>dist[2][mask[2]] = [0.0, 1.414]</code> \u2192 <code>max = 1.414</code>    - <code>dist_an</code>\uff1a<code>dist[2][mask[2]==False] = [4.242, 2.828]</code> \u2192 <code>min = 2.828</code></p> </li> <li> <p>\u6837\u672c 3\uff08\u6807\u7b7e 2\uff09\uff1a    - <code>mask[3] = [False, False, True, True]</code>\uff08\u540c\u7c7b\uff1a\u6837\u672c 2, 3\uff09    - <code>dist_ap</code>\uff1a<code>dist[3][mask[3]] = [1.414, 0.0]</code> \u2192 <code>max = 1.414</code>    - <code>dist_an</code>\uff1a<code>dist[3][mask[3]==False] = [5.656, 4.242]</code> \u2192 <code>min = 4.242</code></p> </li> </ol> <p>\u2705 \u6700\u7ec8 <code>dist_ap</code> \u548c <code>dist_an</code>\uff1a </p>Python<pre><code>dist_ap = [1.414, 1.414, 1.414, 1.414]\ndist_an = [4.242, 2.828, 2.828, 4.242]\n</code></pre><p></p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/TripletLoss/#4-triplet-loss","title":"4. \u8ba1\u7b97 Triplet Loss","text":"<p>\u4ee3\u7801\uff1a </p>Python<pre><code>y = torch.ones_like(dist_an)\nloss = self.ranking_loss(dist_an, dist_ap, y)\n</code></pre> - <code>y = [1, 1, 1, 1]</code>\uff08\u6211\u4eec\u5e0c\u671b <code>dist_an &gt; dist_ap</code>\uff09 - <code>MarginRankingLoss</code> \u516c\u5f0f\uff1a Text Only<pre><code>loss = max(0, -y * (dist_an - dist_ap) + margin)\n      = max(0, dist_ap - dist_an + margin)\n</code></pre> - \u8ba1\u7b97\u6bcf\u4e2a\u6837\u672c\u7684\u635f\u5931\uff1a   - \u6837\u672c 0\uff1a<code>max(0, 1.414 - 4.242 + 0.3) = max(0, -2.528) = 0</code>   - \u6837\u672c 1\uff1a<code>max(0, 1.414 - 2.828 + 0.3) = max(0, -1.114) = 0</code>   - \u6837\u672c 2\uff1a<code>max(0, 1.414 - 2.828 + 0.3) = max(0, -1.114) = 0</code>   - \u6837\u672c 3\uff1a<code>max(0, 1.414 - 4.242 + 0.3) = max(0, -2.528) = 0</code> - \u6700\u7ec8 loss\uff1a<code>(0 + 0 + 0 + 0) / 4 = 0</code><p></p> <p>\u2705 \u7ed3\u8bba\uff1a - \u7531\u4e8e <code>dist_an</code> \u5df2\u7ecf\u6bd4 <code>dist_ap</code> \u5927\u5f88\u591a\uff08\u6ee1\u8db3 <code>dist_an &gt; dist_ap + margin</code>\uff09\uff0c\u6240\u4ee5\u635f\u5931\u4e3a 0\u3002 - \u5982\u679c <code>dist_an</code> \u4e0d\u591f\u5927\uff0c\u635f\u5931\u4f1a\u60e9\u7f5a\u6a21\u578b\uff0c\u4f7f\u5176\u62c9\u8fd1\u6b63\u6837\u672c\u3001\u63a8\u8fdc\u8d1f\u6837\u672c\u3002</p>"},{"location":"notes/Pytorch-Tutorial/LossFunction/TripletLoss/#_2","title":"\u603b\u7ed3","text":"<ol> <li>\u8ba1\u7b97\u6240\u6709\u6837\u672c\u5bf9\u7684\u8ddd\u79bb\u77e9\u9635 <code>dist</code>\uff08\u6b27\u6c0f\u8ddd\u79bb\uff09\u3002</li> <li>\u96be\u6837\u672c\u6316\u6398\uff1a    - <code>dist_ap</code>\uff1a\u540c\u7c7b\u6700\u8fdc\u6837\u672c\uff08\u6700\u96be\u6b63\u6837\u672c\uff09\u3002    - <code>dist_an</code>\uff1a\u4e0d\u540c\u7c7b\u6700\u8fd1\u6837\u672c\uff08\u6700\u96be\u8d1f\u6837\u672c\uff09\u3002</li> <li>\u8ba1\u7b97 Triplet Loss\uff1a    - \u5982\u679c <code>dist_an</code> \u4e0d\u6bd4 <code>dist_ap</code> \u5927\u81f3\u5c11 <code>margin</code>\uff0c\u5219\u4ea7\u751f\u635f\u5931\u3002</li> </ol> <p>\u8fd9\u6837\uff0c\u6a21\u578b\u4f1a\u5b66\u4e60\u8ba9 \u540c\u7c7b\u6837\u672c\u66f4\u63a5\u8fd1\uff0c\u4e0d\u540c\u7c7b\u6837\u672c\u66f4\u8fdc\u79bb\uff0c\u4ece\u800c\u63d0\u5347\u7279\u5f81\u5224\u522b\u6027\u3002</p>"},{"location":"notes/RL/Chap2BellmanEquation/","title":"Chapter2 Bellman Equation","text":""},{"location":"notes/RL/Chap2BellmanEquation/#_1","title":"\u8d1d\u5c14\u66fc\u516c\u5f0f\uff08\u5f3a\u5316\u5b66\u4e60\uff09\u6838\u5fc3\u77e5\u8bc6\u70b9\u603b\u7ed3","text":"<p> \u7ea6 4604 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 23 \u5206\u949f</p>"},{"location":"notes/RL/Chap2BellmanEquation/#_2","title":"\u4e00\u3001\u8d1d\u5c14\u66fc\u516c\u5f0f\u57fa\u7840\u8ba4\u77e5","text":"<ol> <li>\u6838\u5fc3\u5b9a\u4e49\uff1a\u63cf\u8ff0\u4e0d\u540c\u72b6\u6001\u7684\u72b6\u6001\u4ef7\u503c\uff08State Value\uff0c\u8bb0\u4e3a \\(v_\\pi(s)\\)\uff09 \u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u662f\u8ba1\u7b97\u72b6\u6001\u4ef7\u503c\u7684\u6838\u5fc3\u5de5\u5177\u3002</li> <li>\u672c\u8d28\u903b\u8f91\uff1a\u5c06\u5f53\u524d\u72b6\u6001\u7684\u4ef7\u503c\u62c6\u5206\u4e3a\u201c\u5373\u65f6\u5956\u52b1\u201d\u548c\u201c\u672a\u6765\u72b6\u6001\u4ef7\u503c\u7684\u6298\u73b0\u201d\u4e24\u90e8\u5206\uff0c\u4f53\u73b0\u5f3a\u5316\u5b66\u4e60\u4e2d\u201c\u77ed\u671f\u6536\u76ca\u201d\u4e0e\u201c\u957f\u671f\u6536\u76ca\u201d\u7684\u6743\u8861\u3002</li> </ol>"},{"location":"notes/RL/Chap2BellmanEquation/#_3","title":"\u4e8c\u3001\u63a8\u5bfc\u524d\u7f6e\u6982\u5ff5\u4e0e\u516c\u5f0f","text":"<ol> <li>\u5173\u952e\u672f\u8bed\u56de\u987e    - \u6298\u6263\u56de\u62a5\uff08Discounted Return\uff0c\\(G_t\\)\uff09\uff1a\u4ece\u65f6\u523b\\(t\\)\u5f00\u59cb\u7684\u7d2f\u8ba1\u5956\u52b1\uff0c\u9700\u8003\u8651\u6298\u6263\u56e0\u5b50\\(\\gamma\\)\uff08\\(0 \\leq \\gamma \\leq 1\\)\uff09\uff0c\u516c\u5f0f\u4e3a\uff1a\\(G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots\\)    - \u72b6\u6001\u4ef7\u503c\uff08State Value\uff0c\\(v_\\pi(s)\\)\uff09\uff1a\u5728\u7b56\u7565\\(\\pi\\)\u4e0b\uff0c\u4ece\u72b6\u6001\\(s\\)\u51fa\u53d1\u7684\u6298\u6263\u56de\u62a5\u7684\u671f\u671b\uff0c\u5373\\(v_\\pi(s) = \\mathbb{E}_\\pi[G_t | S_t = s]\\)</li> <li>\u56de\u62a5\u62c6\u5206\u5173\u952e\u6b65\u9aa4\uff1a\u5c06\\(G_t\\)\u62c6\u5206\u4e3a\u5373\u65f6\u5956\u52b1\u548c\u672a\u6765\u56de\u62a5\u7684\u6298\u73b0\uff0c\u5373\\(G_t = R_{t+1} + \\gamma G_{t+1}\\)\uff0c\u4e3a\u540e\u7eed\u671f\u671b\u62c6\u5206\u5960\u5b9a\u57fa\u7840\u3002</li> </ol>"},{"location":"notes/RL/Chap2BellmanEquation/#_4","title":"\u4e09\u3001\u8d1d\u5c14\u66fc\u516c\u5f0f\u63a8\u5bfc\u8fc7\u7a0b","text":"<ol> <li> <p>\u7b2c\u4e00\u6b65\uff1a\u62c6\u5206\u671f\u671b\uff08\u57fa\u4e8e\u56de\u62a5\u62c6\u5206\uff09    \u5bf9\u72b6\u6001\u4ef7\u503c\u516c\u5f0f\u4e2d\u7684\u671f\u671b\u8fdb\u884c\u62c6\u5206\uff08\u671f\u671b\u7684\u7ebf\u6027\u6027\u8d28\uff09\uff1a \\(v_\\pi(s) = \\mathbb{E}_\\pi[R_{t+1} + \\gamma G_{t+1} | S_t = s] = \\mathbb{E}_\\pi[R_{t+1} | S_t = s] + \\gamma \\mathbb{E}_\\pi[G_{t+1} | S_t = s]\\)     \u62c6\u5206\u540e\u5f97\u5230\u4e24\u9879\uff1a\u5373\u65f6\u5956\u52b1\u7684\u671f\u671b\u548c\u672a\u6765\u56de\u62a5\u671f\u671b\u7684\u6298\u73b0\u3002</p> </li> <li> <p>\u7b2c\u4e8c\u6b65\uff1a\u8ba1\u7b97\"\u5373\u65f6\u5956\u52b1\u7684\u671f\u671b\"    \u9700\u8003\u8651\u7b56\u7565\\(\\pi\\)\uff08\u72b6\u6001\\(s\\)\u4e0b\u9009\u62e9\u52a8\u4f5c\\(a\\)\u7684\u6982\u7387\\(\\pi(a|s)\\)\uff09\u548c\u73af\u5883\u52a8\u6001\uff08\u52a8\u4f5c\\(a\\)\u4e0b\u83b7\u5f97\u5956\u52b1\\(r\\)\u7684\u6982\u7387\\(p(r|s,a)\\)\uff09\uff0c\u516c\u5f0f\u4e3a\uff1a \\(\\mathbb{E}_\\pi[R_{t+1} | S_t = s] = \\sum_a \\pi(a|s) \\mathbb{E}[R_{t+1}|S_t=s,A_t=a] \\\\ =\\sum_a \\pi(a|s) \\sum_r r \\cdot p(r|s,a)\\)    \u672c\u8d28\u662f\u201c\u7b56\u7565\u4e0b\u6240\u6709\u52a8\u4f5c\u7684\u671f\u671b\u5956\u52b1\u52a0\u6743\u548c\u201d\u3002</p> </li> <li> <p>\u7b2c\u4e09\u6b65\uff1a\u8ba1\u7b97\"\u672a\u6765\u56de\u62a5\u671f\u671b\u7684\u6298\u73b0\" </p> </li> </ol> <ul> <li> <p>\u5229\u7528\u9a6c\u5c14\u53ef\u592b\u6027\u8d28\uff08\u65e0\u8bb0\u5fc6\u6027\uff09\uff1a\u672a\u6765\u56de\u62a5\u4ec5\u4f9d\u8d56\u4e8e\u4e0b\u4e00\u4e2a\u72b6\u6001\\(s'\\)\uff0c\u4e0e\u5f53\u524d\u72b6\u6001\\(s\\)\u65e0\u5173\uff0c\u5373\\(\\mathbb{E}_\\pi[G_{t+1} | S_t = s] = \\mathbb{E}_\\pi[v_\\pi(S_{t+1}) | S_t = s]\\)\u3002  </p> </li> <li> <p>\u7ed3\u5408\u73af\u5883\u52a8\u6001\uff08\u52a8\u4f5c\\(a\\)\u4e0b\u8f6c\u79fb\u5230\u72b6\u6001\\(S_{t+1}s'\\)\u7684\u6982\u7387\\(p(s'|s,a)\\)\uff09\uff0c\u516c\u5f0f\u4e3a\uff1a  </p> <p>$  \\begin{align}  \\mathbb{E}[G_{t+1}|S_t = s] &amp;= \\sum_{s'} \\mathbb{E}[G_{t+1}|S_t = s, S_{t+1} = s']p(s'|s) \\  &amp;= \\sum_{s'} \\mathbb{E}[G_{t+1}|S_{t+1} = s']p(s'|s) \\  &amp;= \\sum_{s'} v_\\pi(s')p(s'|s) \\  &amp;= \\sum_{s'} v_\\pi(s') \\sum_{a} p(s'|s,a)\\pi(a|s) \\ &amp;=\\sum_a\\pi(a|s)\\sum_{s'}p(s'|s,a)v_\\pi(s')  \\end{align}  $</p> </li> </ul> <ol> <li>\u6700\u7ec8\u8d1d\u5c14\u66fc\u516c\u5f0f    \u5408\u5e76\u4e0a\u8ff0\u4e24\u9879\uff0c\u5f97\u5230\u5b8c\u6574\u516c\u5f0f\uff1a \\(v_\\pi(s) = \\sum_a \\pi(a|s) \\left[ \\sum_r r \\cdot p(r|s,a) + \\gamma \\sum_{s'} p(s'|s,a) \\cdot v_\\pi(s') \\right]\\)</li> </ol>"},{"location":"notes/RL/Chap2BellmanEquation/#_5","title":"\u56db\u3001\u8d1d\u5c14\u66fc\u516c\u5f0f\u7684\u5173\u952e\u7279\u6027","text":"<ol> <li>\u591a\u65b9\u7a0b\u6027\uff1a\u5e76\u975e\u5355\u4e00\u516c\u5f0f\uff0c\u800c\u662f\u5bf9\u72b6\u6001\u7a7a\u95f4\u4e2d\u6240\u6709\u72b6\u6001\\(s\\) \u90fd\u6210\u7acb\u3002\u82e5\u6709\\(n\\)\u4e2a\u72b6\u6001\uff0c\u4f1a\u5f62\u6210\\(n\\)\u4e2a\u7ebf\u6027\u65b9\u7a0b\uff0c\u8054\u7acb\u53ef\u89e3\u51fa\u6240\u6709\u72b6\u6001\u4ef7\u503c\u3002</li> <li>\u7b56\u7565\u4f9d\u8d56\u6027\uff1a\u516c\u5f0f\u4e2d\u7684\\(\\pi(a|s)\\)\uff08\u7b56\u7565\uff09\u51b3\u5b9a\u4e86\u72b6\u6001\u4ef7\u503c\u7684\u8ba1\u7b97\u7ed3\u679c\uff0c\u4e0d\u540c\u7b56\u7565\u5bf9\u5e94\u4e0d\u540c\u7684\u72b6\u6001\u4ef7\u503c\uff08\u6838\u5fc3\u7528\u9014\uff1a\u7b56\u7565\u8bc4\u4f30\uff08Policy Evaluation\uff09\uff0c\u5373\u5224\u65ad\u7b56\u7565\u4f18\u52a3\uff09\u3002</li> <li>\u73af\u5883\u52a8\u6001\u4f9d\u8d56\u6027\uff1a\u4f9d\u8d56\\(p(r|s,a)\\)\u548c\\(p(s'|s,a)\\)\uff08\u73af\u5883\u6a21\u578b/\u52a8\u6001\u6a21\u578b\uff09\uff0c\u82e5\u5df2\u77e5\u6a21\u578b\u53ef\u76f4\u63a5\u8ba1\u7b97\uff1b\u82e5\u672a\u77e5\u6a21\u578b\uff0c\u9700\u7528\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\uff08\u5982\u8499\u7279\u5361\u6d1b\u3001\u65f6\u5e8f\u5dee\u5206\uff09\u65b9\u6cd5\u3002</li> <li>\u81ea\u4e3e\u6027\uff08Bootstrapping\uff09\uff1a\u5f53\u524d\u72b6\u6001\u4ef7\u503c\u7684\u8ba1\u7b97\u4f9d\u8d56\u5176\u4ed6\u72b6\u6001\u4ef7\u503c\uff0c\u9700\u901a\u8fc7\u8054\u7acb\u65b9\u7a0b\u6216\u8fed\u4ee3\u65b9\u6cd5\u6c42\u89e3\uff08\u800c\u975e\u76f4\u63a5\u8ba1\u7b97\uff09\u3002</li> </ol>"},{"location":"notes/RL/Chap2BellmanEquation/#_6","title":"\u4e94\u3001\u5b9e\u4f8b\u5e94\u7528\uff08\u57fa\u4e8e\u89c6\u9891\u6848\u4f8b\uff09","text":""},{"location":"notes/RL/Chap2BellmanEquation/#1","title":"\u6848\u4f8b1\uff1a\u5355\u52a8\u4f5c\u3001\u786e\u5b9a\u8f6c\u79fb\u7684\u7b80\u5355\u573a\u666f","text":"<ul> <li>\u8bbe\u5b9a\uff1a\u72b6\u6001\\(s_1\\)\u4e0b\uff0c\u7b56\u7565\\(\\pi(a_3|s_1)=1\\)\uff08\u4ec5\u9009\u52a8\u4f5c\\(a_3\\)\uff09\uff1b\u52a8\u4f5c\\(a_3\\)\u7684\u5956\u52b1\\(r=0\\)\uff08\u6982\u73871\uff09\uff0c\u8f6c\u79fb\u5230\\(s_3\\)\uff08\u6982\u73871\uff09\u3002</li> <li>\u4ee3\u5165\u516c\u5f0f\uff1a   \u5373\u65f6\u5956\u52b1\u671f\u671b=0\uff0c\u672a\u6765\u56de\u62a5\u671f\u671b=\\(v_\\pi(s_3)\\)\uff0c\u6700\u7ec8\u8d1d\u5c14\u66fc\u516c\u5f0f\u7b80\u5316\u4e3a\uff1a\\(v_\\pi(s_1) = 0 + \\gamma \\cdot v_\\pi(s_3)\\)\u3002</li> <li>\u76f4\u89c2\u7ed3\u8bba\uff1a\\(s_1\\)\u7684\u4ef7\u503c\u4ec5\u4f9d\u8d56\\(s_3\\)\u7684\u4ef7\u503c\uff0c\u7b26\u5408\"\u79bb\u76ee\u6807\u72b6\u6001\u8d8a\u8fd1\uff0c\u4ef7\u503c\u8d8a\u9ad8\"\u7684\u903b\u8f91\uff08\u5982\u89c6\u9891\u4e2d\\(s_2/s_3/s_4\\)\u4ef7\u503c\u4e3a10\uff0c\\(s_1\\)\u4ef7\u503c\u4e3a\\(9=\\gamma \\times 10\\)\uff0c\\(\\gamma=0.9\\)\uff09\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#2","title":"\u6848\u4f8b2\uff1a\u591a\u52a8\u4f5c\u3001\u6982\u7387\u8f6c\u79fb\u7684\u573a\u666f","text":"<ul> <li>\u8bbe\u5b9a\uff1a\u72b6\u6001\\(s_1\\)\u4e0b\uff0c\u7b56\u7565\\(\\pi(\u53f3|s_1)=0.5\\)\u3001\\(\\pi(\u4e0b|s_1)=0.5\\)\uff1b\u5411\u53f3\u8f6c\u79fb\u5230\\(s_2\\)\uff08\u5956\u52b1-1\uff09\uff0c\u5411\u4e0b\u8f6c\u79fb\u5230\\(s_3\\)\uff08\u5956\u52b10\uff09\u3002</li> <li>\u4ee3\u5165\u516c\u5f0f\uff1a \\(v_\\pi(s_1) = 0.5 \\times (-1 + \\gamma v_\\pi(s_2)) + 0.5 \\times (0 + \\gamma v_\\pi(s_3))\\)\u3002</li> <li>\u7b56\u7565\u5bf9\u6bd4\uff1a\u8be5\u7b56\u7565\u4e0b\\(s_1\\)\u4ef7\u503c\u4e3a8.9\uff08\\(\\gamma=0.9\\)\uff09\uff0c\u4f4e\u4e8e\u6848\u4f8b1\u4e2d\\(s_1=9\\)\u7684\u4ef7\u503c\uff0c\u8bf4\u660e\"\u542b\u60e9\u7f5a\u52a8\u4f5c\u7684\u7b56\u7565\u66f4\u5dee\"\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#_7","title":"\u516d\u3001\u516c\u5f0f\u7684\u5ef6\u4f38\u610f\u4e49","text":"<ol> <li>\u540e\u7eed\u5e94\u7528\uff1a\u901a\u8fc7\u8d1d\u5c14\u66fc\u516c\u5f0f\u8ba1\u7b97\u51fa\u72b6\u6001\u4ef7\u503c\u540e\uff0c\u53ef\u8fdb\u4e00\u6b65\u6539\u8fdb\u7b56\u7565\uff08\u5982\u9009\u62e9\u80fd\u63d0\u5347\u72b6\u6001\u4ef7\u503c\u7684\u52a8\u4f5c\uff09\uff0c\u6700\u7ec8\u903c\u8fd1\u6700\u4f18\u7b56\u7565\u3002</li> <li>\u4e0e\u65e0\u6a21\u578b\u65b9\u6cd5\u7684\u5173\u8054\uff1a\u82e5\u672a\u77e5\u73af\u5883\u6a21\u578b\uff08\\(p(r|s,a)\\)\u3001\\(p(s'|s,a)\\)\uff09\uff0c\u8d1d\u5c14\u66fc\u516c\u5f0f\u7684\u601d\u60f3\u4ecd\u9002\u7528\uff08\u5982\u65f6\u5e8f\u5dee\u5206\u65b9\u6cd5\u7528\u7ecf\u9a8c\u4f30\u8ba1\u671f\u671b\uff09\uff0c\u662f\u5f3a\u5316\u5b66\u4e60\u7684\u6838\u5fc3\u7406\u8bba\u57fa\u7840\u3002</li> </ol>"},{"location":"notes/RL/Chap2BellmanEquation/#2-","title":"\u7b2c2\u8bfe-\u8d1d\u5c14\u66fc\u516c\u5f0f\uff08\u516c\u5f0f\u5411\u91cf\u5f62\u5f0f\u4e0e\u6c42\u89e3\uff09\u77e5\u8bc6\u70b9\u6574\u7406","text":""},{"location":"notes/RL/Chap2BellmanEquation/#_8","title":"\u4e00\u3001\u8d1d\u5c14\u66fc\u516c\u5f0f\u7684\u77e9\u9635\u5411\u91cf\u5f62\u5f0f\u63a8\u5bfc","text":""},{"location":"notes/RL/Chap2BellmanEquation/#1_1","title":"1. \u63a8\u5bfc\u524d\u63d0","text":"<ul> <li>\u5355\u6761\u8d1d\u5c14\u66fc\u516c\u5f0f\u65e0\u6cd5\u6c42\u89e3\u72b6\u6001\u4ef7\u503c\uff08State Value\uff09\uff0c\u56e0\u516c\u5f0f\u4e2d\u540c\u65f6\u5305\u542b\u5f53\u524d\u72b6\u6001\u4ef7\u503c\u4e0e\u5176\u4ed6\u72b6\u6001\u4ef7\u503c\u3002</li> <li>\u5bf9\u6240\u6709\u72b6\u6001\uff08\u5171n\u4e2a\uff09\u800c\u8a00\uff0c\u9488\u5bf9\u5355\u4e2a\u72b6\u6001\u7684\u8d1d\u5c14\u66fc\u516c\u5f0f\uff08Elementwise Form\uff09\u5747\u6210\u7acb\uff0c\u53ef\u901a\u8fc7\u6574\u5408n\u6761\u516c\u5f0f\u5f97\u5230\u77e9\u9635\u5411\u91cf\u5f62\u5f0f\uff0c\u4fbf\u4e8e\u6c42\u89e3\u4e0e\u7406\u89e3\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#2_1","title":"2. \u6838\u5fc3\u516c\u5f0f\u6f14\u5316","text":"<ul> <li>\u539f\u59cb\u8d1d\u5c14\u66fc\u516c\u5f0f\u7b80\u5316\uff1a\u5c06\u516c\u5f0f\u4e2d\u201c\u5373\u65f6\u5956\u52b1\u9879\u201d\u4e0e\u201c\u72b6\u6001\u8f6c\u79fb\u6982\u7387\u9879\u201d\u5408\u5e76\uff0c\u5f97\u5230\u7b80\u5316\u5f0f\uff1a \\(v^\\pi(s) = r^\\pi(s) + \\gamma \\sum_{s'} P^\\pi(s \\to s') v^\\pi(s')\\) </li> <li>\\(r^\\pi(s)\\)\uff1a\u4ece\u5f53\u524d\u72b6\u6001\\(s\\)\u51fa\u53d1\uff0c\u5373\u65f6\u5956\u52b1\uff08Immediate Reward\uff09\u7684\u5e73\u5747\u503c\u3002  </li> <li>\\(P^\\pi(s \\to s')\\)\uff1a\u4ece\u72b6\u6001\\(s\\)\u8f6c\u79fb\u5230\u72b6\u6001\\(s'\\)\u7684\u6982\u7387\uff08\u57fa\u4e8e\u7b56\u7565\\(\\pi\\)\uff09\u3002</li> <li>\u72b6\u6001\u7f16\u53f7\u4e0e\u5411\u91cf\u5b9a\u4e49\uff1a\u5bf9\u6240\u6709\u72b6\u6001\u6807\u8bb0\u4e3a\\(s_1, s_2, ..., s_n\\)\uff0c\u5b9a\u4e49\u4ee5\u4e0b\u5411\u91cf\u4e0e\u77e9\u9635\uff1a</li> <li>\u72b6\u6001\u4ef7\u503c\u5411\u91cf \\(v^\\pi\\)\uff1a\\(v^\\pi = \\begin{bmatrix} v^\\pi(s_1) \\\\ v^\\pi(s_2) \\\\ ... \\\\ v^\\pi(s_n) \\end{bmatrix}\\)\uff0c\u5305\u542b\u6240\u6709\u72b6\u6001\u7684\u4ef7\u503c\u3002</li> <li>\u5373\u65f6\u5956\u52b1\u5411\u91cf \\(r^\\pi\\)\uff1a\\(r^\\pi = \\begin{bmatrix} r^\\pi(s_1) \\\\ r^\\pi(s_2) \\\\ ... \\\\ r^\\pi(s_n) \\end{bmatrix}\\)\uff0c\u5305\u542b\u6240\u6709\u72b6\u6001\u7684\u5373\u65f6\u5956\u52b1\u5e73\u5747\u503c\u3002</li> <li>\u72b6\u6001\u8f6c\u79fb\u77e9\u9635 \\(P^\\pi\\)\uff08State Transition Matrix\uff09\uff1a     \u77e9\u9635\u5143\u7d20\\([P^\\pi]_{ij}\\)\u8868\u793a\u4ece\u72b6\u6001\\(s_i\\)\u8f6c\u79fb\u5230\u72b6\u6001\\(s_j\\)\u7684\u6982\u7387\uff0c\u5373\\([P^\\pi]_{ij} = P^\\pi(s_i \\to s_j)\\)\u3002</li> <li>\u6700\u7ec8\u77e9\u9635\u5411\u91cf\u5f62\u5f0f\uff1a\\(v^\\pi = r^\\pi + \\gamma P^\\pi v^\\pi\\)</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#3","title":"3. \u5b9e\u4f8b\u8bf4\u660e","text":""},{"location":"notes/RL/Chap2BellmanEquation/#14","title":"\u5b9e\u4f8b1\uff1a\u786e\u5b9a\u6027\u7b56\u7565\uff084\u4e2a\u72b6\u6001\uff09","text":"<ul> <li>\u5373\u65f6\u5956\u52b1\u5411\u91cf\\(r^\\pi\\)\uff1a   \u4ece\\(s_1\\)\u51fa\u53d1\u5373\u65f6\u5956\u52b1\u4e3a0\uff0c\u4ece\\(s_2, s_3, s_4\\)\u51fa\u53d1\u5373\u65f6\u5956\u52b1\u5747\u4e3a1\uff0c\u6545\\(r^\\pi = \\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}\\)\u3002</li> <li>\u72b6\u6001\u8f6c\u79fb\u77e9\u9635\\(P^\\pi\\)\uff1a   \u7b2c\u4e00\u884c\u5bf9\u5e94\\(s_1\\)\u7684\u8f6c\u79fb\u6982\u7387\uff1a\\(s_1 \\to s_1\\)\uff080\uff09\u3001\\(s_1 \\to s_2\\)\uff080\uff09\u3001\\(s_1 \\to s_3\\)\uff081\uff09\u3001\\(s_1 \\to s_4\\)\uff080\uff09\uff0c\u5373\u7b2c\u4e00\u884c\u4e3a\\([0, 0, 1, 0]\\)\uff0c\u5176\u4f59\u884c\u6309\u7b56\u7565\u540c\u7406\u63a8\u5bfc\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#24","title":"\u5b9e\u4f8b2\uff1a\u6982\u7387\u6027\u7b56\u7565\uff084\u4e2a\u72b6\u6001\uff09","text":"<ul> <li>\u5373\u65f6\u5956\u52b1\u5411\u91cf\\(r^\\pi\\)\uff08\u4ee5\\(s_1\\)\u4e3a\u4f8b\uff09\uff1a \\(s_1\\)\u67090.5\u6982\u7387\u5411\u53f3\u8f6c\u79fb\uff08\u5956\u52b1-1\uff09\u30010.5\u6982\u7387\u5411\u4e0b\u8f6c\u79fb\uff08\u5956\u52b10\uff09\uff0c\u6545\\(r^\\pi(s_1) = 0.5 \\times (-1) + 0.5 \\times 0 = -0.5\\)\u3002</li> <li>\u72b6\u6001\u8f6c\u79fb\u77e9\u9635\\(P^\\pi\\)\uff08\u4ee5\\(s_1\\)\u4e3a\u4f8b\uff09\uff1a \\(s_1 \\to s_2\\)\uff080.5\uff09\u3001\\(s_1 \\to s_3\\)\uff080.5\uff09\u3001\\(s_1 \\to s_1\\)\uff080\uff09\u3001\\(s_1 \\to s_4\\)\uff080\uff09\uff0c\u5373\u7b2c\u4e00\u884c\u4e3a\\([0, 0.5, 0.5, 0]\\)\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#vpi","title":"\u4e8c\u3001\u72b6\u6001\u4ef7\u503c\uff08\\(v^\\pi\\)\uff09\u7684\u6c42\u89e3\u65b9\u6cd5","text":""},{"location":"notes/RL/Chap2BellmanEquation/#1_2","title":"1. \u6c42\u89e3\u7684\u6838\u5fc3\u610f\u4e49","text":"<ul> <li>\u8be5\u8fc7\u7a0b\u79f0\u4e3a\u7b56\u7565\u8bc4\u4f30\uff08Policy Evaluation\uff09\uff0c\u662f\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u7840\u5de5\u5177\uff1a\u53ea\u6709\u901a\u8fc7\u8bc4\u4f30\u7b56\u7565\u7684\u72b6\u6001\u4ef7\u503c\uff0c\u624d\u80fd\u5224\u65ad\u7b56\u7565\u4f18\u52a3\uff0c\u8fdb\u800c\u6539\u8fdb\u7b56\u7565\u3001\u627e\u5230\u6700\u4f18\u7b56\u7565\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#2_2","title":"2. \u4e24\u79cd\u6c42\u89e3\u65b9\u6cd5","text":""},{"location":"notes/RL/Chap2BellmanEquation/#1closed-form-solution","title":"\u65b9\u6cd51\uff1a\u89e3\u6790\u89e3\uff08Closed-Form Solution\uff09","text":"<ul> <li>\u516c\u5f0f\u63a8\u5bfc\uff1a\u57fa\u4e8e\u77e9\u9635\u5411\u91cf\u5f62\u5f0f\\(v^\\pi = r^\\pi + \\gamma P^\\pi v^\\pi\\)\uff0c\u79fb\u9879\u6574\u7406\u5f97\uff1a \\((I - \\gamma P^\\pi) v^\\pi = r^\\pi\\)\uff08\\(I\\)\u4e3a\u5355\u4f4d\u77e9\u9635\uff09\uff0c\u4e24\u8fb9\u5de6\u4e58\\((I - \\gamma P^\\pi)^{-1}\\)\uff0c\u6700\u7ec8\u89e3\u6790\u89e3\u4e3a\uff1a \\(v^\\pi = (I - \\gamma P^\\pi)^{-1} r^\\pi\\)\u3002</li> <li>\u5c40\u9650\u6027\uff1a\u4ec5\u7406\u8bba\u4f18\u7f8e\uff0c\u5b9e\u9645\u4e2d\u56e0\u72b6\u6001\u7a7a\u95f4\u5927\u65f6\u77e9\u9635\u7ef4\u5ea6\u9ad8\uff0c\u6c42\u9006\u8ba1\u7b97\u91cf\u6781\u5927\uff0c\u96be\u4ee5\u5e94\u7528\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#2iterative-solution","title":"\u65b9\u6cd52\uff1a\u8fed\u4ee3\u6cd5\uff08Iterative Solution\uff09","text":"<ul> <li>\u6838\u5fc3\u601d\u60f3\uff1a\u901a\u8fc7\u8fed\u4ee3\u66f4\u65b0\u72b6\u6001\u4ef7\u503c\u5411\u91cf\uff0c\u76f4\u81f3\u6536\u655b\u5230\u771f\u5b9e\u503c\\(v^\\pi\\)\u3002</li> <li>\u8fed\u4ee3\u516c\u5f0f\uff1a\\(v_{k+1}^\\pi = r^\\pi + \\gamma P^\\pi v_k^\\pi\\) </li> <li>\\(v_k^\\pi\\)\uff1a\u7b2c\\(k\\)\u6b21\u8fed\u4ee3\u7684\u72b6\u6001\u4ef7\u503c\u5411\u91cf\uff08\u521d\u59cb\u53ef\u8bbe\u4e3a\u51680\u7b49\u4efb\u610f\u503c\uff09\u3002  </li> <li>\\(v_{k+1}^\\pi\\)\uff1a\u7b2c\\(k+1\\)\u6b21\u8fed\u4ee3\u7684\u72b6\u6001\u4ef7\u503c\u5411\u91cf\uff0c\u7531\\(v_k^\\pi\\)\u4ee3\u5165\u516c\u5f0f\u8ba1\u7b97\u5f97\u5230\u3002</li> <li>\u6536\u655b\u6027\uff1a\u53ef\u8bc1\u660e\u5f53\u8fed\u4ee3\u6b21\u6570\\(k \\to \\infty\\)\u65f6\uff0c\\(v_k^\\pi\\)\u6536\u655b\u5230\u771f\u5b9e\u72b6\u6001\u4ef7\u503c\\(v^\\pi\\)\uff08\u901a\u8fc7\u5b9a\u4e49\u8bef\u5dee\\(\\delta_k = \\| v_k^\\pi - v^\\pi \\|\\)\uff0c\u53ef\u8bc1\\(\\delta_k \\to 0\\)\uff09\u3002</li> </ul> <p>Proof. Define the error as \\(\\delta_k = v_k - v_\\pi\\). We only need to show \\(\\delta_k \\to 0\\). </p> <p>Substituting \\(v_{k+1} = \\delta_{k+1} + v_\\pi\\) and \\(v_k = \\delta_k + v_\\pi\\) into \\(v_{k+1} = r_\\pi + \\gamma P_\\pi v_k\\) gives $$ \\delta_{k+1} + v_\\pi = r_\\pi + \\gamma P_\\pi (\\delta_k + v_\\pi), $$ </p> <p>which can be rewritten as</p> <p>$$ \\delta_{k+1} = -v_\\pi + r_\\pi + \\gamma P_\\pi \\delta_k + \\gamma P_\\pi v_\\pi = \\gamma P_\\pi \\delta_k. $$ </p> <p>As a result, $$ \\delta_{k+1} = \\gamma P_\\pi \\delta_k = \\gamma^2 P_\\pi^2 \\delta_{k-1} = \\dots = \\gamma^{k+1} P_\\pi^{k+1} \\delta_0. $$ </p> <p>Note that \\(0 \\leq P_\\pi^k \\leq 1\\), which means every entry of \\(P_\\pi^k\\) is no greater than 1 for any \\(k = 0,1,2,\\dots\\). </p> <p>That is because \\(P_\\pi^k \\mathbf{1} = \\mathbf{1}\\), where \\(\\mathbf{1} = [1,\\dots,1]^T\\). </p> <p>On the other hand, since \\(\\gamma &lt; 1\\), we know \\(\\gamma^k \\to 0\\) and hence \\(\\delta_{k+1} = \\gamma^{k+1} P_\\pi^{k+1} \\delta_0 \\to 0\\) as \\(k \\to \\infty\\).</p> <ol> <li>\u5b9a\u4e49\u8bef\u5dee\u9879\uff1a    \u9996\u5148\u5b9a\u4e49\u8bef\u5dee \\(\\delta_k = v_k - v_\\pi\\)\uff0c\u8fd9\u91cc \\(v_k\\) \u662f\u7b2c \\(k\\) \u6b21\u8fed\u4ee3\u7684\u72b6\u6001\u4ef7\u503c\u5411\u91cf\uff0c\\(v_\\pi\\) \u662f\u7b56\u7565 \\(\\pi\\) \u5bf9\u5e94\u7684\u771f\u5b9e\u72b6\u6001\u4ef7\u503c\u5411\u91cf\u3002\u6211\u4eec\u7684\u76ee\u6807\u662f\u8bc1\u660e\u5f53\u8fed\u4ee3\u6b21\u6570 \\(k\\) \u8d8b\u4e8e\u65e0\u7a77\u65f6\uff0c\\(\\delta_k\\) \u8d8b\u4e8e \\(0\\)\uff0c\u5373\u8fed\u4ee3\u5f97\u5230\u7684 \\(v_k\\) \u6536\u655b\u5230\u771f\u5b9e\u7684 \\(v_\\pi\\)\u3002</li> <li>\u4ee3\u5165\u8fed\u4ee3\u516c\u5f0f\uff1a    \u5df2\u77e5\u8fed\u4ee3\u516c\u5f0f\u4e3a \\(v_{k+1} = r_\\pi + \\gamma P_\\pi v_k\\)\uff08\u5176\u4e2d \\(r_\\pi\\) \u662f\u5373\u65f6\u5956\u52b1\u5411\u91cf\uff0c\\(P_\\pi\\) \u662f\u72b6\u6001\u8f6c\u79fb\u77e9\u9635\uff0c\\(\\gamma\\) \u662f\u6298\u6263\u56e0\u5b50\uff09\u3002\u5c06 \\(v_{k+1} = \\delta_{k+1} + v_\\pi\\) \u548c \\(v_k = \\delta_k + v_\\pi\\) \u4ee3\u5165\u8be5\u8fed\u4ee3\u516c\u5f0f\uff0c\u5f97\u5230\uff1a \\(\\(\\delta_{k+1} + v_\\pi = r_\\pi + \\gamma P_\\pi (\\delta_k + v_\\pi)\\)\\)</li> <li>\u5316\u7b80\u5f97\u5230\u8bef\u5dee\u9012\u63a8\u5173\u7cfb\uff1a    \u5bf9\u4e0a\u8ff0\u7b49\u5f0f\u8fdb\u884c\u6574\u7406\uff0c\u5c06\u542b \\(v_\\pi\\) \u7684\u9879\u79fb\u5230\u7b49\u5f0f\u4e00\u8fb9\uff1a \\(\\(\\delta_{k+1} = -v_\\pi + r_\\pi + \\gamma P_\\pi \\delta_k + \\gamma P_\\pi v_\\pi\\)\\)    \u53c8\u56e0\u4e3a\u771f\u5b9e\u7684\u72b6\u6001\u4ef7\u503c\u5411\u91cf \\(v_\\pi\\) \u6ee1\u8db3\u8d1d\u5c14\u66fc\u65b9\u7a0b \\(v_\\pi = r_\\pi + \\gamma P_\\pi v_\\pi\\)\uff0c\u5373 \\(-v_\\pi + r_\\pi + \\gamma P_\\pi v_\\pi = 0\\)\uff0c\u6240\u4ee5\u4e0a\u5f0f\u53ef\u5316\u7b80\u4e3a\uff1a \\(\\(\\delta_{k+1} = \\gamma P_\\pi \\delta_k\\)\\)</li> <li>\u9012\u63a8\u5c55\u5f00\u8bef\u5dee\u9879\uff1a    \u7531 \\(\\delta_{k+1} = \\gamma P_\\pi \\delta_k\\)\uff0c\u53ef\u4ee5\u4e0d\u65ad\u9012\u63a8\u5f97\u5230\uff1a \\(\\(\\delta_{k+1} = \\gamma P_\\pi \\delta_k = \\gamma^2 P_\\pi^2 \\delta_{k - 1} = \\dots = \\gamma^{k + 1} P_\\pi^{k + 1} \\delta_0\\)\\)    \u8fd9\u91cc \\(\\delta_0 = v_0 - v_\\pi\\) \u662f\u521d\u59cb\u8bef\u5dee\uff08\\(v_0\\) \u4e3a\u521d\u59cb\u7684\u72b6\u6001\u4ef7\u503c\u5411\u91cf\uff09\u3002</li> <li>\u5206\u6790\u6536\u655b\u6027\uff1a    - \u5bf9\u4e8e\u72b6\u6001\u8f6c\u79fb\u77e9\u9635\u7684\u5e42 \\(P_\\pi^k\\)\uff0c\u7531\u4e8e\u72b6\u6001\u8f6c\u79fb\u6982\u7387\u90fd\u662f\u975e\u8d1f\u7684\uff0c\u4e14\u6bcf\u884c\u7684\u548c\u4e3a \\(1\\)\uff08\u56e0\u4e3a\u4ece\u4e00\u4e2a\u72b6\u6001\u8f6c\u79fb\u5230\u6240\u6709\u53ef\u80fd\u72b6\u6001\u7684\u6982\u7387\u548c\u4e3a \\(1\\)\uff09\uff0c\u6240\u4ee5 \\(P_\\pi^k\\) \u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u6ee1\u8db3 \\(0 \\leq [P_\\pi^k]_{ij} \\leq 1\\)\u3002\u5e76\u4e14\u6709 \\(P_\\pi^k \\mathbf{1} = \\mathbf{1}\\)\uff08\u5176\u4e2d \\(\\mathbf{1}\\) \u662f\u5168 \\(1\\) \u5411\u91cf\uff09\uff0c\u8fd9\u4e5f\u9a8c\u8bc1\u4e86 \\(P_\\pi^k\\) \u5143\u7d20\u7684\u6709\u754c\u6027\u3002    - \u5df2\u77e5\u6298\u6263\u56e0\u5b50 \\(\\gamma &lt; 1\\)\uff0c\u6240\u4ee5\u5f53 \\(k \\to \\infty\\) \u65f6\uff0c\\(\\gamma^{k + 1} \\to 0\\)\u3002    - \u7ed3\u5408 \\(P_\\pi^{k + 1}\\) \u5143\u7d20\u7684\u6709\u754c\u6027\uff08\u6bcf\u4e2a\u5143\u7d20\u90fd\u4e0d\u8d85\u8fc7 \\(1\\)\uff09\uff0c\u4ee5\u53ca\u521d\u59cb\u8bef\u5dee \\(\\delta_0\\) \u662f\u6709\u9650\u5411\u91cf\uff0c\u53ef\u5f97 \\(\\gamma^{k + 1} P_\\pi^{k + 1} \\delta_0 \\to 0\\)\uff0c\u5373 \\(\\delta_{k + 1} \\to 0\\)\uff08\u5f53 \\(k \\to \\infty\\) \u65f6\uff09\u3002    \u56e0\u6b64\uff0c\u8fed\u4ee3\u5f97\u5230\u7684\u72b6\u6001\u4ef7\u503c\u5411\u91cf \\(v_k\\) \u6536\u655b\u5230\u771f\u5b9e\u7684\u72b6\u6001\u4ef7\u503c\u5411\u91cf \\(v_\\pi\\)\uff0c\u4ece\u800c\u8bc1\u660e\u4e86\u7528\u8fed\u4ee3\u6cd5\u6c42\u89e3\u72b6\u6001\u4ef7\u503c\u7684\u6536\u655b\u6027\u3002</li> </ol>"},{"location":"notes/RL/Chap2BellmanEquation/#_9","title":"\u4e09\u3001\u7b56\u7565\u8bc4\u4f30\u7684\u5b9e\u4f8b\u4e0e\u7ed3\u8bba","text":""},{"location":"notes/RL/Chap2BellmanEquation/#1_3","title":"1. \u5b9e\u4f8b\u80cc\u666f","text":"<ul> <li>\u5956\u52b1\u89c4\u5219\uff1a\u5c1d\u8bd5\u8df3\u8fc7\u8fb9\u754c/\u8fdb\u5165\u7981\u6b62\u533a\u57df\uff08Forbidden Area\uff09\u5f97-1\uff0c\u8fdb\u5165\u76ee\u6807\u533a\u57df\uff08Target Area\uff09\u5f97+1\uff0c\u5176\u4ed6\u60c5\u51b5\u6309\u7b56\u7565\u5b9a\u3002</li> <li>\u6298\u6263\u56e0\u5b50\\(\\gamma = 0.9\\)\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#2_3","title":"2. \u4e0d\u540c\u7b56\u7565\u7684\u8bc4\u4f30\u7ed3\u679c","text":""},{"location":"notes/RL/Chap2BellmanEquation/#1_4","title":"\uff081\uff09\u4f18\u8d28\u7b56\u7565","text":"<ul> <li>\u7b56\u7565\u7279\u5f81\uff1a\u4e0d\u8df3\u8fb9\u754c\u3001\u4e0d\u649e\u5899\u3001\u4e0d\u8fdb\u7981\u6b62\u533a\u57df\uff0c\u80fd\u5bfc\u5411\u76ee\u6807\u533a\u57df\u3002</li> <li>\u72b6\u6001\u4ef7\u503c\u7279\u5f81\uff1a\u6240\u6709\u72b6\u6001\u4ef7\u503c\u5747\u4e3a\u6b63\u6570\uff1b\u4e14\u79bb\u76ee\u6807\u533a\u57df\u8d8a\u8fd1\uff0c\u72b6\u6001\u4ef7\u503c\u8d8a\u5927\uff08\u7b26\u5408\u76f4\u89c9\uff0c\u8fd1\u76ee\u6807\u533a\u57df\u66f4\u6613\u83b7\u5f97\u9ad8\u5956\u52b1\uff09\u3002</li> <li>\u7279\u6b8a\u7ed3\u8bba\uff1a\u4e0d\u540c\u7b56\u7565\u53ef\u80fd\u5f97\u5230\u76f8\u540c\u72b6\u6001\u4ef7\u503c\uff08\u5982\u67d0\u4e24\u4e2a\u683c\u5b50\u5206\u522b\u201c\u5411\u4e0b\u8d70\u201d\u548c\u201c\u5411\u53f3\u8d70\u201d\uff0c\u6700\u7ec8\u4ef7\u503c\u4e00\u81f4\uff09\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#2_4","title":"\uff082\uff09\u52a3\u8d28\u7b56\u7565","text":"<ul> <li>\u7b56\u75651\uff1a\u6240\u6709\u72b6\u6001\u5747\u201c\u5411\u53f3\u8d70\u201d\uff08\u6613\u649e\u5899/\u8df3\u8fb9\u754c\uff09\uff0c\u72b6\u6001\u4ef7\u503c\u5168\u4e3a\u8d1f\u6570\u3002</li> <li>\u7b56\u75652\uff1a\u968f\u673a\u7b56\u7565\uff08\u591a\u72b6\u6001\u4f1a\u649e\u5899/\u8fdb\u7981\u6b62\u533a\u57df\uff09\uff0c\u72b6\u6001\u4ef7\u503c\u4e0e\u76f4\u89c9\u4e00\u81f4\uff08\u6574\u4f53\u504f\u4f4e\uff09\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#3_1","title":"3. \u6838\u5fc3\u7ed3\u8bba","text":"<p>\u901a\u8fc7\u8ba1\u7b97\u72b6\u6001\u4ef7\u503c\\(v^\\pi\\)\uff0c\u53ef\u76f4\u89c2\u5224\u65ad\u7b56\u7565\u7684\u4f18\u52a3\uff1a\u4f18\u8d28\u7b56\u7565\u5bf9\u5e94\u6b63\u7684\u3001\u8f83\u9ad8\u7684\u72b6\u6001\u4ef7\u503c\uff0c\u52a3\u8d28\u7b56\u7565\u5bf9\u5e94\u8d1f\u7684\u3001\u8f83\u4f4e\u7684\u72b6\u6001\u4ef7\u503c\u3002</p>"},{"location":"notes/RL/Chap2BellmanEquation/#_10","title":"\u56db\u3001\u5173\u952e\u672f\u8bed\u6c47\u603b","text":"\u672f\u8bed \u82f1\u6587 \u6838\u5fc3\u5b9a\u4e49 \u72b6\u6001\u4ef7\u503c State Value\uff08\\(v^\\pi\\)\uff09 \u4ece\u67d0\u72b6\u6001\u51fa\u53d1\uff0c\u57fa\u4e8e\u7b56\u7565\\(\\pi\\)\u7684\u957f\u671f\u5956\u52b1\u671f\u671b \u5373\u65f6\u5956\u52b1\u5411\u91cf Immediate Reward Vector\uff08\\(r^\\pi\\)\uff09 \u6240\u6709\u72b6\u6001\u7684\u5373\u65f6\u5956\u52b1\u5e73\u5747\u503c\u6784\u6210\u7684\u5411\u91cf \u72b6\u6001\u8f6c\u79fb\u77e9\u9635 State Transition Matrix\uff08\\(P^\\pi\\)\uff09 \u5143\u7d20\\([P^\\pi]_{ij}\\)\u8868\u793a\u4ece\\(s_i\\)\u5230\\(s_j\\)\u7684\u8f6c\u79fb\u6982\u7387 \u7b56\u7565\u8bc4\u4f30 Policy Evaluation \u57fa\u4e8e\u8d1d\u5c14\u66fc\u516c\u5f0f\u6c42\u89e3\\(v^\\pi\\)\uff0c\u5224\u65ad\u7b56\u7565\u4f18\u52a3\u7684\u8fc7\u7a0b \u89e3\u6790\u89e3 Closed-Form Solution \u76f4\u63a5\u901a\u8fc7\u77e9\u9635\u6c42\u9006\u5f97\u5230\u7684\\(v^\\pi\\)\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8 \u8fed\u4ee3\u6cd5 Iterative Solution \u901a\u8fc7\u8fed\u4ee3\u66f4\u65b0\\(v^\\pi\\)\u76f4\u81f3\u6536\u655b\uff0c\u5b9e\u9645\u5e94\u7528\u4e2d\u5e38\u7528"},{"location":"notes/RL/Chap2BellmanEquation/#2-action-value","title":"\u7b2c2\u8bfe-\u8d1d\u5c14\u66fc\u516c\u5f0f\uff08Action Value\u7684\u5b9a\u4e49\uff09\u77e5\u8bc6\u70b9\u603b\u7ed3","text":""},{"location":"notes/RL/Chap2BellmanEquation/#action-value","title":"\u6838\u5fc3\u6982\u5ff5\uff1aAction Value\uff08\u52a8\u4f5c\u4ef7\u503c\uff09","text":""},{"location":"notes/RL/Chap2BellmanEquation/#1_5","title":"1. \u5b9a\u4e49","text":"<ul> <li>\u672c\u8d28\uff1a\u667a\u80fd\u4f53\uff08Agent\uff09\u4ece\u5f53\u524d\u72b6\u6001\\(s\\)\u51fa\u53d1\uff0c\u9009\u62e9\u67d0\u4e2a\u52a8\u4f5c\\(a\\)\u540e\uff0c\u540e\u7eed\u9075\u5faa\u7b56\u7565\\(\u03c0\\)\u6240\u80fd\u83b7\u5f97\u7684\u5e73\u5747\u56de\u62a5\uff08Average Return\uff09\u3002</li> <li>\u7b26\u53f7\u8868\u793a\uff1a\\(q_\u03c0(s,a)\\)\uff0c\u5176\u4e2d\uff1a</li> <li>\\(\u03c0\\)\uff1a\u8868\u793a\u5f53\u524d\u9075\u5faa\u7684\u7b56\u7565\uff0c\u4e0d\u540c\u7b56\u7565\u5bf9\u5e94\u4e0d\u540c\u7684\u52a8\u4f5c\u4ef7\u503c\uff1b</li> <li>\\((s,a)\\)\uff1a\u72b6\u6001-\u52a8\u4f5c\u5bf9\uff0c\u52a8\u4f5c\u4ef7\u503c\u4f9d\u8d56\u4e8e\u201c\u4ece\u54ea\u4e2a\u72b6\u6001\u51fa\u53d1\u201d\u548c\u201c\u9009\u62e9\u54ea\u4e2a\u52a8\u4f5c\u201d\uff0c\u662f\u72b6\u6001\u4e0e\u52a8\u4f5c\u7684\u4e8c\u5143\u51fd\u6570\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#2_5","title":"2. \u6838\u5fc3\u4f5c\u7528","text":"<ul> <li>\u52a8\u4f5c\u4ef7\u503c\u662f\u7b56\u7565\u9009\u62e9\u7684\u6838\u5fc3\u4f9d\u636e\uff1a\u5728\u67d0\u4e00\u72b6\u6001\u4e0b\uff0c\u667a\u80fd\u4f53\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u52a8\u4f5c\u7684\\(q_\u03c0(s,a)\\)\uff0c\u4f18\u5148\u9009\u62e9\u4ef7\u503c\u66f4\u5927\u7684\u52a8\u4f5c\uff08\u8be5\u52a8\u4f5c\u80fd\u5e26\u6765\u66f4\u591a\u957f\u671f\u56de\u62a5\uff09\uff1b</li> <li>\u540e\u7eed\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff08\u5982Sarsa\u3001Q-Learning\uff09\u5747\u4ee5\u52a8\u4f5c\u4ef7\u503c\u4e3a\u6838\u5fc3\u5c55\u5f00\uff0c\u662f\u5b9e\u73b0\u7b56\u7565\u4f18\u5316\u7684\u5173\u952e\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#action-valuestate-value","title":"Action Value\u4e0eState Value\uff08\u72b6\u6001\u4ef7\u503c\uff09\u7684\u5173\u7cfb","text":""},{"location":"notes/RL/Chap2BellmanEquation/#1_6","title":"1. \u4e24\u8005\u533a\u522b\u4e0e\u8054\u7cfb","text":"\u7ef4\u5ea6 State Value\uff08\u72b6\u6001\u4ef7\u503c\uff09\\(v_\u03c0(s)\\) Action Value\uff08\u52a8\u4f5c\u4ef7\u503c\uff09\\(q_\u03c0(s,a)\\) \u5b9a\u4e49 \u4ece\u72b6\u6001\\(s\\)\u51fa\u53d1\uff0c\u9075\u5faa\u7b56\u7565\\(\u03c0\\)\u7684\u5e73\u5747\u56de\u62a5 \u4ece\u72b6\u6001\\(s\\)\u51fa\u53d1\u3001\u9009\u62e9\u52a8\u4f5c\\(a\\)\u540e\uff0c\u9075\u5faa\u7b56\u7565\\(\u03c0\\)\u7684\u5e73\u5747\u56de\u62a5 \u4f9d\u8d56\u5bf9\u8c61 \u4ec5\u4f9d\u8d56\u72b6\u6001\\(s\\)\u548c\u7b56\u7565\\(\u03c0\\) \u4f9d\u8d56\u72b6\u6001\\(s\\)\u3001\u52a8\u4f5c\\(a\\)\u548c\u7b56\u7565\\(\u03c0\\) \u6838\u5fc3\u4f5c\u7528 \u8bc4\u4f30\u72b6\u6001\u7684\u201c\u597d\u574f\u201d \u8bc4\u4f30\u201c\u72b6\u6001-\u52a8\u4f5c\u5bf9\u201d\u7684\u201c\u597d\u574f\u201d\uff0c\u76f4\u63a5\u6307\u5bfc\u52a8\u4f5c\u9009\u62e9"},{"location":"notes/RL/Chap2BellmanEquation/#2_6","title":"2. \u6570\u5b66\u5173\u8054\uff08\u6838\u5fc3\u516c\u5f0f\uff09","text":""},{"location":"notes/RL/Chap2BellmanEquation/#1action-valuestate-value","title":"\uff081\uff09\u7531Action Value\u63a8\u5bfcState Value","text":"<p>\u72b6\u6001\u4ef7\u503c\u662f\u8be5\u72b6\u6001\u4e0b\u6240\u6709\u53ef\u80fd\u52a8\u4f5c\u7684\u52a8\u4f5c\u4ef7\u503c\uff0c\u6309\u7b56\u7565\\(\u03c0\\)\u7684\u52a8\u4f5c\u9009\u62e9\u6982\u7387\u52a0\u6743\u5e73\u5747\u7684\u7ed3\u679c\uff1a \\(v_\u03c0(s) = \u03a3_a [\u03c0(a|s) * q_\u03c0(s,a)]\\) </p> <ul> <li>\\(\u03c0(a|s)\\)\uff1a\u7b56\u7565\\(\u03c0\\)\u4e0b\uff0c\u5728\u72b6\u6001\\(s\\)\u9009\u62e9\u52a8\u4f5c\\(a\\)\u7684\u6982\u7387\uff1b</li> <li>\u542b\u4e49\uff1a\u72b6\u6001\u7684\u4ef7\u503c\u7531\u201c\u8be5\u72b6\u6001\u4e0b\u6240\u6709\u53ef\u80fd\u52a8\u4f5c\u7684\u4ef7\u503c\u201d\u53ca\u5176\u201c\u88ab\u9009\u62e9\u7684\u6982\u7387\u201d\u5171\u540c\u51b3\u5b9a\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#2state-valueaction-value","title":"\uff082\uff09\u7531State Value\u63a8\u5bfcAction Value","text":"<p>\u7ed3\u5408\u8d1d\u5c14\u66fc\u516c\u5f0f\uff08\u72b6\u6001\u4ef7\u503c\u7684\u9012\u5f52\u8868\u8fbe\u5f0f\uff09\uff0c\u53ef\u63a8\u5bfc\u51fa\u52a8\u4f5c\u4ef7\u503c\u7684\u8868\u8fbe\u5f0f\uff1a \\(q_\u03c0(s,a) = E[R_{t+1} + \u03b3 * v_\u03c0(S_{t+1}) | S_t=s, A_t=a] = \\sum_r r \\cdot p(r|s,a) + \\gamma \\sum_{s'} p(s'|s,a) \\cdot v_\\pi(s')\\) </p> <ul> <li>\\(R_{t+1}\\)\uff1a\u9009\u62e9\u52a8\u4f5c\\(a\\)\u540e\u83b7\u5f97\u7684\u5373\u65f6\u5956\u52b1\uff1b</li> <li>\\(\u03b3\\)\uff1a\u6298\u6263\u56e0\u5b50\uff08\u8861\u91cf\u672a\u6765\u56de\u62a5\u7684\u91cd\u8981\u6027\uff09\uff1b</li> <li>\\(S_{t+1}\\)\uff1a\u6267\u884c\u52a8\u4f5c\\(a\\)\u540e\u8f6c\u79fb\u5230\u7684\u4e0b\u4e00\u72b6\u6001\uff1b</li> <li>\u542b\u4e49\uff1a\u52a8\u4f5c\u4ef7\u503c = \u5373\u65f6\u5956\u52b1 + \u6298\u6263\u540e\u7684\u4e0b\u4e00\u72b6\u6001\u4ef7\u503c\u7684\u671f\u671b\uff1b</li> <li>\u4e24\u8005\u662f\u201c\u786c\u5e01\u7684\u4e24\u9762\u201d\uff1a\u5df2\u77e5\u6240\u6709\u52a8\u4f5c\u4ef7\u503c\u53ef\u6c42\u72b6\u6001\u4ef7\u503c\uff0c\u53cd\u4e4b\u5df2\u77e5\u6240\u6709\u72b6\u6001\u4ef7\u503c\u4e5f\u53ef\u6c42\u52a8\u4f5c\u4ef7\u503c\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#_11","title":"\u5173\u952e\u6613\u9519\u70b9\u4e0e\u5b9e\u4f8b\u89e3\u6790","text":""},{"location":"notes/RL/Chap2BellmanEquation/#1-action-value0","title":"1. \u6613\u9519\u70b9\uff1a\u672a\u88ab\u7b56\u7565\u9009\u62e9\u7684\u52a8\u4f5c\uff0c\u5176Action Value\u662f\u5426\u4e3a0\uff1f","text":"<ul> <li>\u7ed3\u8bba\uff1a\u5426\u3002\u5373\u4f7f\u7b56\u7565\\(\u03c0\\)\u5728\u72b6\u6001\\(s\\)\u4e0b\u4ec5\u9009\u62e9\u67d0\u4e00\u52a8\u4f5c\uff08\u5982\u4ec5\u9009\\(a2\\)\uff09\uff0c\u5176\u4ed6\u52a8\u4f5c\uff08\u5982\\(a1\\)\u3001\\(a3\\)\uff09\u7684\u52a8\u4f5c\u4ef7\u503c\u4ecd\u9700\u8ba1\u7b97\uff0c\u800c\u975e0\uff1b</li> <li>\u539f\u56e0\uff1a\u540e\u7eed\u7b56\u7565\u4f18\u5316\uff08\u5982\u7b56\u7565\u6539\u8fdb\uff09\u9700\u6bd4\u8f83\u6240\u6709\u52a8\u4f5c\u7684\u4ef7\u503c\uff0c\u53ef\u80fd\u53d1\u73b0\u672a\u88ab\u9009\u62e9\u7684\u52a8\u4f5c\u5b9e\u9645\u4ef7\u503c\u66f4\u9ad8\uff0c\u8fdb\u800c\u66f4\u65b0\u7b56\u7565\uff08\u9009\u62e9\u8be5\u52a8\u4f5c\uff09\u3002</li> </ul>"},{"location":"notes/RL/Chap2BellmanEquation/#2_7","title":"2. \u5b9e\u4f8b\u8ba1\u7b97\uff08\u786e\u5b9a\u6027\u7b56\u7565\u573a\u666f\uff09","text":"<p>\u5047\u8bbe\u573a\u666f\uff1a\u72b6\u6001\\(s1\\)\u6709\u52a8\u4f5c\\(a2\\)\uff08\u7b56\u7565\u6307\u5b9a\u52a8\u4f5c\uff09\u548c\\(a3\\)\uff08\u672a\u88ab\u7b56\u7565\u9009\u62e9\uff09\uff0c\u8f6c\u79fb\u89c4\u5219\u5982\u4e0b\uff1a - \u9009\u62e9\\(a2\\)\uff1a\u5373\u65f6\u5956\u52b1\\(R=-1\\)\uff0c\u8f6c\u79fb\u5230\\(s2\\)\uff0c\\(v_\u03c0(s2)\\)\u5df2\u77e5\uff1b - \u9009\u62e9\\(a3\\)\uff1a\u5373\u65f6\u5956\u52b1\\(R=0\\)\uff0c\u8f6c\u79fb\u5230\\(s3\\)\uff0c\\(v_\u03c0(s3)\\)\u5df2\u77e5\u3002</p> <p>\u5219\u52a8\u4f5c\u4ef7\u503c\u8ba1\u7b97\u4e3a\uff1a - \\(q_\u03c0(s1,a2) = -1 + \u03b3 * v_\u03c0(s2)\\)\uff08\u786e\u5b9a\u6027\u8f6c\u79fb\uff0c\u671f\u671b\u5373\u786e\u5b9a\u503c\uff09\uff1b - \\(q_\u03c0(s1,a3) = 0 + \u03b3 * v_\u03c0(s3)\\)\uff08\u5373\u4f7f\u672a\u88ab\u7b56\u7565\u9009\u62e9\uff0c\u4ecd\u9700\u6309\u516c\u5f0f\u8ba1\u7b97\uff09\u3002</p>"},{"location":"notes/RL/Chap2BellmanEquation/#action-value_1","title":"Action Value\u7684\u8ba1\u7b97\u65b9\u6cd5","text":"<ol> <li>\u95f4\u63a5\u6cd5\uff1a\u5148\u901a\u8fc7\u8d1d\u5c14\u66fc\u516c\u5f0f\u6c42\u89e3\u6240\u6709\u72b6\u6001\u7684\\(v_\u03c0(s)\\)\uff0c\u518d\u4ee3\u5165\u52a8\u4f5c\u4ef7\u503c\u516c\u5f0f\\(q_\u03c0(s,a) = E[R_{t+1} + \u03b3 * v_\u03c0(S_{t+1})]\\)\u8ba1\u7b97\uff1b</li> <li>\u76f4\u63a5\u6cd5\uff1a\u4e0d\u4f9d\u8d56\u72b6\u6001\u4ef7\u503c\uff0c\u76f4\u63a5\u901a\u8fc7\u6570\u636e\uff08\u5982\u8f68\u8ff9\u91c7\u6837\uff09\u4f30\u7b97\u52a8\u4f5c\u4ef7\u503c\uff08\u540e\u7eed\u8499\u7279\u5361\u6d1b\u3001\u65f6\u5e8f\u5dee\u5206\u65b9\u6cd5\u4f1a\u8be6\u7ec6\u8bb2\u89e3\uff09\uff1b</li> <li>\u4e24\u79cd\u65b9\u6cd5\u5747\u652f\u6301\u201c\u57fa\u4e8e\u6a21\u578b\u201d\uff08\u5df2\u77e5\u72b6\u6001\u8f6c\u79fb\u6982\u7387\u548c\u5956\u52b1\u51fd\u6570\uff09\u548c\u201c\u65e0\u6a21\u578b\u201d\uff08\u672a\u77e5\u73af\u5883\u6a21\u578b\uff0c\u4f9d\u8d56\u91c7\u6837\u6570\u636e\uff09\u573a\u666f\u3002</li> </ol> <p>\u603b\u7ed3</p> <ul> <li>State value: $ v_{\\pi}(s) = \\mathbb{E}[G_t | S_t = s] $</li> <li>Action value: $q_{\\pi}(s, a) = \\mathbb{E}[G_t | S_t = s, A_t = a] $</li> <li>The Bellman equation (elementwise form):   $   \\begin{align}   v_{\\pi}(s) &amp;= \\sum_{a} \\pi(a|s) \\underbrace{\\left[ \\sum_{r} p(r|s, a)r + \\gamma \\sum_{s'} p(s'|s, a)v_{\\pi}(s') \\right]}{q \\}(s, a)   &amp;= \\sum_{a} \\pi(a|s) q_{\\pi}(s, a)   \\end{align}   $</li> <li>The Bellman equation (matrix-vector form):   $   v_{\\pi} = r_{\\pi} + \\gamma P_{\\pi} v_{\\pi}   $</li> </ul>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/","title":"Chapter3 Bellman Optimality","text":""},{"location":"notes/RL/Chap3BellmanOptimalEquation/#3-","title":"\u7b2c3\u8bfe-\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\uff08\u6700\u4f18\u7b56\u7565\u548c\u516c\u5f0f\u63a8\u5bfc\uff09\u77e5\u8bc6\u70b9\u6574\u7406","text":"<p> \u7ea6 3475 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 17 \u5206\u949f</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_1","title":"\u4e00\u3001\u6700\u4f18\u7b56\u7565\u7684\u5b9a\u4e49\u4e0e\u6838\u5fc3\u95ee\u9898","text":""},{"location":"notes/RL/Chap3BellmanOptimalEquation/#1","title":"1. \u7b56\u7565\u4f18\u52a3\u7684\u6bd4\u8f83\u6807\u51c6","text":"<ul> <li>\u82e5\u5b58\u5728\u4e24\u4e2a\u7b56\u7565\\(\\pi_1\\)\u548c\\(\\pi_2\\)\uff0c\u5bf9\u4e8e\u6240\u6709\u72b6\u6001\\(s\\)\uff0c\\(\\pi_1\\)\u5bf9\u5e94\u7684\u72b6\u6001\u4ef7\u503c\\(v_{\\pi_1}(s)\\)\u5747\u5927\u4e8e\\(\\pi_2\\)\u5bf9\u5e94\u7684\u72b6\u6001\u4ef7\u503c\\(v_{\\pi_2}(s)\\)\uff0c\u5219\u79f0\\(\\pi_1\\)\u4f18\u4e8e\\(\\pi_2\\)\u3002</li> <li>\u6700\u4f18\u7b56\u7565\\(\\pi^*\\)\u7684\u5b9a\u4e49\uff1a\u5bf9\u4efb\u610f\u72b6\u6001\\(s\\) \u548c\u4efb\u610f\u5176\u4ed6\u7b56\u7565\\(\\pi\\)\uff0c\u5747\u6ee1\u8db3\\(v_{\\pi^*}(s) \\geq v_{\\pi}(s)\\)\uff0c\u5373\\(\\pi^*\\)\u5728\u6240\u6709\u72b6\u6001\u4e0b\u7684\u4ef7\u503c\u90fd\u4e0d\u4f4e\u4e8e\u5176\u4ed6\u4efb\u4f55\u7b56\u7565\u3002</li> </ul>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#2","title":"2. \u6700\u4f18\u7b56\u7565\u7684\u56db\u5927\u6838\u5fc3\u95ee\u9898","text":"<ol> <li>\u5b58\u5728\u6027\uff1a\u662f\u5426\u5b58\u5728\u6ee1\u8db3\u4e0a\u8ff0\u5b9a\u4e49\u7684\u6700\u4f18\u7b56\u7565\\(\\pi^*\\)\uff1f\uff08\u7406\u60f3\u4e2d\u201c\u5168\u72b6\u6001\u4f18\u4e8e\u5176\u4ed6\u7b56\u7565\u201d\u7684\u7b56\u7565\u662f\u5426\u771f\u5b9e\u5b58\u5728\uff1f\uff09</li> <li>\u552f\u4e00\u6027\uff1a\u6700\u4f18\u7b56\u7565\u662f\u552f\u4e00\u7684\uff0c\u8fd8\u662f\u5b58\u5728\u591a\u4e2a\u4e0d\u540c\u4f46\u5747\u6ee1\u8db3\u201c\u6700\u4f18\u201d\u6761\u4ef6\u7684\u7b56\u7565\uff1f</li> <li>\u7b56\u7565\u7c7b\u578b\uff1a\u6700\u4f18\u7b56\u7565\u662f\u786e\u5b9a\u6027\u7b56\u7565\uff08\u67d0\u72b6\u6001\u4e0b\u56fa\u5b9a\u9009\u62e9\u4e00\u4e2a\u52a8\u4f5c\uff09\uff0c\u8fd8\u662f\u968f\u673a\u6027\u7b56\u7565\uff08\u67d0\u72b6\u6001\u4e0b\u6309\u6982\u7387\u9009\u62e9\u591a\u4e2a\u52a8\u4f5c\uff09\uff1f</li> <li>\u6c42\u89e3\u65b9\u6cd5\uff1a\u5982\u4f55\u901a\u8fc7\u6570\u5b66\u5de5\u5177\u63a8\u5bfc\u5e76\u5f97\u5230\u6700\u4f18\u7b56\u7565\\(\\pi^*\\)\uff1f\uff08\u6838\u5fc3\u95ee\u9898\uff0c\u9700\u901a\u8fc7\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u89e3\u7b54\uff09</li> </ol>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_2","title":"\u4e8c\u3001\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f","text":""},{"location":"notes/RL/Chap3BellmanOptimalEquation/#1_1","title":"1. \u516c\u5f0f\u5f62\u5f0f\u4e0e\u6838\u5fc3\u6539\u52a8","text":"<p>\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u662f\u5728\u666e\u901a\u8d1d\u5c14\u66fc\u516c\u5f0f\uff08\u4f9d\u8d56\u7ed9\u5b9a\u7b56\u7565\\(\\pi\\)\uff09\u7684\u57fa\u7840\u4e0a\uff0c\u589e\u52a0\u4e86\u201c\u7b56\u7565\u6700\u5927\u5316\u201d\u64cd\u4f5c\uff0c\u5177\u4f53\u5f62\u5f0f\u5982\u4e0b\uff1a</p> \u516c\u5f0f\u7c7b\u578b \u8868\u8fbe\u5f0f\u6838\u5fc3\u903b\u8f91 \u5173\u952e\u533a\u522b \u666e\u901a\u8d1d\u5c14\u66fc\u516c\u5f0f \\(v_{\\pi}(s) = \\mathbb{E}_{\\pi}\\left[ r + \\gamma v_{\\pi}(s') \\mid s \\right]\\) \u7b56\u7565\\(\\pi\\)\u662f\u7ed9\u5b9a\u7684\uff0c\u4ec5\u9700\u8ba1\u7b97\u8be5\u7b56\u7565\u4e0b\u7684\u72b6\u6001\u4ef7\u503c\\(v_{\\pi}(s)\\) \u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f \\(v_*(s) = \\max_{\\pi} \\mathbb{E}_{\\pi}\\left[ r + \\gamma v_*(s') \\mid s \\right]\\) \u7b56\u7565\\(\\pi\\)\u662f\u5f85\u4f18\u5316\u7684\uff0c\u9700\u5148\u627e\u5230\u4f7f\u4ef7\u503c\u6700\u5927\u7684\\(\\pi\\)\uff0c\u518d\u8ba1\u7b97\u6700\u4f18\u72b6\u6001\u4ef7\u503c\\(v_*(s)\\) <ul> <li>\u7b26\u53f7\u8bf4\u660e\uff1a\\(v_*(s)\\)\u8868\u793a\u201c\u6700\u4f18\u72b6\u6001\u4ef7\u503c\u201d\uff0c\u5373\u6700\u4f18\u7b56\u7565\\(\\pi^*\\)\u5bf9\u5e94\u7684\u72b6\u6001\u4ef7\u503c\uff1b\\(\\max_{\\pi}\\)\u8868\u793a\u5bf9\u6240\u6709\u53ef\u80fd\u7684\u7b56\u7565\u53d6\u6700\u5927\u503c\u3002</li> <li>\u7b80\u5316\u8868\u8fbe\uff1a\u516c\u5f0f\u4e2d\u671f\u671b\u9879\u53ef\u7f29\u5199\u4e3a\u52a8\u4f5c\u4ef7\u503c\\(q(s,a)\\)\uff08\u5373\u72b6\u6001\\(s\\)\u4e0b\u9009\u62e9\u52a8\u4f5c\\(a\\)\u7684\u4ef7\u503c\uff09\uff0c\u56e0\u6b64\u6700\u4f18\u516c\u5f0f\u53ef\u8fdb\u4e00\u6b65\u7b80\u5316\u4e3a\\(v_*(s) = \\max_a q(s,a)\\)\u3002</li> </ul>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#2_1","title":"2. \u5df2\u77e5\u6761\u4ef6\u4e0e\u6c42\u89e3\u76ee\u6807","text":"\u7c7b\u522b \u5177\u4f53\u5185\u5bb9 \u5df2\u77e5\u6761\u4ef6 1. \u72b6\u6001\u8f6c\u79fb\u6982\u7387\\(p(s' \\mid s,a)\\)\uff08\u7cfb\u7edf\u6a21\u578b\u53c2\u6570\uff0c\u63cf\u8ff0\u201c\u72b6\u6001\\(s\\)\u9009\u52a8\u4f5c\\(a\\)\u540e\u8f6c\u79fb\u5230\\(s'\\)\u201d\u7684\u6982\u7387\uff092. \u5373\u65f6\u5956\u52b1\\(r\\)\uff08\u73af\u5883\u53cd\u9988\uff0c\u5982\u201c\u9009\u52a8\u4f5c\\(a\\)\u540e\u83b7\u5f97\u7684\u6536\u76ca/\u60e9\u7f5a\u201d\uff093. \u6298\u6263\u56e0\u5b50\\(\\gamma\\)\uff08\u63a7\u5236\u672a\u6765\u5956\u52b1\u7684\u6743\u91cd\uff0c\\(0 \\leq \\gamma \\leq 1\\)\uff09 \u6c42\u89e3\u76ee\u6807 1. \u6700\u4f18\u72b6\u6001\u4ef7\u503c\\(v_*(s)\\)\uff08\u6240\u6709\u72b6\u6001\u4e0b\u7684\u6700\u4f18\u4ef7\u503c\u5411\u91cf\uff092. \u6700\u4f18\u7b56\u7565\\(\\pi^*\\)\uff08\u4f7f\\(v(s)\\)\u8fbe\u5230\\(v_*(s)\\)\u7684\u7b56\u7565\uff09"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#3","title":"3. \u516c\u5f0f\u7684\u201c\u4f18\u7f8e\u6027\u201d\u4e0e\u201c\u590d\u6742\u6027\u201d","text":"<ul> <li>\u4f18\u7f8e\u6027\uff1a\u5f62\u5f0f\u7b80\u6d01\uff0c\u4ec5\u901a\u8fc7\u201c\\(\\max_{\\pi}\\)\u201d\u64cd\u4f5c\uff0c\u5c31\u5c06\u201c\u6700\u4f18\u7b56\u7565\u201d\u4e0e\u201c\u6700\u4f18\u72b6\u6001\u4ef7\u503c\u201d\u7684\u5173\u7cfb\u523b\u753b\u6e05\u695a\uff0c\u7edf\u4e00\u4e86\u201c\u7b56\u7565\u4f18\u5316\u201d\u4e0e\u201c\u4ef7\u503c\u8ba1\u7b97\u201d\u4e24\u4e2a\u95ee\u9898\u3002</li> <li>\u590d\u6742\u6027\uff1a   1. \u5d4c\u5957\u4f18\u5316\uff1a\u516c\u5f0f\u53f3\u4fa7\u5305\u542b\u201c\u5bf9\u7b56\u7565\\(\\pi\\)\u6c42\u6700\u5927\u503c\u201d\u7684\u4f18\u5316\u95ee\u9898\uff0c\u9700\u5148\u89e3\u51b3\u4f18\u5316\u95ee\u9898\u624d\u80fd\u8ba1\u7b97\\(v_*(s)\\)\uff1b   2. \u53cc\u672a\u77e5\u91cf\uff1a\u8868\u9762\u4e0a\u9700\u540c\u65f6\u6c42\u89e3\\(v_*(s)\\)\uff08\u4ef7\u503c\u5411\u91cf\uff09\u548c\\(\\pi^*\\)\uff08\u7b56\u7565\uff09\uff0c\u521d\u5b66\u8005\u6613\u56f0\u60d1\u201c\u5982\u4f55\u7528\u4e00\u4e2a\u516c\u5f0f\u89e3\u4e24\u4e2a\u672a\u77e5\u91cf\u201d\u3002</li> </ul>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_3","title":"\u4e09\u3001\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u7684\u6c42\u89e3\u601d\u8def\uff08\u6838\u5fc3\u63a8\u5bfc\uff09","text":""},{"location":"notes/RL/Chap3BellmanOptimalEquation/#1_2","title":"1. \u6c42\u89e3\u903b\u8f91\uff1a\u5206\u4e24\u6b65\u62c6\u89e3\u201c\u53cc\u672a\u77e5\u91cf\u201d\u95ee\u9898","text":"<p>\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u7684\u6c42\u89e3\u6838\u5fc3\u662f\u5148\u56fa\u5b9a\u4ef7\u503c\u6c42\u7b56\u7565\uff0c\u518d\u4ee3\u5165\u7b56\u7565\u6c42\u4ef7\u503c\uff0c\u901a\u8fc7\u201c\u5206\u6b65\u62c6\u89e3\u201d\u89e3\u51b3\u201c\u53cc\u672a\u77e5\u91cf\u201d\u56f0\u5883\uff0c\u5177\u4f53\u4ee5\u4e24\u4e2a\u4f8b\u5b50\u8bf4\u660e\uff1a</p> <p>\u76ee\u6807:</p> <p>\\(v(s) = \\max_\\pi \\sum_a \\pi(a|s)(\\sum_r (p|s,a)r+\\gamma \\sum_{s'}p(s'|s,a)v(s')),\\forall s \\in \\mathcal{S} \\\\ = \\max_\\pi \\sum_a \\pi(a|s)q(s,a)\\)</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#1how-to-solve-2-unknowns-from-1-equation","title":"\u4f8b1\uff1aHow to solve 2 unknowns from 1 equation","text":"<p>\u5047\u8bbe\u5b58\u5728\u516c\u5f0f\\(x = \\max_a (2x - 1 - a^2)\\)\uff0c\u9700\u6c42\u89e3\\(x\\)\uff08\u5bf9\u5e94\\(v_*(s)\\)\uff09\u548c\\(a\\)\uff08\u5bf9\u5e94\u7b56\u7565\\(\\pi^*\\)\u7684\u52a8\u4f5c\u9009\u62e9\uff09\uff1a 1. \u7b2c\u4e00\u6b65\uff1a\u56fa\u5b9a\\(x\\)\uff0c\u6c42\u6700\u4f18\\(a\\)\uff1a    \u5bf9\\(a\\)\u6c42\u6700\u5927\u503c\uff0c\u56e0\\(-a^2\\)\u7684\u6700\u5927\u503c\u5728\\(a=0\\)\u65f6\u53d6\u5f97\uff08\u6b64\u65f6\\(-a^2=0\\)\uff09\uff0c\u56e0\u6b64\\(\\max_a (2x - 1 - a^2) = 2x - 1\\)\uff0c\u6700\u4f18\\(a=0\\)\u3002 2. \u7b2c\u4e8c\u6b65\uff1a\u4ee3\u5165\\(a=0\\)\uff0c\u6c42\\(x\\)\uff1a    \u516c\u5f0f\u53d8\u4e3a\\(x = 2x - 1\\)\uff0c\u89e3\u5f97\\(x=1\\)\u3002    \u6700\u7ec8\u7ed3\u679c\uff1a\\(x=1\\)\uff08\u6700\u4f18\u4ef7\u503c\uff09\uff0c\\(a=0\\)\uff08\u6700\u4f18\u52a8\u4f5c\uff09\u3002</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#2-how-to-solve-max_pi-sum_a-piasqsa","title":"\u4f8b2 How to solve \\(\\max_{\\pi} \\sum_{a} \\pi(a|s)q(s,a)\\)","text":"<p>Suppose \\(q_1, q_2, q_3 \\in \\mathbb{R}\\) are given. Find \\(c_1^*, c_2^*, c_3^*\\) solving $$ \\max_{c_1,c_2,c_3} c_1q_1 + c_2q_2 + c_3q_3. $$ where \\(c_1 + c_2 + c_3 = 1\\) and \\(c_1, c_2, c_3 \\geq 0\\).</p> <p>Without loss of generality, suppose \\(q_3 \\geq q_1, q_2\\). Then, the optimal solution is \\(c_3^* = 1\\) and \\(c_1^* = c_2^* = 0\\). That is because for any \\(c_1, c_2, c_3\\) $$ q_3 = (c_1 + c_2 + c_3)q_3 = c_1q_3 + c_2q_3 + c_3q_3 \\geq c_1q_1 + c_2q_2 + c_3q_3. $$</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_4","title":"\u5f3a\u5316\u5b66\u4e60\u573a\u666f\uff08\u6620\u5c04\u5230\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\uff09","text":"<p>\u5047\u8bbe\u67d0\u72b6\u6001\\(s\\)\u4e0b\u67095\u4e2a\u53ef\u80fd\u52a8\u4f5c\\(a_1 \\sim a_5\\)\uff0c\u5bf9\u5e94\u52a8\u4f5c\u4ef7\u503c\\(q(s,a_1) \\sim q(s,a_5)\\)\uff0c\u9700\u6c42\u89e3\\(\\pi^*(s,a)\\)\uff08\u7b56\u7565\uff09\u548c\\(v_*(s)\\)\uff08\u6700\u4f18\u4ef7\u503c\uff09\uff1a 1. \u7b2c\u4e00\u6b65\uff1a\u56fa\u5b9a\\(v_*(s')\\)\uff0c\u6c42\u6700\u4f18\\(\\pi\\)\uff1a    \u52a8\u4f5c\u4ef7\u503c\\(q(s,a) = r + \\gamma \\sum_{s'} p(s' \\mid s,a) v_*(s')\\)\uff0c\u82e5\u6682\u65f6\u56fa\u5b9a\\(v_*(s')\\)\uff08\u53ef\u5148\u8bbe\u521d\u59cb\u503c\uff09\uff0c\u5219\\(q(s,a)\\)\u53ef\u8ba1\u7b97\u3002    \u6700\u4f18\u7b56\u7565\u9700\u6ee1\u8db3\uff1a\u5bf9\u201c\u4f7f\\(q(s,a)\\)\u6700\u5927\u7684\u52a8\u4f5c\\(a^*\\)\u201d\uff0c\u53d6\\(\\pi^*(s,a^*) = 1\\)\uff08\u786e\u5b9a\u6027\u9009\u62e9\u8be5\u52a8\u4f5c\uff09\uff1b\u5bf9\u5176\u4ed6\u52a8\u4f5c\\(a \\neq a^*\\)\uff0c\u53d6\\(\\pi^*(s,a) = 0\\)\u3002    \u6b64\u65f6\\(\\max_{\\pi} \\mathbb{E}_{\\pi}[q(s,a)] = \\max_a q(s,a)\\)\uff08\u5373\u6700\u4f18\u52a8\u4f5c\u5bf9\u5e94\u7684\u52a8\u4f5c\u4ef7\u503c\uff09\u3002 2. \u7b2c\u4e8c\u6b65\uff1a\u4ee3\u5165\u6700\u4f18\\(\\pi\\)\uff0c\u6c42\\(v_*(s)\\)\uff1a    \u6700\u4f18\u72b6\u6001\u4ef7\u503c\\(v_*(s) = \\max_a q(s,a)\\)\uff0c\u5373\u201c\u6700\u4f18\u52a8\u4f5c\u7684\u52a8\u4f5c\u4ef7\u503c\u201d\u5c31\u662f\u8be5\u72b6\u6001\u7684\u6700\u4f18\u72b6\u6001\u4ef7\u503c\u3002</p> <p>Inspired by the above example, considering that \\(\\sum_a \\pi(a|s) = 1\\), </p> <p>we have   \\(\\underbrace{\\max_{\\pi} \\sum_a \\pi(a|s) q(s, a)} = \\underbrace{\\max_{a \\in \\mathcal{A}(s)} q(s, a)},\\) </p> <p>where the optimality is achieved when   \\(\\pi(a|s) = \\begin{cases}  1 &amp; a = a^* \\\\ 0 &amp; a \\neq a^*  \\end{cases}\\)</p> <p>where \\(a^* = \\arg \\max_a q(s, a)\\).</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#2_2","title":"2. \u6838\u5fc3\u7ed3\u8bba","text":"<ul> <li>\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u7684\u6c42\u89e3\u672c\u8d28\u662f\u201c\u8d2a\u5fc3\u7b56\u7565\u201d\uff1a\u5728\u6bcf\u4e2a\u72b6\u6001\u4e0b\uff0c\u9009\u62e9\u80fd\u4f7f\u201c\u5373\u65f6\u5956\u52b1+\u672a\u6765\u6700\u4f18\u4ef7\u503c\u201d\u6700\u5927\u7684\u52a8\u4f5c\uff0c\u8be5\u52a8\u4f5c\u5bf9\u5e94\u7684\u7b56\u7565\u5373\u4e3a\u5c40\u90e8\u6700\u4f18\u7b56\u7565\uff0c\u6240\u6709\u72b6\u6001\u7684\u5c40\u90e8\u6700\u4f18\u7b56\u7565\u6784\u6210\u5168\u5c40\u6700\u4f18\u7b56\u7565\\(\\pi^*\\)\u3002</li> <li>\u6700\u4f18\u7b56\u7565\u7684\u7c7b\u578b\uff1a\u901a\u8fc7\u4e0a\u8ff0\u63a8\u5bfc\u53ef\u77e5\uff0c\u6700\u4f18\u7b56\u7565\u53ef\u8868\u793a\u4e3a\u786e\u5b9a\u6027\u7b56\u7565\uff08\u9009\u62e9\\(q(s,a)\\)\u6700\u5927\u7684\u52a8\u4f5c\uff09\uff0c\u5373\u4f7f\u5b58\u5728\u591a\u4e2a\u52a8\u4f5c\u7684\\(q(s,a)\\)\u76f8\u7b49\uff0c\u4e5f\u53ef\u901a\u8fc7\u201c\u786e\u5b9a\u6027\u9009\u62e9\u5176\u4e2d\u4efb\u610f\u4e00\u4e2a\u201d\u5b9e\u73b0\u6700\u4f18\uff0c\u65e0\u9700\u968f\u673a\u6027\u7b56\u7565\u3002</li> </ul>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_5","title":"\u56db\u3001\u516c\u5f0f\u4e0e\u6700\u4f18\u7b56\u7565\u7684\u5173\u8054","text":"<p>\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u662f\u8fde\u63a5\u201c\u6700\u4f18\u4ef7\u503c\u201d\u4e0e\u201c\u6700\u4f18\u7b56\u7565\u201d\u7684\u6865\u6881\uff1a 1. \u82e5\u5df2\u77e5\u6700\u4f18\u72b6\u6001\u4ef7\u503c\\(v_*(s)\\)\uff0c\u53ef\u901a\u8fc7\\(q(s,a) = r + \\gamma \\sum_{s'} p(s' \\mid s,a) v_*(s')\\)\u8ba1\u7b97\u6240\u6709\u52a8\u4f5c\u4ef7\u503c\uff0c\u518d\u9009\u62e9\\(q(s,a)\\)\u6700\u5927\u7684\u52a8\u4f5c\uff0c\u5f97\u5230\u6700\u4f18\u7b56\u7565\\(\\pi^*\\)\uff1b 2. \u82e5\u5df2\u77e5\u6700\u4f18\u7b56\u7565\\(\\pi^*\\)\uff0c\u53ef\u901a\u8fc7\u666e\u901a\u8d1d\u5c14\u66fc\u516c\u5f0f\\(v_*(s) = \\mathbb{E}_{\\pi^*}\\left[ r + \\gamma v_*(s') \\mid s \\right]\\)\u8ba1\u7b97\u6700\u4f18\u72b6\u6001\u4ef7\u503c\\(v_*(s)\\)\u3002</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#3-_1","title":"\u7b2c3\u8bfe-\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\uff08\u516c\u5f0f\u6c42\u89e3\u4ee5\u53ca\u6700\u4f18\u6027\uff09\u77e5\u8bc6\u70b9\u6574\u7406","text":""},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_6","title":"\u4e00\u3001\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u7684\u7b80\u5316\u5f62\u5f0f","text":"<ol> <li> <p>\u6838\u5fc3\u8f6c\u5316\u903b\u8f91\uff1a\u5c06\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u4e2d\u53f3\u4fa7\u7684\\(max\u03c0\\)\uff08\u5bf9\u7b56\u7565\u7684\u6700\u5927\u5316\uff09\u5b9a\u4e49\u4e3a\u51fd\u6570\\(f(v)\\)\uff0c\u5176\u4e2d\\(v\\)\u4e3a\u72b6\u6001\u503c\u51fd\u6570\uff08State Value\uff09\u3002    - \u5173\u952e\u524d\u63d0\uff1a\u56fa\u5b9a\\(v\\)\u540e\uff0c\u53ef\u6c42\u89e3\u51fa\u5bf9\u5e94\u7b56\u7565\\(\u03c0\\)\uff0c\u6700\u7ec8\u6700\u4f18\u503c\u4ec5\u4e0e\\(v\\)\u76f8\u5173\uff0c\u56e0\u6b64\\(max\u03c0\\)\u7684\u7ed3\u679c\u53ef\u8868\u793a\u4e3a\\(v\\)\u7684\u51fd\u6570\\(f(v)\\)\u3002    - \u7b80\u5316\u540e\u516c\u5f0f\uff1a\\(v = f(v)\\)\uff08\\(f(v)\\)\u4e3a\u5411\u91cf\uff0c\u5411\u91cf\u4e2d\u5bf9\u5e94\u72b6\u6001\\(s\\)\u7684\u5143\u7d20\u5373\u8be5\u72b6\u6001\u4e0b\u7684\u6700\u4f18\u503c\u8ba1\u7b97\u9879\uff09\u3002</p> </li> <li> <p>\\(f(v)\\)\u7684\u5411\u91cf\u5c5e\u6027\uff1a\\(f(v)\\)\u7684\u6bcf\u4e2a\u5143\u7d20\u5bf9\u5e94\u4e00\u4e2a\u72b6\u6001\\(s\\)\uff0c\u63cf\u8ff0\u8be5\u72b6\u6001\u5728\u6700\u4f18\u7b56\u7565\u4e0b\u7684\u4ef7\u503c\uff0c\u9700\u7ed3\u5408\u72b6\u6001\u8f6c\u79fb\u6982\u7387\u3001\u5956\u52b1\u7b49\u5f3a\u5316\u5b66\u4e60\u6838\u5fc3\u8981\u7d20\u8ba1\u7b97\uff08\u627f\u63a5\u524d\u5e8f\u8bfe\u7a0b\u4e2d\u8d1d\u5c14\u66fc\u516c\u5f0f\u7684\u57fa\u7840\u5b9a\u4e49\uff09\u3002</p> </li> </ol>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#contraction-mapping-theorem","title":"\u4e8c\u3001\u6838\u5fc3\u6570\u5b66\u5de5\u5177\uff1a\u6536\u7f29\u6620\u5c04\u5b9a\u7406\uff08Contraction Mapping Theorem\uff09","text":""},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_7","title":"\uff08\u4e00\uff09\u524d\u7f6e\u57fa\u7840\u6982\u5ff5","text":"<ol> <li> <p>\u4e0d\u52a8\u70b9\uff08Fixed Point\uff09    - \u5b9a\u4e49\uff1a\u82e5\u5728\u96c6\u5408\\(X\\)\u4e0a\u5b58\u5728\u70b9\\(x\\)\uff0c\u6620\u5c04\uff08\u51fd\u6570\uff09\\(f\\)\u6ee1\u8db3\\(f(x) = x\\)\uff0c\u5219\\(x\\)\u79f0\u4e3a\\(f\\)\u7684\u4e0d\u52a8\u70b9\u3002    - \u76f4\u89c2\u89e3\u91ca\uff1a\u70b9\\(x\\)\u7ecf\u8fc7\u51fd\u6570\\(f\\)\u6620\u5c04\u540e\u4ecd\u56de\u5230\u81ea\u8eab\uff0c\u201c\u4f4d\u7f6e\u4e0d\u53d8\u201d\u3002</p> </li> <li> <p>\u6536\u7f29\u6620\u5c04\uff08Contraction Mapping / Contractive Function\uff09    - \u5b9a\u4e49\uff1a\u5bf9\u4efb\u610f\u4e24\u4e2a\u70b9\\(x\u2081\\)\u3001\\(x\u2082\\)\uff0c\u82e5\u5b58\u5728\u5e38\u6570\\(\u03b3 &lt; 1\\)\uff08\u6536\u7f29\u56e0\u5b50\uff09\uff0c\u4f7f\u5f97\\(||f(x\u2081) - f(x\u2082)|| \u2264 \u03b3\u00b7||x\u2081 - x\u2082||\\)\uff08\\(||\u00b7||\\)\u8868\u793a\u8303\u6570\uff0c\u8861\u91cf\u201c\u8ddd\u79bb\u201d\uff09\uff0c\u5219\\(f\\)\u4e3a\u6536\u7f29\u6620\u5c04\u3002    - \u76f4\u89c2\u89e3\u91ca\uff1a\u4efb\u610f\u4e24\u70b9\u7ecf\u8fc7\\(f\\)\u6620\u5c04\u540e\uff0c\u5b83\u4eec\u7684\u201c\u8ddd\u79bb\u201d\u4f1a\u88ab\u7f29\u5c0f\uff08\u6536\u7f29\u56e0\u5b50\\(\u03b3\\)\u63a7\u5236\u7f29\u5c0f\u6bd4\u4f8b\uff09\uff0c\u56e0\u6b64\u51fd\u6570\u5177\u6709\u201c\u538b\u7f29\u201d\u7279\u6027\u3002</p> </li> <li> <p>\u793a\u4f8b\u9a8c\u8bc1    | \u6848\u4f8b                             | \u4e0d\u52a8\u70b9\u9a8c\u8bc1                          | \u6536\u7f29\u6620\u5c04\u9a8c\u8bc1                                                 |    | -------------------------------- | ----------------------------------- | ------------------------------------------------------------ |    | \u6807\u91cf\u51fd\u6570\\(f(x) = 0.5x\\)            | \\(f(0) = 0.5\u00d70 = 0\\)\uff0c\u6545\\(x=0\\)\u662f\u4e0d\u52a8\u70b9 | \u5bf9\u4efb\u610f\\(x_1\u3001x_2\\)\uff0c\\(||0.5x_1 - 0.5x_2|| = 0.5\u00d7||x_1 - x_2||\\)\uff0c\u53d6\\(\u03b3=0.5 &lt; 1\\)\uff0c\u6ee1\u8db3\u5b9a\u4e49 |    | \u5411\u91cf\u51fd\u6570\\(f(x) = Ax\\)\uff08\\(A\\)\u4e3a\u77e9\u9635\uff09 | \\(f(0) = A\u00d70 = 0\\)\uff0c\u6545\\(x=0\\)\u662f\u4e0d\u52a8\u70b9   | \u82e5\u77e9\u9635\\(A\\)\u7684\u8303\u6570\\(||A|| &lt; 1\\)\uff0c\u5219\\(||Ax_1 - Ax_2|| \u2264 ||A||\u00b7||x_1 - x_2||\\)\uff0c\u6ee1\u8db3\u5b9a\u4e49 |</p> </li> </ol>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_8","title":"\uff08\u4e8c\uff09\u6536\u7f29\u6620\u5c04\u5b9a\u7406\u7684\u6838\u5fc3\u7ed3\u8bba","text":"<p>\u82e5\\(f\\)\u662f\u6536\u7f29\u6620\u5c04\uff0c\u5219\u65b9\u7a0b\\(x = f(x)\\)\u6ee1\u8db3\u4ee5\u4e0b3\u4e2a\u5173\u952e\u6027\u8d28\uff08\u4e3a\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u6c42\u89e3\u63d0\u4f9b\u7406\u8bba\u4fdd\u969c\uff09\uff1a 1. \u5b58\u5728\u6027\uff08Existence\uff09\uff1a\u5fc5\u7136\u5b58\u5728\u81f3\u5c11\u4e00\u4e2a\u4e0d\u52a8\u70b9\\(x_*\\)\uff0c\u4f7f\u5f97\\(f(x_*) = x_*\\)\uff08\u65e0\u9700\u5173\u6ce8\\(f\\)\u7684\u5177\u4f53\u8868\u8fbe\u5f0f\uff0c\u4ec5\u9700\u786e\u8ba4\u5176\u4e3a\u6536\u7f29\u6620\u5c04\uff09\u3002 2. \u552f\u4e00\u6027\uff08Uniqueness\uff09\uff1a\u4e0a\u8ff0\u4e0d\u52a8\u70b9\\(x_*\\)\u662f\u552f\u4e00\u7684\uff08\u6392\u9664\u201c\u591a\u89e3\u201d\u95ee\u9898\uff0c\u786e\u4fdd\u6700\u4f18\u503c\u7684\u786e\u5b9a\u6027\uff09\u3002 3. \u53ef\u89e3\u6027\uff08Solvability\uff09\uff1a\u53ef\u901a\u8fc7\u8fed\u4ee3\u7b97\u6cd5\u6c42\u89e3\\(x_*\\)\uff0c\u8fed\u4ee3\u516c\u5f0f\u4e3a\\(x_{k+1} = f(x_k)\\)\uff08\\(x_0\\)\u4e3a\u521d\u59cb\u503c\uff09\uff1a    - \u6536\u655b\u6027\uff1a\u5f53\u8fed\u4ee3\u6b21\u6570\\(k\u2192\u221e\\)\u65f6\uff0c\\(x_k\\)\u4f1a\u6536\u655b\u5230\u4e0d\u52a8\u70b9\\(x_*\\)\uff1b    - \u5b9e\u7528\u6027\uff1a\u5b9e\u9645\u8ba1\u7b97\u4e2d\u65e0\u9700\u8fed\u4ee3\u81f3\u65e0\u7a77\u6b21\uff0c\u8fed\u4ee3\u82e5\u5e72\u6b65\u540e\u5373\u53ef\u5f97\u5230\u6ee1\u8db3\u7cbe\u5ea6\u7684\u8fd1\u4f3c\u89e3\uff1b    - \u6536\u655b\u901f\u5ea6\uff1a\u6307\u6570\u7ea7\u6536\u655b\uff08\u6536\u655b\u901f\u5ea6\u5feb\uff0c\u8ba1\u7b97\u6548\u7387\u9ad8\uff09\u3002</p> <p># \u538b\u7f29\u6620\u5c04\u5b9a\u7406\u7684\u8bc1\u660e</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#1-x_k_k1infty-x_k-fx_k-1","title":"\u90e8\u52061\uff1a\u8bc1\u660e\u5e8f\u5217 \\(\\{x_k\\}_{k=1}^\\infty\\)\uff08\u5176\u4e2d \\(x_k = f(x_{k-1})\\)\uff09\u6536\u655b","text":"<p>\u8bc1\u660e\u4f9d\u8d56\u67ef\u897f\u5e8f\u5217\u7684\u6982\u5ff5\uff1a\u82e5\u5e8f\u5217 \\(x_1, x_2, \\dots\\) \u6ee1\u8db3\u201c\u5bf9\u4efb\u610f\u5c0f\u7684 \\(\\varepsilon &gt; 0\\)\uff0c\u5b58\u5728\u6574\u6570 \\(N\\)\uff0c\u4f7f\u5f97\u5bf9\u6240\u6709 \\(m, n &gt; N\\)\uff0c\u6709 \\(\\|x_m - x_n\\| &lt; \\varepsilon\\)\u201d\uff0c\u5219\u79f0\u8be5\u5e8f\u5217\u4e3a\u67ef\u897f\u5e8f\u5217\u3002\u5176\u76f4\u89c2\u542b\u4e49\u662f\u201c\\(N\\) \u4e4b\u540e\u7684\u6240\u6709\u5143\u7d20\u90fd\u8db3\u591f\u63a5\u8fd1\u201d\u3002\u67ef\u897f\u5e8f\u5217\u7684\u6838\u5fc3\u6027\u8d28\u662f\uff1a\u67ef\u897f\u5e8f\u5217\u5fc5\u6536\u655b\u5230\u4e00\u4e2a\u6781\u9650\uff0c\u8fd9\u4e00\u6027\u8d28\u662f\u8bc1\u660e\u7684\u5173\u952e\u3002</p> <p>\u6ce8\u610f\uff1a\u4ec5\u6ee1\u8db3\u201c\u76f8\u90bb\u9879\u5dee\u8d8b\u4e8e0\uff08\\(x_{n+1} - x_n \\to 0\\)\uff09\u201d\u4e0d\u8db3\u4ee5\u8bf4\u660e\u662f\u67ef\u897f\u5e8f\u5217\uff08\u4f8b\u5982 \\(x_n = \\sqrt{n}\\)\uff0c\u867d \\(x_{n+1} - x_n \\to 0\\)\uff0c\u4f46 \\(x_n = \\sqrt{n}\\) \u53d1\u6563\uff09\u3002</p> <p>\u63a5\u4e0b\u6765\u8bc1\u660e \\(\\{x_k = f(x_{k-1})\\}_{k=1}^\\infty\\) \u662f\u67ef\u897f\u5e8f\u5217\uff08\u4ece\u800c\u6536\u655b\uff09\uff1a</p> <ol> <li> <p>\u538b\u7f29\u6620\u5c04\u7684\u9012\u63a8\u4f30\u8ba1\uff1a    \u56e0 \\(f\\) \u662f\u538b\u7f29\u6620\u5c04\uff08\u5b58\u5728\u5e38\u6570 \\(\\gamma\\)\uff0c\\(0 \\leq \\gamma &lt; 1\\)\uff0c\u4f7f\u5f97\u5bf9\u4efb\u610f \\(x, y\\)\uff0c\u6709 \\(\\|f(x) - f(y)\\| \\leq \\gamma \\|x - y\\|\\)\uff09\uff0c\u6545\uff1a    $$    |x_{k+1} - x_k| = |f(x_k) - f(x_{k-1})| \\leq \\gamma |x_k - x_{k-1}|    $$    \u9012\u63a8\u53ef\u5f97\uff1a    $$    |x_k - x_{k-1}| \\leq \\gamma |x_{k-1} - x_{k-2}|, \\quad \\dots, \\quad |x_2 - x_1| \\leq \\gamma |x_1 - x_0|    $$    \u56e0\u6b64\uff0c\u901a\u8fc7\u8fed\u4ee3\u653e\u7f29\uff1a    $$    |x_{k+1} - x_k| \\leq \\gamma^k |x_1 - x_0|    $$    \u7531\u4e8e \\(\\gamma &lt; 1\\)\uff0c\\(\\|x_{k+1} - x_k\\|\\) \u968f \\(k \\to \\infty\\) \u6307\u6570\u7ea7\u6536\u655b\u52300\uff0c\u4f46\u8fd9\u4e0d\u8db3\u4ee5\u76f4\u63a5\u63a8\u51fa \\(\\{x_k\\}\\) \u6536\u655b\uff0c\u9700\u8fdb\u4e00\u6b65\u5206\u6790\u4efb\u610f\u4e24\u9879\u7684\u5dee\u3002</p> </li> <li> <p>\u4efb\u610f\u4e24\u9879\u5dee\u7684\u4f30\u8ba1\uff08\u67ef\u897f\u5e8f\u5217\u5224\u5b9a\uff09\uff1a    \u5bf9\u4efb\u610f \\(m &gt; n\\)\uff0c\u5c06 \\(\\|x_m - x_n\\|\\) \u62c6\u5206\u4e3a\u76f8\u90bb\u9879\u7684\u7d2f\u52a0\u548c\uff1a    $$    |x_m - x_n| = |x_m - x_{m-1} + x_{m-1} - \\dots - x_{n+1} + x_{n+1} - x_n|    $$    \u7531\u8303\u6570\u7684\u4e09\u89d2\u4e0d\u7b49\u5f0f\uff0c\u5f97\uff1a    $$    |x_m - x_n| \\leq |x_m - x_{m-1}| + \\dots + |x_{n+1} - x_n|    $$    \u4ee3\u5165\u201c\\(\\|x_{k+1} - x_k\\| \\leq \\gamma^k \\|x_1 - x_0\\|\\)\u201d\u7684\u4f30\u8ba1\uff0c\u5f97\uff1a    $$    |x_m - x_n| \\leq \\gamma^{m-1} |x_1 - x_0| + \\dots + \\gamma^n |x_1 - x_0|    $$    \u8fd9\u662f\u516c\u6bd4\u4e3a \\(\\gamma\\)\uff08\\(\\gamma &lt; 1\\)\uff09\u7684\u7b49\u6bd4\u6570\u5217\u6c42\u548c\uff0c\u56e0\u6b64\uff1a    $$    |x_m - x_n| \\leq \\gamma^n \\cdot \\frac{1 - \\gamma^{m-n}}{1 - \\gamma} \\cdot |x_1 - x_0| \\leq \\frac{\\gamma^n}{1 - \\gamma} |x_1 - x_0| \\tag{3.4}    $$</p> </li> <li> <p>\u67ef\u897f\u5e8f\u5217\u7684\u7ed3\u8bba\uff1a    \u5bf9\u4efb\u610f \\(\\varepsilon &gt; 0\\)\uff0c\u7531\u4e8e \\(\\gamma^n \\to 0\\)\uff08\u5f53 \\(n \\to \\infty\\)\uff09\uff0c\u603b\u80fd\u627e\u5230 \\(N\\)\uff0c\u4f7f\u5f97\u5bf9\u6240\u6709 \\(m, n &gt; N\\)\uff0c\u6709 \\(\\|x_m - x_n\\| &lt; \\varepsilon\\)\u3002\u56e0\u6b64\uff0c\\(\\{x_k\\}\\) \u662f\u67ef\u897f\u5e8f\u5217\uff0c\u6545\u5fc5\u6536\u655b\u5230\u6781\u9650\u70b9 \\(x^* = \\lim_{k \\to \\infty} x_k\\)\u3002</p> </li> </ol>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#2-x-lim_k-to-infty-x_k","title":"\u90e8\u52062\uff1a\u8bc1\u660e\u6781\u9650 \\(x^* = \\lim_{k \\to \\infty} x_k\\) \u662f\u4e0d\u52a8\u70b9","text":"<p>\u7531\u538b\u7f29\u6620\u5c04\u7684\u4f30\u8ba1\uff0c\\(\\|f(x_k) - x_k\\| = \\|x_{k+1} - x_k\\| \\leq \\gamma^k \\|x_1 - x_0\\|\\)\u3002\u7531\u4e8e \\(\\gamma &lt; 1\\)\uff0c\\(\\|f(x_k) - x_k\\|\\) \u968f \\(k \\to \\infty\\) \u6307\u6570\u7ea7\u6536\u655b\u52300\u3002</p> <p>\u5bf9 \\(f(x_k) - x_k\\) \u53d6\u6781\u9650\uff08\u56e0 \\(f\\) \u8fde\u7eed\uff0c\u6781\u9650\u53ef\u4ea4\u6362\uff09\uff0c\u5f97\uff1a $$ \\lim_{k \\to \\infty} |f(x_k) - x_k| = |f(x^) - x^| = 0 $$ \u6545 \\(f(x^*) = x^*\\)\uff0c\u5373 \\(x^*\\) \u662f\u4e0d\u52a8\u70b9\u3002</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#3_1","title":"\u90e8\u52063\uff1a\u8bc1\u660e\u4e0d\u52a8\u70b9\u552f\u4e00","text":"<p>\u5047\u8bbe\u5b58\u5728\u53e6\u4e00\u4e2a\u4e0d\u52a8\u70b9 \\(x'\\)\uff08\u6ee1\u8db3 \\(f(x') = x'\\)\uff09\uff0c\u5219\u7531\u538b\u7f29\u6620\u5c04\u7684\u5b9a\u4e49\uff1a $$ |x' - x^| = |f(x') - f(x^)| \\leq \\gamma |x' - x^*| $$ \u7531\u4e8e \\(\\gamma &lt; 1\\)\uff0c\u4e0a\u8ff0\u4e0d\u7b49\u5f0f\u6210\u7acb\u5f53\u4e14\u4ec5\u5f53 \\(\\|x' - x^*\\| = 0\\)\uff0c\u6545 \\(x' = x^*\\)\uff0c\u5373\u4e0d\u52a8\u70b9\u552f\u4e00\u3002</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#4-x_k-x","title":"\u90e8\u52064\uff1a\u8bc1\u660e \\(x_k\\) \u6307\u6570\u7ea7\u6536\u655b\u5230 \\(x^*\\)","text":"<p>\u56de\u987e\u5f0f (3.4)\uff1a\u5bf9\u4efb\u610f \\(m &gt; n\\)\uff0c\u6709 \\(\\|x_m - x_n\\| \\leq \\frac{\\gamma^n}{1 - \\gamma} \\|x_1 - x_0\\|\\)\u3002\u4ee4 \\(m \\to \\infty\\)\uff08\u5229\u7528\u6781\u9650\u7684\u4fdd\u5e8f\u6027\uff09\uff0c\u5219\uff1a $$ |x^* - x_n| = \\lim_{m \\to \\infty} |x_m - x_n| \\leq \\frac{\\gamma^n}{1 - \\gamma} |x_1 - x_0| $$ \u7531\u4e8e \\(\\gamma &lt; 1\\)\uff0c\u5f53 \\(n \\to \\infty\\) \u65f6\uff0c\u8bef\u5dee \\(\\|x^* - x_n\\|\\) \u968f \\(\\gamma^n\\) \u6307\u6570\u7ea7\u6536\u655b\u52300\u3002</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_9","title":"\u4e09\u3001\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u7684\u6c42\u89e3\uff08\u57fa\u4e8e\u6536\u7f29\u6620\u5c04\u5b9a\u7406\uff09","text":""},{"location":"notes/RL/Chap3BellmanOptimalEquation/#fv","title":"\uff08\u4e00\uff09\u5173\u952e\u524d\u63d0\uff1a\u8bc1\u660e\\(f(v)\\)\u662f\u6536\u7f29\u6620\u5c04","text":"<p>\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u4e2d\u7684\\(f(v)\\)\u6ee1\u8db3\u6536\u7f29\u6620\u5c04\u5b9a\u4e49\uff0c\u6838\u5fc3\u4f9d\u636e\u662f\u6298\u6263\u56e0\u5b50\\(\u03b3 &lt; 1\\)\uff08\u5f3a\u5316\u5b66\u4e60\u4e2d\\(\u03b3\\)\u7528\u4e8e\u8861\u91cf\u672a\u6765\u5956\u52b1\u7684\u6743\u91cd\uff0c\u901a\u5e38\u53d6\\(0 &lt; \u03b3 &lt; 1\\)\uff09\uff0c\u7531\u6b64\u53ef\u63a8\u5bfc\u51fa\\(||f(v_1) - f(v_2)|| \u2264 \u03b3\u00b7||v_1 - v_2||\\)\uff0c\u6545\\(f(v)\\)\u662f\u6536\u7f29\u6620\u5c04\u3002</p> <p>Proof of Theorem 3.2</p> <p>Consider any two vectors  $v_1, v_2 \\in \\mathbb{R}^{|\\mathcal{S}|} $, and suppose that $ \\pi_1^ \\doteq \\arg\\max_\\pi (r_\\pi + \\gamma P_\\pi v_1)  \\(and\\)  \\pi_2^ \\doteq \\arg\\max_\\pi (r_\\pi + \\gamma P_\\pi v_2) $. Then,</p> \\[ f(v_1) = \\max_\\pi (r_\\pi + \\gamma P_\\pi v_1) = r_{\\pi_1^*} + \\gamma P_{\\pi_1^*} v_1 \\geq r_{\\pi_2^*} + \\gamma P_{\\pi_2^*} v_1, \\] \\[ f(v_2) = \\max_\\pi (r_\\pi + \\gamma P_\\pi v_2) = r_{\\pi_2^*} + \\gamma P_{\\pi_2^*} v_2 \\geq r_{\\pi_1^*} + \\gamma P_{\\pi_1^*} v_2, \\] <p>where \\( \\geq \\) is an elementwise comparison. As a result,</p> \\[ \\begin{align*} f(v_1) - f(v_2) &amp;= r_{\\pi_1^*} + \\gamma P_{\\pi_1^*} v_1 - \\left( r_{\\pi_2^*} + \\gamma P_{\\pi_2^*} v_2 \\right) \\\\ &amp;\\leq r_{\\pi_1^*} + \\gamma P_{\\pi_1^*} v_1 - \\left( r_{\\pi_1^*} + \\gamma P_{\\pi_1^*} v_2 \\right) \\\\ &amp;= \\gamma P_{\\pi_1^*} (v_1 - v_2). \\end{align*} \\] <p>Similarly, it can be shown that $ f(v_2) - f(v_1) \\leq \\gamma P_{\\pi_2^*} (v_2 - v_1) $. Therefore,</p> \\[ \\gamma P_{\\pi_2^*} (v_1 - v_2) \\leq f(v_1) - f(v_2) \\leq \\gamma P_{\\pi_1^*} (v_1 - v_2). \\] <p>Define</p> \\[ z \\doteq \\max \\left\\{ |\\gamma P_{\\pi_2^*} (v_1 - v_2)|, |\\gamma P_{\\pi_1^*} (v_1 - v_2)| \\right\\} \\in \\mathbb{R}^{|\\mathcal{S}|}, \\] <p>where $ \\max(\\cdot) ,  |\\cdot| , and  \\geq $ are all elementwise operators. By definition, $ z \\geq 0 $. On the one hand, it is easy to see that</p> \\[ -z \\leq \\gamma P_{\\pi_2^*} (v_1 - v_2) \\leq f(v_1) - f(v_2) \\leq \\gamma P_{\\pi_1^*} (v_1 - v_2) \\leq z, \\] <p>which implies</p> \\[ |f(v_1) - f(v_2)| \\leq z. \\] <p>It then follows that</p> \\[ \\| f(v_1) - f(v_2) \\|_\\infty \\leq \\| z \\|_\\infty, \\tag{3.5} \\] <p>where $ | \\cdot |_\\infty $ is the maximum norm.</p> <p>On the other hand, suppose that $ z_i $ is the $ i $-th entry of $ z $, and $ p_i^T $ and $ q_i^T $ are the $ i $-th row of $ P_{\\pi_1^} $ and $ P_{\\pi_2^} $, respectively. Then,</p> \\[ z_i = \\max \\left\\{ |\\gamma p_i^T (v_1 - v_2)|, |\\gamma q_i^T (v_1 - v_2)| \\right\\}. \\] <p>Since \\(p_i\\) is a vector with all nonnegative elements and the sum of the elements is equal to one, it follows that</p> \\[ |p_i^T (v_1 - v_2)| \\leq p_i^T |v_1 - v_2| \\leq \\| v_1 - v_2 \\|_\\infty. \\] <p>Similarly, we have $ |q_i^T (v_1 - v_2)| \\leq | v_1 - v_2 |\\infty $. Therefore, $ z_i \\leq \\gamma | v_1 - v_2 |\\infty $ and hence</p> \\[ \\| z \\|_\\infty = \\max_i |z_i| \\leq \\gamma \\| v_1 - v_2 \\|_\\infty. \\] <p>Substituting this inequality gives</p> \\[ \\| f(v_1) - f(v_2) \\|_\\infty \\leq \\gamma \\| v_1 - v_2 \\|_\\infty, \\] <p>which concludes the proof of the contraction property of  \\(f(v)\\).</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#3_2","title":"\uff08\u4e8c\uff09\u6c42\u89e3\u7ed3\u8bba\uff08\u5bf9\u5e94\u6536\u7f29\u6620\u5c04\u5b9a\u7406\u76843\u4e2a\u6027\u8d28\uff09","text":"<ol> <li>\u89e3\u7684\u5b58\u5728\u6027\uff1a\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\\(v = f(v)\\)\u5fc5\u7136\u5b58\u5728\u89e3\uff0c\u8bb0\u4e3a\u6700\u4f18\u72b6\u6001\u503c\u51fd\u6570\\(v*\\)\u3002  </li> <li>\u89e3\u7684\u552f\u4e00\u6027\uff1a\u6700\u4f18\u72b6\u6001\u503c\u51fd\u6570\\(v^*\\)\u662f\u552f\u4e00\u7684\uff08\u4e0d\u5b58\u5728\u591a\u4e2a\u201c\u6700\u4f18\u503c\u201d\uff09\u3002  </li> <li>\u8fed\u4ee3\u6c42\u89e3\u65b9\u6cd5\uff1a\u901a\u8fc7\\(v_{k+1} = f(v_k)\\)\u8fed\u4ee3\u8ba1\u7b97\uff0c\\(v_k\\)\u6700\u7ec8\u4f1a\u6536\u655b\u5230\\(v^*\\)\uff08\u540e\u7eed\u8bfe\u7a0b\u4e2d\u7684\u201c\u503c\u8fed\u4ee3\u7b97\u6cd5\u201d\u5373\u57fa\u4e8e\u6b64\u539f\u7406\uff09\u3002</li> </ol>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_10","title":"\u56db\u3001\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u89e3\u7684\u6700\u4f18\u6027\uff08\u4e0e\u6700\u4f18\u7b56\u7565\u7684\u5173\u8054\uff09","text":""},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_11","title":"\uff08\u4e00\uff09\u6700\u4f18\u7b56\u7565\u7684\u5b9a\u4e49\u4e0e\u63a8\u5bfc","text":"<ol> <li>\u6700\u4f18\u7b56\u7565\\(\u03c0^*\\)\u7684\u5b9a\u4e49\uff1a\u5f53\u72b6\u6001\u503c\u51fd\u6570\u56fa\u5b9a\u4e3a\\(v^*\\)\u65f6\uff0c\u80fd\u4f7f\\(f(v^*) = v^*\\)\u6210\u7acb\u7684\u7b56\u7565\uff0c\u5373\u5bf9\u6bcf\u4e2a\u72b6\u6001\\(s\\)\uff0c\u9009\u62e9\u80fd\u6700\u5927\u5316\u201c\u5373\u65f6\u5956\u52b1 + \u6298\u6263\u540e\u672a\u6765\u4ef7\u503c\u201d\u7684\u52a8\u4f5c\u3002  </li> <li>\u516c\u5f0f\u8f6c\u5316\uff1a\u5c06\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u4e2d\u7684\\(\\max \u03c0\\)\u66ff\u6362\u4e3a\\(\u03c0^*\\)\uff0c\u5f97\u5230\\(v^* = r + \u03b3P_{\u03c0^*}v^*\\)\uff08\\(r\\)\u4e3a\u5956\u52b1\u5411\u91cf\uff0c\\(P_{\u03c0^*}\\)\u4e3a\\(\u03c0^*\\)\u5bf9\u5e94\u7684\u72b6\u6001\u8f6c\u79fb\u6982\u7387\u77e9\u9635\uff09\uff0c\u8be5\u5f0f\u672c\u8d28\u662f\u5bf9\u5e94\u6700\u4f18\u7b56\u7565\\(\u03c0^*\\)\u7684\u8d1d\u5c14\u66fc\u516c\u5f0f\u3002    - \u7ed3\u8bba\uff1a\\(v^*\\)\u5c31\u662f\u6700\u4f18\u7b56\u7565\\(\u03c0^*\\)\u5bf9\u5e94\u7684\u72b6\u6001\u503c\u51fd\u6570\uff0c\u5373\\(v^* = v_{\u03c0^*}\\)\uff08\\(v^\u03c0*\\)\u8868\u793a\u7b56\u7565\\(\u03c0*\\)\u7684\u72b6\u6001\u503c\uff09\u3002</li> </ol>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#v","title":"\uff08\u4e8c\uff09\\(v*\\)\u7684\u6700\u4f18\u6027\u8bc1\u660e","text":"<p>\\(v*\\)\u662f\u6240\u6709\u53ef\u80fd\u7b56\u7565\u5bf9\u5e94\u7684\u72b6\u6001\u503c\u51fd\u6570\u4e2d\u7684\u6700\u5927\u503c\uff1a - \u5bf9\u4efb\u610f\u975e\u6700\u4f18\u7b56\u7565\\(\u03c0\\)\uff0c\u5176\u72b6\u6001\u503c\u51fd\u6570\\(v_\u03c0\\)\u6ee1\u8db3\\(v_\u03c0 \u2264 v^*\\)\uff08\u5373\\(v*\\)\u4f18\u4e8e\u6240\u6709\u975e\u6700\u4f18\u7b56\u7565\u7684\u4ef7\u503c\uff09\uff1b - \u56e0\u6b64\uff0c\\(\u03c0^*\\)\u662f\u6700\u4f18\u7b56\u7565\uff08\u5176\u5bf9\u5e94\u7684\\(v_{\u03c0^*} = v^*\\)\u4e3a\u6700\u5927\u4ef7\u503c\uff09\u3002</p> <p>Proof of Theorem 3.4</p> <p>For any policy $ \\pi $, it holds that</p> \\[ v_\\pi = r_\\pi + \\gamma P_\\pi v_\\pi. \\] <p>Since</p> \\[ v^* = \\max_\\pi (r_\\pi + \\gamma P_\\pi v^*) = r_{\\pi^*} + \\gamma P_{\\pi^*} v^* \\geq r_\\pi + \\gamma P_\\pi v^*, \\] <p>we have</p> \\[ v^* - v_\\pi \\geq (r_\\pi + \\gamma P_\\pi v^*) - (r_\\pi + \\gamma P_\\pi v_\\pi) = \\gamma P_\\pi (v^* - v_\\pi). \\] <p>Repeatedly applying the above inequality gives $ v^ - v_\\pi \\geq \\gamma P_\\pi (v^ - v_\\pi) \\geq \\gamma^2 P_\\pi^2 (v^ - v_\\pi) \\geq \\cdots \\geq \\gamma^n P_\\pi^n (v^ - v_\\pi) $. It follows that</p> \\[ v^* - v_\\pi \\geq \\lim_{n \\to \\infty} \\gamma^n P_\\pi^n (v^* - v_\\pi) = 0, \\] <p>where the last equality is true because $\\gamma &lt; 1 $ and $ P_\\pi^n $ is a nonnegative matrix with all its elements less than or equal to 1 (because $ P_\\pi^n \\mathbf{1} = \\mathbf{1} $) Therefore, $ v^* \\geq v_\\pi $ for any $ \\pi $.</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_12","title":"\uff08\u4e09\uff09\u6700\u4f18\u7b56\u7565\\(\u03c0*\\)\u7684\u5f62\u5f0f","text":"<p>\\(\u03c0*\\)\u662f\u786e\u5b9a\u6027\uff08Deterministic\uff09\u8d2a\u5fc3\u7b56\u7565\uff08Greedy Policy\uff09\uff1a - \u5bf9\u6bcf\u4e2a\u72b6\u6001\\(s\\)\uff0c\\(\u03c0^*\\)\u4f1a\u9009\u62e9\u4f7f\u201c\u52a8\u4f5c\u503c\u51fd\u6570\uff08Action Value\uff09\\(q^*(s,a)\\)\u201d\u6700\u5927\u7684\u52a8\u4f5c\\(a^*\\)\uff1b - \u9009\u62e9\u6982\u7387\uff1a\\(\u03c0^*(a^*|s) = 1\\)\uff08\u5fc5\u7136\u9009\u62e9\u6700\u4f18\u52a8\u4f5c\uff09\uff0c\\(\u03c0^*(a|s) = 0\\)\uff08\u4e0d\u9009\u62e9\u5176\u4ed6\u52a8\u4f5c\uff09\u3002</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#3-_2","title":"\u7b2c3\u8bfe-\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\uff08\u6700\u4f18\u7b56\u7565\u7684\u6709\u8da3\u6027\u8d28\uff09\u77e5\u8bc6\u70b9\u6574\u7406","text":""},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_13","title":"\u4e00\u3001\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u6838\u5fc3\u903b\u8f91","text":"<ol> <li>\u516c\u5f0f\u4f5c\u7528\uff1a\u4f5c\u4e3a\u6c42\u89e3\u5f3a\u5316\u5b66\u4e60\u4e2d\u6700\u4f18\u7b56\u7565\uff08\u03c0*\uff09 \u548c\u6700\u4f18\u72b6\u6001\u4ef7\u503c\uff08v*\uff09 \u7684\u6838\u5fc3\u5de5\u5177\uff0c\u80fd\u76f4\u63a5\u5173\u8054\u5df2\u77e5\u6761\u4ef6\u4e0e\u76ee\u6807\u89e3\uff0c\u4e3a\u7b56\u7565\u4f18\u5316\u63d0\u4f9b\u6570\u5b66\u4f9d\u636e\u3002</li> <li>\u53d8\u91cf\u5173\u7cfb\uff1a    - \u5df2\u77e5\u91cf\uff08\u7ea2\u8272\u53d8\u91cf\uff09\uff1a\u51b3\u5b9a\u6700\u4f18\u7b56\u7565\u7684\u5173\u952e\u8f93\u5165\uff0c\u662f\u6784\u5efa\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u7684\u57fa\u7840\uff0c\u5305\u62ec\u4e09\u7c7b\uff1a<ul> <li>\u7cfb\u7edf\u6a21\u578b\uff08\u6982\u7387P\uff09\uff1a\u63cf\u8ff0\u72b6\u6001\u8f6c\u79fb\u89c4\u5f8b\u7684\u91cf\u5316\u6307\u6807\uff0c\u5373\u4ece\u5f53\u524d\u72b6\u6001s\u6267\u884c\u52a8\u4f5ca\u540e\uff0c\u8f6c\u79fb\u5230\u4e0b\u4e00\u72b6\u6001s'\u7684\u6982\u7387\uff0c\u53cd\u6620\u73af\u5883\u672c\u8eab\u7684\u52a8\u6001\u7279\u6027\u3002</li> <li>\u5956\u52b1\u51fd\u6570\uff08r\uff09\uff1a\u4eba\u5de5\u5b9a\u4e49\u7684\u5956\u60e9\u89c4\u5219\uff0c\u7528\u4e8e\u5f15\u5bfc\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u4f8b\u5982\u5230\u8fbe\u76ee\u6807\u533a\u57df\u5956\u52b1\u4e3a\u6b63\uff08\u5982+1\uff09\u3001\u8fdb\u5165\u7981\u6b62\u533a\u57df\u6216\u649e\u8fb9\u754c\u5956\u52b1\u4e3a\u8d1f\uff08\u5982-1\uff09\u3002</li> <li>\u6298\u6263\u56e0\u5b50\uff08\u03b3\uff09\uff1a\u8c03\u8282\u667a\u80fd\u4f53\u5bf9\u77ed\u671f\u5956\u52b1\u4e0e\u957f\u671f\u5956\u52b1\u91cd\u89c6\u7a0b\u5ea6\u7684\u53c2\u6570\uff0c\u53d6\u503c\u8303\u56f4\u4e3a[0,1)\uff0c\u662f\u5e73\u8861\u5373\u65f6\u6536\u76ca\u4e0e\u672a\u6765\u6536\u76ca\u7684\u6838\u5fc3\u3002</li> <li>\u6c42\u89e3\u91cf\uff08\u9ed1\u8272\u53d8\u91cf\uff09\uff1a\u901a\u8fc7\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u8ba1\u7b97\u5f97\u51fa\u7684\u76ee\u6807\u7ed3\u679c\uff0c\u5373\u80fd\u4f7f\u957f\u671f\u6536\u76ca\u6700\u5927\u5316\u7684\u6700\u4f18\u7b56\u7565\uff08\u03c0\uff09\uff0c\u4ee5\u53ca\u5bf9\u5e94\u7b56\u7565\u4e0b\u5404\u72b6\u6001\u7684\u6700\u4f18\u72b6\u6001\u4ef7\u503c\uff08v\uff09\u3002</li> </ul> </li> </ol>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_14","title":"\u4e8c\u3001\u5f71\u54cd\u6700\u4f18\u7b56\u7565\u7684\u5173\u952e\u56e0\u7d20\uff08\u5b9e\u9a8c\u9a8c\u8bc1\uff09","text":"<p>\u4ee5\u201c\u7f51\u683c\u4e16\u754c\u201d\u4e3a\u5b9e\u9a8c\u573a\u666f\uff08\u5305\u542b\u76ee\u6807\u533a\u57df\u3001\u7981\u6b62\u533a\u57df\u4e0e\u8fb9\u754c\uff09\uff0c\u9a8c\u8bc1\u5956\u52b1\u51fd\u6570\uff08r\uff09 \u548c\u6298\u6263\u56e0\u5b50\uff08\u03b3\uff09 \u5bf9\u6700\u4f18\u7b56\u7565\u7684\u76f4\u63a5\u5f71\u54cd\uff08\u7cfb\u7edf\u6a21\u578b\u901a\u5e38\u7531\u73af\u5883\u51b3\u5b9a\uff0c\u96be\u4ee5\u6539\u53d8\uff0c\u6545\u6682\u4e0d\u8ba8\u8bba\uff09\u3002</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#1_3","title":"1. \u6298\u6263\u56e0\u5b50\uff08\u03b3\uff09\u7684\u5f71\u54cd\uff1a\u63a7\u5236\u667a\u80fd\u4f53\u201c\u77ed\u89c6/\u8fdc\u89c6\u201d\u7279\u6027","text":"<p>\u6298\u6263\u56e0\u5b50\u7684\u5927\u5c0f\u76f4\u63a5\u51b3\u5b9a\u667a\u80fd\u4f53\u5bf9\u672a\u6765\u5956\u52b1\u7684\u6743\u91cd\u5206\u914d\uff0c\u8fdb\u800c\u6539\u53d8\u7b56\u7565\u9009\u62e9\uff0c\u5b9e\u9a8c\u5206\u4e09\u79cd\u5178\u578b\u573a\u666f\uff1a</p> \u6298\u6263\u56e0\u5b50\uff08\u03b3\uff09 \u667a\u80fd\u4f53\u7279\u6027 \u7b56\u7565\u8868\u73b0\uff08\u7f51\u683c\u4e16\u754c\u6848\u4f8b\uff09 \u6838\u5fc3\u539f\u56e0 0.9\uff08\u8f83\u5927\uff09 \u8fdc\u89c6\uff1a\u91cd\u89c6\u957f\u671f\u603b\u6536\u76ca \u4e3b\u52a8\u7a7f\u8fc7\u7981\u6b62\u533a\u57df\uff08\u77ed\u671f\u627f\u53d7-1\u60e9\u7f5a\uff09\uff0c\u5feb\u901f\u62b5\u8fbe\u76ee\u6807\u533a\u57df \u867d\u7136\u7a7f\u8fc7\u7981\u6b62\u533a\u57df\u4f1a\u6709\u77ed\u671f\u60e9\u7f5a\uff0c\u4f46\u80fd\u66f4\u65e9\u83b7\u5f97\u76ee\u6807\u533a\u57df\u7684\u957f\u671f\u5956\u52b1\uff1b\u03b3\u8f83\u5927\u65f6\uff0c\u672a\u6765\u5956\u52b1\u6298\u6263\u5e45\u5ea6\u5c0f\uff0c\u603b\u6536\u76ca\u9ad8\u4e8e\u7ed5\u8def\u65b9\u6848\u3002 0.5\uff08\u4e2d\u7b49\uff09 \u4e2d\u6027\uff1a\u5e73\u8861\u77ed\u671f\u4e0e\u957f\u671f\u6536\u76ca \u7ed5\u5f00\u7981\u6b62\u533a\u57df\uff0c\u9009\u62e9\u66f4\u957f\u8def\u5f84\u524d\u5f80\u76ee\u6807\u533a\u57df \u6b64\u65f6\u7ed5\u8def\u7684\u77ed\u671f\u65e0\u60e9\u7f5a\uff0c\u53e0\u52a0\u672a\u6765\u5956\u52b1\u7684\u6298\u6263\u6548\u5e94\u540e\uff0c\u603b\u6536\u76ca\u8d85\u8fc7\u7a7f\u8fc7\u7981\u6b62\u533a\u57df\u7684\u65b9\u6848\uff0c\u7b56\u7565\u81ea\u7136\u503e\u5411\u89c4\u907f\u98ce\u9669\u3002 0\uff08\u6781\u5c0f\uff09 \u6781\u7aef\u77ed\u89c6\uff1a\u4ec5\u5173\u6ce8\u5373\u65f6\u5956\u52b1 \u539f\u5730\u4e0d\u52a8\u6216\u4ec5\u9009\u62e9\u5373\u65f6\u5956\u52b1\u22650\u7684\u52a8\u4f5c\uff0c\u65e0\u6cd5\u5230\u8fbe\u76ee\u6807\u533a\u57df \u5f53\u03b3=0\u65f6\uff0c\u672a\u6765\u5956\u52b1\u7ecf\u6298\u6263\u540e\u5168\u90e8\u4e3a0\uff0c\u603b\u6536\u76ca\u7b49\u4ef7\u4e8e\u5373\u65f6\u5956\u52b1\uff1b\u667a\u80fd\u4f53\u4ec5\u89c4\u907f\u5373\u65f6\u60e9\u7f5a\uff08\u5982\u649e\u8fb9\u754c\u3001\u8fdb\u7981\u6b62\u533a\uff09\uff0c\u5b8c\u5168\u5ffd\u7565\u957f\u671f\u76ee\u6807\u3002"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#2-r","title":"2. \u5956\u52b1\u51fd\u6570\uff08r\uff09\u7684\u5f71\u54cd\uff1a\u8c03\u6574\u5956\u60e9\u6743\u91cd\u5f15\u5bfc\u884c\u4e3a","text":"<p>\u901a\u8fc7\u6539\u53d8\u201c\u7981\u6b62\u533a\u57df\u201d\u7684\u60e9\u7f5a\u529b\u5ea6\uff0c\u53ef\u76f4\u63a5\u53cd\u8f6c\u667a\u80fd\u4f53\u7684\u7b56\u7565\u9009\u62e9\uff1a - \u539f\u8bbe\u7f6e\uff08\u7981\u6b62\u533a\u57dfr=-1\uff0c\u03b3=0.9\uff09\uff1a\u667a\u80fd\u4f53\u9009\u62e9\u7a7f\u8fc7\u7981\u6b62\u533a\u57df\uff0c\u4ee5\u77ed\u671f\u5c0f\u60e9\u7f5a\u6362\u53d6\u957f\u671f\u9ad8\u6536\u76ca\u3002 - \u8c03\u6574\u540e\uff08\u7981\u6b62\u533a\u57dfr=-10\uff0c\u03b3=0.9\uff09\uff1a\u667a\u80fd\u4f53\u9009\u62e9\u7ed5\u5f00\u7981\u6b62\u533a\u57df\uff0c\u56e0\u77ed\u671f\u5927\u60e9\u7f5a\u7684\u4ee3\u4ef7\u8fdc\u8d85\u957f\u671f\u5956\u52b1\u6536\u76ca\uff0c\u7b56\u7565\u968f\u5956\u60e9\u6743\u91cd\u53d8\u5316\u800c\u53cd\u8f6c\u3002</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_15","title":"\u4e09\u3001\u6700\u4f18\u7b56\u7565\u7684\u4e0d\u53d8\u6027\uff1a\u5956\u52b1\u7ebf\u6027\u53d8\u6362\u4e0d\u6539\u53d8\u7b56\u7565","text":""},{"location":"notes/RL/Chap3BellmanOptimalEquation/#1_4","title":"1. \u6838\u5fc3\u7ed3\u8bba","text":"<p>\u82e5\u5bf9\u6240\u6709\u5956\u52b1\u8fdb\u884c\u7ebf\u6027\u53d8\u6362\uff08\u5373\\(\\(r' = \\alpha \\cdot r + \\beta\\)\\)\uff0c\u5176\u4e2d\\(\\alpha &gt; 0\\)\u4e3a\u6b63\u7684\u7f29\u653e\u56e0\u5b50\uff0c\\(\\beta\\)\u4e3a\u504f\u7f6e\u91cf\uff09\uff0c\u5219\u6700\u4f18\u7b56\u7565\uff08\u03c0*\uff09\u4fdd\u6301\u4e0d\u53d8\uff0c\u4ec5\u6700\u4f18\u72b6\u6001\u4ef7\u503c\uff08v*\uff09\u4f1a\u540c\u6b65\u53d1\u751f\u7ebf\u6027\u53d8\u6362\u3002</p> <p>\u53d8\u6362\u516c\u5f0f\u4e3a\\(v' = \\alpha \\cdot v^* + \\frac{\\beta}{1-\\gamma}\\mathbb{1}\\),\u5176\u4e2d\\(\\gamma\\)\u4e3adiscounted rate\uff0c\\(\\mathbb{1} =[1,1,...,1]^T\\)</p> <p>### Box 3.5: Proof of Theorem 3.6</p> <p>For any policy $ \\pi $, define $ r_\\pi = [\\ldots, r_\\pi(s), \\ldots]^T $ where</p> \\[ r_\\pi(s) = \\sum_{a \\in \\mathcal{A}} \\pi(a|s) \\sum_{r \\in \\mathcal{R}} p(r|s,a) r, \\quad s \\in \\mathcal{S}. \\] <p>If $ r \\to \\alpha r + \\beta $, then $ r_\\pi(s) \\to \\alpha r_\\pi(s) + \\beta $ and hence $ r_\\pi \\to \\alpha r_\\pi + \\beta \\mathbf{1} $, where $ \\mathbf{1} = [1, \\ldots, 1]^T $. In this case, the BOE becomes</p> \\[ v' = \\max_{\\pi \\in \\Pi} (\\alpha r_\\pi + \\beta \\mathbf{1} + \\gamma P_\\pi v'). \\tag{3.9} \\] <p>We next solve the new BOE in (3.9) by showing that $ v' = \\alpha v^ + c \\mathbf{1} $ with $ c = \\beta/(1-\\gamma) $ is a solution of (3.9). In particular, substituting $ v' = \\alpha v^ + c \\mathbf{1} $ into (3.9) gives</p> \\[ \\alpha v^* + c \\mathbf{1} = \\max_{\\pi \\in \\Pi} (\\alpha r_\\pi + \\beta \\mathbf{1} + \\gamma P_\\pi (\\alpha v^* + c \\mathbf{1})) = \\max_{\\pi \\in \\Pi} (\\alpha r_\\pi + \\beta \\mathbf{1} + \\alpha \\gamma P_\\pi v^* + c \\gamma \\mathbf{1}), \\] <p>where the last equality is due to the fact that $ P_\\pi \\mathbf{1} = \\mathbf{1} $. The above equation can be reorganized as</p> \\[ \\alpha v^* = \\max_{\\pi \\in \\Pi} (\\alpha r_\\pi + \\alpha \\gamma P_\\pi v^*) + \\beta \\mathbf{1} + c \\gamma \\mathbf{1} - c \\mathbf{1}, \\] <p>which is equivalent to</p> \\[ \\beta \\mathbf{1} + c \\gamma \\mathbf{1} - c \\mathbf{1} = 0. \\] <p>Since $ c = \\beta/(1-\\gamma) $, the above equation is valid and hence $ v' = \\alpha v^ + c \\mathbf{1} $ is the solution of (3.9). Since (3.9) is the BOE, $ v' $ is also the unique solution. Finally, since $ v' $ is an affine transformation of $ v^$, the relative relationships between the action values remain the same. Hence, the greedy optimal policy derived from  $ v' $is the same as that from $ v^ $: $ \\arg\\max_{\\pi \\in \\Pi} (r_\\pi + \\gamma P_\\pi v') $ is the same as $ \\arg\\max_\\pi (r_\\pi + \\gamma P_\\pi v^) $.</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#2_3","title":"2. \u539f\u7406\u5206\u6790","text":"<p>\u6700\u4f18\u7b56\u7565\u7684\u9009\u62e9\u4f9d\u8d56\u52a8\u4f5c\u4ef7\u503c\uff08Q\u503c\uff09\u7684\u76f8\u5bf9\u5927\u5c0f\uff0c\u800c\u975e\u7edd\u5bf9\u6570\u503c\uff1a - \u7ebf\u6027\u53d8\u6362\u540e\uff0c\u6240\u6709\u52a8\u4f5c\u7684Q\u503c\u4f1a\u540c\u6b65\u8fdb\u884c\u7f29\u653e\u548c\u504f\u79fb\uff08\u4f8b\u5982\u539fQ\u503c\u4e3a[1,2,1]\uff0c\u53d8\u6362\u540e\u53ef\u80fd\u4e3a[100,200,100]\uff09\uff0c\u4f46\u201c\u6700\u5927\u503c\u5bf9\u5e94\u7684\u52a8\u4f5c\u201d\u59cb\u7ec8\u4e0d\u53d8\uff0c\u56e0\u6b64\u7b56\u7565\u4e0d\u4f1a\u6539\u53d8\u3002 - \u793a\u4f8b\u9a8c\u8bc1\uff1a   - \u539f\u5956\u52b1\u89c4\u5219\uff1a\u8fb9\u754c/\u7981\u6b62\u533ar=-1\uff0c\u76ee\u6807\u533a\u57dfr=+1\uff0c\u5176\u4ed6\u6b65\u9aa4r=0\u3002   - \u7ebf\u6027\u53d8\u6362\uff08r'=r+1\uff09\uff1a\u8fb9\u754c/\u7981\u6b62\u533ar'=0\uff0c\u76ee\u6807\u533a\u57dfr'=2\uff0c\u5176\u4ed6\u6b65\u9aa4r'=1\u3002   - \u7ed3\u679c\uff1a\u6700\u4f18\u7b56\u7565\u5b8c\u5168\u4e00\u81f4\uff0c\u4ec5\u72b6\u6001\u4ef7\u503c\u6570\u503c\u53d1\u751f\u53d8\u5316\uff08\u5982\u539fv=5\uff0c\u53d8\u6362\u540e\\(\\(v' = 5 + \\frac{1}{1-0.9} = 15\\)\\)\uff09\u3002</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_16","title":"\u56db\u3001\u6700\u4f18\u7b56\u7565\u7684\u201c\u907f\u7ed5\u6027\u201d\uff1a\u4e3a\u4f55\u4e0d\u505a\u65e0\u610f\u4e49\u7ed5\u8def\uff1f","text":""},{"location":"notes/RL/Chap3BellmanOptimalEquation/#1_5","title":"1. \u95ee\u9898\u80cc\u666f","text":"<p>\u82e5\u201c\u975e\u76ee\u6807/\u975e\u7981\u6b62\u533a\u57df\u201d\u7684\u5956\u52b1r=0\uff08\u65e0\u6b65\u6570\u60e9\u7f5a\uff09\uff0c\u7406\u8bba\u4e0a\u667a\u80fd\u4f53\u53ef\u9009\u62e9\u7ed5\u8def\uff08\u5982s1\u2192s2\u2192s1\u2192\u76ee\u6807\uff09\uff0c\u4f46\u6700\u4f18\u7b56\u7565\u4ecd\u503e\u5411\u6700\u77ed\u8def\u5f84\uff0c\u6838\u5fc3\u539f\u56e0\u4e0e\u6298\u6263\u56e0\u5b50\uff08\u03b3\uff09\u76f8\u5173\u3002</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#2_4","title":"2. \u6838\u5fc3\u539f\u56e0\uff1a\u6298\u6263\u56e0\u5b50\u7684\u201c\u65f6\u95f4\u60e9\u7f5a\u201d\u6548\u5e94","text":"<p>\u7ed5\u8def\u4f1a\u5ef6\u8fdf\u667a\u80fd\u4f53\u5230\u8fbe\u76ee\u6807\u533a\u57df\u7684\u65f6\u95f4\uff0c\u5bfc\u81f4\u201c\u76ee\u6807\u5956\u52b1\u201d\u7684\u6298\u6263\u6b21\u6570\u589e\u52a0\uff1a - \u5047\u8bbe\u03b3=0.9\uff0c\u6700\u77ed\u8def\u5f842\u6b65\u5230\u8fbe\u76ee\u6807\uff0c\u76ee\u6807\u5956\u52b1\u6298\u540e\u4e3a\\(\\(1 \\cdot \\gamma^2 = 0.81\\)\\)\uff1b\u82e5\u7ed5\u8def4\u6b65\u5230\u8fbe\uff0c\u76ee\u6807\u5956\u52b1\u6298\u540e\u4e3a\\(\\(1 \\cdot \\gamma^4 \\approx 0.656\\)\\)\uff0c\u540e\u8005\u6536\u76ca\u663e\u8457\u66f4\u4f4e\u3002 - \u7ed3\u8bba\uff1a\u5373\u4f7f\u65e0\u660e\u786e\u201c\u6b65\u6570\u60e9\u7f5a\u201d\uff0c\u03b3\u7684\u5b58\u5728\u4e5f\u4f1a\u5bf9\u201c\u5ef6\u8fdf\u5956\u52b1\u201d\u4ea7\u751f\u5929\u7136\u7684\u6298\u6263\u6548\u5e94\uff0c\u4f7f\u6700\u4f18\u7b56\u7565\u503e\u5411\u9009\u62e9\u6700\u77ed\u8def\u5f84\uff0c\u907f\u514d\u65e0\u610f\u4e49\u7ed5\u8def\u3002</p>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_17","title":"\u4e94\u3001\u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\u7684\u57fa\u7840\u6027\u8d28\uff08\u56de\u987e\u4e0e\u8865\u5145\uff09","text":"<ol> <li>\u89e3\u7684\u5b58\u5728\u6027\u4e0e\u552f\u4e00\u6027\uff1a    - \u6700\u4f18\u72b6\u6001\u4ef7\u503c\uff08v\uff09\uff1a\u5728\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u6846\u67b6\u4e0b\uff0c\u7531\u538b\u7f29\u6620\u5c04\u5b9a\u7406\uff08Contraction Mapping Theorem\uff09 \u53ef\u8bc1\u660e\u5176\u5b58\u5728\u4e14\u552f\u4e00\u3002    - \u6700\u4f18\u7b56\u7565\uff08\u03c0\uff09\uff1a\u5bf9\u5e94\u6700\u4f18\u72b6\u6001\u4ef7\u503c\uff08v\uff09\u7684\u6700\u4f18\u7b56\u7565\u4e0d\u4e00\u5b9a\u552f\u4e00\uff0c\u53ef\u80fd\u5b58\u5728\u591a\u4e2a\u7b56\u7565\u80fd\u4f7f\u72b6\u6001\u4ef7\u503c\u8fbe\u5230v\u3002</li> <li>\u6c42\u89e3\u65b9\u6cd5\uff1a\u5df2\u4ecb\u7ecd\u7684\u8fed\u4ee3\u7c7b\u7b97\u6cd5\uff08\u503c\u8fed\u4ee3\u3001\u7b56\u7565\u8fed\u4ee3\uff09\u53ef\u901a\u8fc7\u53cd\u590d\u66f4\u65b0\u72b6\u6001\u4ef7\u503c\uff08v\uff09\u548c\u7b56\u7565\uff08\u03c0\uff09\uff0c\u9010\u6b65\u6536\u655b\u5230\u6700\u4f18\u89e3\uff08v\u548c\u03c0\uff09\u3002</li> </ol>"},{"location":"notes/RL/Chap3BellmanOptimalEquation/#_18","title":"\u516d\u3001\u5173\u952e\u603b\u7ed3","text":"<ol> <li>\u6700\u4f18\u7b56\u7565\u7531\u5956\u52b1\u51fd\u6570\uff08r\uff09\u3001\u6298\u6263\u56e0\u5b50\uff08\u03b3\uff09\u3001\u7cfb\u7edf\u6a21\u578b\uff08P\uff09 \u5171\u540c\u51b3\u5b9a\uff0c\u5176\u4e2dr\u548c\u03b3\u662f\u4eba\u5de5\u53ef\u8c03\u63a7\u7684\u6838\u5fc3\u53c2\u6570\uff0c\u9700\u6839\u636e\u4efb\u52a1\u76ee\u6807\u8bbe\u8ba1\u3002</li> <li>\u6298\u6263\u56e0\u5b50\uff08\u03b3\uff09\u63a7\u5236\u667a\u80fd\u4f53\u201c\u77ed\u89c6/\u8fdc\u89c6\u201d\u7279\u6027\uff1a\u03b3\u8d8a\u5927\uff0c\u667a\u80fd\u4f53\u8d8a\u91cd\u89c6\u957f\u671f\u6536\u76ca\uff1b\u03b3\u8d8a\u5c0f\uff0c\u8d8a\u5173\u6ce8\u5373\u65f6\u6536\u76ca\u3002</li> <li>\u5956\u52b1\u7684\u7ebf\u6027\u53d8\u6362\u4e0d\u6539\u53d8\u6700\u4f18\u7b56\u7565\uff0c\u4ec5\u5f71\u54cd\u72b6\u6001\u4ef7\u503c\u6570\u503c\uff0c\u53ef\u5229\u7528\u6b64\u7279\u6027\u7b80\u5316\u5956\u52b1\u8bbe\u8ba1\uff08\u5982\u5c06\u8d1f\u5956\u52b1\u8c03\u6574\u4e3a\u975e\u8d1f\uff0c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff09\u3002</li> <li>\u6298\u6263\u56e0\u5b50\uff08\u03b3\uff09\u5177\u6709\u5929\u7136\u7684\u201c\u53cd\u7ed5\u8def\u201d\u4f5c\u7528\uff0c\u65e0\u9700\u989d\u5916\u8bbe\u8ba1\u201c\u6b65\u6570\u60e9\u7f5a\u201d\uff0c\u5373\u53ef\u5f15\u5bfc\u667a\u80fd\u4f53\u9009\u62e9\u6700\u77ed\u8def\u5f84\u3002</li> </ol>"},{"location":"notes/RL/Chap4VauleIteration/","title":"Chap4VauleIteration","text":"<p> \u7ea6 0 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/","title":"\u503c\u8fed\u4ee3\u7b97\u6cd5\u6838\u5fc3\u57fa\u7840","text":""},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_1","title":"\u503c\u8fed\u4ee3\u7b97\u6cd5\u6838\u5fc3\u57fa\u7840","text":"<p> \u7ea6 3521 \u4e2a\u5b57  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 18 \u5206\u949f</p> <ol> <li> <p>\u7b97\u6cd5\u6765\u6e90\uff1a\u57fa\u4e8e\u7b2c3\u8bfe\u7684 \u8d1d\u5c14\u66fc\u6700\u4f18\u516c\u5f0f\uff0c\u901a\u8fc7 \u201c\u538b\u7f29\u6620\u5c04\u5b9a\u7406\uff08Contraction Mapping Theorem\uff09\u201d \u53ef\u8bc1\u660e\uff1a\u6309\u503c\u8fed\u4ee3\u7b97\u6cd5\u8fed\u4ee3\u5373\u53ef\u6536\u655b\u5230\u6700\u4f18\u7b56\u7565\u4e0e\u6700\u4f18\u72b6\u6001\u503c\uff08Optimal State Value\uff09\u3002</p> </li> <li> <p>\u5173\u952e\u6982\u5ff5\u6f84\u6e05\uff1a\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u7684 \\(\\(v_k\\)\\) \u5e76\u975e\u201c\u72b6\u6001\u503c\uff08State Value\uff09\u201d\uff0c\u800c\u662f\u4e00\u4e2a\u53ef\u4efb\u610f\u521d\u59cb\u5316\u7684 \u5411\u91cf/\u6570\u503c\uff0c\u4ec5\u7528\u4e8e\u9010\u6b65\u903c\u8fd1\u6700\u4f18\u503c\uff0c\u8fd9\u4e5f\u662f\u201c\u503c\u8fed\u4ee3\u201d\u540d\u79f0\u7684\u7531\u6765\u3002</p> </li> </ol>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_2","title":"\u503c\u8fed\u4ee3\u7b97\u6cd5\u6838\u5fc3\u6b65\u9aa4\uff08\u542b\u6570\u5b66\u5f62\u5f0f\u4e0e\u5b9e\u73b0\u903b\u8f91\uff09","text":"<p>\u503c\u8fed\u4ee3\u7b97\u6cd5\u5206\u4e3a \u201c\u7b56\u7565\u66f4\u65b0 (Policy Update)\u201d \u548c \u201c\u503c\u66f4\u65b0 (Value Update)\u201d \u4e24\u6b65\uff0c\u53ef\u7528\u201c\u5143\u7d20\u5f62\u5f0f\uff08\u7f16\u7a0b\u5b9e\u73b0\uff09\u201d\u6765\u7406\u89e3\uff1a</p>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#1","title":"1. \u4e24\u6b65\u6838\u5fc3\u6d41\u7a0b","text":"\u6b65\u9aa4 \u76ee\u6807 \u6570\u5b66\u903b\u8f91\uff08\u5143\u7d20\u5f62\u5f0f\uff09 \u5b9e\u73b0\u5173\u952e\u64cd\u4f5c \u7b56\u7565\u66f4\u65b0 \u57fa\u4e8e\u5f53\u524d \\(\\(v_k\\)\\) \u627e\u5230\u8d2a\u5a6a\u7b56\u7565 \\(\\(\\pi_{k+1}\\)\\) \u5bf9\u6bcf\u4e2a\u72b6\u6001 \\(\\(s\\)\\) \u8ba1\u7b97\u6240\u6709\u52a8\u4f5c \\(\\(a\\)\\) \u7684 Q \u503c\uff1a$$ q_k(s,a) = r(s,a) + \\gamma \\sum_{s'} P(s'\\mid s,a)\\, v_k(s') $$ \u9009\u53d6\u6700\u5927\u503c\u52a8\u4f5c \\(\\(a^*\\)\\) 1. \u904d\u5386\u6240\u6709\u72b6\u6001\uff1b2. \u8ba1\u7b97 \\(\\(q_k(s,a)\\)\\)\uff1b3. \u53d6\u6700\u5927\u503c\u5f62\u6210\u786e\u5b9a\u6027\u7b56\u7565 \u503c\u66f4\u65b0 \u57fa\u4e8e \\(\\(\\pi_{k+1}\\)\\) \u8ba1\u7b97\u65b0\u503c \\(\\(v_{k+1}\\)\\) $$ v_{k+1}(s) = \\max_a q_k(s,a) $$ \u590d\u7528 \\(\\(q_k(s,a)\\)\\) \u53d6\u6700\u5927\u503c\u4f5c\u4e3a \\(\\(v_{k+1}(s)\\)\\)"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#2","title":"2. \u7b97\u6cd5\u7ec8\u6b62\u6761\u4ef6","text":"<p>\u82e5 \\(\\(\\lVert v_{k+1} - v_k \\rVert &lt; \\epsilon\\)\\)\uff08\u5982 \\(\\(\\epsilon=10^{-3}\\)\\)\uff09\u89c6\u4e3a\u6536\u655b\uff0c\u5bf9\u5e94\u7b56\u7565\u5373\u4e3a\u6700\u4f18\u7b56\u7565\u3002</p>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_3","title":"\u503c\u8fed\u4ee3\u7b97\u6cd5\u4f2a\u4ee3\u7801\uff08\u53ef\u6267\u884c\u6846\u67b6\uff09","text":"<ol> <li>\u521d\u59cb\u5316\uff1a\u4efb\u610f\u8bbe\u7f6e\u521d\u59cb\u503c\u5411\u91cf \\(\\(v_0\\)\\)\uff08\u5982\u5168 0\uff09\uff0c\u8bbe\u9608\u503c \\(\\(\\epsilon\\)\\)\u3002</li> <li>\u5faa\u73af\uff08\u76f4\u5230\u6536\u655b\uff09\uff1a\u5bf9\u6bcf\u4e2a\u72b6\u6001 \\(\\(s\\)\\)\uff1a</li> <li>\u8ba1\u7b97\u6bcf\u4e2a\u52a8\u4f5c\uff1a$$ q(s,a) = r(s,a) + \\gamma \\sum_{s'} P(s'\\mid s,a)\\, v_k(s') $$</li> <li>\u7b56\u7565\u66f4\u65b0\uff1a\u53d6\u4f7f \\(\\(q(s,a)\\)\\) \u6700\u5927\u7684\u52a8\u4f5c \\(\\(a^*\\)\\)\uff0c\u4ee4 \\(\\(\\pi_{k+1}(s)=a^*\\)\\)</li> <li>\u503c\u66f4\u65b0\uff1a$$ v_{k+1}(s) = \\max_a q(s,a) $$</li> <li>\u6536\u655b\u5224\u5b9a\uff1a\u82e5\u6240\u6709\u72b6\u6001 \\(\\(|v_{k+1}(s) - v_k(s)| &lt; \\epsilon\\)\\) \u505c\u6b62\uff1b\u5426\u5219 \\(\\(v_k \\leftarrow v_{k+1}\\)\\)\u3002</li> <li>\u8f93\u51fa\uff1a\u6700\u4f18\u7b56\u7565 \\(\\(\\pi^* = \\pi_{k+1}\\)\\)\uff0c\u6700\u4f18\u503c \\(\\(v^* = v_{k+1}\\)\\)\u3002</li> </ol>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_4","title":"\u5b9e\u4f8b\u6f14\u793a\uff08\u7f51\u683c\u4e16\u754c\uff09","text":"<p>\u4ee5\u542b Forbidden Area \u4e0e Target Area \u7684\u7f51\u683c\u4e16\u754c\u4e3a\u4f8b\uff1a</p> <ol> <li>\u521d\u59cb\u5316\uff08\\(\\(k=0\\)\\)\uff09\uff1a\u8bbe \\(\\(v_0=0\\)\\)\uff0c\u8ba1\u7b97\u6240\u6709 \\(\\(q_0(s,a)\\)\\)\uff0c\u5f97\u5230\u521d\u59cb\u8d2a\u5a6a\u7b56\u7565\u4e0e \\(\\(v_1 = \\max_a q_0(s,a)\\)\\)\u3002</li> <li>\u7b2c\u4e00\u6b21\u8fed\u4ee3\uff08\\(\\(k=1\\)\\)\uff09\uff1a\u7528 \\(\\(v_1\\)\\) \u8ba1\u7b97 \\(\\(q_1(s,a)\\)\\)\uff0c\u7b56\u7565\u66f4\u65b0\u540e\u5168\u90e8\u72b6\u6001\u6700\u4f18\uff0c\\(\\(v_2\\)\\) \u6536\u655b\u3002</li> <li>\u7ed3\u8bba\uff1a\u7b80\u5355\u95ee\u9898 2\u20133 \u8f6e\u5373\u53ef\u6536\u655b\uff1b\u590d\u6742\u95ee\u9898\u9700\u66f4\u591a\u8fed\u4ee3\uff0c\u53ea\u8981\u7ec8\u6b62\u6761\u4ef6\u6ee1\u8db3\u5373\u53ef\u5f97\u5230\u6700\u4f18\u89e3\u3002</li> </ol>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_5","title":"\u7f16\u7a0b\u5b9e\u73b0\u63d0\u793a","text":"<ol> <li>Q \u503c\u65e0\u9700\u663e\u5f0f\u5b58\u6574\u5f20\u8868\uff0c\u53ea\u9700\u6309\u9700\u8ba1\u7b97\uff1a$$ q(s,a)= r(s,a)+\\gamma \\sum_{s'} P(s'\\mid s,a) v_k(s') $$\u3002</li> <li>\u591a\u4e2a\u52a8\u4f5c\u5e76\u5217\u6700\u4f18\u65f6\u53ef\u968f\u673a\u9009\u4e00\u4e2a\uff0c\u4e0d\u5f71\u54cd\u6536\u655b\u3002</li> <li>\u5b9e\u8df5\u5e38\u7528\uff1a\u82e5\u6240\u6709\u72b6\u6001 \\(\\(|v_{k+1}(s)-v_k(s)|&lt;\\epsilon\\)\\) \u5219\u505c\u6b62\u3002</li> </ol>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#4-","title":"\u7b2c4\u8bfe - \u503c\u8fed\u4ee3\u4e0e\u7b56\u7565\u8fed\u4ee3\uff08\u7b56\u7565\u8fed\u4ee3\u7b97\u6cd5\uff09\u77e5\u8bc6\u70b9\u6574\u7406","text":""},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_6","title":"\u4e00\u3001\u8bfe\u7a0b\u5b9a\u4f4d\u4e0e\u7b97\u6cd5\u5173\u8054","text":"<ol> <li>\u77e5\u8bc6\u627f\u63a5\uff1a\u7b56\u7565\u8fed\u4ee3\uff08Policy Iteration\uff09\u662f\u5f3a\u5316\u5b66\u4e60\u4e2d Model-Based \u6838\u5fc3\u7b97\u6cd5\uff0c\u4e0a\u627f\u8d1d\u5c14\u66fc\u65b9\u7a0b\uff08\u7b56\u7565\u8bc4\u4f30\uff09\uff0c\u4e0b\u63a5\u201c\u622a\u65ad\u7b56\u7565\u8fed\u4ee3\u201d\uff0c\u4e5f\u662f\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u7684\u57fa\u7840\u3002</li> <li>\u4e0e\u503c\u8fed\u4ee3\u7684\u5173\u7cfb\uff1a\u7b56\u7565\u8fed\u4ee3\u4e0e\u503c\u8fed\u4ee3\u662f\u201c\u622a\u65ad\u7b56\u7565\u8fed\u4ee3\u201d\u7684\u4e24\u4e2a\u7aef\u70b9\u2014\u2014\u7b56\u7565\u8fed\u4ee3\u7684\u201c\u7b56\u7565\u8bc4\u4f30\u201d\u8fed\u4ee3\u81f3\u6536\u655b\uff1b\u503c\u8fed\u4ee3\u53ea\u505a 1 \u6b65\u8bc4\u4f30\u3002\u5dee\u522b\u662f\u5bf9\u8bc4\u4f30\u7cbe\u5ea6\u7684\u53d6\u820d\u3002</li> </ol>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_7","title":"\u4e8c\u3001\u7b56\u7565\u8fed\u4ee3\u7b97\u6cd5\u6838\u5fc3\u6846\u67b6","text":""},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#1_1","title":"1. \u6838\u5fc3\u5faa\u73af\u903b\u8f91","text":"\\[ \\pi_0 \\;\\xrightarrow{\\text{\u8bc4\u4f30}}\\; v^{\\pi_0} \\;\\xrightarrow{\\text{\u6539\u8fdb}}\\; \\pi_1 \\;\\xrightarrow{\\text{\u8bc4\u4f30}}\\; v^{\\pi_1} \\;\\xrightarrow{\\text{\u6539\u8fdb}}\\; \\pi_2 \\; \\cdots \\;\\longrightarrow \\pi^* \\]"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#2_1","title":"2. \u4e24\u5927\u6838\u5fc3\u6b65\u9aa4","text":"\u6b65\u9aa4 \u76ee\u6807 \u5143\u7d20\u7ea7\u6570\u5b66\u5f62\u5f0f \u6838\u5fc3\u64cd\u4f5c \u7b56\u7565\u8bc4\u4f30 (PE) \u7ed9\u5b9a \\(\\(\\pi_k\\)\\) \u6c42 \\(\\(v^{\\pi_k}\\)\\) $$ v^{\\pi_k}(s)=\\sum_a \\pi_k(a\\mid s)\\Big[r(s,a)+\\gamma\\sum_{s'} P(s'\\mid s,a)v^{\\pi_k}(s')\\Big] $$ \u8fed\u4ee3\u76f4\u5230\u503c\u5411\u91cf\u53d8\u5316 &lt; \u9608\u503c \u7b56\u7565\u6539\u8fdb (PI) \u57fa\u4e8e \\(\\(v^{\\pi_k}\\)\\) \u5f97\u5230\u66f4\u4f18 \\(\\(\\pi_{k+1}\\)\\) $$ \\pi_{k+1}(s)=\\operatorname*{argmax}a\\Big[r(s,a)+\\gamma\\sum(s')\\Big] $$}P(s'\\mid s,a)v^{\\pi_k \u8ba1\u7b97\u6240\u6709 \\(\\(q^{\\pi_k}(s,a)\\)\\) \u53d6\u6700\u5927\u52a8\u4f5c"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_8","title":"\u4e09\u3001\u5173\u952e\u95ee\u9898\u89e3\u7b54","text":""},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#1_2","title":"1. \u7b56\u7565\u8bc4\u4f30\u7684\u4e24\u79cd\u65b9\u6cd5","text":"<ul> <li>\u89e3\u6790\u89e3\uff1a\u77e9\u9635\u5f62\u5f0f $$ v = (I-\\gamma P<sup>{\\pi})</sup> $$\uff08\u72b6\u6001\u591a\u65f6\u4e0d\u5b9e\u7528\uff09\u3002} R^{\\pi</li> <li>\u8fed\u4ee3\u89e3\uff1a\u4ece \\(\\(v^{(0)}\\)\\) \u51fa\u53d1\uff1a   $$ v^{(j+1)}(s)=\\sum_a \\pi_k(a\\mid s)\\Big[r(s,a)+\\gamma\\sum_{s'}P(s'\\mid s,a) v^{(j)}(s')\\Big] $$   \u76f4\u5230 \\(\\(\\max_s |v^{(j+1)}(s)-v^{(j)}(s)|&lt;\\epsilon\\)\\)\u3002</li> </ul>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#2_2","title":"2. \u4e3a\u4ec0\u4e48\u6539\u8fdb\u540e\u66f4\u4f18\uff1f","text":"<p>\u7b56\u7565\u6539\u8fdb\u5b9a\u7406\uff1a\u57fa\u4e8e \\(\\(v^{\\pi_k}\\)\\) \u751f\u6210\u7684\u8d2a\u5a6a\u7b56\u7565 \\(\\(\\pi_{k+1}\\)\\) \u6ee1\u8db3 $$ v^{\\pi_{k+1}}(s) \\ge v^{\\pi_k}(s),\\;\\forall s $$ \u4e14\u81f3\u5c11\u4e00\u5904\u4e25\u683c\u5927\u4e8e\uff0c\u56e0\u6b64\u6536\u76ca\u4e0d\u52a3\u3002</p> <p>### Lemma 4.1 (Policy improvement)</p> <p>If \\(\\pi_{k+1} = \\arg\\max_\\pi (r_\\pi + \\gamma P_\\pi v_{\\pi_k})\\), then \\(v_{\\pi_{k+1}} \\geq v_{\\pi_k}\\).</p> <p>Here, \\(v_{\\pi_{k+1}} \\geq v_{\\pi_k}\\) means that \\(v_{\\pi_{k+1}}(s) \\geq v_{\\pi_k}(s)\\) for all \\(s\\). The proof of this lemma is given in Box 4.1.</p>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#proof-of-lemma-41","title":"Proof of Lemma 4.1","text":"<p>Since \\(v_{\\pi_{k+1}}\\) and \\(v_{\\pi_k}\\) are state values, they satisfy the Bellman equations:</p> \\[v_{\\pi_{k+1}} = r_{\\pi_{k+1}} + \\gamma P_{\\pi_{k+1}} v_{\\pi_{k+1}},\\] \\[v_{\\pi_k} = r_{\\pi_k} + \\gamma P_{\\pi_k} v_{\\pi_k}.\\] <p>Since \\(\\pi_{k+1} = \\arg\\max_\\pi (r_\\pi + \\gamma P_\\pi v_{\\pi_k})\\), we know that</p> \\[r_{\\pi_{k+1}} + \\gamma P_{\\pi_{k+1}} v_{\\pi_k} \\geq r_{\\pi_k} + \\gamma P_{\\pi_k} v_{\\pi_k}.\\] <p>It then follows that</p> \\[ \\begin{align*} v_{\\pi_k} - v_{\\pi_{k+1}} &amp;= (r_{\\pi_k} + \\gamma P_{\\pi_k} v_{\\pi_k}) - (r_{\\pi_{k+1}} + \\gamma P_{\\pi_{k+1}} v_{\\pi_{k+1}}) \\\\ &amp;\\leq (r_{\\pi_{k+1}} + \\gamma P_{\\pi_{k+1}} v_{\\pi_k}) - (r_{\\pi_{k+1}} + \\gamma P_{\\pi_{k+1}} v_{\\pi_{k+1}}) \\\\ &amp;\\leq \\gamma P_{\\pi_{k+1}} (v_{\\pi_k} - v_{\\pi_{k+1}}). \\end{align*} \\] <p>Therefore,</p> \\[ \\begin{align*} v_{\\pi_k} - v_{\\pi_{k+1}} &amp;\\leq \\gamma^2 P_{\\pi_{k+1}}^2 (v_{\\pi_k} - v_{\\pi_{k+1}}) \\leq \\dots \\leq \\gamma^n P_{\\pi_{k+1}}^n (v_{\\pi_k} - v_{\\pi_{k+1}}) \\\\ &amp;\\leq \\lim_{n \\to \\infty} \\gamma^n P_{\\pi_{k+1}}^n (v_{\\pi_k} - v_{\\pi_{k+1}}) = 0. \\end{align*} \\] <p>The limit is due to the facts that \\(\\gamma^n \\to 0\\) as \\(n \\to \\infty\\) and \\(P_{\\pi_{k+1}}^n\\) is a nonnegative stochastic matrix for any \\(n\\). Here, a stochastic matrix refers to a nonnegative matrix whose row sums are equal to one for all rows.</p>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#3","title":"3. \u6536\u655b\u6027","text":"<ol> <li>\u5355\u8c03\uff1a$$ v^{\\pi_k} $$ \u5355\u8c03\u4e0d\u51cf\u4e14\u6709\u4e0a\u754c \\(\\(v^*\\)\\)\u3002</li> <li>\u6298\u6263\uff1a$$ \\gamma\\in[0,1) $$ \u786e\u4fdd\u56de\u62a5\u6709\u754c\uff0c\u6700\u7ec8 $$ v^{\\pi_k} \\to v^* $$\uff0c\u5bf9\u5e94\u7b56\u7565\u5373 \\(\\(\\pi^*\\)\\)\u3002</li> </ol> <p>Info</p> <p>Theorem 4.1 (Convergence of policy iteration). The state value sequence \\(\\{v_{\\pi_k}\\}^\\infty_{k=0}\\) generated by the policy iteration algorithm converges to the optimal state value \\(v^\u2217\\). As a result, the policy sequence \\(\\{\\pi_k\\}_{k=0}^\\infty\\) converges to an optimal policy. </p>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#proof-of-theorem-41","title":"Proof of Theorem 4.1","text":"<p>The idea of the proof is to show that the policy iteration algorithm converges faster than the value iteration algorithm.</p> <p>In particular, to prove the convergence of \\(\\{v_{\\pi_k}\\}_{k=0}^\\infty\\), we introduce another sequence \\(\\{v_k\\}_{k=0}^\\infty\\) generated by \\(\\(v_{k+1} = f(v_k) = \\max_\\pi (r_\\pi + \\gamma P_\\pi v_k).\\)\\) This iterative algorithm is exactly the value iteration algorithm. We already know that \\(v_k\\) converges to \\(v^*\\) when given any initial value \\(v_0\\).</p> <p>For \\(k=0\\), we can always find a \\(v_0\\) such that \\(v_{\\pi_0} \\geq v_0\\) for any \\(\\pi_0\\).</p> <p>We next show that \\(v_k \\leq v_{\\pi_k} \\leq v^*\\) for all \\(k\\) by induction.</p> <p>For \\(k \\geq 0\\), suppose that \\(v_{\\pi_k} \\geq v_k\\).</p> <p>For \\(k+1\\), we have $$ \\begin{align} v_{\\pi_{k+1}} - v_{k+1} &amp;= (r_{\\pi_{k+1}} + \\gamma P_{\\pi_{k+1}} v_{\\pi_{k+1}}) - \\max_\\pi (r_\\pi + \\gamma P_\\pi v_k) \\ &amp;\\geq (r_{\\pi_{k+1}} + \\gamma P_{\\pi_{k+1}} v_{\\pi_k}) - \\max_\\pi (r_\\pi + \\gamma P_\\pi v_k) \\quad \\text{(because \\(v_{\\pi_{k+1}} \\geq v_{\\pi_k}\\) by Lemma 4.1 and \\(P_{\\pi_{k+1}} \\geq 0\\))} \\ &amp;= (r_{\\pi_{k+1}} + \\gamma P_{\\pi_{k+1}} v_{\\pi_k}) - (r_{\\pi_k'} + \\gamma P_{\\pi_k'} v_k) \\quad \\text{(suppose \\(\\pi_k' = \\arg\\max_\\pi (r_\\pi + \\gamma P_\\pi v_k)\\))} \\ &amp;\\geq (r_{\\pi_k'} + \\gamma P_{\\pi_k'} v_{\\pi_k}) - (r_{\\pi_k'} + \\gamma P_{\\pi_k'} v_k) \\quad \\text{(because \\(\\pi_{k+1} = \\arg\\max_\\pi (r_\\pi + \\gamma P_\\pi v_{\\pi_k})\\))} \\ &amp;= \\gamma P_{\\pi_k'} (v_{\\pi_k} - v_k). \\end{align} $$</p> <p>Since \\(v_{\\pi_k} - v_k \\geq 0\\) and \\(P_{\\pi_k'}\\) is nonnegative, we have \\(P_{\\pi_k'} (v_{\\pi_k} - v_k) \\geq 0\\) and hence \\(v_{\\pi_{k+1}} - v_{k+1} \\geq 0\\).</p> <p>Therefore, we can show by induction that \\(v_k \\leq v_{\\pi_k} \\leq v^*\\) for any \\(k \\geq 0\\). Since \\(v_k\\) converges to \\(v^*\\), \\(v_{\\pi_k}\\) also converges to \\(v^*\\).</p>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_9","title":"\u56db\u3001\u7b56\u7565\u8fed\u4ee3\u4f2a\u4ee3\u7801","text":"<ol> <li>\u521d\u59cb\u5316\uff1a\u968f\u673a\u7b56\u7565 \\(\\(\\pi_0\\)\\)\uff0c\u6298\u6263 \\(\\(\\gamma\\)\\)\uff0c\u9608\u503c \\(\\(\\epsilon\\)\\)\u3002</li> <li>\u5faa\u73af\u76f4\u5230\u7b56\u7565\u7a33\u5b9a\uff1a</li> <li>\u7b56\u7565\u8bc4\u4f30\uff1a\u6c42\u89e3Bellman\u516c\u5f0f\uff0c\u8fd9\u91cc\u4f7f\u7528\u8fed\u4ee3\u6c42 \\(v_{\\pi_k}\\)\uff1a       $$ v^{(j+1)}(s)=\\sum_a \\pi_k(a\\mid s)\\Big[r(s,a)+\\gamma\\sum_{s'}P(s'\\mid s,a)v^{(j)}(s')\\Big] $$       \u82e5 \\(\\(\\max_s |v^{(j+1)}(s)-v^{(j)}(s)|&lt;\\epsilon\\)\\) \u505c\u6b62\uff0c\u4ee4 \\(\\(v_{\\pi_k}=v^{(j+1)}\\)\\)\u3002</li> <li>\u7b56\u7565\u6539\u8fdb\uff1a\u5bf9\u6bcf\u4e2a \\(\\(s\\)\\)\uff1a       $$ q_{\\pi_k}(s,a)=r(s,a)+\\gamma\\sum_{s'}P(s'\\mid s,a)v_{\\pi_k}(s') $$       \u53d6\u6700\u5927\u52a8\u4f5c\u5f97 \\(\\(\\pi_{k+1}(s)\\)\\)\u3002</li> <li>\u82e5 \\(\\(\\pi_{k+1}=\\pi_k\\)\\) \u505c\u6b62\uff1b\u5426\u5219 \\(\\(\\pi_k\\leftarrow\\pi_{k+1}\\)\\)\u3002</li> <li>\u8f93\u51fa\uff1a \\(\\(\\pi^*=\\pi_{k+1},\\; v^*=v_{\\pi_{k+1}}\\)\\)\u3002</li> </ol>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_10","title":"\u4e94\u3001\u5b9e\u4f8b","text":""},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#1-2","title":"1. 2 \u683c\u7f51\u683c","text":"<ul> <li>\u72b6\u6001\uff1a\\(\\(s_1,s_2\\)\\)\uff08\\(\\(s_2\\)\\) \u4e3a\u76ee\u6807\uff09\u3002</li> <li>\u52a8\u4f5c\uff1a\u5de6\u3001\u505c\u3001\u53f3\u3002</li> <li>\u5956\u52b1\uff1a$$ r(s_2,\\cdot)=1 $$ \u5176\u4f59 $$ -1 $$\u3002</li> <li>\u521d\u59cb\u7b56\u7565 \\(\\(\\pi_0\\)\\)\uff1a\u603b\u662f\u5de6\u3002</li> <li>\u8bc4\u4f30\u5f97\uff1a\u957f\u671f\u9677\u5165 \\(\\(s_1\\)\\) \u56de\u62a5\u6781\u4f4e\uff0c$$ v^{\\pi_0}(s_2)=1 $$\u3002</li> <li>\u6539\u8fdb\uff1a\u5728 \\(\\(s_1\\)\\) \u53f3\u79fb\u52a8\u4f5c\u4ef7\u503c\u6700\u5927\uff0c\u5f97 \\(\\(\\pi_1(s_1)=\\text{\u53f3}\\)\\)\uff0c\\(\\(\\pi_1(s_2)=\\text{\u505c}\\)\\)\uff0c\u6536\u655b\u3002</li> </ul>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#2-55","title":"2. 5\u00d75 \u7f51\u683c\uff08\u542b\u7981\u6b62\u533a\uff09","text":"<ul> <li>\u73b0\u8c61\uff1a\u9760\u8fd1\u76ee\u6807\u7684\u72b6\u6001\u5148\u4f18\u5316\u3002</li> <li>\u539f\u56e0\uff1a\u8fd9\u4e9b\u72b6\u6001\u7684\u503c\u5148\u63a5\u8fd1\u6700\u4f18\uff0c\u4f7f\u5176\u76f8\u90bb\u72b6\u6001\u7684 \\(\\(q\\)\\) \u4f30\u8ba1\u66f4\u51c6\u786e\uff0c\u63a8\u52a8\u5916\u5c42\u6269\u6563\u3002</li> </ul>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_11","title":"\u516d\u3001\u5b9e\u73b0\u6ce8\u610f\u4e8b\u9879","text":"<ol> <li>\u7b56\u7565\u8bc4\u4f30\u4e0d\u5fc5\u6781\u5ea6\u7cbe\u786e\uff0c\u53ef\u7528\u8f83\u5bbd\u677e \\(\\(\\epsilon\\)\\)\uff08\u5982 0.1\uff09\u52a0\u901f\uff0c\u540e\u7eed\u8fed\u4ee3\u4f1a\u4fee\u6b63\u3002</li> <li>\u591a\u6700\u4f18\u52a8\u4f5c\u53ef\u968f\u673a\u9009\u6216\u5e73\u5747\u5206\u914d\uff1b\u6700\u7ec8\u4ecd\u6536\u655b\u5230\u540c\u4e00 \\(\\(\\pi^*\\)\\)\u3002</li> <li>\u9700\u51c6\u5907\u9ad8\u6548\u7ed3\u6784\u5b58\u50a8 \\(\\(P(s'\\mid s,a)\\)\\) \u4e0e \\(\\(r(s,a)\\)\\) \u4ee5\u4fbf\u8ba1\u7b97 \\(\\(q(s,a)\\)\\)\u3002</li> </ol>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#4-_1","title":"\u7b2c4\u8bfe-\u503c\u8fed\u4ee3\u4e0e\u7b56\u7565\u8fed\u4ee3\uff08\u622a\u65ad\u7b56\u7565\u8fed\u4ee3\u7b97\u6cd5\uff09\u77e5\u8bc6\u70b9\u6574\u7406","text":""},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_12","title":"\u4e00\u3001\u6838\u5fc3\u7b97\u6cd5\u5173\u7cfb\u6846\u67b6","text":"<p>\u622a\u65ad\u7b56\u7565\u8fed\u4ee3\uff08Truncated Policy Iteration\uff09\u5e76\u975e\u72ec\u7acb\u7b97\u6cd5\uff0c\u800c\u662f\u503c\u8fed\u4ee3\uff08Value Iteration\uff09\u4e0e\u7b56\u7565\u8fed\u4ee3\uff08Policy Iteration\uff09\u7684\u4e00\u822c\u5316\u63a8\u5e7f\uff0c\u540e\u4e24\u8005\u662f\u622a\u65ad\u7b56\u7565\u8fed\u4ee3\u7684\u201c\u6781\u7aef\u7279\u6b8a\u60c5\u51b5\u201d\uff1a - \u5f53\u622a\u65ad\u8fed\u4ee3\u6b65\u6570\uff08j\uff09=1\u65f6\uff0c\u622a\u65ad\u7b56\u7565\u8fed\u4ee3\u9000\u5316\u4e3a\u503c\u8fed\u4ee3\uff1b - \u5f53\u622a\u65ad\u8fed\u4ee3\u6b65\u6570\uff08j\uff09=\\(\\infty\\)\u65f6\uff0c\u622a\u65ad\u7b56\u7565\u8fed\u4ee3\u9000\u5316\u4e3a\u7b56\u7565\u8fed\u4ee3\u3002</p>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_13","title":"\u4e8c\u3001\u4e09\u5927\u7b97\u6cd5\u6838\u5fc3\u6d41\u7a0b\u5bf9\u6bd4","text":""},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#1-policy-iteration","title":"1. \u7b56\u7565\u8fed\u4ee3\uff08Policy Iteration\uff09","text":""},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_14","title":"\u6838\u5fc3\u903b\u8f91","text":"<p>\u4ece\u521d\u59cb\u7b56\u7565\\(\\pi_0\\)\uff08\u53ef\u4efb\u610f\u8bbe\u5b9a\uff0c\u65e0\u9700\u6700\u4f18\uff09\u51fa\u53d1\uff0c\u901a\u8fc7\u201c\u7b56\u7565\u8bc4\u4f30\u2192\u7b56\u7565\u6539\u8fdb\u201d\u7684\u5faa\u73af\u8fed\u4ee3\uff0c\u9010\u6b65\u903c\u8fd1\u6700\u4f18\u7b56\u7565\u4e0e\u6700\u4f18\u72b6\u6001\u503c\uff08\\(v^*\\)\uff09\u3002</p>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#k","title":"\u5173\u952e\u6b65\u9aa4\uff08\u7b2ck\u8f6e\u8fed\u4ee3\uff09","text":"<ol> <li>\u7b56\u7565\u8bc4\u4f30\uff08Policy Evaluation\uff09\uff1a\u9488\u5bf9\u5f53\u524d\u7b56\u7565\\(\\pi_k\\)\uff0c\u6c42\u89e3\u8d1d\u5c14\u66fc\u65b9\u7a0b\u5f97\u5230\u5176\u5bf9\u5e94\u7684\u72b6\u6001\u503c\\(v_{\\pi_k}\\)\uff08\u9700\u901a\u8fc7\u5185\u5d4c\u65e0\u7a77\u6b21\u8fed\u4ee3\u6536\u655b\u5230\u7cbe\u786e\u89e3\\(v_{\\pi_k}\\)\uff09\uff1b    - \u6570\u5b66\u903b\u8f91\uff1a\\(v_{\\pi_k}(s) = \\mathbb{E}[R_{k+1} + \\gamma v_{\\pi_k}(S_{k+1}) | S_k=s, \\pi_k]\\)\uff08s\u4e3a\u6240\u6709\u72b6\u6001\uff09\uff1b    - \u8fed\u4ee3\u8fc7\u7a0b\uff1a\u4ece\u4efb\u610f\u521d\u59cb\u503c\\(v_{\\pi_k}(0)\\)\u51fa\u53d1\uff0c\u53cd\u590d\u66f4\u65b0\\(v_{\\pi_k}(j+1) = \\mathbb{E}[R_{k+1} + \\gamma v_{\\pi_k}(j)(S_{k+1}) | S_k=s, \\pi_k]\\)\uff0c\u76f4\u81f3\\(v_{\\pi_k}(j)\\)\u6536\u655b\u5230\\(v_{\\pi_k}\\)\u3002</li> <li>\u7b56\u7565\u6539\u8fdb\uff08Policy Improvement\uff09\uff1a\u57fa\u4e8e\u5f97\u5230\u7684\\(v_{\\pi_k}\\)\uff0c\u901a\u8fc7\u8d2a\u5fc3\u4f18\u5316\u66f4\u65b0\u7b56\u7565\\(\\pi_{k+1}\\)\uff1a    - \u6570\u5b66\u903b\u8f91\uff1a\\(\\pi_{k+1}(s) = \\arg\\max_a \\mathbb{E}[R_{k+1} + \\gamma v_{\\pi_k}(S_{k+1}) | S_k=s, A_k=a]\\)\uff08\u5bf9\u6bcf\u4e2a\u72b6\u6001s\u9009\u62e9\u6700\u4f18\u52a8\u4f5ca\uff09\u3002</li> </ol>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_15","title":"\u7279\u70b9","text":"<ul> <li>\u7406\u8bba\u4e0a\u9700\u201c\u65e0\u7a77\u6b21\u5185\u5d4c\u8fed\u4ee3\u201d\u5b8c\u6210\u7b56\u7565\u8bc4\u4f30\uff0c\u7cbe\u5ea6\u9ad8\u4f46\u8ba1\u7b97\u6210\u672c\u6781\u9ad8\uff1b</li> <li>\u5b9e\u9645\u5de5\u7a0b\u4e2d\u65e0\u6cd5\u5b9e\u73b0\uff08\u65e0\u6cd5\u8ba1\u7b97\u65e0\u7a77\u6b65\uff09\uff0c\u9700\u901a\u8fc7\u622a\u65ad\u8fed\u4ee3\u8fd1\u4f3c\u3002</li> </ul>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#2-value-iteration","title":"2. \u503c\u8fed\u4ee3\uff08Value Iteration\uff09","text":""},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_16","title":"\u6838\u5fc3\u903b\u8f91","text":"<p>\u4ece\u521d\u59cb\u72b6\u6001\u503c\\(v_0\\)\uff08\u53ef\u4efb\u610f\u8bbe\u5b9a\uff09\u51fa\u53d1\uff0c\u901a\u8fc7\u201c\u7b56\u7565\u66f4\u65b0\u2192\u503c\u66f4\u65b0\u201d\u7684\u7b80\u5316\u5faa\u73af\uff0c\u76f4\u63a5\u903c\u8fd1\u6700\u4f18\u72b6\u6001\u503c\\(v^*\\)\uff0c\u518d\u63a8\u5bfc\u6700\u4f18\u7b56\u7565\u3002</p>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#k_1","title":"\u5173\u952e\u6b65\u9aa4\uff08\u7b2ck\u8f6e\u8fed\u4ee3\uff09","text":"<ol> <li>\u7b56\u7565\u66f4\u65b0\uff08Policy Update\uff09\uff1a\u57fa\u4e8e\u5f53\u524d\u72b6\u6001\u503c\\(v_k\\)\uff0c\u8d2a\u5fc3\u751f\u6210\u4e34\u65f6\u7b56\u7565\\(\\pi_{k+1}\\)\uff1a    - \u6570\u5b66\u903b\u8f91\uff1a\\(\\pi_{k+1}(s) = \\arg\\max_a \\mathbb{E}[R_{k+1} + \\gamma v_k(S_{k+1}) | S_k=s, A_k=a]\\)\uff1b</li> <li>\u503c\u66f4\u65b0\uff08Value Update\uff09\uff1a\u4ec5\u901a\u8fc71\u6b65\u8fed\u4ee3\u66f4\u65b0\u72b6\u6001\u503c\\(v_{k+1}\\)\uff08\u65e0\u9700\u6536\u655b\u5230\\(v_{\\pi_{k+1}}\\)\uff09\uff1a    - \u6570\u5b66\u903b\u8f91\uff1a\\(v_{k+1}(s) = \\mathbb{E}[R_{k+1} + \\gamma v_k(S_{k+1}) | S_k=s, \\pi_{k+1}]\\)\u3002</li> </ol>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_17","title":"\u7279\u70b9","text":"<ul> <li>\u7b56\u7565\u8bc4\u4f30\u4ec51\u6b65\uff0c\u8ba1\u7b97\u6210\u672c\u4f4e\u4f46\u5355\u8f6e\u7cbe\u5ea6\u8f83\u4f4e\uff1b</li> <li>\u65e0\u9700\u663e\u5f0f\u7ef4\u62a4\u7b56\u7565\uff0c\u901a\u8fc7\u503c\u8fed\u4ee3\u76f4\u63a5\u903c\u8fd1\\(v^*\\)\uff0c\u6700\u7ec8\u7531\\(v^*\\)\u63a8\u5bfc\u6700\u4f18\u7b56\u7565\u3002</li> </ul>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#3-truncated-policy-iteration","title":"3. \u622a\u65ad\u7b56\u7565\u8fed\u4ee3\uff08Truncated Policy Iteration\uff09","text":""},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_18","title":"\u6838\u5fc3\u903b\u8f91","text":"<p>\u89e3\u51b3\u524d\u4e24\u79cd\u7b97\u6cd5\u7684\u6781\u7aef\u6027\uff1a\u5728\u7b56\u7565\u8bc4\u4f30\u9636\u6bb5\u5f15\u5165\u6709\u9650\u622a\u65ad\u6b65\u6570j\uff08\u53ef\u81ea\u5b9a\u4e49\uff0c\u5982j=2\u300110\u3001100\uff09\uff0c\u5e73\u8861\u7cbe\u5ea6\u4e0e\u8ba1\u7b97\u6210\u672c\u3002</p>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#k_2","title":"\u5173\u952e\u6b65\u9aa4\uff08\u7b2ck\u8f6e\u8fed\u4ee3\uff09","text":"<ol> <li>\u7b56\u7565\u8bc4\u4f30\uff08\u622a\u65ad\u7248\uff09\uff1a\u9488\u5bf9\u5f53\u524d\u7b56\u7565\\(\\pi_k\\)\uff0c\u4ece\u521d\u59cb\u503c\\(v_{k-1}\\)\uff08\u7ee7\u627f\u81ea\u4e0a\u4e00\u8f6e\u8fed\u4ee3\u7ed3\u679c\uff09\u51fa\u53d1\uff0c\u4ec5\u6267\u884cj\u6b65\u5185\u5d4c\u8fed\u4ee3\uff0c\u5f97\u5230\u8fd1\u4f3c\u72b6\u6001\u503c\\(v_{\\pi_k}(j)\\)\uff08\u800c\u975e\u65e0\u7a77\u6b65\u6536\u655b\u7684\\(v_{\\pi_k}\\)\uff09\uff1b</li> <li>\u7b56\u7565\u6539\u8fdb\uff1a\u57fa\u4e8e\u8fd1\u4f3c\u503c\\(v_{\\pi_k}(j)\\)\uff0c\u8d2a\u5fc3\u66f4\u65b0\u7b56\u7565\\(\\pi_{k+1}\\)\uff0c\u903b\u8f91\u4e0e\u7b56\u7565\u8fed\u4ee3\u4e00\u81f4\uff1b</li> <li>\u8fed\u4ee3\u7ec8\u6b62\uff1a\u5f53\u622a\u65ad\u6b65\u6570j\u8fbe\u5230\u9884\u8bbe\u9608\u503c\u65f6\uff0c\u505c\u6b62\u5f53\u524d\u8f6e\u7b56\u7565\u8bc4\u4f30\uff0c\u8fdb\u5165\u4e0b\u4e00\u8f6e\u5faa\u73af\u3002</li> </ol>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_19","title":"\u4f2a\u4ee3\u7801\u6838\u5fc3\u5dee\u5f02","text":"<p>\u4e0e\u7b56\u7565\u8fed\u4ee3\u4f2a\u4ee3\u7801\u7ed3\u6784\u4e00\u81f4\uff0c\u4ec5\u5c06\u201c\u7b56\u7565\u8bc4\u4f30\u7684\u6536\u655b\u5224\u65ad\u201d\u66ff\u6362\u4e3a\u201c\u622a\u65ad\u6b65\u6570\u8ba1\u6570\u5224\u65ad\u201d\uff1a - \u7b56\u7565\u8fed\u4ee3\uff1awhile \\(v_{\\pi_k}(j)\\)\u672a\u6536\u655b \u2192 \u7ee7\u7eed\u8fed\u4ee3\uff1b - \u622a\u65ad\u7b56\u7565\u8fed\u4ee3\uff1afor j in 1 to \u9884\u8bbe\u6b65\u6570 \u2192 \u6267\u884cj\u6b65\u540e\u505c\u6b62\u3002</p>"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#_20","title":"\u4e09\u3001\u4e09\u5927\u7b97\u6cd5\u5173\u952e\u5dee\u5f02\u4e0e\u6838\u5fc3\u7ed3\u8bba","text":""},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#1_3","title":"1. \u6838\u5fc3\u5dee\u5f02\uff1a\u7b56\u7565\u8bc4\u4f30\u7684\u8fed\u4ee3\u6b65\u6570","text":"\u7b97\u6cd5 \u7b56\u7565\u8bc4\u4f30\u8fed\u4ee3\u6b65\u6570 \u72b6\u6001\u503c\u7cbe\u5ea6 \u8ba1\u7b97\u6210\u672c \u5de5\u7a0b\u5b9e\u7528\u6027 \u7b56\u7565\u8fed\u4ee3 \\(\\infty\\)\uff08\u7406\u8bba\uff09 \u6700\u9ad8\uff08\u7cbe\u786e\\(v_{\\pi_k}\\)\uff09 \u6781\u9ad8\uff08\u4e0d\u53ef\u5b9e\u73b0\uff09 \u4ec5\u7406\u8bba\u53c2\u8003 \u503c\u8fed\u4ee3 1 \u8f83\u4f4e\uff08\u8fd1\u4f3c\\(v_{\\pi_{k+1}}\\)\uff09 \u6781\u4f4e \u9002\u5408\u5feb\u901f\u8fed\u4ee3\u573a\u666f \u622a\u65ad\u7b56\u7565\u8fed\u4ee3 \u81ea\u5b9a\u4e49j\uff08\u6709\u9650\uff09 \u4e2d\u7b49\uff08\\(v_{\\pi_k}(j)\\)\uff09 \u4e2d\u7b49\uff08\u53ef\u63a7\uff09 \u5b9e\u9645\u5de5\u7a0b\u9996\u9009"},{"location":"notes/RL/Chap4VaulePolicyTruncatedIteration/#2_3","title":"2. \u6536\u655b\u6027\u4fdd\u969c","text":"<ul> <li>\u7406\u8bba\u4f9d\u636e\uff1a\u82e5\u7b56\u7565\u8bc4\u4f30\u7684\u521d\u59cb\u503c\u4e3a\\(v_{\\pi_{k-1}}\\)\uff08\u4e0a\u4e00\u8f6e\u7b56\u7565\u7684\u72b6\u6001\u503c\uff09\uff0c\u5219\u5185\u5d4c\u8fed\u4ee3\u7684\u72b6\u6001\u503c\\(v_{\\pi_k}(j)\\)\u6ee1\u8db3\u201c\u5355\u8c03\u9012\u589e\u201d\u7279\u6027\uff08\\(v_{\\pi_k}(j+1) \\geq v_{\\pi_k}(j)\\)\uff09\uff0c\u4e14\u6700\u7ec8\u6536\u655b\u5230\\(v_{\\pi_k}\\)\uff1b</li> <li>\u76f4\u89c2\u8868\u73b0\uff1a\u5982\u89c6\u9891\u4e2d\u6536\u655b\u66f2\u7ebf\u56fe\u6240\u793a\uff1a</li> <li>\u6a2a\u8f74\uff1a\u5916\u5faa\u73af\u8fed\u4ee3\u8f6e\u6b21k\uff1b</li> <li>\u7eb5\u8f74\uff1a\u72b6\u6001\u503c\u5927\u5c0f\uff1b</li> <li>\u7ea2\u7ebf\uff1a\u6700\u4f18\u72b6\u6001\u503c\\(v^*\\)\uff1b</li> <li>\u7d2b\u7ebf\uff08\u503c\u8fed\u4ee3\uff09\uff1a\u4ece\u521d\u59cb\u503c\u51fa\u53d1\uff0c\u6bcf\u8f6e1\u6b65\u66f4\u65b0\uff0c\u9010\u6b65\u903c\u8fd1\\(v^*\\)\uff1b</li> <li>\u84dd\u7ebf\uff08\u7b56\u7565\u8fed\u4ee3\uff09\uff1a\u6bcf\u8f6e\u65e0\u7a77\u6b65\u66f4\u65b0\uff0c\u7cbe\u5ea6\u66f4\u9ad8\u4f46\u8fed\u4ee3\u66f4\u6162\uff1b</li> <li>\u9ed1\u7ebf\uff08\u622a\u65ad\u7b56\u7565\u8fed\u4ee3\uff09\uff1a\u4ecb\u4e8e\u4e24\u8005\u4e4b\u95f4\uff0c\u7cbe\u5ea6\u4f18\u4e8e\u503c\u8fed\u4ee3\u3001\u901f\u5ea6\u4f18\u4e8e\u7b56\u7565\u8fed\u4ee3\uff0c\u6700\u7ec8\u540c\u6837\u6536\u655b\u5230\\(v^*\\)\u3002</li> </ul>"},{"location":"notes/RL/Chap5MC/","title":"\u7b2c5\u8bfe-\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\uff08\u901a\u8fc7\u4f8b\u5b50\u4ecb\u7ecd\u8499\u7279\u5361\u6d1b\uff09\u77e5\u8bc6\u70b9\u6574\u7406","text":""},{"location":"notes/RL/Chap5MC/#5-","title":"\u7b2c5\u8bfe-\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\uff08\u901a\u8fc7\u4f8b\u5b50\u4ecb\u7ecd\u8499\u7279\u5361\u6d1b\uff09\u77e5\u8bc6\u70b9\u6574\u7406","text":"<p> \u7ea6 2041 \u4e2a\u5b57  17 \u884c\u4ee3\u7801  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 10 \u5206\u949f</p>"},{"location":"notes/RL/Chap5MC/#monte-carlo-estimation","title":"\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\uff08Monte Carlo Estimation\uff09\u6838\u5fc3\u601d\u60f3","text":""},{"location":"notes/RL/Chap5MC/#1","title":"1. \u95ee\u9898\u5f15\u5165\uff1a\u629b\u786c\u5e01\u671f\u671b\u4f30\u8ba1\uff08\u793a\u4f8b\uff09","text":"<ul> <li>\u95ee\u9898\u5b9a\u4e49\uff1a\u629b\u4e00\u679a\u786c\u5e01\uff0c\u7ed3\u679c\u7528\u968f\u673a\u53d8\u91cf \\(X\\) \u8868\u793a\uff1a</li> <li>\u6b63\u9762\uff1a\\(X=+1\\)</li> <li>\u53cd\u9762\uff1a\\(X=-1\\)</li> <li> <p>\u76ee\u6807\uff1a\u4f30\u8ba1 \\(X\\) \u7684\u671f\u671b \\(E[X]\\)</p> </li> <li> <p>\u4e24\u79cd\u6c42\u89e3\u601d\u8def\u5bf9\u6bd4</p> </li> </ul> \u65b9\u6cd5\u7c7b\u578b \u6838\u5fc3\u903b\u8f91 \u8ba1\u7b97\u8fc7\u7a0b \u5c40\u9650\u6027 Model-based\uff08\u57fa\u4e8e\u6a21\u578b\uff09 \u5df2\u77e5\u968f\u673a\u53d8\u91cf\u7684\u6982\u7387\u5206\u5e03\uff0c\u76f4\u63a5\u7528\u671f\u671b\u5b9a\u4e49\u8ba1\u7b97 \u82e5 \\(P(X=+1)=0.5,\\;P(X=-1)=0.5\\)\uff0c\u5219 \\(E[X] = (+1)P(X=+1)+(-1)P(X=-1)=0\\) \u5b9e\u9645\u4e2d\u5e38\u672a\u77e5\u73af\u5883\u5206\u5e03\uff08\u6a21\u578b\uff09\uff0c\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528 Model-free\uff08\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\uff09 \u65e0\u9700\u5df2\u77e5\u5206\u5e03\uff0c\u901a\u8fc7\u5927\u91cf\u91c7\u6837\u6c42\u5747\u503c\u8fd1\u4f3c\u671f\u671b 1) \u505a \\(n\\) \u6b21\u72ec\u7acb\u8bd5\u9a8c\u5f97\u6837\u672c \\(x_1,\\dots,x_n\\)\uff08\\(x_i\\in\\{+1,-1\\}\\)\uff09\uff1b2) \u8ba1\u7b97 \\(\\bar{x}=\\tfrac{1}{n}\\sum_{i=1}^n x_i\\)\uff1b3) \u4ee4 \\(E[X]\\approx \\bar{x}\\) \u5c0f\u6837\u672c\u65b9\u5dee\u5927\uff0c\u9700\u8981\u8db3\u591f\u5927 \\(n\\) \u624d\u80fd\u903c\u8fd1\u771f\u5b9e\u671f\u671b"},{"location":"notes/RL/Chap5MC/#2-law-of-large-numbers","title":"2. \u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u7684\u6570\u5b66\u652f\u6491\uff1a\u5927\u6570\u5b9a\u7406\uff08Law of Large Numbers\uff09","text":"<ul> <li> <p>\u524d\u63d0\u6761\u4ef6\uff1a\\(x_1, x_2, \\dots, x_n\\) \u4e3a\u72ec\u7acb\u540c\u5206\u5e03\uff08i.i.d.\uff09\u6837\u672c\u3002</p> </li> <li> <p>\u6838\u5fc3\u7ed3\u8bba\uff1a   1. \u65e0\u504f\u6027\uff1a      $$ E[\\bar{x}] = E[X] $$   2. \u65b9\u5dee\u6536\u655b\uff1a      $$ \\operatorname{Var}(\\bar{x}) = \\frac{\\operatorname{Var}(X)}{n} \\xrightarrow[n\\to\\infty]{} 0 $$      \u56e0\u6b64 \\(\\bar{x}\\) \u4ee5\u6982\u7387 1 \u6536\u655b\u5230 \\(E[X]\\)\u3002</p> </li> <li> <p>\u53ef\u89c6\u5316\u8bf4\u660e:</p> </li> </ul> <p></p>"},{"location":"notes/RL/Chap5MC/#3","title":"3. \u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u610f\u4e49","text":"<ul> <li>\u4ef7\u503c\u51fd\u6570\u672c\u8d28\uff1a\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u72b6\u6001\u4ef7\u503c \\(V(s)\\) \u4e0e\u52a8\u4f5c\u4ef7\u503c \\(Q(s,a)\\) \u5747\u662f\u201c\u672a\u6765\u56de\u62a5\u7684\u671f\u671b\u201d\u3002</li> <li>\u9002\u914d\u539f\u56e0\uff1a\u5f53\u73af\u5883\u6a21\u578b\uff08\u8f6c\u79fb\u6982\u7387\u4e0e\u5956\u52b1\u5206\u5e03\uff09\u672a\u77e5\u65f6\uff0c\u53ef\u901a\u8fc7\u91c7\u6837\u5b8c\u6574 Episode \u56de\u62a5\u7684\u5e73\u5747\u6765\u4f30\u8ba1\u8fd9\u4e9b\u671f\u671b\u3002</li> </ul>"},{"location":"notes/RL/Chap5MC/#_1","title":"\u5173\u952e\u6982\u5ff5\u8fa8\u6790\u4e0e\u91cd\u8981\u63d0\u793a","text":"<ol> <li>\u5e7f\u4e49\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\uff1a\u51e1\u201c\u901a\u8fc7\u968f\u673a\u91c7\u6837\u5e76\u7528\u7edf\u8ba1\u91cf\uff08\u5982\u5747\u503c\uff09\u8fd1\u4f3c\u76ee\u6807\u91cf\uff08\u5982\u671f\u671b\uff09\u201d\u7684\u601d\u60f3\u90fd\u5c5e\u8499\u7279\u5361\u6d1b\u8303\u7574\u3002</li> <li>MC Basic \u7b97\u6cd5\u5b9a\u4f4d\uff1a\u867d\u6570\u636e\u6548\u7387\u4f4e\u3001\u9700\u5b8c\u6574 Episode\uff0c\u4f46\u5176\u601d\u60f3\u5960\u5b9a\u201c\u8131\u79bb\u6a21\u578b\u4ecd\u80fd\u4f30\u8ba1\u671f\u671b\u201d\u7684\u57fa\u7840\uff0c\u662f\u6539\u8fdb\u7b97\u6cd5\uff08\u5982\u589e\u91cf\u5f0f\u3001\u5e26\u63a7\u5236\uff09\u524d\u7f6e\u6982\u5ff5\u3002</li> <li>\u4e0e\u540e\u7eed\u65b9\u6cd5\u5bf9\u6bd4\uff1a\u8499\u7279\u5361\u6d1b\u9700\u5b8c\u6574\u8f68\u8ff9\uff1b\u65f6\u5e8f\u5dee\u5206\uff08TD\uff09\u53ef\u5728\u672a\u7ec8\u6b62\u524d\u66f4\u65b0\uff0c\u4e8c\u8005\u5171\u540c\u6784\u6210\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u4e24\u5927\u6838\u5fc3\u601d\u8def\u3002</li> </ol>"},{"location":"notes/RL/Chap5MC/#5-mc-basic","title":"\u7b2c5\u8bfe-\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\uff08MC Basic\u7b97\u6cd5\uff09\u6838\u5fc3\u77e5\u8bc6\u70b9\u6574\u7406","text":""},{"location":"notes/RL/Chap5MC/#_2","title":"\u524d\u7f6e\u77e5\u8bc6\u56de\u987e","text":"<p>MC Basic\u7b97\u6cd5\u662fPolicy Iteration\uff08\u7b56\u7565\u8fed\u4ee3\uff09\u7684Model-Free\u53d8\u5f62\uff0c\u9700\u5148\u638c\u63e1\u7b56\u7565\u8fed\u4ee3\u7684\u6838\u5fc3\u903b\u8f91\u4e0e\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570\u7684\u5b9a\u4e49\u3002</p>"},{"location":"notes/RL/Chap5MC/#policy-iteration","title":"Policy Iteration\uff08\u7b56\u7565\u8fed\u4ee3\uff09\u7b97\u6cd5","text":"<p>\u7b56\u7565\u8fed\u4ee3\u662fModel-Based\uff08\u4f9d\u8d56\u73af\u5883\u6a21\u578b\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u6bcf\u8f6e\u8fed\u4ee3\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u6b65\u9aa4\uff1a 1. Policy Evaluation\uff08\u7b56\u7565\u8bc4\u4f30\uff09    \u5df2\u77e5\u5f53\u524d\u7b56\u7565\\(\\pi_k\\)\uff0c\u901a\u8fc7\u6c42\u89e3\u8d1d\u5c14\u66fc\u65b9\u7a0b\uff0c\u8ba1\u7b97\u8be5\u7b56\u7565\u4e0b\u6240\u6709\u72b6\u6001\u7684\u72b6\u6001\u4ef7\u503c\u51fd\u6570\\(v_{\\pi_k}(s)\\)\uff08\u5373\u4ece\u72b6\u6001\\(s\\)\u51fa\u53d1\uff0c\u9075\u5faa\\(\\pi_k\\)\u7684\u671f\u671b\u56de\u62a5\uff09\uff1a \\(\\(v_{\\pi}(s) = \\mathbb{E}_{\\pi}[G_t | S_t = s] = \\sum_a \\pi(a|s) \\sum_{s',r} p(s',r|s,a) \\left[ r + \\gamma v_{\\pi}(s') \\right]\\)\\)    \u5176\u4e2d\uff0c\\(p(s',r|s,a)\\)\u662f\u73af\u5883\u6a21\u578b\uff08\u72b6\u6001\u8f6c\u79fb\u6982\u7387+\u5373\u65f6\u5956\u52b1\u5206\u5e03\uff09\uff0c\\(\\gamma\\)\u662f\u6298\u6263\u56e0\u5b50\uff08\\(0 \\leq \\gamma \\leq 1\\)\uff09\u3002</p> <ol> <li>Policy Improvement\uff08\u7b56\u7565\u6539\u8fdb\uff09    \u57fa\u4e8e\u8bc4\u4f30\u5f97\u5230\u7684\\(v_{\\pi_k}(s)\\)\uff0c\u901a\u8fc7\u6700\u5927\u5316\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570\\(q_{\\pi_k}(s,a)\\) \u66f4\u65b0\u7b56\u7565\uff0c\u5f97\u5230\u66f4\u4f18\u7b56\u7565\\(\\pi_{k+1}\\)\uff1a \\(\\(\\pi_{k+1}(s) = \\arg\\max_a q_{\\pi_k}(s,a)\\)\\) </li> </ol>"},{"location":"notes/RL/Chap5MC/#q_pisa","title":"\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570\\(q_{\\pi}(s,a)\\)\u7684\u4e24\u79cd\u8ba1\u7b97\u65b9\u5f0f","text":"<p>\\(q_{\\pi}(s,a)\\)\u8868\u793a\u201c\u4ece\u72b6\u6001\\(s\\)\u51fa\u53d1\uff0c\u6267\u884c\u52a8\u4f5c\\(a\\)\u540e\u9075\u5faa\u7b56\u7565\\(\\pi\\)\u201d\u7684\u671f\u671b\u56de\u62a5\uff0c\u662f\u7b56\u7565\u6539\u8fdb\u7684\u6838\u5fc3\u4f9d\u636e\uff0c\u5176\u8ba1\u7b97\u5206\u4e3a\u4e24\u7c7b\uff1a | \u8ba1\u7b97\u65b9\u5f0f    | \u4f9d\u8d56\u6a21\u578b\uff1f | \u516c\u5f0f\u8868\u8fbe                                                     | \u9002\u7528\u573a\u666f                         | | ----------- | ---------- | ------------------------------------------------------------ | -------------------------------- | | Model-Based | \u662f         | \\(q_{\\pi}(s,a) = \\sum_{s',r} p(s',r|s,a) \\left[ r + \\gamma v_{\\pi}(s') \\right]\\) | Policy Iteration/Value Iteration | | Model-Free  | \u5426         | \\(q_{\\pi}(s,a) = \\mathbb{E}_{\\pi}[G_t | S_t = s, A_t = a]\\)    | \u8499\u7279\u5361\u6d1b\u65b9\u6cd5\uff08MC\uff09               |</p> <p>\u5176\u4e2d\uff0c\\(G_t\\)\u662f\u6298\u6263\u56de\u62a5\uff08Discounted Return\uff09\uff0c\u5b9a\u4e49\u4e3a\uff1a \\(\\(G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots + \\gamma^{T-t-1} R_T\\)\\) \\(T\\)\u662fepisode\uff08\u56de\u5408\uff09\u7684\u7ec8\u6b62\u6b65\uff0c\\(R_{t+i}\\)\u662f\\(t+i\\)\u65f6\u523b\u7684\u5373\u65f6\u5956\u52b1\u3002</p>"},{"location":"notes/RL/Chap5MC/#monte-carlo-mean-estimation","title":"Monte Carlo Mean Estimation\uff08\u8499\u7279\u5361\u6d1b\u5747\u503c\u4f30\u8ba1\uff09","text":"<p>\u6838\u5fc3\u4f5c\u7528\uff1a\u5728\u65e0\u73af\u5883\u6a21\u578b\u65f6\uff0c\u901a\u8fc7\u91c7\u6837\u591a\u4e2a\u72ec\u7acb\u6837\u672c\u7684\u5747\u503c\uff0c\u4f30\u8ba1\u968f\u673a\u53d8\u91cf\u7684\u671f\u671b\u3002 \u5bf9\u5e94\u5230\u5f3a\u5316\u5b66\u4e60\uff1a\\(q_{\\pi}(s,a)\\)\u662f\\(G_t\\)\u7684\u671f\u671b\uff0c\u56e0\u6b64\u53ef\u901a\u8fc7\u91c7\u6837\u591a\u4e2a\u4ece\\((s,a)\\)\u51fa\u53d1\u7684episode\uff0c\u8ba1\u7b97\u6bcf\u4e2aepisode\u7684\\(G_t\\)\uff0c\u518d\u6c42\u5747\u503c\u4f5c\u4e3a\\(q_{\\pi}(s,a)\\)\u7684\u4f30\u8ba1\uff1a \\(\\(\\hat{q}_{\\pi}(s,a) = \\frac{1}{N} \\sum_{i=1}^N G_t^{(i)}\\)\\) \u5176\u4e2d\uff0c\\(N\\)\u662f\u91c7\u6837\u7684episode\u6570\u91cf\uff0c\\(G_t^{(i)}\\)\u662f\u7b2c\\(i\\)\u4e2aepisode\u7684\u6298\u6263\u56de\u62a5\u3002</p>"},{"location":"notes/RL/Chap5MC/#mc-basic","title":"MC Basic\u7b97\u6cd5\u6838\u5fc3\u601d\u60f3","text":"<p>MC Basic\u7684\u672c\u8d28\u662f\u5c06Policy Iteration\u4e2d\u201c\u4f9d\u8d56\u6a21\u578b\u7684\\(q_{\\pi}\\)\u8ba1\u7b97\u201d\u66ff\u6362\u4e3a\u201c\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u91c7\u6837\u7684\\(q_{\\pi}\\)\u4f30\u8ba1\u201d\uff0c\u4ece\u800c\u5b9e\u73b0Model-Free\uff08\u4e0d\u4f9d\u8d56\u73af\u5883\u6a21\u578b\uff09\u7684\u7b56\u7565\u8fed\u4ee3\u3002  </p> <p>\u6838\u5fc3\u903b\u8f91\uff1a - \u65e0\u6a21\u578b \u2192 \u65e0\u6cd5\u7528\\(p(s',r|s,a)\\)\u8ba1\u7b97\\(q_{\\pi}\\)\uff1b - \u66ff\u4ee3\u65b9\u6848 \u2192 \u7528\u201c\u91c7\u6837\u6570\u636e\uff08Experience\uff09\u201d\u4f30\u8ba1\\(q_{\\pi}\\)\uff08\u5373\u8499\u7279\u5361\u6d1b\u5747\u503c\u4f30\u8ba1\uff09\uff1b - \u6700\u7ec8\u76ee\u6807 \u2192 \u4fdd\u6301Policy Iteration\u7684\u201c\u8bc4\u4f30-\u6539\u8fdb\u201d\u6846\u67b6\uff0c\u540c\u65f6\u6446\u8131\u5bf9\u73af\u5883\u6a21\u578b\u7684\u4f9d\u8d56\u3002</p>"},{"location":"notes/RL/Chap5MC/#mc-basic_1","title":"MC Basic\u7b97\u6cd5\u6b65\u9aa4\u4e0e\u4f2a\u4ee3\u7801","text":""},{"location":"notes/RL/Chap5MC/#_3","title":"\u7b97\u6cd5\u6574\u4f53\u6d41\u7a0b","text":"<p>MC Basic\u7684\u6bcf\u8f6e\u8fed\u4ee3\uff08\u7b2c\\(k\\)\u6b21\uff09\u4ecd\u5206\u4e3a\u201c\u7b56\u7565\u8bc4\u4f30\u201d\u548c\u201c\u7b56\u7565\u6539\u8fdb\u201d\u4e24\u6b65\uff0c\u6838\u5fc3\u5dee\u5f02\u5728\u7b56\u7565\u8bc4\u4f30\u7684\u5b9e\u73b0\uff1a</p>"},{"location":"notes/RL/Chap5MC/#1policy-evaluationmodel-free","title":"\u6b65\u9aa41\uff1aPolicy Evaluation\uff08\u7b56\u7565\u8bc4\u4f30\uff0cModel-Free\u7248\uff09","text":"<p>\u5bf9\u6240\u6709\u72b6\u6001-\u52a8\u4f5c\u5bf9\\((s,a)\\)\uff0c\u6267\u884c\u4ee5\u4e0b\u64cd\u4f5c\uff1a 1. \u4ece\\((s,a)\\)\u51fa\u53d1\uff0c\u9075\u5faa\u5f53\u524d\u7b56\u7565\\(\\pi_k\\)\uff0c\u751f\u6210\\(N\\)\u4e2a\u72ec\u7acb\u7684episode\uff08\\(N\\)\u9700\u8db3\u591f\u5927\u4ee5\u4fdd\u8bc1\u4f30\u8ba1\u7cbe\u5ea6\uff09\uff1b 2. \u5bf9\u6bcf\u4e2aepisode\uff0c\u8ba1\u7b97\u4ece\\((s,a)\\)\u5f00\u59cb\u7684\u6298\u6263\u56de\u62a5\\(G_t^{(1)}, G_t^{(2)}, \\dots, G_t^{(N)}\\)\uff1b 3. \u7528\u6837\u672c\u5747\u503c\u4f30\u8ba1\\(q_{\\pi_k}(s,a)\\)\uff1a \\(\\(\\hat{q}_{\\pi_k}(s,a) = \\frac{1}{N} \\sum_{i=1}^N G_t^{(i)}\\)\\) </p>"},{"location":"notes/RL/Chap5MC/#2policy-improvementpolicy-iteration","title":"\u6b65\u9aa42\uff1aPolicy Improvement\uff08\u7b56\u7565\u6539\u8fdb\uff0c\u4e0ePolicy Iteration\u4e00\u81f4\uff09","text":"<p>\u5bf9\u6bcf\u4e2a\u72b6\u6001\\(s\\)\uff0c\u9009\u62e9\u4f7f\\(\\hat{q}_{\\pi_k}(s,a)\\)\u6700\u5927\u7684\u52a8\u4f5c\u4f5c\u4e3a\u65b0\u7b56\u7565\\(\\pi_{k+1}(s)\\)\uff1a \\(\\(\\pi_{k+1}(s) = \\arg\\max_a \\hat{q}_{\\pi_k}(s,a)\\)\\) </p>"},{"location":"notes/RL/Chap5MC/#pseudocode","title":"\u4f2a\u4ee3\u7801\uff08Pseudocode\uff09","text":"Text Only<pre><code>1. \u521d\u59cb\u5316\uff1a\n   - \u9009\u62e9\u4efb\u610f\u521d\u59cb\u7b56\u7565\u03c0\u2080\uff08\u5982\u968f\u673a\u7b56\u7565\uff09\n   - \u8bbe\u5b9a\u6298\u6263\u56e0\u5b50\u03b3\u3001\u91c7\u6837episode\u6570\u91cfN\n\n2. \u8fed\u4ee3\uff08k=0,1,2,... \u76f4\u5230\u7b56\u7565\u6536\u655b\uff09\uff1a\n   a. \u7b56\u7565\u8bc4\u4f30\uff08\u4f30\u8ba1q_\u03c0\u2096(s,a)\uff09\uff1a\n      \u5bf9\u6240\u6709\u72b6\u6001s \u2208 S\uff1a\n         \u5bf9\u6240\u6709\u52a8\u4f5ca \u2208 A(s)\uff1a\n             \u751f\u6210N\u4e2a\u4ece(s,a)\u51fa\u53d1\u3001\u9075\u5faa\u03c0\u2096\u7684episode\n             \u8ba1\u7b97\u6bcf\u4e2aepisode\u7684\u6298\u6263\u56de\u62a5G_t\u207d\u00b9\u207e, G_t\u207d\u00b2\u207e, ..., G_t\u207d\u1d3a\u207e\n             \u4f30\u8ba1q_\u03c0\u2096(s,a) = (1/N) * \u03a3G_t\u207d\u2071\u207e\uff08i\u4ece1\u5230N\uff09\n\n   b. \u7b56\u7565\u6539\u8fdb\uff08\u66f4\u65b0\u4e3a\u03c0\u2096\u208a\u2081\uff09\uff1a\n      \u5bf9\u6240\u6709\u72b6\u6001s \u2208 S\uff1a\n          \u03c0\u2096\u208a\u2081(s) = argmax\u2090 q_\u03c0\u2096(s,a) \uff08\u9009\u62e9\u4f7fq\u503c\u6700\u5927\u7684\u52a8\u4f5c\uff09\n\n3. \u8f93\u51fa\u6700\u7ec8\u6536\u655b\u7684\u7b56\u7565\u03c0*\n</code></pre>"},{"location":"notes/RL/Chap5MC/#mc-basicpolicy-iteration","title":"MC Basic\u4e0ePolicy Iteration\u7684\u5173\u952e\u5bf9\u6bd4","text":"\u5bf9\u6bd4\u7ef4\u5ea6 MC Basic\uff08Model-Free\uff09 Policy Iteration\uff08Model-Based\uff09 \u7b56\u7565\u8bc4\u4f30\u65b9\u5f0f \u8499\u7279\u5361\u6d1b\u91c7\u6837\uff08\u6837\u672c\u5747\u503c\u4f30\u8ba1q_\u03c0\uff09 \u6c42\u89e3\u8d1d\u5c14\u66fc\u65b9\u7a0b\uff08\u5148\u6c42v_\u03c0\uff0c\u518d\u8f6cq_\u03c0\uff09 \u662f\u5426\u4f9d\u8d56\u73af\u5883\u6a21\u578b \u5426\uff08\u4f9d\u8d56\u91c7\u6837\u6570\u636e/\u7ecf\u9a8c\uff09 \u662f\uff08\u4f9d\u8d56p(s',r \u503c\u51fd\u6570\u4f30\u8ba1\u5bf9\u8c61 \u76f4\u63a5\u4f30\u8ba1q_\u03c0(s,a) \u5148\u4f30\u8ba1v_\u03c0(s)\uff0c\u518d\u63a8\u5bfcq_\u03c0(s,a) \u6570\u636e\u9700\u6c42 \u5927\u91cfepisode\u91c7\u6837\u6570\u636e \u65e0\u9700\u6570\u636e\uff08\u9700\u6a21\u578b\u53c2\u6570\uff09 \u8ba1\u7b97\u6548\u7387 \u4f4e\uff08\u9700\u904d\u5386\u6240\u6709(s,a)\u5e76\u91c7\u6837\u591aepisode\uff09 \u9ad8\uff08\u65b9\u7a0b\u6c42\u89e3\uff0c\u65e0\u91c7\u6837\u5f00\u9500\uff09"},{"location":"notes/RL/Chap5MC/#mc-basic_2","title":"MC Basic\u7b97\u6cd5\u7279\u6027\u4e0e\u6ce8\u610f\u4e8b\u9879","text":""},{"location":"notes/RL/Chap5MC/#_4","title":"\u6536\u655b\u6027","text":"<ul> <li>\u6838\u5fc3\u7ed3\u8bba\uff1aMC Basic\u7684\u6536\u655b\u6027\u4e0ePolicy Iteration\u4e00\u81f4\uff0c\u5f53\u91c7\u6837\u6570\u91cfN\u2192\u221e\u65f6\uff0cq_\u03c0\u7684\u4f30\u8ba1\u503c\u6536\u655b\u5230\u771f\u5b9e\u503c\uff0c\u6700\u7ec8\u7b56\u7565\u4f1a\u6536\u655b\u5230\u6700\u4f18\u7b56\u7565\u03c0*\u3002  </li> <li>\u539f\u56e0\uff1a\u8499\u7279\u5361\u6d1b\u5747\u503c\u4f30\u8ba1\u662f\u65e0\u504f\u4f30\u8ba1\uff0c\u5f53\u6837\u672c\u91cf\u8db3\u591f\u5927\u65f6\uff0c\u4f30\u8ba1\u503c\u8d8b\u8fd1\u4e8e\u771f\u5b9e\u671f\u671b\uff1b\u7b56\u7565\u6539\u8fdb\u6b65\u9aa4\u4e0ePolicy Iteration\u5b8c\u5168\u76f8\u540c\uff0c\u4fdd\u8bc1\u7b56\u7565\u5355\u8c03\u9012\u589e\u3002</li> </ul>"},{"location":"notes/RL/Chap5MC/#_5","title":"\u6548\u7387\u4e0e\u5b9e\u7528\u6027","text":"<ul> <li>\u6548\u7387\u4f4e\uff1a\u9700\u904d\u5386\u6240\u6709\u72b6\u6001-\u52a8\u4f5c\u5bf9\\((s,a)\\)\uff0c\u4e14\u6bcf\u4e2a\\((s,a)\\)\u9700\u91c7\u6837\u591a\u4e2aepisode\uff0c\u6570\u636e\u5229\u7528\u7387\u6781\u4f4e\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002  </li> <li>\u5b9e\u7528\u6027\u5dee\uff1aMC Basic\u662f\u8bb2\u5e08\u4e3a\u201c\u5265\u79bb\u6838\u5fc3\u601d\u60f3\u201d\u81ea\u5b9a\u4e49\u7684\u7b97\u6cd5\uff08\u975e\u901a\u7528\u6807\u51c6\u7b97\u6cd5\uff09\uff0c\u5b9e\u9645\u4e2d\u4e0d\u4f1a\u76f4\u63a5\u4f7f\u7528\uff0c\u4f46\u5b83\u662f\u540e\u7eed\u9ad8\u6548MC\u7b97\u6cd5\uff08\u5982MC Exploring Starts\u3001MC \u03b5-Greedy\uff09\u7684\u57fa\u7840\u3002</li> </ul>"},{"location":"notes/RL/Chap5MC/#q_","title":"\u76f4\u63a5\u4f30\u8ba1q_\u03c0\u7684\u539f\u56e0","text":"<p>MC Basic\u9009\u62e9\u76f4\u63a5\u4f30\u8ba1\\(q_{\\pi}(s,a)\\)\uff0c\u800c\u975e\u5148\u4f30\u8ba1\\(v_{\\pi}(s)\\)\uff0c\u6838\u5fc3\u539f\u56e0\u662f\uff1a - \u4ece\\(v_{\\pi}(s)\\)\u63a8\u5bfc\\(q_{\\pi}(s,a)\\)\u9700\u8981\u73af\u5883\u6a21\u578b\\(p(s',r|s,a)\\)\uff08Model-Based\uff09\uff0c\u800cMC Basic\u662fModel-Free\u7b97\u6cd5\uff0c\u65e0\u6cd5\u83b7\u53d6\u6a21\u578b\u53c2\u6570\uff0c\u56e0\u6b64\u5fc5\u987b\u76f4\u63a5\u4f30\u8ba1\\(q_{\\pi}(s,a)\\)\u3002</p>"},{"location":"notes/RL/Chap5MC/#_6","title":"\u6838\u5fc3\u601d\u60f3\u4ef7\u503c","text":"<p>MC Basic\u7684\u6700\u5927\u610f\u4e49\u662f\u6e05\u6670\u63ed\u793a\u4e86\u201c\u4eceModel-Based\u5230Model-Free\u201d\u7684\u8f6c\u5316\u903b\u8f91\uff1a \u5373\u201c\u7528\u2018\u91c7\u6837\u6570\u636e\u7684\u7edf\u8ba1\u4f30\u8ba1\u2019\u66ff\u4ee3\u2018\u6a21\u578b\u53c2\u6570\u7684\u89e3\u6790\u8ba1\u7b97\u2019\u201d\uff0c\u8fd9\u662f\u6240\u6709\u8499\u7279\u5361\u6d1b\u7c7b\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u6838\u5fc3\u601d\u8def\u3002</p>"},{"location":"notes/RL/Chapter1/","title":"Chapter1","text":""},{"location":"notes/RL/Chapter1/#1-","title":"\u300a\u5f3a\u5316\u5b66\u4e60\u7684\u6570\u5b66\u539f\u7406\u300b\u7b2c1\u8bfe-\u57fa\u672c\u6982\u5ff5\u77e5\u8bc6\u70b9\u6574\u7406","text":"<p> \u7ea6 2694 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 13 \u5206\u949f</p>"},{"location":"notes/RL/Chapter1/#grid-world","title":"\u6838\u5fc3\u5b9e\u4f8b\uff1a\u7f51\u683c\u4e16\u754c\uff08grid-world\uff09","text":"<ol> <li>\u4e16\u754c\u6784\u6210\uff1a\u7531\u7f51\u683c\u7ec4\u6210\uff0c\u5305\u542b3\u7c7b\u7f51\u683c    - \u53ef\u8fdb\u5165\u533a\u57df\uff08\u767d\u8272\uff09\uff1a\u673a\u5668\u4eba\u53ef\u6b63\u5e38\u79fb\u52a8\u8fdb\u5165    - \u7981\u6b62\u533a\u57df\uff08\u9ec4\u8272\uff09\uff1a\u8bfe\u7a0b\u4e2d\u5b9a\u4e49\u4e3a\u300c\u53ef\u8fdb\u5165\u4f46\u4f1a\u53d7\u60e9\u7f5a\u300d\uff08\u6bd4\u300c\u7269\u7406\u4e0d\u53ef\u8fdb\u5165\u300d\u66f4\u901a\u7528\uff0c\u53ef\u80fd\u51fa\u73b0\u201c\u5192\u9669\u8d70\u7981\u533a\u57df\u6284\u8fd1\u8def\u201d\u7684\u6709\u8da3\u884c\u4e3a\uff09    - \u76ee\u6807\u533a\u57df\uff08target area\uff09\uff1a\u673a\u5668\u4eba\u9700\u62b5\u8fbe\u7684\u6700\u7ec8\u76ee\u6807    - \u8fb9\u754c\uff1a\u673a\u5668\u4eba\u65e0\u6cd5\u8d85\u8d8a\uff0c\u649e\u8fb9\u754c\u540e\u4f1a\u5f39\u56de\u539f\u72b6\u6001</li> <li>\u673a\u5668\u4eba\u89c4\u5219\uff1a\u4ec5\u80fd\u5728\u76f8\u90bb\u7f51\u683c\uff08\u4e0a\u4e0b\u5de6\u53f3\uff09\u79fb\u52a8\uff0c\u4e0d\u53ef\u659c\u5411\u79fb\u52a8</li> <li>\u6838\u5fc3\u4efb\u52a1\uff1a\u627e\u5230\u4ece\u8d77\u70b9\u5230\u76ee\u6807\u533a\u57df\u7684\u300c\u4f18\u8d28\u8def\u5f84\u300d\uff0c\u76f4\u89c2\u5224\u65ad\u6807\u51c6\u5305\u62ec\uff1a    - \u907f\u514d\u8fdb\u5165\u7981\u6b62\u533a\u57df    - \u51cf\u5c11\u65e0\u610f\u4e49\u62d0\u5f2f\uff08\u5982\u53cd\u590d\u5f80\u8fd4\uff09    - \u4e0d\u5c1d\u8bd5\u8d85\u8d8a\u8fb9\u754c</li> </ol>"},{"location":"notes/RL/Chapter1/#_1","title":"\u4e09\u3001\u5f3a\u5316\u5b66\u4e60\u6838\u5fc3\u57fa\u7840\u6982\u5ff5","text":""},{"location":"notes/RL/Chapter1/#statestate-space","title":"\uff08\u4e00\uff09\u72b6\u6001\uff08State\uff09\u4e0e\u72b6\u6001\u7a7a\u95f4\uff08State Space\uff09","text":"<ol> <li>\u72b6\u6001\uff08State\uff09    - \u5b9a\u4e49\uff1a\u63cf\u8ff0\u667a\u80fd\u4f53\uff08agent\uff09\u76f8\u5bf9\u4e8e\u73af\u5883\u7684\u72b6\u6001\uff08status\uff09    - \u7f51\u683c\u4e16\u754c\u5b9e\u4f8b\uff1a\u5373\u673a\u5668\u4eba\u7684\u300c\u4f4d\u7f6e\u300d\uff0c\u7528s\u2081\u3001s\u2082\u2026s\u2089\u8868\u793a\uff08\u6bcf\u4e2a\u7b26\u53f7\u5bf9\u5e94\u4e8c\u7ef4\u5e73\u9762\u7684(x,y)\u5750\u6807\uff09    - \u6269\u5c55\u573a\u666f\uff1a\u590d\u6742\u95ee\u9898\u4e2d\uff0c\u72b6\u6001\u8fd8\u53ef\u80fd\u5305\u542b\u901f\u5ea6\u3001\u52a0\u901f\u5ea6\u7b49\u989d\u5916\u4fe1\u606f</li> <li>\u72b6\u6001\u7a7a\u95f4\uff08State Space\uff09    - \u5b9a\u4e49\uff1a\u6240\u6709\u53ef\u80fd\u72b6\u6001\u7684\u96c6\u5408\uff08\u672c\u8d28\u662f\u6570\u5b66\u4e2d\u7684\u201c\u96c6\u5408\u201d\uff0c\u975e\u590d\u6742\u7ebf\u6027\u7a7a\u95f4\uff09    - \u8868\u793a\u7b26\u53f7\uff1a\u7528\u82b1\u4f53\u300c\ud835\udce2\u300d\u8868\u793a\uff0c\u5f62\u5f0f\u4e3a\ud835\udce2 = {s\u2081, s\u2082, ..., s\u2099}\uff08n\u4e3a\u72b6\u6001\u603b\u6570\uff0c\u53ef\u4ece\u4e0a\u4e0b\u6587\u63a8\u65ad\u8303\u56f4\uff09</li> </ol>"},{"location":"notes/RL/Chapter1/#actionaction-space","title":"\uff08\u4e8c\uff09\u52a8\u4f5c\uff08Action\uff09\u4e0e\u52a8\u4f5c\u7a7a\u95f4\uff08Action Space\uff09","text":"<ol> <li>\u52a8\u4f5c\uff08Action\uff09    - \u5b9a\u4e49\uff1a\u667a\u80fd\u4f53\u5728\u67d0\u4e00\u72b6\u6001\u4e0b\u53ef\u91c7\u53d6\u7684\u5177\u4f53\u884c\u4e3a    - \u7f51\u683c\u4e16\u754c\u5b9e\u4f8b\uff1a\u51715\u79cd\u52a8\u4f5c\uff0c\u5206\u522b\u4e3aa\u2081\uff08\u5411\u4e0a\uff09\u3001a\u2082\uff08\u5411\u53f3\uff09\u3001a\u2083\uff08\u5411\u4e0b\uff09\u3001a\u2084\uff08\u5411\u5de6\uff09\u3001a\u2085\uff08\u539f\u5730\u4e0d\u52a8\uff09</li> <li>\u52a8\u4f5c\u7a7a\u95f4\uff08Action Space\uff09    - \u5b9a\u4e49\uff1a\u67d0\u4e00\u72b6\u6001\u4e0b\u6240\u6709\u53ef\u80fd\u52a8\u4f5c\u7684\u96c6\u5408    - \u8868\u793a\u7b26\u53f7\uff1a\u7528\u82b1\u4f53\u300c\ud835\udcd0\u300d\u8868\u793a\uff0c\u5f62\u5f0f\u4e3a\ud835\udcd0(s\u1d62)\uff08\u62ec\u53f7\u6807\u6ce8s\u1d62\uff0c\u5f3a\u8c03\u300c\u52a8\u4f5c\u7a7a\u95f4\u4e0e\u72b6\u6001\u76f8\u5173\u300d\uff0c\u4e0d\u540c\u72b6\u6001\u7684\u53ef\u6267\u884c\u52a8\u4f5c\u53ef\u80fd\u4e0d\u540c\uff09</li> </ol>"},{"location":"notes/RL/Chapter1/#state-transition","title":"\uff08\u4e09\uff09\u72b6\u6001\u8f6c\u79fb\uff08State Transition\uff09","text":"<ol> <li>\u5b9a\u4e49\uff1a\u667a\u80fd\u4f53\u5728\u67d0\u4e00\u72b6\u6001\u4e0b\u91c7\u53d6\u67d0\u4e00\u52a8\u4f5c\u540e\uff0c\u4ece\u5f53\u524d\u72b6\u6001\u79fb\u52a8\u5230\u4e0b\u4e00\u72b6\u6001\u7684\u8fc7\u7a0b</li> <li>\u7f51\u683c\u4e16\u754c\u5b9e\u4f8b\uff1a    - \u4f8b1\uff1a\u5728s\u2081\u72b6\u6001\u91c7\u53d6a\u2082\uff08\u5411\u53f3\uff09\u52a8\u4f5c\uff0c\u4e0b\u4e00\u72b6\u6001\u4e3as\u2082    - \u4f8b2\uff1a\u5728s\u2081\u72b6\u6001\u91c7\u53d6a\u2081\uff08\u5411\u4e0a\uff09\u52a8\u4f5c\uff0c\u56e0\u649e\u8fb9\u754c\u5f39\u56de\uff0c\u4e0b\u4e00\u72b6\u6001\u4ecd\u4e3as\u2081    - \u4f8b3\uff1a\u5728s\u2085\uff08\u7981\u533a\u57df\u76f8\u90bb\uff09\u91c7\u53d6a\u2082\uff08\u5411\u53f3\uff09\u52a8\u4f5c\uff0c\u4e0b\u4e00\u72b6\u6001\u4e3as\u2086\uff08\u7981\u533a\u57df\uff0c\u4f1a\u53d7\u60e9\u7f5a\uff09</li> <li>\u8868\u793a\u65b9\u5f0f\uff1a\u7b80\u5355\u573a\u666f\u53ef\u7528\u300c\u8868\u683c\u300d\u8868\u793a\uff08\u884c=\u72b6\u6001\uff0c\u5217=\u52a8\u4f5c\uff0c\u5355\u5143\u683c=\u4e0b\u4e00\u72b6\u6001\uff09\uff0c\u4f46\u4ec5\u9002\u7528\u4e8e\u300c\u786e\u5b9a\u6027\u8f6c\u79fb\u300d\uff08\u65e0\u968f\u673a\u56e0\u7d20\uff09</li> </ol>"},{"location":"notes/RL/Chapter1/#state-transition-probability","title":"\uff08\u56db\uff09\u72b6\u6001\u8f6c\u79fb\u6982\u7387\uff08State Transition Probability\uff09","text":"<ol> <li>\u5b9a\u4e49\uff1a\u7528\u300c\u6761\u4ef6\u6982\u7387\u300d\u63cf\u8ff0\u72b6\u6001\u8f6c\u79fb\u7684\u53ef\u80fd\u6027\uff0c\u53ef\u5904\u7406\u300c\u968f\u673a\u6027\u8f6c\u79fb\u300d\uff08\u6bd4\u8868\u683c\u66f4\u901a\u7528\uff09</li> <li>\u8868\u793a\u7b26\u53f7\uff1ap(s' | s, a)\uff0c\u542b\u4e49\u4e3a\u201c\u5728\u72b6\u6001s\u4e0b\u91c7\u53d6\u52a8\u4f5ca\uff0c\u8f6c\u79fb\u5230\u72b6\u6001s'\u7684\u6982\u7387\u201d</li> <li>\u5b9e\u4f8b\uff1a    - \u786e\u5b9a\u6027\u8f6c\u79fb\uff1ap(s\u2082 | s\u2081, a\u2082) = 1\uff08s\u2081\u91c7\u53d6a\u2082\u5fc5\u5230s\u2082\uff09\uff0cp(s\u1d62 | s\u2081, a\u2082) = 0\uff08i\u22602\u65f6\u6982\u7387\u4e3a0\uff09    - \u968f\u673a\u6027\u8f6c\u79fb\uff08\u5982\u8003\u8651\u98ce\u7684\u5f71\u54cd\uff09\uff1ap(s\u2082 | s\u2081, a\u2082) = 0.5\uff0cp(s\u2085 | s\u2081, a\u2082) = 0.5\uff08s\u2081\u91c7\u53d6a\u2082\uff0c50%\u5230s\u2082\u300150%\u5230s\u2085\uff09</li> </ol>"},{"location":"notes/RL/Chapter1/#policy","title":"\uff08\u4e94\uff09\u7b56\u7565\uff08Policy\uff09","text":"<ol> <li>\u5b9a\u4e49\uff1a\u6307\u5bfc\u667a\u80fd\u4f53\u201c\u5728\u67d0\u4e00\u72b6\u6001\u4e0b\u5e94\u91c7\u53d6\u4f55\u79cd\u52a8\u4f5c\u201d\u7684\u89c4\u5219\uff0c\u662f\u5f3a\u5316\u5b66\u4e60\u7684\u6838\u5fc3\u72ec\u6709\u6982\u5ff5</li> <li>\u76f4\u89c2\u8868\u793a\uff1a\u7528\u7bad\u5934\u6807\u6ce8\u6bcf\u4e2a\u72b6\u6001\u7684\u63a8\u8350\u52a8\u4f5c\uff08\u5982s\u2081\u7bad\u5934\u5411\u53f3\uff0c\u8868\u793a\u63a8\u8350a\u2082\u52a8\u4f5c\uff09\uff0c\u57fa\u4e8e\u7b56\u7565\u53ef\u751f\u6210\u300c\u8def\u5f84\uff08path\uff09\u300d\u6216\u300c\u8f68\u8ff9\uff08trajectory\uff09\u300d\uff08\u5982\u4ece\u8d77\u70b9\u6309\u7b56\u7565\u52a8\u4f5c\u4f9d\u6b21\u8f6c\u79fb\u5230\u76ee\u6807\u7684\u8fc7\u7a0b\uff09</li> <li>\u6570\u5b66\u8868\u793a\uff1a\u7528\u300c\u6761\u4ef6\u6982\u7387\u300d\u03c0(a | s)\u63cf\u8ff0\uff0c\u542b\u4e49\u4e3a\u201c\u5728\u72b6\u6001s\u4e0b\u91c7\u53d6\u52a8\u4f5ca\u7684\u6982\u7387\u201d\uff0c\u6ee1\u8db3\u300c\u67d0\u4e00\u72b6\u6001\u4e0b\u6240\u6709\u52a8\u4f5c\u6982\u7387\u548c\u4e3a1\u300d</li> <li>\u5206\u7c7b\uff1a    - \u786e\u5b9a\u6027\u7b56\u7565\uff1a\u67d0\u4e00\u52a8\u4f5c\u6982\u7387\u4e3a1\uff0c\u5176\u4f59\u4e3a0\uff08\u5982\u03c0(a\u2082 | s\u2081) = 1\uff0c\u03c0(a\u2081,a\u2083,a\u2084,a\u2085 | s\u2081) = 0\uff09    - \u968f\u673a\u6027\u7b56\u7565\uff1a\u591a\u4e2a\u52a8\u4f5c\u6709\u975e\u96f6\u6982\u7387\uff08\u5982\u03c0(a\u2082 | s\u2081) = 0.5\uff0c\u03c0(a\u2083 | s\u2081) = 0.5\uff0c\u5176\u4f59\u4e3a0\uff09</li> <li>\u5de5\u7a0b\u5b9e\u73b0\uff1a    - \u8868\u793a\uff1a\u7528\u6570\u7ec4/\u77e9\u9635\u5b58\u50a8\uff08\u884c=\u72b6\u6001\uff0c\u5217=\u52a8\u4f5c\uff0c\u5355\u5143\u683c=\u52a8\u4f5c\u6982\u7387\uff09    - \u6267\u884c\uff08\u968f\u673a\u6027\u7b56\u7565\uff09\uff1a\u4ece[0,1]\u5747\u5300\u968f\u673a\u91c7\u6837x\uff0c\u6309\u6982\u7387\u533a\u95f4\u9009\u62e9\u52a8\u4f5c\uff08\u5982x\u2208[0,0.5]\u9009a\u2082\uff0cx\u2208[0.5,1]\u9009a\u2083\uff09</li> </ol>"},{"location":"notes/RL/Chapter1/#reward","title":"\uff08\u516d\uff09Reward\uff08\u5956\u52b1\uff09","text":"<ol> <li> <p>\u5b9a\u4e49\u4e0e\u672c\u8d28    - \u672c\u8d28\uff1a\u667a\u80fd\u4f53\uff08agent\uff09\u5728\u67d0\u4e00\u72b6\u6001\u91c7\u53d6\u52a8\u4f5c\u540e\u83b7\u5f97\u7684\u300c\u5b9e\u6570\u6807\u91cf\u300d\uff0c\u662f\u4eba\u673a\u4ea4\u4e92\u7684\u6838\u5fc3\u63a5\u53e3\uff08\u5f15\u5bfc\u667a\u80fd\u4f53\u884c\u4e3a\uff09    - \u542b\u4e49\uff1a\u6b63\u6570\u8868\u793a\u300c\u9f13\u52b1\u8be5\u884c\u4e3a\u300d\uff0c\u8d1f\u6570\u8868\u793a\u300c\u60e9\u7f5a\u8be5\u884c\u4e3a\u300d\uff0c0\u8868\u793a\u300c\u65e0\u60e9\u7f5a\uff08\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u9690\u542b\u9f13\u52b1\uff09\u300d    - \u7075\u6d3b\u6027\uff1a\u53ef\u901a\u8fc7\u6570\u5b66\u8f6c\u6362\u8c03\u6574\u6b63\u8d1f\u542b\u4e49\uff08\u5982\u7528\u6b63\u6570\u8868\u60e9\u7f5a\u3001\u8d1f\u6570\u8868\u9f13\u52b1\uff09\uff0c\u6838\u5fc3\u662f\u667a\u80fd\u4f53\u76ee\u6807\u4e0e\u5956\u52b1\u65b9\u5411\u4e00\u81f4\uff08\u6700\u5927\u5316\u9f13\u52b1/\u6700\u5c0f\u5316\u60e9\u7f5a\uff09</p> </li> <li> <p>\u7f51\u683c\u4e16\u754c\u5b9e\u4f8b\u8bbe\u8ba1    - \u8fb9\u754c\u60e9\u7f5a\uff1a\u8bd5\u56fe\u8d85\u8d8a\u8fb9\u754c\uff08\u5982s1\u91c7\u53d6a1\u5411\u4e0a\uff09\uff0c\u5956\u52b1<code>r_bound = -1</code>    - \u7981\u533a\u57df\u60e9\u7f5a\uff1a\u8fdb\u5165\u7981\u6b62\u533a\u57df\uff08\u5982s5\u91c7\u53d6a2\u5411\u53f3\u5230s6\uff09\uff0c\u5956\u52b1<code>r_forbid = -1</code>    - \u76ee\u6807\u5956\u52b1\uff1a\u8fdb\u5165\u76ee\u6807\u533a\u57df\uff08\u5982\u5230s9\uff09\uff0c\u5956\u52b1<code>r_target = +1</code>    - \u5176\u4ed6\u884c\u4e3a\uff1a\u6b63\u5e38\u79fb\u52a8\uff08\u5982s1\u91c7\u53d6a2\u5411\u53f3\u5230s2\uff09\u3001\u539f\u5730\u4e0d\u52a8\uff0c\u5956\u52b1\u5747\u4e3a0</p> </li> <li> <p>\u5173\u952e\u6ce8\u610f\u70b9    - \u4f9d\u8d56\u5bf9\u8c61\uff1aReward\u4ec5\u4f9d\u8d56\u300c\u5f53\u524d\u72b6\u6001+\u5f53\u524d\u52a8\u4f5c\u300d\uff0c\u4e0e\u300c\u4e0b\u4e00\u4e2a\u72b6\u6001\u300d\u65e0\u5173</p> <ul> <li>\u5b9e\u4f8b\uff1as1\u91c7\u53d6a1\uff08\u649e\u8fb9\u754c\uff0c\u4e0b\u72b6\u6001s1\uff0c\u5956\u52b1-1\uff09\u4e0es1\u91c7\u53d6a5\uff08\u539f\u5730\u4e0d\u52a8\uff0c\u4e0b\u72b6\u6001s1\uff0c\u5956\u52b10\uff09\uff0c\u4e0b\u72b6\u6001\u76f8\u540c\u4f46\u5956\u52b1\u4e0d\u540c\uff0c\u56e0\u52a8\u4f5c\u542b\u4e49\u4e0d\u540c</li> <li>\u8868\u793a\u65b9\u5f0f\uff1a</li> <li>\u8868\u683c\u5f62\u5f0f\uff1a\u884c=\u72b6\u6001\uff0c\u5217=\u52a8\u4f5c\uff0c\u5355\u5143\u683c=\u5956\u52b1\uff0c\u4ec5\u9002\u7528\u4e8e\u300c\u786e\u5b9a\u6027\u5956\u52b1\u300d\uff08\u67d0\u72b6\u6001-\u52a8\u4f5c\u5bf9\u5e94\u56fa\u5b9a\u5956\u52b1\uff09</li> <li>\u6982\u7387\u5f62\u5f0f\uff1a\u7528\u6761\u4ef6\u6982\u7387<code>p(r | s, a)</code>\u63cf\u8ff0\uff0c\u53ef\u5904\u7406\u300c\u968f\u673a\u6027\u5956\u52b1\u300d\uff08\u5982\u52aa\u529b\u5b66\u4e60\u53ef\u80fd\u83b7\u5f97\u4e0d\u540c\u6b63\u5956\u52b1\uff09\uff0c\u4f8b\uff1a<code>p(r=-1 | s1, a1) = 1</code>\uff08\u786e\u5b9a\u6027\uff09\u3001<code>p(r=2 | s, a)=0.6, p(r=1 | s, a)=0.4</code>\uff08\u968f\u673a\u6027\uff09</li> </ul> </li> </ol>"},{"location":"notes/RL/Chapter1/#trajectory","title":"\uff08\u516d\uff09Trajectory\uff08\u8f68\u8ff9\uff09","text":"<ol> <li>\u5b9a\u4e49\uff1a\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u4ea4\u4e92\u5f62\u6210\u7684\u300c\u72b6\u6001-\u52a8\u4f5c-\u5956\u52b1\u300d\u5e8f\u5217\u94fe\uff0c\u5373<code>s\u2080 \u2192(a\u2080,r\u2080) s\u2081 \u2192(a\u2081,r\u2081) s\u2082 \u2192\u2026\u2192s\u2099</code></li> <li>\u7f51\u683c\u4e16\u754c\u5b9e\u4f8b\uff1a\u4eces1\u51fa\u53d1\uff0cs1\uff08a2,0\uff09\u2192s2\uff08a3,0\uff09\u2192s5\uff08a3,0\uff09\u2192s8\uff08a2,1\uff09\u2192s9\uff0c\u5f62\u6210\u5b8c\u6574\u8f68\u8ff9</li> <li>\u5c5e\u6027\uff1a\u8f68\u8ff9\u957f\u5ea6\u53ef\u6709\u9650\uff08\u5982\u5230\u76ee\u6807\u540e\u505c\u6b62\uff09\u6216\u65e0\u9650\uff08\u5982\u76ee\u6807\u533a\u57df\u6301\u7eed\u6267\u884c\u7b56\u7565\uff09</li> </ol>"},{"location":"notes/RL/Chapter1/#return","title":"\uff08\u4e03\uff09Return\uff08\u56de\u62a5\uff09","text":"<ol> <li>\u5b9a\u4e49\uff1a\u67d0\u6761\u8f68\u8ff9\u4e0a\u6240\u6709\u5956\u52b1\u7684\u300c\u603b\u548c\u300d\uff0c\u662f\u8bc4\u4f30\u8f68\u8ff9/\u5bf9\u5e94\u7b56\u7565\u597d\u574f\u7684\u6838\u5fc3\u6307\u6807    - \u516c\u5f0f\uff08\u6709\u9650\u8f68\u8ff9\uff09\uff1a<code>Return = r\u2080 + r\u2081 + r\u2082 + \u2026 + r\u2099</code></li> <li> <p>\u7f51\u683c\u4e16\u754c\u5b9e\u4f8b\u5bf9\u6bd4    - \u4f18\u8d28\u8f68\u8ff9\uff08\u907f\u7981\u533a\u57df\uff09\uff1as1\u2192s2\u2192s5\u2192s8\u2192s9\uff0c\u5956\u52b1\u5e8f\u5217[0,0,0,1]\uff0cReturn=1    - \u8f83\u5dee\u8f68\u8ff9\uff08\u8fdb\u7981\u533a\u57df\uff09\uff1as1\u2192s4\u2192s5\u2192s6\uff08\u7981\u533a\u57df\uff0c-1\uff09\u2192s9\uff0c\u5956\u52b1\u5e8f\u5217[0,0,-1,1]\uff0cReturn=0    - \u7ed3\u8bba\uff1aReturn\u8d8a\u5927\uff0c\u8f68\u8ff9/\u7b56\u7565\u8d8a\u4f18\uff0c\u5b9e\u73b0\u300c\u76f4\u89c2\u5224\u65ad\u2192\u6570\u5b66\u91cf\u5316\u300d\u7684\u8f6c\u6362</p> </li> <li> <p>Discounted Return\uff08\u6298\u6263\u56de\u62a5\uff09</p> </li> <li>\u6838\u5fc3\u95ee\u9898\uff1a\u65e0\u9650\u8f68\u8ff9\uff08\u5982\u76ee\u6807\u533a\u57df\u6301\u7eed\u83b7\u5f97+1\u5956\u52b1\uff09\u7684\u666e\u901aReturn\u4f1a\u300c\u53d1\u6563\u5230\u65e0\u7a77\u300d\uff0c\u65e0\u6cd5\u91cf\u5316\u8bc4\u4f30</li> <li>\u5b9a\u4e49\uff1a\u5f15\u5165\u6298\u6263\u7387<code>\u03b3</code>\uff08<code>0 \u2264 \u03b3 \u2264 1</code>\uff09\uff0c\u5bf9\u672a\u6765\u5956\u52b1\u6309\u300c\u65f6\u95f4\u6b65\u6b21\u65b9\u300d\u8870\u51cf\uff0c\u516c\u5f0f\u4e3a\uff1a    - <code>Discounted Return = r\u2080 + \u03b3r\u2081 + \u03b3\u00b2r\u2082 + \u03b3\u00b3r\u2083 + \u2026</code></li> <li> <p>\u6298\u6263\u7387<code>\u03b3</code>\u7684\u4f5c\u7528    - \u6536\u655b\u6027\uff1a\u5f53<code>\u03b3 &lt; 1</code>\u65f6\uff0c\u65e0\u9650\u5956\u52b1\u5e8f\u5217\u548c\u6536\u655b\u4e3a\u6709\u9650\u503c\uff08\u7b49\u6bd4\u6570\u5217\u6c42\u548c\uff1a<code>S = r\u2080 + \u03b3r\u2081 + \u2026 = r\u2080 + \u03b3*(r\u2081 + \u03b3r\u2082 + \u2026)</code>\uff0c\u82e5\u540e\u7eed\u5956\u52b1\u6052\u5b9a\u4e3ar\uff0c\u603b\u548c\u4e3a<code>r/(1-\u03b3)</code>\uff09    - \u884c\u4e3a\u5f15\u5bfc\uff1a</p> <ul> <li><code>\u03b3\u21920</code>\uff1a\u667a\u80fd\u4f53\u300c\u8fd1\u89c6\u300d\uff0c\u4ec5\u5173\u6ce8\u5f53\u524d/\u8fd1\u671f\u5956\u52b1\uff08\u5982<code>\u03b3=0.1</code>\uff0c\u672a\u67653\u6b65\u5956\u52b1\u8870\u51cf\u81f30.001\uff0c\u5f71\u54cd\u53ef\u5ffd\u7565\uff09</li> <li><code>\u03b3\u21921</code>\uff1a\u667a\u80fd\u4f53\u300c\u8fdc\u89c6\u300d\uff0c\u91cd\u89c6\u957f\u8fdc\u5956\u52b1\uff08\u5982<code>\u03b3=0.99</code>\uff0c\u672a\u676530\u6b65\u5956\u52b1\u4ecd\u6709<code>0.99\u00b3\u2070\u22480.74</code>\uff0c\u5f71\u54cd\u663e\u8457\uff09</li> </ul> </li> <li> <p>\u7f51\u683c\u4e16\u754c\u5b9e\u4f8b\u8ba1\u7b97\uff1a\u76ee\u6807\u533a\u57df\u6301\u7eed\u83b7\u5f97+1\u5956\u52b1\uff0c\u8f68\u8ff9\u540e\u534a\u6bb5\u4e3as9\uff08a5,1\uff09\u2192s9\uff08a5,1\uff09\u2192\u2026\uff0c\u6298\u6263\u56de\u62a5\u4e3a\uff1a    - \u5047\u8bbe\u524d3\u6b65\u5956\u52b1\u4e3a0\uff0c\u4ece\u7b2c4\u6b65\u5f00\u59cb\u4e3a1\uff1a<code>0 + 0 + 0 + \u03b3\u00b3*1 + \u03b3\u2074*1 + \u2026 = \u03b3\u00b3/(1-\u03b3)</code>\uff08<code>\u03b3 &lt; 1</code>\u65f6\u6536\u655b\uff09</p> </li> </ol>"},{"location":"notes/RL/Chapter1/#episode","title":"\uff08\u516b\uff09Episode\uff08\u56de\u5408\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u6709\u300c\u7ec8\u6b62\u72b6\u6001\uff08terminal state\uff09\u300d\u7684\u6709\u9650\u8f68\u8ff9\uff0c\u5373\u667a\u80fd\u4f53\u4ece\u521d\u59cb\u72b6\u6001\u51fa\u53d1\uff0c\u5230\u7ec8\u6b62\u72b6\u6001\u540e\u505c\u6b62\uff0c\u5f62\u6210\u4e00\u4e2a\u56de\u5408\uff08\u5982\u6e38\u620f\u901a\u5173\u3001\u673a\u5668\u4eba\u5230\u8fbe\u76ee\u6807\u540e\u505c\u6b62\uff09</li> <li>\u5bf9\u5e94\u4efb\u52a1\uff1aEpisodic Tasks\uff08\u56de\u5408\u5236\u4efb\u52a1\uff09\uff0c\u4f8b\uff1a\u7f51\u683c\u4e16\u754c\u5230\u8fbe\u76ee\u6807\u540e\u505c\u6b62</li> </ul> <ol> <li> <p>Continuing Tasks\uff08\u6301\u7eed\u578b\u4efb\u52a1\uff09    - \u5b9a\u4e49\uff1a\u65e0\u7ec8\u6b62\u72b6\u6001\uff0c\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u4ea4\u4e92\u300c\u6c38\u4e45\u6301\u7eed\u300d\u7684\u4efb\u52a1\uff08\u73b0\u5b9e\u4e2d\u65e0\u7edd\u5bf9\u6c38\u4e45\uff0c\u9700\u8fd1\u4f3c\uff09\uff0c\u4f8b\uff1a\u673a\u5668\u4eba\u957f\u671f\u5de1\u903b\u3001\u6301\u7eed\u4f18\u5316\u7684\u63a8\u8350\u7cfb\u7edf</p> </li> <li> <p>\u4e24\u79cd\u4efb\u52a1\u7684\u7edf\u4e00\u65b9\u6cd5    - \u65b9\u6cd51\uff1a\u5c06\u7ec8\u6b62\u72b6\u6001\u8bbe\u4e3a\u300c\u5438\u6536\u72b6\u6001\uff08absorbing state\uff09\u300d</p> <ul> <li>\u89c4\u5219\uff1a\u8fdb\u5165\u5438\u6536\u72b6\u6001\u540e\uff0c\u65e0\u8bba\u91c7\u53d6\u4f55\u79cd\u52a8\u4f5c\uff0c\u5747\u505c\u7559\u5728\u8be5\u72b6\u6001\uff0c\u4e14\u540e\u7eed\u5956\u52b1\u5168\u4e3a0\uff08\u5982\u76ee\u6807\u533a\u57df\u4ec5\u5141\u8bb8\u539f\u5730\u4e0d\u52a8\uff0c\u5956\u52b10\uff09</li> <li>\u65b9\u6cd52\uff1a\u5c06\u7ec8\u6b62\u72b6\u6001\u89c6\u4e3a\u300c\u666e\u901a\u72b6\u6001\u300d</li> <li>\u89c4\u5219\uff1a\u76ee\u6807\u533a\u57df\u6709\u6b63\u5e38\u7b56\u7565\uff08\u5982\u7b56\u7565\u4f18\u5219\u6301\u7eed\u505c\u7559\u83b7+1\uff0c\u7b56\u7565\u5dee\u5219\u53ef\u80fd\u8df3\u51fa\uff09\uff0c\u65e0\u9700\u7279\u6b8a\u5904\u7406\uff0c\u66f4\u5177\u4e00\u822c\u6027\uff08\u8bfe\u7a0b\u91c7\u7528\u6b64\u65b9\u6cd5\uff09</li> </ul> </li> </ol>"},{"location":"notes/RL/Chapter1/#markov-decision-processmdp","title":"\u6838\u5fc3\u6846\u67b6\uff1aMarkov Decision Process\uff08MDP\uff0c\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff09","text":""},{"location":"notes/RL/Chapter1/#mdp","title":"\uff08\u4e00\uff09MDP\u7684\u6838\u5fc3\u8981\u7d20","text":"<p>MDP\u662f\u5f3a\u5316\u5b66\u4e60\u7684\u7edf\u4e00\u6570\u5b66\u6846\u67b6\uff0c\u5305\u542b5\u4e2a\u6838\u5fc3\u8981\u7d20\uff0c\u8bb0\u4e3a<code>MDP = (\ud835\udce2, \ud835\udcd0, \ud835\udce1, p, \u03c0)</code>\uff0c\u5404\u8981\u7d20\u542b\u4e49\u5982\u4e0b\uff1a | \u8981\u7d20\u7b26\u53f7 | \u8981\u7d20\u540d\u79f0 | \u5b9a\u4e49\u4e0e\u8bf4\u660e                                                   | | -------- | -------- | ------------------------------------------------------------ | | \ud835\udce2        | \u72b6\u6001\u7a7a\u95f4 | \u6240\u6709\u53ef\u80fd\u72b6\u6001\u7684\u96c6\u5408\uff0c\u5982\u7f51\u683c\u4e16\u754c\u4e2d\ud835\udce2 = {s\u2081, s\u2082, \u2026, s\u2089}          | | \ud835\udcd0        | \u52a8\u4f5c\u7a7a\u95f4 | \u6bcf\u4e2a\u72b6\u6001\u5bf9\u5e94\u7684\u53ef\u6267\u884c\u52a8\u4f5c\u96c6\u5408\uff0c\u4e0e\u72b6\u6001\u76f8\u5173\uff0c\u8bb0\u4e3a\ud835\udcd0(s)\uff0c\u5982\ud835\udcd0(s\u2081) = {a\u2081,a\u2082,a\u2083,a\u2084,a\u2085} | | \ud835\udce1        | \u5956\u52b1\u7a7a\u95f4 | \u6240\u6709\u53ef\u80fd\u5956\u52b1\u7684\u96c6\u5408\uff0c\u5982\u7f51\u683c\u4e16\u754c\u4e2d\ud835\udce1 = {-1, 0, +1}              | | p        | \u6982\u7387\u5206\u5e03 | \u5305\u542b\u72b6\u6001\u8f6c\u79fb\u6982\u7387<code>p(s' | s, a)</code>\u548c\u5956\u52b1\u6982\u7387<code>p(r | s, a)</code>\uff0c\u63cf\u8ff0\u73af\u5883\u968f\u673a\u6027 | | \u03c0        | \u7b56\u7565     | \u72b6\u6001\u5230\u52a8\u4f5c\u7684\u6620\u5c04\uff0c\u7528<code>\u03c0(a | s)</code>\u8868\u793a\u72b6\u6001s\u4e0b\u91c7\u53d6\u52a8\u4f5ca\u7684\u6982\u7387\uff0c\u6307\u5bfc\u667a\u80fd\u4f53\u884c\u4e3a |</p>"},{"location":"notes/RL/Chapter1/#mdpmarkov-property","title":"\uff08\u4e8c\uff09MDP\u7684\u6838\u5fc3\u6027\u8d28\uff1aMarkov Property\uff08\u9a6c\u5c14\u53ef\u592b\u6027\u8d28\uff09","text":"<ol> <li>\u5b9a\u4e49\uff1a\u300c\u65e0\u8bb0\u5fc6\u6027\u300d\u2014\u2014\u667a\u80fd\u4f53\u4e0b\u4e00\u4e2a\u72b6\u6001\u7684\u6982\u7387\u4ec5\u4f9d\u8d56\u300c\u5f53\u524d\u72b6\u6001+\u5f53\u524d\u52a8\u4f5c\u300d\uff0c\u4e0e\u300c\u5386\u53f2\u72b6\u6001/\u52a8\u4f5c\u300d\u65e0\u5173\uff0c\u516c\u5f0f\u8868\u8fbe\u4e3a\uff1a    - \u72b6\u6001\u8f6c\u79fb\uff1a<code>p(s\u209c\u208a\u2081 | s\u209c, a\u209c) = p(s\u209c\u208a\u2081 | s\u2080,a\u2080,s\u2081,a\u2081,\u2026,s\u209c,a\u209c)</code>    - \u5956\u52b1\uff1a<code>p(r\u209c | s\u209c, a\u209c) = p(r\u209c | s\u2080,a\u2080,s\u2081,a\u2081,\u2026,s\u209c,a\u209c)</code></li> <li>\u542b\u4e49\uff1a\u7b80\u5316\u95ee\u9898\u590d\u6742\u5ea6\uff0c\u65e0\u9700\u5b58\u50a8\u5386\u53f2\u4ea4\u4e92\u4fe1\u606f\uff0c\u4ec5\u9700\u5173\u6ce8\u5f53\u524d\u72b6\u6001\u4e0e\u52a8\u4f5c\u5373\u53ef\u9884\u6d4b\u672a\u6765</li> </ol>"},{"location":"notes/RL/Chapter1/#mdpmarkov-process","title":"\uff08\u4e09\uff09MDP\u4e0eMarkov Process\uff08\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\uff09\u7684\u5173\u7cfb","text":"<ul> <li>Markov Process\uff08MP\uff09\uff1a\u4ec5\u5305\u542b\u300c\u72b6\u6001\u7a7a\u95f4\ud835\udce2\u300d\u548c\u300c\u72b6\u6001\u8f6c\u79fb\u6982\u7387p\u300d\uff0c\u65e0\u52a8\u4f5c\u4e0e\u7b56\u7565\uff0c\u662f\u65e0\u51b3\u7b56\u7684\u72b6\u6001\u6f14\u5316\u8fc7\u7a0b</li> <li>MDP\u4e0eMP\u7684\u8f6c\u5316\uff1a\u5f53MDP\u4e2d\u7684\u7b56\u7565\u03c0\u56fa\u5b9a\u65f6\uff0c\u7b56\u7565\u4e0e\u73af\u5883\u878d\u5408\uff0c\u52a8\u4f5c\u9009\u62e9\u7531\u03c0\u786e\u5b9a\uff0cMDP\u9000\u5316\u4e3aMP\uff08\u5373\u56fa\u5b9a\u7b56\u7565\u4e0b\u7684\u72b6\u6001\u8f6c\u79fb\u8fc7\u7a0b\uff09</li> <li>\u5b9e\u4f8b\uff1a\u7f51\u683c\u4e16\u754c\u4e2d\u56fa\u5b9a\u7b56\u7565\u03c0\uff08s1\u2192a2, s2\u2192a3,\u2026\uff09\uff0c\u72b6\u6001\u8f6c\u79fb\u4ec5\u4f9d\u8d56\u5f53\u524d\u72b6\u6001\u4e0e\u03c0\uff0c\u5f62\u6210MP</li> </ul>"},{"location":"notes/RL/Chapter2StateValue/","title":"Chapter2 StateValue","text":""},{"location":"notes/RL/Chapter2StateValue/#2-","title":"\u300a\u5f3a\u5316\u5b66\u4e60\u7684\u6570\u5b66\u539f\u7406\u300b\u7b2c2\u8bfe-\u8d1d\u5c14\u66fc\u516c\u5f0f\uff08\u77e5\u8bc6\u70b9\u6574\u7406","text":"<p> \u7ea6 1013 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 5 \u5206\u949f</p>"},{"location":"notes/RL/Chapter2StateValue/#return","title":"Return\u7684\u6838\u5fc3\u4f5c\u7528\uff1a\u7b56\u7565\u8bc4\u4f30\u7684\u91cf\u5316\u5de5\u5177","text":""},{"location":"notes/RL/Chapter2StateValue/#return_1","title":"\uff08\u4e00\uff09Return\u6982\u5ff5\u590d\u4e60","text":"<ul> <li>\u5b9a\u4e49\uff1a\u67d0\u6761\u8f68\u8ff9\u4e0a\u6240\u6709\u5956\u52b1\u7684\u201c\u6298\u6263\u603b\u548c\u201d\uff0c\u516c\u5f0f\u4e3a<code>Return = r\u2080 + \u03b3r\u2081 + \u03b3\u00b2r\u2082 + \u2026</code>\uff08<code>\u03b3</code>\u4e3a\u6298\u6263\u7387\uff0c<code>0\u2264\u03b3\u22641</code>\uff09</li> <li>\u672c\u8d28\uff1a\u5c06\u201c\u8f68\u8ff9\u7684\u4f18\u52a3\u201d\u8f6c\u5316\u4e3a\u53ef\u8ba1\u7b97\u7684\u6570\u503c\uff0c\u662f\u8fde\u63a5\u201c\u76f4\u89c2\u5224\u65ad\u201d\u4e0e\u201c\u6570\u5b66\u5206\u6790\u201d\u7684\u7ebd\u5e26</li> </ul>"},{"location":"notes/RL/Chapter2StateValue/#3return","title":"\uff08\u4e8c\uff09\u5b9e\u4f8b\u9a8c\u8bc1\uff1a3\u79cd\u7b56\u7565\u7684Return\u5bf9\u6bd4","text":"<ol> <li> <p>\u5b9e\u9a8c\u8bbe\u5b9a    - \u73af\u5883\uff1a\u7edf\u4e00\u7684\u7f51\u683c\u4e16\u754c\uff08\u542b\u76ee\u6807\u533a\u57df\u3001\u7981\u6b62\u533a\u57df\u3001\u53ef\u901a\u884c\u533a\u57df\uff09    - \u53d8\u91cf\uff1a\u4ec5s1\u72b6\u6001\u7684\u7b56\u7565\u4e0d\u540c\uff0c\u5176\u4ed6\u72b6\u6001\u7b56\u7565\u4e00\u81f4</p> <ul> <li>\u7b56\u75651\uff1as1\u2192\u5411\u4e0b\u8d70\uff08\u65e0\u7981\u6b62\u533a\u57df\u98ce\u9669\uff09</li> <li>\u7b56\u75652\uff1as1\u2192\u5411\u53f3\u8d70\uff08\u5fc5\u8fdb\u7981\u6b62\u533a\u57df\uff09</li> <li>\u7b56\u75653\uff1as1\u219250%\u6982\u7387\u5411\u53f3\u300150%\u6982\u7387\u5411\u4e0b\uff08\u968f\u673a\u98ce\u9669\uff09</li> </ul> </li> <li> <p>\u5404\u7b56\u7565Return\u8ba1\u7b97\uff08\u57fa\u4e8e\u6298\u6263\u56de\u62a5\uff09    | \u7b56\u7565  | \u8f68\u8ff9\u7279\u70b9               | Return\u8ba1\u7b97\u8fc7\u7a0b                                               | \u6700\u7ec8\u7ed3\u679c       |    | ----- | ---------------------- | ------------------------------------------------------------ | -------------- |    | \u7b56\u75651 | \u907f\u7981\u6b62\u533a\u57df\uff0c\u76f4\u8fbe\u76ee\u6807   | \u8f68\u8ff9\uff1as1\u2192s3\u2192s4\uff08\u76ee\u6807\uff09\uff0c\u540e\u7eed\u6301\u7eed\u83b7+1\u5956\u52b1\uff0cReturn=\u03b3(1 + \u03b3 + \u03b3\u00b2 + \u2026) = \u03b3/(1-\u03b3) | \u03b3/(1-\u03b3)        |    | \u7b56\u75652 | \u5fc5\u8fdb\u7981\u6b62\u533a\u57df\uff0c\u518d\u5230\u76ee\u6807 | \u8f68\u8ff9\uff1as1\u2192\u7981\u6b62\u533a\u57df\uff08-1\uff09\u2192s4\uff08\u76ee\u6807\uff09\uff0c\u540e\u7eed\u6301\u7eed\u83b7+1\u5956\u52b1\uff0cReturn=-1 + \u03b3/(1-\u03b3) | -1 + \u03b3/(1-\u03b3)   |    | \u7b56\u75653 | \u968f\u673a\u8f68\u8ff9\uff0850%\u98ce\u9669\uff09    | \u6309\u6982\u7387\u52a0\u6743\uff1a0.5\uff08\u7b56\u75652 Return\uff09 + 0.5*\uff08\u7b56\u75651 Return\uff09      | -0.5 + \u03b3/(1-\u03b3) |</p> </li> <li> <p>\u7ed3\u8bba\uff1aReturn\u5b9e\u73b0\u7b56\u7565\u91cf\u5316\u8bc4\u4f30    - \u6570\u5b66\u5173\u7cfb\uff1a<code>Return1 &gt; Return3 &gt; Return2</code>    - \u76f4\u89c2\u5bf9\u5e94\uff1a\u7b56\u75651\u6700\u4f18\uff08\u65e0\u98ce\u9669\uff09\u2192\u7b56\u75653\u5c45\u4e2d\uff08\u968f\u673a\u98ce\u9669\uff09\u2192\u7b56\u75652\u6700\u5dee\uff08\u5fc5\u8fdb\u7981\u6b62\u533a\u57df\uff09    - \u6838\u5fc3\u4ef7\u503c\uff1aReturn\u5c06\u201c\u7b56\u7565\u597d\u574f\u201d\u4ece\u201c\u4e3b\u89c2\u5224\u65ad\u201d\u8f6c\u5316\u4e3a\u201c\u5ba2\u89c2\u6570\u503c\u6bd4\u8f83\u201d\uff0c\u4e3a\u540e\u7eed\u7b56\u7565\u6539\u8fdb\u63d0\u4f9b\u91cf\u5316\u4f9d\u636e</p> </li> </ol>"},{"location":"notes/RL/Chapter2StateValue/#returnbootstrapping","title":"Return\u7684\u8ba1\u7b97\u65b9\u6cd5\u4e0eBootstrapping\u601d\u60f3","text":""},{"location":"notes/RL/Chapter2StateValue/#_1","title":"\uff08\u4e00\uff09\u4e24\u79cd\u8ba1\u7b97\u65b9\u6cd5\u5bf9\u6bd4","text":""},{"location":"notes/RL/Chapter2StateValue/#1","title":"\u65b9\u6cd51\uff1a\u57fa\u4e8e\u5b9a\u4e49\u7684\u76f4\u63a5\u8ba1\u7b97","text":"<ul> <li>\u539f\u7406\uff1a\u6309\u8f68\u8ff9\u987a\u5e8f\uff0c\u9010\u6b21\u7d2f\u52a0\u201c\u6298\u6263\u5956\u52b1\u201d</li> <li>\u793a\u4f8b\uff084\u72b6\u6001\u5faa\u73af\u7cfb\u7edf\uff0cs1\u2192s2\u2192s3\u2192s4\u2192s1\uff09\uff1a</li> <li>s1\u7684Return\uff08\u8bb0\u4e3av1\uff09\uff1a<code>v1 = r1 + \u03b3r2 + \u03b3\u00b2r3 + \u03b3\u00b3r4 + \u03b3\u2074r1 + \u2026</code></li> <li>s2\u7684Return\uff08\u8bb0\u4e3av2\uff09\uff1a<code>v2 = r2 + \u03b3r3 + \u03b3\u00b2r4 + \u03b3\u00b3r1 + \u2026</code></li> <li>\u7f3a\u70b9\uff1a\u9700\u904d\u5386\u5b8c\u6574\u8f68\u8ff9\uff08\u65e0\u9650\u8f68\u8ff9\u65f6\u8ba1\u7b97\u590d\u6742\uff09</li> </ul>"},{"location":"notes/RL/Chapter2StateValue/#2","title":"\u65b9\u6cd52\uff1a\u57fa\u4e8e\u72b6\u6001\u4ef7\u503c\u4f9d\u8d56\u7684\u9012\u63a8\u8ba1\u7b97","text":"<ul> <li>\u539f\u7406\uff1a\u5229\u7528\u201c\u5f53\u524d\u72b6\u6001\u4ef7\u503c = \u5373\u65f6\u5956\u52b1 + \u6298\u6263\u00d7\u4e0b\u4e00\u4e2a\u72b6\u6001\u4ef7\u503c\u201d\u7684\u9012\u63a8\u5173\u7cfb</li> <li>\u793a\u4f8b\uff08\u540c4\u72b6\u6001\u7cfb\u7edf\uff09\uff1a</li> <li><code>v1 = r1 + \u03b3v2</code>\uff08s1\u7684\u4ef7\u503c=\u5373\u65f6\u5956\u52b1r1 + \u6298\u6263\u540es2\u7684\u4ef7\u503c\uff09</li> <li><code>v2 = r2 + \u03b3v3</code>\uff08s2\u7684\u4ef7\u503c=\u5373\u65f6\u5956\u52b1r2 + \u6298\u6263\u540es3\u7684\u4ef7\u503c\uff09</li> <li><code>v3 = r3 + \u03b3v4</code>\uff0c<code>v4 = r4 + \u03b3v1</code></li> <li>\u4f18\u52bf\uff1a\u65e0\u9700\u904d\u5386\u8f68\u8ff9\uff0c\u901a\u8fc7\u72b6\u6001\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u7b80\u5316\u8ba1\u7b97</li> </ul>"},{"location":"notes/RL/Chapter2StateValue/#bootstrapping","title":"\uff08\u4e8c\uff09Bootstrapping\uff08\u81ea\u4e3e\uff09\u601d\u60f3","text":"<ol> <li>\u5b9a\u4e49\uff1a\u901a\u8fc7\u201c\u5f85\u6c42\u72b6\u6001\u4ef7\u503c\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u201d\u6c42\u89e3\u81ea\u8eab\u7684\u601d\u60f3\uff0c\u5373\u201c\u7528\u72b6\u6001\u4ef7\u503c\u7684\u96c6\u5408\u6c42\u89e3\u8be5\u96c6\u5408\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u201d</li> <li>\u76f4\u89c2\u7c7b\u6bd4\uff1a\u7c7b\u4f3c\u201c\u62c9\u7740\u978b\u5e26\u8bd5\u56fe\u628a\u81ea\u5df1\u63d0\u8d77\u6765\u201d\uff0c\u770b\u4f3c\u77db\u76fe\uff0c\u5b9e\u5219\u901a\u8fc7\u6570\u5b66\u8f6c\u5316\u53ef\u89e3</li> <li>\u6838\u5fc3\u610f\u4e49\uff1a\u4e3a\u8d1d\u5c14\u66fc\u516c\u5f0f\u7684\u63a8\u5bfc\u63d0\u4f9b\u6838\u5fc3\u601d\u8def\u2014\u2014\u5c06\u65e0\u9650\u8f68\u8ff9\u7684Return\u8ba1\u7b97\u8f6c\u5316\u4e3a\u6709\u9650\u7684\u7ebf\u6027\u65b9\u7a0b\u7ec4\u6c42\u89e3</li> </ol>"},{"location":"notes/RL/Chapter2StateValue/#_2","title":"\u8d1d\u5c14\u66fc\u516c\u5f0f\u7684\u96cf\u5f62\uff1a\u77e9\u9635\u5411\u91cf\u5f62\u5f0f\u4e0e\u6c42\u89e3","text":""},{"location":"notes/RL/Chapter2StateValue/#_3","title":"\uff08\u4e00\uff09\u77e9\u9635\u5411\u91cf\u5f62\u5f0f\u63a8\u5bfc","text":"<ol> <li>\u53d8\u91cf\u5b9a\u4e49    - \u72b6\u6001\u4ef7\u503c\u5411\u91cf\uff1a<code>v = [v1, v2, v3, v4]^T</code>\uff084\u4e2a\u72b6\u6001\u7684\u4ef7\u503c\uff09    - \u5373\u65f6\u5956\u52b1\u5411\u91cf\uff1a<code>r = [r1, r2, r3, r4]^T</code>\uff08\u5404\u72b6\u6001\u7684\u5373\u65f6\u5956\u52b1\uff09    - \u72b6\u6001\u8f6c\u79fb\u77e9\u9635\uff1a<code>P</code>\uff08<code>P[i][j]</code>\u8868\u793a\u4ece\u72b6\u6001i\u8f6c\u79fb\u5230\u72b6\u6001j\u7684\u6982\u7387\uff0c\u793a\u4f8b\u4e2d\u4e3a\u5faa\u73af\u8f6c\u79fb\uff0c<code>P = [[0,1,0,0],[0,0,1,0],[0,0,0,1],[1,0,0,0]]</code>\uff09</li> <li>\u516c\u5f0f\u8f6c\u5316    - \u9012\u63a8\u5173\u7cfb\uff1a<code>v = r + \u03b3Pv</code>\uff08\u72b6\u6001\u4ef7\u503c = \u5373\u65f6\u5956\u52b1 + \u6298\u6263\u00d7\u72b6\u6001\u8f6c\u79fb\u00d7\u72b6\u6001\u4ef7\u503c\uff09    - \u672c\u8d28\uff1a\u8fd9\u662f\u201c\u786e\u5b9a\u6027\u7b56\u7565+\u786e\u5b9a\u6027\u8f6c\u79fb\u201d\u573a\u666f\u4e0b\u7684\u8d1d\u5c14\u66fc\u516c\u5f0f\u96cf\u5f62</li> </ol>"},{"location":"notes/RL/Chapter2StateValue/#_4","title":"\uff08\u4e8c\uff09\u6c42\u89e3\u65b9\u6cd5\uff08\u7ebf\u6027\u4ee3\u6570\uff09","text":"<ol> <li>\u516c\u5f0f\u53d8\u5f62\uff1a\u5c06\u542bv\u7684\u9879\u79fb\u5230\u5de6\u4fa7\uff0c\u5f97<code>(I - \u03b3P)v = r</code>\uff08I\u4e3a\u5355\u4f4d\u77e9\u9635\uff09</li> <li>\u6c42\u89e3\u6761\u4ef6\uff1a\u5f53<code>||\u03b3P|| &lt; 1</code>\uff08\u03b3&lt;1\u4e14P\u4e3a\u8f6c\u79fb\u77e9\u9635\uff09\u65f6\uff0c<code>(I - \u03b3P)</code>\u53ef\u9006</li> <li>\u89e3\u7684\u5f62\u5f0f\uff1a<code>v = (I - \u03b3P)\u207b\u00b9r</code>\uff08\u901a\u8fc7\u77e9\u9635\u6c42\u9006\u5373\u53ef\u5f97\u5230\u5404\u72b6\u6001\u7684\u4ef7\u503c\uff09</li> <li>\u6838\u5fc3\u542f\u793a\uff1a\u77e9\u9635\u5411\u91cf\u5f62\u5f0f\u5c06\u201c\u591a\u4e2a\u9012\u63a8\u65b9\u7a0b\u201d\u6574\u5408\u4e3a\u201c\u5355\u4e00\u7ebf\u6027\u65b9\u7a0b\u7ec4\u201d\uff0c\u5927\u5e45\u7b80\u5316\u6c42\u89e3\u8fc7\u7a0b\uff0c\u4e3a\u540e\u7eed\u4e00\u822c\u5316\u8d1d\u5c14\u66fc\u516c\u5f0f\u5960\u5b9a\u57fa\u7840</li> </ol>"},{"location":"notes/RL/Chapter2StateValue/#_5","title":"\u5b9e\u4f8b\u5e94\u7528\uff1a\u7f51\u683c\u4e16\u754c\u4e2d\u7684\u8d1d\u5c14\u66fc\u516c\u5f0f","text":"<ol> <li>\u573a\u666f\u56de\u5f52\uff1a\u57fa\u4e8e\u7b2c1\u8bfe\u7684\u7f51\u683c\u4e16\u754c\uff08s1-s9\uff0c\u542b\u76ee\u6807\u3001\u7981\u6b62\u533a\u57df\uff09</li> <li>\u8d1d\u5c14\u66fc\u516c\u5f0f\u4e66\u5199\uff08\u4ee5\u7279\u5b9a\u7b56\u7565\u4e3a\u4f8b\uff09    - s1\uff08\u5411\u4e0b\u5230s3\uff0c\u5373\u65f6\u5956\u52b10\uff09\uff1a<code>v1 = 0 + \u03b3v3</code>    - s2\uff08\u5411\u53f3\u5230s4\uff0c\u5373\u65f6\u5956\u52b11\uff09\uff1a<code>v2 = 1 + \u03b3v4</code>    - s3\uff08\u5411\u53f3\u5230s4\uff0c\u5373\u65f6\u5956\u52b10\uff09\uff1a<code>v3 = 0 + \u03b3v4</code>    - ...\uff08\u5176\u4ed6\u72b6\u6001\u540c\u7406\uff0c\u6309\u7b56\u7565\u786e\u5b9a\u8f6c\u79fb\u65b9\u5411\u4e0e\u5373\u65f6\u5956\u52b1\uff09</li> <li>\u6c42\u89e3\u65b9\u5f0f\uff1a\u4e0a\u8ff0\u516c\u5f0f\u6784\u6210\u7ebf\u6027\u65b9\u7a0b\u7ec4\uff0c\u53ef\u901a\u8fc7\u624b\u7b97\uff08\u5c0f\u89c4\u6a21\uff09\u6216\u7a0b\u5e8f\uff08\u5927\u89c4\u6a21\uff09\u6c42\u89e3\uff0c\u76f4\u63a5\u5f97\u5230\u5404\u72b6\u6001\u7684\u4ef7\u503c\uff0c\u91cf\u5316\u4e0d\u540c\u72b6\u6001\u7684\u4f18\u52a3</li> </ol>"},{"location":"notes/RL/Chapter2StateValue/#_6","title":"\u524d\u7f6e\u57fa\u7840\uff1a\u6838\u5fc3\u7b26\u53f7\u4e0e\u5355\u6b65\u4ea4\u4e92\u8fc7\u7a0b","text":"<ol> <li> <p>\u6838\u5fc3\u7b26\u53f7\u5b9a\u4e49    - \u72b6\u6001\uff08State\uff09\uff1a<code>S_t</code>\uff08\u5927\u5199\uff0c\u4ee3\u8868\u968f\u673a\u53d8\u91cf\uff09\uff0c\u8868\u793a\u65f6\u523b<code>t</code>\u7684\u72b6\u6001\uff1b<code>s</code>\uff08\u5c0f\u5199\uff0c\u4ee3\u8868\u5177\u4f53\u53d6\u503c\uff09\uff0c\u8868\u793a\u72b6\u6001\u7684\u67d0\u4e2a\u786e\u5b9a\u503c\u3002    - \u52a8\u4f5c\uff08Action\uff09\uff1a<code>A_t</code>\uff08\u5927\u5199\uff0c\u968f\u673a\u53d8\u91cf\uff09\uff0c\u8868\u793a\u65f6\u523b<code>t</code>\u91c7\u53d6\u7684\u52a8\u4f5c\uff1b<code>a</code>\uff08\u5c0f\u5199\uff0c\u5177\u4f53\u53d6\u503c\uff09\uff0c\u8868\u793a\u67d0\u4e00\u786e\u5b9a\u52a8\u4f5c\u3002    - \u5956\u52b1\uff08Reward\uff09\uff1a<code>R_{t+1}</code>\uff08\u5927\u5199\uff0c\u968f\u673a\u53d8\u91cf\uff09\uff0c\u8868\u793a\u5728\u65f6\u523b<code>t</code>\u7684\u72b6\u6001<code>S_t</code>\u91c7\u53d6\u52a8\u4f5c<code>A_t</code>\u540e\uff0c\u65f6\u523b<code>t+1</code>\u83b7\u5f97\u7684\u5956\u52b1\uff08\u6ce8\uff1a\u90e8\u5206\u573a\u666f\u4f1a\u7b80\u5199\u4e3a<code>R_t</code>\uff0c\u4ec5\u4e3a\u4e60\u60ef\u5dee\u5f02\uff0c\u65e0\u6570\u5b66\u672c\u8d28\u533a\u522b\uff09\u3002    - \u6298\u6263\u7387\uff08Discount Rate\uff09\uff1a<code>\u03b3</code>\uff08<code>0\u2264\u03b3\u22641</code>\uff09\uff0c\u7528\u4e8e\u8ba1\u7b97\u6298\u6263\u56de\u62a5\uff0c\u4f53\u73b0\u672a\u6765\u5956\u52b1\u7684\u8870\u51cf\u7a0b\u5ea6\u3002</p> </li> <li> <p>\u5355\u6b65\u4ea4\u4e92\u8fc7\u7a0b    - \u6d41\u7a0b\uff1a<code>S_t</code>\uff08\u5f53\u524d\u72b6\u6001\uff09\u2192<code>A_t</code>\uff08\u91c7\u53d6\u52a8\u4f5c\uff09\u2192<code>R_{t+1}</code>\uff08\u83b7\u5f97\u5956\u52b1\uff09\u2192<code>S_{t+1}</code>\uff08\u8f6c\u79fb\u5230\u4e0b\u4e00\u72b6\u6001\uff09\u3002    - \u968f\u673a\u6027\u6765\u6e90\uff1a</p> <ul> <li>\u52a8\u4f5c\u9009\u62e9\uff1a\u7531\u7b56\u7565\uff08Policy\uff09 <code>\u03c0(a|s)</code>\u51b3\u5b9a\uff08\u72b6\u6001<code>s</code>\u4e0b\u91c7\u53d6\u52a8\u4f5c<code>a</code>\u7684\u6982\u7387\uff09\u3002</li> <li>\u5956\u52b1\u83b7\u53d6\uff1a\u7531\u5956\u52b1\u6982\u7387 <code>p(r|s,a)</code>\u51b3\u5b9a\uff08\u72b6\u6001<code>s</code>\u91c7\u53d6\u52a8\u4f5c<code>a</code>\u540e\u83b7\u5f97\u5956\u52b1<code>r</code>\u7684\u6982\u7387\uff09\u3002</li> <li>\u72b6\u6001\u8f6c\u79fb\uff1a\u7531\u72b6\u6001\u8f6c\u79fb\u6982\u7387 <code>p(s'|s,a)</code>\u51b3\u5b9a\uff08\u72b6\u6001<code>s</code>\u91c7\u53d6\u52a8\u4f5c<code>a</code>\u540e\u8f6c\u79fb\u5230\u72b6\u6001<code>s'</code>\u7684\u6982\u7387\uff09\u3002</li> </ul> </li> </ol>"},{"location":"notes/RL/Chapter2StateValue/#state-value","title":"\u6838\u5fc3\u6982\u5ff5\uff1aState Value\uff08\u72b6\u6001\u4ef7\u503c\uff09","text":""},{"location":"notes/RL/Chapter2StateValue/#_7","title":"\uff08\u4e00\uff09\u5b9a\u4e49\u4e0e\u6570\u5b66\u8868\u8fbe","text":"<ol> <li> <p>\u524d\u7f6e\u6982\u5ff5\uff1a\u6298\u6263\u56de\u62a5\uff08Discounted Return\uff09    - \u5b9a\u4e49\uff1a\u4ece\u65f6\u523b<code>t</code>\u7684\u72b6\u6001<code>S_t</code>\u51fa\u53d1\uff0c\u6cbf\u8f68\u8ff9\u83b7\u5f97\u7684\u6240\u6709\u5956\u52b1\u7ecf\u6298\u6263\u540e\u7684\u603b\u548c\uff0c\u8bb0\u4e3a<code>G_t</code>\uff08\u968f\u673a\u53d8\u91cf\uff0c\u56e0\u8f68\u8ff9\u968f\u673a\u6027\u53d8\u5316\uff09\u3002    - \u516c\u5f0f\uff1a<code>G_t = R_{t+1} + \u03b3R_{t+2} + \u03b3\u00b2R_{t+3} + \u2026 = \u03a3\uff08\u4ecek=0\u5230\u221e\uff09\u03b3^k R_{t+1+k}</code>\u3002</p> </li> <li> <p>State Value\u7684\u5b9a\u4e49    - \u672c\u8d28\uff1a\u6298\u6263\u56de\u62a5<code>G_t</code>\u7684\u6761\u4ef6\u671f\u671b\uff0c\u5373\u4ece\u67d0\u4e00\u786e\u5b9a\u72b6\u6001<code>s</code>\u51fa\u53d1\uff0c\u9075\u5faa\u7b56\u7565<code>\u03c0</code>\u65f6\uff0c\u6240\u6709\u53ef\u80fd\u8f68\u8ff9\u7684\u6298\u6263\u56de\u62a5\u7684\u5e73\u5747\u503c\u3002    - \u5168\u79f0\uff1aState-Value Function\uff08\u72b6\u6001\u4ef7\u503c\u51fd\u6570\uff09\uff0c\u7b80\u79f0\u4e3a\u72b6\u6001\u4ef7\u503c\u3002    - \u6570\u5b66\u7b26\u53f7\uff1a<code>v_\u03c0(s)</code>\uff08\u4e0b\u6807<code>\u03c0</code>\u8868\u793a\u4f9d\u8d56\u7b56\u7565\uff0c\u62ec\u53f7\u5185<code>s</code>\u8868\u793a\u5f53\u524d\u72b6\u6001\uff09\u3002    - \u516c\u5f0f\uff1a<code>v_\u03c0(s) = E[G_t | S_t = s]</code>\uff08<code>E[\u00b7]</code>\u8868\u793a\u671f\u671b\uff0c<code>S_t = s</code>\u8868\u793a\u201c\u65f6\u523b<code>t</code>\u72b6\u6001\u4e3a\u786e\u5b9a\u503c<code>s</code>\u201d\u7684\u6761\u4ef6\uff09\u3002</p> </li> </ol>"},{"location":"notes/RL/Chapter2StateValue/#state-value_1","title":"\uff08\u4e8c\uff09State Value\u7684\u6838\u5fc3\u5c5e\u6027","text":"<ol> <li> <p>\u53cc\u4f9d\u8d56\u7279\u6027    - \u4f9d\u8d56\u72b6\u6001<code>s</code>\uff1a\u4e0d\u540c\u72b6\u6001\u7684\u521d\u59cb\u6761\u4ef6\u4e0d\u540c\uff0c\u8f68\u8ff9\u4e0e\u56de\u62a5\u4e0d\u540c\uff0c\u72b6\u6001\u4ef7\u503c\u4e5f\u4e0d\u540c\uff08\u5982\u201c\u9760\u8fd1\u76ee\u6807\u7684\u72b6\u6001\u201d\u4ef7\u503c\u901a\u5e38\u9ad8\u4e8e\u201c\u8fdc\u79bb\u76ee\u6807\u7684\u72b6\u6001\u201d\uff09\u3002    - \u4f9d\u8d56\u7b56\u7565<code>\u03c0</code>\uff1a\u4e0d\u540c\u7b56\u7565\u5f15\u5bfc\u7684\u52a8\u4f5c\u9009\u62e9\u4e0d\u540c\uff0c\u5bfc\u81f4\u8f68\u8ff9\u4e0e\u56de\u62a5\u5dee\u5f02\uff0c\u72b6\u6001\u4ef7\u503c\u4e5f\u4e0d\u540c\uff08\u5982\u201c\u6700\u4f18\u7b56\u7565\u201d\u4e0b\u7684\u72b6\u6001\u4ef7\u503c\u9ad8\u4e8e\u201c\u968f\u673a\u7b56\u7565\u201d\uff09\u3002    - \u8865\u5145\u8868\u793a\uff1a\u53ef\u5199\u4e3a<code>v(s, \u03c0)</code>\uff08\u660e\u786e\u4f53\u73b0\u5bf9<code>s</code>\u548c<code>\u03c0</code>\u7684\u4f9d\u8d56\uff09\uff0c\u7b80\u5316\u540e\u5e38\u7528<code>v_\u03c0(s)</code>\u3002</p> </li> <li> <p>\u4ef7\u503c\u542b\u4e49    - \u6570\u503c\u610f\u4e49\uff1a<code>v_\u03c0(s)</code>\u8d8a\u5927\uff0c\u4ee3\u8868\u4ece\u72b6\u6001<code>s</code>\u51fa\u53d1\u9075\u5faa\u7b56\u7565<code>\u03c0</code>\u65f6\uff0c\u957f\u671f\u83b7\u5f97\u7684\u5e73\u5747\u56de\u62a5\u8d8a\u9ad8\uff0c\u5373\u8be5\u72b6\u6001\u201c\u8d8a\u6709\u4ef7\u503c\u201d\u3002    - \u4f5c\u7528\uff1a\u91cf\u5316\u72b6\u6001\u4f18\u52a3\uff0c\u4e3a\u7b56\u7565\u8bc4\u4f30\uff08\u5224\u65ad\u7b56\u7565\u597d\u574f\uff09\u548c\u7b56\u7565\u4f18\u5316\uff08\u5bfb\u627e\u66f4\u4f18\u7b56\u7565\uff09\u63d0\u4f9b\u6838\u5fc3\u4f9d\u636e\u3002</p> </li> </ol>"},{"location":"notes/RL/Chapter2StateValue/#returnstate-value","title":"\u4e09\u3001\u5173\u952e\u533a\u5206\uff1aReturn\uff08\u56de\u62a5\uff09\u4e0eState Value\uff08\u72b6\u6001\u4ef7\u503c\uff09","text":"\u5bf9\u6bd4\u7ef4\u5ea6 Return\uff08\u6298\u6263\u56de\u62a5\uff09 State Value\uff08\u72b6\u6001\u4ef7\u503c\uff09 \u8ba1\u7b97\u5bf9\u8c61 \u5355\u4e2a\u8f68\u8ff9\uff08\u4e00\u6761\u5177\u4f53\u7684\u4ea4\u4e92\u5e8f\u5217\uff09 \u591a\u4e2a\u8f68\u8ff9\uff08\u4ece\u540c\u4e00\u72b6\u6001\u51fa\u53d1\u7684\u6240\u6709\u53ef\u80fd\u8f68\u8ff9\uff09 \u968f\u673a\u6027 \u968f\u673a\u53d8\u91cf\uff08\u968f\u8f68\u8ff9\u4e0d\u540c\u800c\u53d8\u5316\uff09 \u786e\u5b9a\u503c\uff08\u5bf9\u968f\u673a\u56de\u62a5\u7684\u5e73\u5747\uff0c\u6d88\u9664\u968f\u673a\u6027\uff09 \u4f9d\u8d56\u56e0\u7d20 \u4ec5\u4f9d\u8d56\u5177\u4f53\u8f68\u8ff9 \u4f9d\u8d56\u72b6\u6001<code>s</code>\u548c\u7b56\u7565<code>\u03c0</code> \u7279\u6b8a\u60c5\u51b5 \u5f53\u73af\u5883\u4e0e\u7b56\u7565\u5747\u4e3a\u786e\u5b9a\u6027\u65f6\uff08\u4ec5\u4e00\u6761\u8f68\u8ff9\uff09\uff0cReturn\u7b49\u4e8e\u5bf9\u5e94\u72b6\u6001\u7684State Value -"},{"location":"notes/RL/Chapter2StateValue/#3s1","title":"\u56db\u3001\u5b9e\u4f8b\u9a8c\u8bc1\uff1a3\u79cd\u7b56\u7565\u4e0b\u7684s1\u72b6\u6001\u4ef7\u503c\u8ba1\u7b97","text":"<p>\u57fa\u4e8e\u524d\u5e8f\u8bfe\u7a0b\u7684\u201c\u7f51\u683c\u4e16\u754c\u201d\u573a\u666f\uff08\u542b\u76ee\u6807\u533a\u57df\u3001\u7981\u6b62\u533a\u57df\uff09\uff0c3\u79cd\u7b56\u7565\u4ec5<code>s1</code>\u72b6\u6001\u7684\u52a8\u4f5c\u4e0d\u540c\uff0c\u5176\u4ed6\u72b6\u6001\u7b56\u7565\u4e00\u81f4\uff0c\u8ba1\u7b97<code>s1</code>\u7684<code>v_\u03c0(s1)</code>\uff1a</p> \u7b56\u7565 \u7b56\u7565\u63cf\u8ff0\uff08s1\u72b6\u6001\u52a8\u4f5c\uff09 \u8f68\u8ff9\u7279\u70b9 \u72b6\u6001\u4ef7\u503c\u8ba1\u7b97\u8fc7\u7a0b \u7ed3\u679c \u03c0\u2081 \u786e\u5b9a\u6027\u5411\u4e0b\u8d70 \u4ec51\u6761\u8f68\u8ff9\uff08\u907f\u7981\u6b62\u533a\u57df\uff09 \u8f68\u8ff9\u56de\u62a5=\u03b3/(1-\u03b3)\uff08\u524d\u5e8f\u8bfe\u7a0b\u5df2\u8ba1\u7b97\uff09\uff0c\u56e0\u4ec51\u6761\u8f68\u8ff9\uff0c\u671f\u671b=\u56de\u62a5\u672c\u8eab v_\u03c0\u2081(s1)=\u03b3/(1-\u03b3) \u03c0\u2082 \u786e\u5b9a\u6027\u5411\u53f3\u8d70 \u4ec51\u6761\u8f68\u8ff9\uff08\u5fc5\u8fdb\u7981\u6b62\u533a\u57df\uff09 \u8f68\u8ff9\u56de\u62a5=-1 + \u03b3/(1-\u03b3)\uff0c\u56e0\u4ec51\u6761\u8f68\u8ff9\uff0c\u671f\u671b=\u56de\u62a5\u672c\u8eab v_\u03c0\u2082(s1)=-1 + \u03b3/(1-\u03b3) \u03c0\u2083 50%\u6982\u7387\u5411\u53f3\u300150%\u5411\u4e0b 2\u6761\u53ef\u80fd\u8f68\u8ff9\uff08\u968f\u673a\u98ce\u9669\uff09 \u671f\u671b=0.5\u00d7\uff08\u03c0\u2082\u8f68\u8ff9\u56de\u62a5\uff09 + 0.5\u00d7\uff08\u03c0\u2081\u8f68\u8ff9\u56de\u62a5\uff09=0.5\u00d7(-1 + \u03b3/(1-\u03b3)) + 0.5\u00d7(\u03b3/(1-\u03b3)) v_\u03c0\u2083(s1)=-0.5 + \u03b3/(1-\u03b3) <ul> <li>\u7ed3\u8bba\uff1a<code>v_\u03c0\u2081(s1) &gt; v_\u03c0\u2083(s1) &gt; v_\u03c0\u2082(s1)</code>\uff0c\u4e0e\u201c\u7b56\u75651\u6700\u4f18\u3001\u7b56\u75652\u6700\u5dee\u3001\u7b56\u75653\u5c45\u4e2d\u201d\u7684\u76f4\u89c2\u5224\u65ad\u5b8c\u5168\u4e00\u81f4\uff0c\u9a8c\u8bc1\u4e86\u72b6\u6001\u4ef7\u503c\u7684\u91cf\u5316\u8bc4\u4f30\u4f5c\u7528\u3002</li> </ul>"},{"location":"notes/RL/Overall%20Map/","title":"Overall Map","text":""},{"location":"notes/RL/Overall%20Map/#overall-map","title":"Overall Map","text":"<p> \u7ea6 350 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p>"},{"location":"notes/RL/Overall%20Map/#chapter-1-basic-concepts","title":"Chapter 1: Basic Concepts","text":"<p>Concepts: state,action,reward,return,episode,policy</p> <p>Grid-world example</p> <p>Markov decision process(MDP)</p>"},{"location":"notes/RL/Overall%20Map/#chapter-2-bellman-equation","title":"Chapter 2: Bellman Equation","text":"<p>One concept: state value </p> <p>\\(v_\\pi(s)=\\mathbb{E}[G_t|S_t=s]\\)</p> <p>One tool: Bellman equation</p> <p>\\(v_\\pi = r_\\pi + \\gamma P_\\pi v_\\pi\\)</p>"},{"location":"notes/RL/Overall%20Map/#chapter-3-bellman-optimality-equation","title":"Chapter 3: Bellman Optimality Equation","text":"<p>A special Bellman equation</p> <p>Two concepts: optimal policy \\(\\pi^*\\) &amp; optimal state value</p> <p>One tool: Bellman optimality equation</p> <p>\\(v = \\max_\\pi{r_\\pi+\\gamma P_\\pi v} = f(v)\\)</p> <p>1) Fixed-Point theorem 2) Fundamental problems 3) An algorithm solving the equation</p>"},{"location":"notes/RL/Overall%20Map/#chapter-4-value-iteration-policy-iteration","title":"Chapter 4: Value Iteration &amp; Policy Iteration","text":"<p>First algorithms for optimal policies</p> <p>Three algorithms:</p> <p>1) Value iteration(VI) 2) Policy iteration(PI) 3) Truncated policy iteration</p> <p>Need the environment model</p>"},{"location":"notes/RL/Overall%20Map/#chapter-5-monte-carlo-learning","title":"Chapter 5: Monte Carlo Learning","text":"<p>Mean estimation with sampling data</p> <p>\\(\\mathbb{E}[X] \\approx \\bar{x} =\\frac{1}{n}\\sum_{i=1}^n x_i\\)</p> <p>First model-free RL algorithms</p> <p>1) MC Basic 2) MC Exploring Starts 3) MC \\(\\epsilon\\)-greedy</p>"},{"location":"notes/RL/Overall%20Map/#chapter-6-stochastic-approximation","title":"Chapter 6: Stochastic Approximation","text":"<p>Gap: from non-incremental to incremental</p> <p>Mean estimation</p> <p>Algorithm:</p> <p>1) Robbins-Monro (RM) algorithm 2) Stochastic gradient descent(SGD) 3) SGD,BGD,MBGD</p>"},{"location":"notes/RL/Overall%20Map/#chapter-7-temporal-difference-learning","title":"Chapter 7: Temporal-Difference Learning","text":"<p>1) TD learning of state values</p> <p>2) Sarsa: TD learning of action values</p> <p>3) Q-learning : TD learning of optimal action values</p> <p>on-policy &amp; off-policy</p> <p>4) Unified point of view</p>"},{"location":"notes/RL/Overall%20Map/#chapter-8-value-function-approximation","title":"Chapter 8: Value Function Approximation","text":"<p>Gap: tabular representation to function representation</p> <p>Algorithms:</p> <p>1) State value estimation with value function approxmation(VFA):</p> <p>2) \\(\\min_w{J(w)} = \\mathbb{E}[v_\\pi(S)-\\hat{v}(S,w)]\\)</p> <p>Sarsa/W-learning with VFA</p> <p>Deep W-learning</p>"},{"location":"notes/RL/Overall%20Map/#chapter-9-policy-gradient-methods","title":"Chapter 9: Policy Gradient Methods","text":"<p>Gap: From value-based to policy-based</p> <p>1) Metrics to define optimal policies</p> <p>\\(J(\\theta)=\\bar{v_\\pi},\\bar{r_\\pi}\\)</p> <p>2) Policy gradient:</p> <p>\\(\\nabla J(\\theta)=\\mathbb{E}[\\nabla_\\theta \\ln{\\pi(A|S,\\theta)q_\\pi(S,A)}]\\)</p> <p>3) Gradient-ascent algorithm(REINFORCE)</p> <p>\\(\\theta_{t+1}=\\theta_t + \\alpha \\nabla_\\theta \\ln{\\pi(a_t|s_t,\\theta_t)q_t(s_t,a_t)}\\)</p>"},{"location":"notes/RL/Overall%20Map/#chapter-10-actor-critic-methods","title":"Chapter 10: Actor-Critic Methods","text":"<p>Gap: policy-based + value-based</p> <p>Algorithms:</p> <p>1) The simplest actor-critic(QAC)</p> <p>2) Advantage actor-critic (A2C)</p> <p>3) Off-policy actor-critic</p> <p>Importance sampling</p> <p>4) Deterministic actor-critic(DPG)</p>"},{"location":"notes/RL/PPO%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/","title":"PPO\u7b97\u6cd5\u539f\u7406","text":""},{"location":"notes/RL/PPO%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/#ppo","title":"PPO\u7b97\u6cd5\u539f\u7406","text":"<p> \u7ea6 1111 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 6 \u5206\u949f</p>"},{"location":"notes/RL/PPO%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/#_1","title":"\u4e00\u3001\u5f3a\u5316\u5b66\u4e60\u57fa\u7840\u6982\u5ff5","text":"<ol> <li> <p>\u6838\u5fc3\u8981\u7d20\uff08\u4ee5\u8d85\u7ea7\u739b\u4e3d\u6e38\u620f\u4e3a\u4f8b\uff09    - Environment\uff08\u73af\u5883\uff09\uff1a\u6e38\u620f\u672c\u8eab\uff08\u753b\u9762\u3001\u540e\u53f0\u7a0b\u5e8f\uff09\uff0c\u8d1f\u8d23\u72b6\u6001\u8f6c\u6362\u3001\u5956\u52b1\u751f\u6210\u7b49    - Agent\uff08\u667a\u80fd\u4f53\uff09\uff1a\u6839\u636e\u7b56\u7565\u51b3\u7b56\u52a8\u4f5c\uff0c\u76ee\u6807\u662f\u6700\u5927\u5316\u7d2f\u79ef\u5956\u52b1    - State\uff08\u72b6\u6001\uff09\uff1a\u6e38\u620f\u5f53\u524d\u72b6\u51b5\uff0c\u662fAgent\u51b3\u7b56\u7684\u4f9d\u636e\uff08\u89c6\u9891\u4e2d\u5047\u8bbeState=Observation\uff09    - Action\uff08\u52a8\u4f5c\uff09\uff1aAgent\u7684\u884c\u4e3a\uff08\u5982\u5de6\u79fb\u3001\u53f3\u79fb\u3001\u8df3\u8dc3\uff09    - Reward\uff08\u5956\u52b1\uff09\uff1a\u73af\u5883\u5bf9\u52a8\u4f5c\u7684\u53cd\u9988\uff08\u5982\u5403\u91d1\u5e01+10\u5206\uff0c\u6b7b\u4ea1-100\u5206\uff09    - Action Space\uff08\u52a8\u4f5c\u7a7a\u95f4\uff09\uff1a\u6240\u6709\u53ef\u80fd\u52a8\u4f5c\u7684\u96c6\u5408\uff08\u5982\u8d85\u7ea7\u739b\u4e3d\u7684left/up/right\uff09    - Trajectory\uff08\u8f68\u8ff9\uff09\uff1a\u72b6\u6001\u4e0e\u52a8\u4f5c\u7684\u5e8f\u5217\uff08S\u2080\u2192A\u2080\u2192S\u2081\u2192A\u2081\u2192\u2026\u2192S\u209c\uff09\uff0c\u4e5f\u79f0episode    - Return\uff08\u56de\u62a5\uff09\uff1a\u4ece\u5f53\u524d\u65f6\u523b\u5230\u7ed3\u675f\u7684\u7d2f\u79ef\u5956\u52b1\uff08\u9700\u8003\u8651\u957f\u8fdc\u6536\u76ca\uff09</p> </li> <li> <p>\u7b56\u7565\u51fd\u6570\uff08\u03c0\uff09    - \u8f93\u5165\uff1aState\uff08\u72b6\u6001\uff09    - \u8f93\u51fa\uff1aAction\u7684\u6982\u7387\u5206\u5e03\uff08\u5982\u5411\u5de60.1\u3001\u5411\u4e0a0.2\u3001\u5411\u53f30.7\uff09    - \u52a8\u4f5c\u9009\u62e9\uff1a\u6839\u636e\u6982\u7387\u91c7\u6837\uff08\u800c\u975e\u53d6\u6700\u5927\u503c\uff09\uff0c\u76ee\u7684\u662f\u63a2\u7d22\u66f4\u591a\u53ef\u80fd\u6027</p> </li> </ol>"},{"location":"notes/RL/PPO%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/#_2","title":"\u4e8c\u3001\u5f3a\u5316\u5b66\u4e60\u6838\u5fc3\u76ee\u6807\u4e0e\u6570\u5b66\u8868\u8fbe","text":"<ol> <li> <p>\u76ee\u6807\uff1a\u8bad\u7ec3\u7b56\u7565\u7f51\u7edc\u53c2\u6570\u03b8\uff0c\u4f7fReturn\u7684\u671f\u671b\u6700\u5927\u5316    - \u6570\u5b66\u8868\u8fbe\uff1a\\(\\max_\\theta \\mathbb{E}_{\\tau \\sim p_\\theta(\\tau)} [R(\\tau)]\\)</p> <ul> <li>\u5176\u4e2d\\(\\tau\\)\u4e3a\u8f68\u8ff9\uff0c\\(p_\\theta(\\tau)\\)\u4e3a\u8f68\u8ff9\u7684\u6982\u7387\u5206\u5e03\uff0c\\(R(\\tau)\\)\u4e3a\u8f68\u8ff9\u7684\u56de\u62a5</li> </ul> </li> <li> <p>\u7b56\u7565\u68af\u5ea6\uff08Policy Gradient\uff09    - \u91c7\u7528\u68af\u5ea6\u4e0a\u5347\u6cd5\u4f18\u5316\u76ee\u6807\u51fd\u6570\uff0c\u68af\u5ea6\u516c\u5f0f\uff1a \\(\\(\\nabla_\\theta J(\\theta) \\approx \\frac{1}{N} \\sum_{i=1}^N \\sum_{t=0}^{T} \\log \\pi_\\theta(a_{i,t} | s_{i,t}) \\cdot R(\\tau_i)\\)\\)    - \u76f4\u89c2\u610f\u4e49\uff1a\u82e5\u8f68\u8ff9\u56de\u62a5\u4e3a\u6b63\uff0c\u589e\u5927\u8be5\u8f68\u8ff9\u4e2d\u6240\u6709\u52a8\u4f5c\u7684\u6982\u7387\uff1b\u82e5\u4e3a\u8d1f\uff0c\u51cf\u5c0f\u6982\u7387</p> </li> </ol>"},{"location":"notes/RL/PPO%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/#_3","title":"\u4e09\u3001\u7b97\u6cd5\u4f18\u5316\u4e0e\u6539\u8fdb","text":"<ol> <li> <p>\u56de\u62a5\u4fee\u6b63    - \u5f15\u5165\u8870\u51cf\u56e0\u5b50\u03b3\uff08\u03b3&lt;1\uff09\uff0c\u4f7f\u8fdc\u671f\u5956\u52b1\u5f71\u54cd\u8870\u51cf\uff1a \\(\\(G_t = R_t + \\gamma R_{t+1} + \\gamma^2 R_{t+2} + \\dots + \\gamma^{T-t} R_T\\)\\)    - \u4ec5\u7d2f\u79ef\u5f53\u524d\u52a8\u4f5c\u540e\u7684\u5956\u52b1\uff08\u52a8\u4f5c\u65e0\u6cd5\u5f71\u54cd\u5386\u53f2\u5956\u52b1\uff09</p> </li> <li> <p>\u4f18\u52bf\u51fd\u6570\uff08Advantage Function\uff09    - \u5b9a\u4e49\uff1a\\(A(s,a) = Q(s,a) - V(s)\\)</p> <ul> <li>\\(Q(s,a)\\)\uff08\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570\uff09\uff1a\u72b6\u6001s\u4e0b\u6267\u884c\u52a8\u4f5ca\u7684\u671f\u671b\u56de\u62a5</li> <li>\\(V(s)\\)\uff08\u72b6\u6001\u4ef7\u503c\u51fd\u6570\uff09\uff1a\u72b6\u6001s\u7684\u671f\u671b\u56de\u62a5</li> <li>\u4f5c\u7528\uff1a\u53bb\u9664\u57fa\u7ebf\u5f71\u54cd\uff0c\u4ec5\u53cd\u6620\u52a8\u4f5c\u76f8\u5bf9\u4f18\u52bf\uff08\u597d\u7684\u52a8\u4f5cA&gt;0\uff0c\u5dee\u7684\u52a8\u4f5cA&lt;0\uff09</li> </ul> </li> <li> <p>GAE\uff08Generalized Advantage Estimation\uff09    - \u5e73\u8861\u91c7\u6837\u504f\u5dee\u4e0e\u65b9\u5dee\uff0c\u7ed3\u5408\u591a\u6b65\u91c7\u6837\u7684\u4f18\u52bf\uff1a \\(\\(\\hat{A}_t^{\\text{GAE}(\\lambda)} = \\sum_{l=0}^\\infty (\\gamma \\lambda)^l \\delta_{t+l}\\)\\)</p> <ul> <li>\u5176\u4e2d\\(\\delta_t = R_{t+1} + \\gamma V(s_{t+1}) - V(s_t)\\)\u4e3a\u65f6\u5e8f\u5dee\u5206\u8bef\u5dee</li> <li>\u03bb\u63a7\u5236\u6743\u91cd\u5206\u914d\uff08\u5982\u03bb=0.9\u65f6\uff0c\u4e00\u6b65\u91c7\u6837\u6743\u91cd0.1\uff0c\u4e24\u6b650.09\uff0c\u9010\u6b65\u8870\u51cf\uff09</li> </ul> </li> <li> <p>Actor-Critic\u67b6\u6784    - Actor\uff1a\u7b56\u7565\u7f51\u7edc\uff0c\u8d1f\u8d23\u8f93\u51fa\u52a8\u4f5c\u6982\u7387    - Critic\uff1a\u4ef7\u503c\u7f51\u7edc\uff0c\u4f30\u7b97\u72b6\u6001\u4ef7\u503cV(s)\uff0c\u8f85\u52a9\u8ba1\u7b97\u4f18\u52bf\u51fd\u6570    - \u4ef7\u503c\u7f51\u7edc\u8bad\u7ec3\uff1a\u62df\u5408\u56de\u62a5\u7684\u8870\u51cf\u7d2f\u79ef\u548c\uff08\\(G_t\\)\u4f5c\u4e3a\u6807\u7b7e\uff09</p> </li> </ol>"},{"location":"notes/RL/PPO%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/#ppo_1","title":"\u56db\u3001PPO\u7b97\u6cd5\u6838\u5fc3","text":"<ol> <li> <p>\u6838\u5fc3\u6539\u8fdb\uff1a\u89e3\u51b3On-Policy\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u91c7\u7528Off-Policy\u8bad\u7ec3    - \u91cd\u8981\u6027\u91c7\u6837\uff1a\u7528\u53c2\u8003\u7b56\u7565\\(\\pi_{\\theta'}\\)\u91c7\u6837\u6570\u636e\uff0c\u8bad\u7ec3\u76ee\u6807\u7b56\u7565\\(\\pi_\\theta\\)\uff0c\u5f15\u5165\u4fee\u6b63\u7cfb\u6570\uff1a \\(\\(L^{CLIP}(\\theta) = \\hat{\\mathbb{E}}_t \\left[ \\min \\left( \\frac{\\pi_\\theta(a_t | s_t)}{\\pi_{\\theta'}(a_t | s_t)} A_t, \\text{clip}\\left( \\frac{\\pi_\\theta(a_t | s_t)}{\\pi_{\\theta'}(a_t | s_t)}, 1-\\epsilon, 1+\\epsilon \\right) A_t \\right) \\right]\\)\\)    - \u622a\u65ad\u673a\u5236\uff1a\u9650\u5236\u7b56\u7565\u66f4\u65b0\u5e45\u5ea6\uff08\u5982\u03b5=0.2\u65f6\uff0c\u6982\u7387\u6bd4\u63a7\u5236\u57280.8~1.2\u4e4b\u95f4\uff09\uff0c\u66ff\u4ee3KL\u6563\u5ea6\u7ea6\u675f</p> </li> <li> <p>\u8bad\u7ec3\u6d41\u7a0b    - \u7528\u53c2\u8003\u7b56\u7565\\(\\theta'\\)\u91c7\u6837\u8f68\u8ff9\u6570\u636e    - \u8ba1\u7b97\u4f18\u52bf\u51fd\u6570\\(A_t\\)    - \u6700\u5c0f\u5316PPO\u635f\u5931\u51fd\u6570\\(L^{CLIP}(\\theta)\\)\u66f4\u65b0\u76ee\u6807\u7b56\u7565\u03b8    - \u91cd\u590d\u91c7\u6837\u4e0e\u8bad\u7ec3\uff08\u6570\u636e\u53ef\u591a\u6b21\u4f7f\u7528\uff09</p> </li> </ol>"},{"location":"notes/RL/PPO%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/#_4","title":"\u4e94\u3001\u8bad\u7ec3\u4ee3\u7801\u4e0e\u5b9e\u73b0\u8981\u70b9","text":"<ol> <li> <p>\u7f51\u7edc\u7ed3\u6784    - \u7b56\u7565\u7f51\u7edc\uff1a\u8f93\u5165\u4e3a\u6e38\u620f\u753b\u9762\uff08\u72b6\u6001\uff09\uff0c\u8f93\u51fa\u52a8\u4f5c\u6982\u7387\u5206\u5e03\uff08\u59823\u4e2a\u795e\u7ecf\u5143+Softmax\uff09    - \u4ef7\u503c\u7f51\u7edc\uff1a\u53ef\u4e0e\u7b56\u7565\u7f51\u7edc\u5171\u4eab\u7279\u5f81\u63d0\u53d6\u5c42\uff0c\u8f93\u51fa\u5355\u4e2a\u503c\uff08\u72b6\u6001\u4ef7\u503c\uff09</p> </li> <li> <p>\u8bad\u7ec3\u6b65\u9aa4    - \u91c7\u96c6\u6570\u636e\uff1a\u8ba9Agent\u73a9N\u573a\u6e38\u620f\uff0c\u83b7\u53d6\u8f68\u8ff9\u4e0e\u56de\u62a5    - \u8ba1\u7b97\u76ee\u6807\uff1a\u7528GAE\u8ba1\u7b97\u4f18\u52bf\u51fd\u6570\\(A_t\\)    - \u66f4\u65b0\u7f51\u7edc\uff1a\u901a\u8fc7PPO\u635f\u5931\u51fd\u6570\u4f18\u5316\u7b56\u7565\u7f51\u7edc\u548c\u4ef7\u503c\u7f51\u7edc    - \u8fed\u4ee3\uff1a\u66f4\u65b0\u53c2\u8003\u7b56\u7565\\(\\theta' \\leftarrow \\theta\\)\uff0c\u91cd\u590d\u8bad\u7ec3</p> </li> </ol>"},{"location":"notes/RL/PPO%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/#_5","title":"\u516d\u3001\u6ce8\u610f\u4e8b\u9879","text":"<ol> <li>\u5956\u52b1\u8bbe\u8ba1\uff1aReward\u5b9a\u4e49\u76f4\u63a5\u5f71\u54cd\u8bad\u7ec3\u6548\u679c\uff0c\u9700\u5408\u7406\u8bbe\u7f6e\uff08\u5982\u901a\u5173\u6b63\u5956\u52b1\u3001\u6b7b\u4ea1\u8d1f\u5956\u52b1\uff09</li> <li>\u63a2\u7d22\u4e0e\u5229\u7528\uff1a\u8bad\u7ec3\u65f6\u9700\u6839\u636e\u6982\u7387\u91c7\u6837\u52a8\u4f5c\uff0c\u907f\u514d\u9677\u5165\u5c40\u90e8\u6700\u4f18</li> <li>\u7b56\u7565\u7ea6\u675f\uff1a\u786e\u4fdd\u76ee\u6807\u7b56\u7565\u4e0e\u53c2\u8003\u7b56\u7565\u5dee\u5f02\u4e0d\u5927\uff08\u901a\u8fc7\u622a\u65ad\u673a\u5236\uff09\uff0c\u5426\u5219\u91c7\u6837\u6570\u636e\u5931\u6548</li> <li>\u4ef7\u503c\u7f51\u7edc\u62df\u5408\uff1a\u9700\u7528\u8870\u51cf\u7d2f\u79ef\u56de\u62a5\u4f5c\u4e3a\u6807\u7b7e\uff0c\u5e73\u8861\u504f\u5dee\u4e0e\u65b9\u5dee</li> <li>\u6548\u7387\u95ee\u9898\uff1aPPO\u901a\u8fc7Off-Policy\u673a\u5236\u590d\u7528\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u901f\u5ea6</li> </ol>"},{"location":"notes/RL/PPO%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/#_6","title":"\u4e03\u3001\u603b\u7ed3","text":"<p>PPO\u7b97\u6cd5\u901a\u8fc7\u91cd\u8981\u6027\u91c7\u6837\u548c\u622a\u65ad\u673a\u5236\uff0c\u5728\u4fdd\u8bc1\u7a33\u5b9a\u6027\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684Off-Policy\u8bad\u7ec3\uff0c\u6838\u5fc3\u662f\u5e73\u8861\u7b56\u7565\u66f4\u65b0\u5e45\u5ea6\u4e0e\u6570\u636e\u5229\u7528\u7387\uff0c\u662f\u5f3a\u5316\u5b66\u4e60\u4e2d\u5e94\u7528\u5e7f\u6cdb\u7684\u7b97\u6cd5\uff08\u5c24\u5176\u5728\u5927\u8bed\u8a00\u6a21\u578bRLHF\u4e2d\uff09\u3002</p>"},{"location":"notes/RL/Pseudocode/","title":"Chapter4 Pseudocode","text":""},{"location":"notes/RL/Pseudocode/#pseudocode","title":"Pseudocode","text":"<p> \u7ea6 5 \u4e2a\u5b57  187 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p>"},{"location":"notes/RL/Pseudocode/#value-iteration","title":"Value Iteration","text":"Python<pre><code>import numpy as np\n\n# Define environment\ngrid_size = 4\nstates = [(i, j) for i in range(grid_size) for j in range(grid_size)]\nactions = ['up', 'down', 'left', 'right']\nterminal_state = (grid_size - 1, grid_size - 1)\n\n# Initialize state-value function V(s)\nV = np.zeros((grid_size, grid_size))\n\n# Discount factor\ngamma = 0.9\n\n# Define policy (for now it can be random)\npolicy = {state: np.random.choice(actions) for state in states}\n\ndef is_terminal(state):\n    return state == terminal_state\n\ndef step(state, action):\n    if state == terminal_state:\n        return state, 0\n\n    i, j = state\n    reward = 0  # Default reward\n    next_state = state  # Default to staying in same position\n\n    if action == 'up':\n        new_i = i - 1\n        if new_i &lt; 0:  # Hit boundary\n            next_state = (i, j)  # Stay in same position\n            reward = -1\n        else:\n            next_state = (new_i, j)\n    elif action == 'down':\n        new_i = i + 1\n        if new_i &gt;= grid_size:  # Hit boundary\n            next_state = (i, j)  # Stay in same position\n            reward = -1\n        else:\n            next_state = (new_i, j)\n    elif action == 'left':\n        new_j = j - 1\n        if new_j &lt; 0:  # Hit boundary\n            next_state = (i, j)  # Stay in same position\n            reward = -1\n        else:\n            next_state = (i, new_j)\n    elif action == 'right':\n        new_j = j + 1\n        if new_j &gt;= grid_size:  # Hit boundary\n            next_state = (i, j)  # Stay in same position\n            reward = -1\n        else:\n            next_state = (i, new_j)\n\n    # Check if we reached the terminal state\n    if next_state == terminal_state:\n        reward = 1\n\n    return next_state, reward\n\ndef value_iteration():\n    theta = 0.001  # threshold for stopping iteration\n    while True:\n        delta = 0\n        for state in states:\n            if is_terminal(state):\n                continue\n\n            v = V[state]\n            max_value = float('-inf')\n            for action in actions:\n                next_state, reward = step(state, action)\n                value = reward + gamma * V[next_state]\n                max_value = max(max_value, float(value))\n\n            V[state] = max_value\n            delta = max(delta, abs(v - V[state]))\n\n        if delta &lt; theta:\n            break\n\n    return V\n\noptimal_V = value_iteration()\n\ndef extract_policy():\n    for state in states:\n        if is_terminal(state):\n            continue\n\n        max_value = float('-inf')\n        best_action = None\n        for action in actions:\n            next_state, reward = step(state, action)\n            value = reward + gamma * optimal_V[next_state]\n            if value &gt; max_value:\n                max_value = value\n                best_action = action\n\n        policy[state] = best_action\n\n    return policy\n\n# Extract the optimal policy from the optimal state-value function\noptimal_policy = extract_policy()\n\n# Print results\nprint(\"Optimal Values:\")\nprint(optimal_V)\nprint(\"\\nOptimal Policy:\")\nfor i in range(grid_size):\n    for j in range(grid_size):\n        if (i, j) != terminal_state:\n            print(policy[(i, j)], end='\\t')\n        else:\n            print(\"G\", end='\\t')  # Goal\n    print(\"\")\n</code></pre>"},{"location":"notes/RL/Pseudocode/#policy-iteration","title":"Policy Iteration","text":"Python<pre><code># Policy Iteration Example\nimport numpy as np\n\n# \u5b9a\u4e49\u7f51\u683c\u4e16\u754c\u73af\u5883\u53c2\u6570\nn_states = 16  # 4x4 \u7f51\u683c\nn_actions = 4  # \u4e0a\u4e0b\u5de6\u53f3\ngamma = 0.9\n\n# \u521d\u59cb\u5316\u968f\u673a\u7b56\u7565\u548c\u4ef7\u503c\u51fd\u6570\npolicy = np.ones([n_states, n_actions]) / n_actions\nvalue_function = np.zeros(n_states)\n\n# \u5b9a\u4e49\u6536\u655b\u7cbe\u5ea6\ntheta = 1e-10\n\ndef policy_evaluation(policy, value_function, gamma, theta):\n    while True:\n        delta = 0\n        for state in range(n_states):\n            v = value_function[state]\n            new_value = 0\n            for action in range(n_actions):\n                next_state_prob = transition_prob[state, action]\n                reward = reward_function[state, action]\n                new_value += policy[state, action] * (reward + gamma * next_state_prob * value_function)\n            value_function[state] = new_value\n            delta = max(delta, np.abs(v - new_value))\n        if delta &lt; theta:\n            break\n    return value_function\n\ndef policy_improvement(value_function, policy, gamma):\n    policy_stable = True\n    for state in range(n_states):\n        chosen_action = np.argmax(policy[state])\n        action_values = np.zeros(n_actions)\n        for action in range(n_actions):\n            next_state_prob = transition_prob[state, action]\n            action_values[action] = reward_function[state, action] + gamma * next_state_prob * value_function\n\n        best_action = np.argmax(action_values)\n        if chosen_action != best_action:\n            policy_stable = False\n            policy[state] = np.eye(n_actions)[best_action]\n\n    return policy, policy_stable\n\n# \u793a\u4f8b\u5b9e\u73b0\u7b56\u7565\u8fed\u4ee3\u65b9\u6cd5\ndef policy_iteration():\n    policy_stable = False\n    while not policy_stable:\n        value_function = policy_evaluation(policy, value_function, gamma, theta)\n        policy, policy_stable = policy_improvement(value_function, policy, gamma)\n\n    return policy, value_function\n\n# \u8c03\u7528\u7b56\u7565\u8fed\u4ee3\u51fd\u6570\noptimal_policy, optimal_value_function = policy_iteration()\n\nprint(\"Optimal Policy:\")\nprint(optimal_policy)\nprint(\"Optimal Value Function:\")\nprint(optimal_value_function)\n</code></pre>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/","title":"\u5927\u6a21\u578b\u5f3a\u5316\u5b66\u4e60PPO","text":""},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#ppo","title":"\u5927\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\uff08PPO\uff09\u4ee3\u7801\u5b9e\u73b0","text":"<p> \u7ea6 1007 \u4e2a\u5b57  85 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 6 \u5206\u949f</p>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#_1","title":"\u4e00\u3001\u524d\u7f6e\u77e5\u8bc6\u4e0e\u8bad\u7ec3\u9636\u6bb5\u6982\u8ff0","text":"<ul> <li>\u5927\u6a21\u578b\u8bad\u7ec3\u4e09\u9636\u6bb5\uff1a\u9884\u8bad\u7ec3 \u2192 \u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u2192 \u5f3a\u5316\u5b66\u4e60\uff08PPO\uff09\uff0c\u89c6\u9891\u805a\u7126\u7b2c\u4e09\u9636\u6bb5</li> <li>\u5f3a\u5316\u5b66\u4e60\u524d\u63d0\uff1a\u9700\u5b8c\u6210\u76d1\u7763\u5fae\u8c03\uff0c\u5e76\u8bad\u7ec3\u4e00\u4e2a\u5956\u52b1\u6a21\u578b\uff08Reward Model\uff09 \u63d0\u4f9b\u5956\u52b1\u4fe1\u53f7</li> <li>\u5efa\u8bae\u5148\u89c2\u770b\u4f5c\u8005\u5173\u4e8ePPO\u7b97\u6cd5\u539f\u7406\u7684\u524d\u7f6e\u89c6\u9891</li> </ul>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#reward-model","title":"\u4e8c\u3001\u5956\u52b1\u6a21\u578b\uff08Reward Model\uff09\u8bad\u7ec3","text":""},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#1","title":"1. \u6570\u636e\u8981\u6c42","text":"<ul> <li>\u6838\u5fc3\u6570\u636e\uff1a\u504f\u597d\u6570\u636e\uff08Preference Data\uff09\uff0c\u5305\u542b\u540c\u4e00\u95ee\u9898\u7684\u4e24\u4e2a\u56de\u7b54\uff08<code>chosen</code>\u4f18\u8d28\u56de\u7b54\u3001<code>rejected</code>\u8f83\u5dee\u56de\u7b54\uff09</li> <li>\u4f18\u52bf\uff1a\u76f8\u6bd4\u76f4\u63a5\u6253\u5206\uff0c\u504f\u597d\u6570\u636e\u66f4\u6613\u751f\u6210\uff08\"\u4e0d\u6015\u4e0d\u8bc6\u8d27\uff0c\u5c31\u6015\u8d27\u6bd4\u8d27\"\uff09</li> </ul>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#2","title":"2. \u6a21\u578b\u7ed3\u6784","text":"<ul> <li>\u57fa\u7840\u6a21\u578b\uff1a\u91c7\u7528\u4e0e\u5f85\u4f18\u5316\u5927\u6a21\u578b\u80fd\u529b\u63a5\u8fd1\u6216\u66f4\u5f3a\u7684\u6a21\u578b\uff08\u8bc4\u4ef7\u6bd4\u751f\u6210\u66f4\u5bb9\u6613\uff09</li> <li>\u8f93\u51fa\u5c42\u6539\u9020\uff1a\u5728\u5927\u6a21\u578b\u57fa\u7840\u4e0a\u589e\u52a0<code>score head</code>\uff08\u8f93\u5165\u4e3atoken\u7684hidden size\uff0c\u8f93\u51fa\u7ef4\u5ea6\u4e3a1\uff09</li> <li>\u8bc4\u5206\u903b\u8f91\uff1a\u4ec5\u5bf9\u5e8f\u5217\u6700\u540e\u4e00\u4e2atoken\u8c03\u7528<code>score head</code>\uff08\u53ef\u89c2\u5bdf\u5b8c\u6574\u5e8f\u5217\uff09</li> </ul>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#3-loss","title":"3. \u635f\u5931\u51fd\u6570\uff08Loss\uff09","text":"<ul> <li>\u516c\u5f0f\uff1a\u5bf9<code>chosen</code>\u4e0e<code>rejected</code>\u7684\u5f97\u5206\u5dee\u503c\u5e94\u7528<code>log sigmoid</code>\u51fd\u6570 Text Only<pre><code>loss = log_sigmoid(score_chosen - score_rejected)\n</code></pre></li> <li>\u7279\u6027\uff1a\u5f53<code>score_chosen &lt; score_rejected</code>\u65f6\uff0c\u635f\u5931\u5448\u6307\u6570\u7ea7\u589e\u957f\uff1b\u53cd\u4e4b\u5219\u5feb\u901f\u4e0b\u964d</li> </ul>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#4-hugging-face-trl","title":"4. \u8bad\u7ec3\u4ee3\u7801\uff08\u57fa\u4e8eHugging Face TRL\u5e93\uff09","text":"Python<pre><code># 1. \u5b9a\u4e49\u5206\u8bcd\u5668\u548c\u6a21\u578b\uff08\u5e8f\u5217\u5206\u7c7b\u6a21\u578b\uff0c\u8f93\u51fa\u8fde\u7eed\u503c\uff09\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n\n# 2. \u914d\u7f6eLoRA\u53c2\u6570\uff08\u91cf\u5316\u8bad\u7ec3\uff09\nlora_config = LoraConfig(\n    task_type=TaskType.SEQ_CLASSIFICATION,\n    ...  # \u5176\u4ed6\u53c2\u6570\n)\nmodel = get_peft_model(model, lora_config)\n\n# 3. \u6570\u636e\u5904\u7406\uff08\u62fc\u63a5\u95ee\u9898\u4e0e\u56de\u7b54\uff0c\u751f\u6210\u8f93\u5165\u5bf9\uff09\ndef process_data(examples):\n    chosen_inputs = tokenizer(examples[\"question\"] + examples[\"chosen\"], ...)\n    rejected_inputs = tokenizer(examples[\"question\"] + examples[\"rejected\"], ...)\n    return {\n        \"input_ids_chosen\": chosen_inputs[\"input_ids\"],\n        \"attention_mask_chosen\": chosen_inputs[\"attention_mask\"],\n        \"input_ids_rejected\": rejected_inputs[\"input_ids\"],\n        \"attention_mask_rejected\": rejected_inputs[\"attention_mask\"],\n    }\n\n# 4. \u5b9a\u4e49\u8bad\u7ec3\u914d\u7f6e\u4e0e\u8bad\u7ec3\u5668\nreward_config = RewardConfig(output_dir=\"./reward_model\")\ntrainer = RewardTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    args=reward_config,\n    train_dataset=processed_dataset,\n)\ntrainer.train()  # \u542f\u52a8\u8bad\u7ec3\n</code></pre>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#ppo_1","title":"\u4e09\u3001PPO\u6a21\u578b\u8bad\u7ec3","text":""},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#1_1","title":"1. \u6d89\u53ca\u7684\u56db\u4e2a\u6838\u5fc3\u6a21\u578b","text":"\u6a21\u578b\u7c7b\u578b \u4f5c\u7528 \u8f93\u51fa\u5c42 \u4f18\u5316\u76ee\u6807 \u57fa\u51c6\u6a21\u578b \u9650\u5236\u65b0\u6a21\u578b\u4e0e\u539f\u59cb\u6a21\u578b\u7684\u5206\u5e03\u5dee\u5f02 LM Head\uff08\u5b57\u5178\u7ef4\u5ea6\uff09 \u65e0\uff08\u56fa\u5b9a\u53c2\u6570\uff09 \u8bad\u7ec3\u6a21\u578b \u751f\u6210\u6587\u672c\u5e76\u4f18\u5316 LM Head \u6700\u5927\u5316\u5956\u52b1\u4fe1\u53f7 \u5956\u52b1\u6a21\u578b \u5bf9\u5b8c\u6574\u95ee\u7b54\u5e8f\u5217\u6253\u5206 Score Head\uff08\u7ef4\u5ea61\uff09 \u65e0\uff08\u5df2\u9884\u8bad\u7ec3\uff09 \u72b6\u6001\u4ef7\u503c\u6a21\u578b \u9884\u6d4b\u6bcf\u4e2atoken\u5e8f\u5217\u7684\u671f\u671b\u56de\u62a5 Value Head\uff08\u7ef4\u5ea61\uff09 \u6700\u5c0f\u5316\u4ef7\u503c\u9884\u6d4b\u8bef\u5dee <ul> <li>\u4f18\u5316\u65b9\u6848\uff1a\u901a\u8fc7LoRA\u9002\u914d\u5668\u5171\u4eab\u5e95\u5c42\u5927\u6a21\u578b\u6743\u91cd\uff0c\u4ec5\u52a0\u8f7d1\u4e2a\u5927\u6a21\u578b+2\u4e2aLoRA\u53c2\u6570\uff0c\u51cf\u5c11\u663e\u5b58\u5360\u7528</li> </ul>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#2_1","title":"2. \u5956\u52b1\u4fe1\u53f7\u8ba1\u7b97","text":"<ul> <li>\u6bcf\u4e2atoken\u7684\u5956\u52b1 = KL\u6563\u5ea6\u60e9\u7f5a + \u6700\u7ec8\u5f97\u5206 Text Only<pre><code>reward = (-0.2 * kl_divergence) + score\n</code></pre>   \uff08\u5176\u4e2d<code>kl_divergence</code>\u4e3a\u8bad\u7ec3\u6a21\u578b\u4e0e\u57fa\u51c6\u6a21\u578b\u7684\u5206\u5e03\u5dee\u5f02\uff0c\u7cfb\u6570-0.2\u4e3a\u8c03\u6574\u53c2\u6570\uff09</li> </ul>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#3-gae","title":"3. \u4f18\u52bf\u51fd\u6570\uff08GAE\uff09","text":"<ul> <li>\u8fed\u4ee3\u8868\u8fbe\u5f0f\uff1a Text Only<pre><code>advantage_t = delta_t + gamma * lambda * advantage_{t+1}\n</code></pre>   \uff08\u4ece\u540e\u5411\u524d\u8ba1\u7b97\uff0c\u5e73\u8861\u504f\u5dee\u4e0e\u65b9\u5dee\uff09</li> </ul>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#4-loss","title":"4. \u635f\u5931\u51fd\u6570\uff08Loss\uff09","text":""},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#1_2","title":"\uff081\uff09\u72b6\u6001\u4ef7\u503c\u7f51\u7edc\u635f\u5931","text":"<ul> <li>\u6807\u7b7e\u8ba1\u7b97\uff1a\u91c7\u7528\u5e7f\u4e49\u4f18\u52bf\u6cd5\uff08<code>return = advantage + value</code>\uff09</li> <li>\u635f\u5931\u516c\u5f0f\uff1a Text Only<pre><code>vf_loss = 0.5 * mean(max(vf_loss1, vf_loss2))\n\u5176\u4e2d\uff1a\nvf_loss1 = (value_pred - return)^2\nvf_loss2 = (clipped_value_pred - return)^2  # \u622a\u65ad\u9884\u6d4b\u503c\u4ee5\u7a33\u5b9a\u8bad\u7ec3\n</code></pre></li> </ul>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#2ppo","title":"\uff082\uff09PPO\u635f\u5931","text":"<ul> <li>\u516c\u5f0f\uff1a Text Only<pre><code>ppo_loss = mean(max(r * (-advantage), clipped_r * (-advantage)))\n\u5176\u4e2d\uff1a\nr = \u8bad\u7ec3\u6a21\u578b\u6982\u7387 / \u91cd\u8981\u6027\u91c7\u6837\u6a21\u578b\u6982\u7387\nclipped_r = clip(r, 1-epsilon, 1+epsilon)  # \u9650\u5236\u6982\u7387\u6bd4\u503c\u8303\u56f4\n</code></pre></li> <li>\u6ce8\u610f\uff1aKL\u6563\u5ea6\u5df2\u878d\u5165\u5956\u52b1\u4fe1\u53f7\uff0c\u6545\u635f\u5931\u51fd\u6570\u4e2d\u65e0\u9700\u989d\u5916\u5305\u542b</li> </ul>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#5","title":"5. \u8bad\u7ec3\u6d41\u7a0b\uff08\u4f2a\u4ee3\u7801\uff09","text":"Python<pre><code>for each batch in prompt_dataset:\n    # \u751f\u6210\u56de\u7b54\u5e76\u8ba1\u7b97\u5956\u52b1\n    responses = importance_sampling_model.generate(batch[\"queries\"])\n    scores = reward_model.score(batch[\"queries\"] + responses)\n\n    # \u8ba1\u7b97\u6982\u7387\u5206\u5e03\u3001\u4ef7\u503c\u4e0e\u4f18\u52bf\n    all_probs, values = importance_sampling_model(batch[\"queries\"] + responses)\n    kl_div = calculate_kl(all_probs, base_model_probs)\n    rewards = (-0.2 * kl_div) + scores\n    advantages = compute_gae(rewards, values)\n\n    # \u591a\u8f6e\u66f4\u65b0\uff08\u5185\u5faa\u73af\uff09\n    for _ in range(epochs):\n        # \u8ba1\u7b97\u635f\u5931\u5e76\u53cd\u5411\u4f20\u64ad\n        new_probs, new_values = training_model(batch[\"queries\"] + responses)\n        vf_loss = compute_vf_loss(new_values, advantages + values)\n        ppo_loss = compute_ppo_loss(new_probs, all_probs, advantages)\n        total_loss = ppo_loss + 0.5 * vf_loss\n        total_loss.backward()\n        optimizer.step()\n</code></pre>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#6-hugging-face-trl","title":"6. \u8bad\u7ec3\u4ee3\u7801\uff08\u57fa\u4e8eHugging Face TRL\u5e93\uff09","text":"Python<pre><code># 1. \u914d\u7f6e\u6a21\u578b\uff08\u542b\u4ef7\u503c\u5934\u7684\u56e0\u679c\u8bed\u8a00\u6a21\u578b\uff09\nmodel = AutoModelForCausalLMWithValueHead.from_pretrained(\n    base_model_name,\n    peft_config=lora_config,  # \u5171\u4eab\u57fa\u51c6\u6a21\u578b\u6743\u91cd\n    reward_adapter=reward_model_path,\n)\n\n# 2. \u52a0\u8f7d\u6570\u636e\uff08\u4ec5\u9700\u95ee\u9898\uff0c\u56de\u7b54\u7531\u6a21\u578b\u751f\u6210\uff09\ndataset = load_dataset(\"json\", data_files=\"queries.json\")\ntokenized_dataset = dataset.map(lambda x: tokenizer(x[\"query\"], ...))\n\n# 3. \u5b9a\u4e49PPO\u914d\u7f6e\nppo_config = PPOConfig(\n    kl_div=\"forward\",  # \u6807\u51c6KL\u6563\u5ea6\u8ba1\u7b97\n    per_device_train_batch_size=4,\n    num_train_epochs=3,\n    ...\n)\n\n# 4. \u5b9a\u4e49\u8bad\u7ec3\u5668\u5e76\u542f\u52a8\u8bad\u7ec3\nppo_trainer = PPOTrainer(\n    config=ppo_config,\n    model=model,\n    ref_model=base_model,  # \u57fa\u51c6\u6a21\u578b\n    tokenizer=tokenizer,\n    dataset=tokenized_dataset,\n)\n\n# 5. \u8bad\u7ec3\u5faa\u73af\nfor batch in ppo_trainer.dataloader:\n    queries = batch[\"input_ids\"]\n    responses = ppo_trainer.generate(queries, max_new_tokens=100)  # \u751f\u6210\u56de\u7b54\n    scores = reward_model.score(queries, responses)  # \u8bc4\u5206\n    ppo_trainer.step(queries, responses, scores)  # \u66f4\u65b0\u6a21\u578b\n</code></pre>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#_2","title":"\u56db\u3001\u6ce8\u610f\u4e8b\u9879","text":"<ol> <li>\u6570\u636e\u5c42\u9762\uff1a\u504f\u597d\u6570\u636e\u9700\u4fdd\u8bc1<code>chosen</code>\u4e0e<code>rejected</code>\u7684\u8d28\u91cf\u5dee\u5f02\u660e\u786e\uff0c\u5426\u5219\u5956\u52b1\u6a21\u578b\u5b66\u4e60\u6548\u679c\u5dee</li> <li>\u6a21\u578b\u5c42\u9762\uff1a    - \u5956\u52b1\u6a21\u578b\u80fd\u529b\u9700\u4e0e\u5f85\u4f18\u5316\u6a21\u578b\u5339\u914d\uff08\u4e0d\u53ef\u8fc7\u5f31\uff09    - \u901a\u8fc7LoRA\u6280\u672f\u51cf\u5c11\u663e\u5b58\u5360\u7528\uff0c\u907f\u514d\u540c\u65f6\u52a0\u8f7d\u591a\u4e2a\u5927\u6a21\u578b</li> <li>\u8bad\u7ec3\u53c2\u6570\uff1a    - \u751f\u6210\u56de\u7b54\u65f6\u9700\u5173\u95ed<code>top_k</code>\uff0c<code>temperature=1.0</code>\uff0c\u4fdd\u8bc1\u91c7\u6837\u8986\u76d6\u5168\u6982\u7387\u7a7a\u95f4    - KL\u6563\u5ea6\u7cfb\u6570\uff08\u5982-0.2\uff09\u9700\u6839\u636e\u4efb\u52a1\u8c03\u6574\uff0c\u5e73\u8861\u63a2\u7d22\u4e0e\u7a33\u5b9a</li> <li>\u635f\u5931\u8ba1\u7b97\uff1a    - \u4ef7\u503c\u7f51\u7edc\u9700\u622a\u65ad\u9884\u6d4b\u503c\uff0c\u9632\u6b62\u8bad\u7ec3\u4e0d\u7a33\u5b9a    - PPO\u635f\u5931\u9700\u9650\u5236\u6982\u7387\u6bd4\u503c\u8303\u56f4\uff08\u901a\u5e38<code>epsilon=0.2</code>\uff09</li> <li>\u8fed\u4ee3\u903b\u8f91\uff1a\u91c7\u7528\u5916\u5faa\u73af\uff08batch\u6570\u636e\uff09+\u5185\u5faa\u73af\uff08\u591a\u8f6e\u66f4\u65b0\uff09\u7ed3\u6784\uff0c\u63d0\u5347\u8bad\u7ec3\u6548\u7387</li> </ol>"},{"location":"notes/RL/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0PPO/#_3","title":"\u4e94\u3001\u6838\u5fc3\u7ed3\u8bba","text":"<ul> <li>\u5f3a\u5316\u5b66\u4e60\uff08PPO\uff09\u662f\u5927\u6a21\u578b\u80fd\u529b\u903c\u8fd1\u9884\u8bad\u7ec3\u6781\u9650\u7684\u5173\u952e\u6b65\u9aa4</li> <li>\u5956\u52b1\u6a21\u578b\u4e0e\u4ef7\u503c\u6a21\u578b\u7684\u8bbe\u8ba1\u662f\u8bad\u7ec3\u6838\u5fc3\uff0c\u9700\u5e73\u8861\u504f\u5dee\u4e0e\u65b9\u5dee</li> <li>\u57fa\u4e8eHugging Face TRL\u5e93\u53ef\u7b80\u5316\u5b9e\u73b0\uff0c\u4f46\u9700\u7406\u89e3\u5e95\u5c42\u516c\u5f0f\u4e0e\u53c2\u6570\u542b\u4e49</li> <li>\u4ee3\u7801\u5730\u5740\uff1ahttps://github.com/RethinkFun/trian_ppo/tree/main/train_ppo</li> </ul>"},{"location":"notes/Research/Thoughts/","title":"Thoughts","text":"<p> \u7ea6 131 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u628aVLM\u7528Robotics Dataset Finetune\uff0c\u63d0\u5347\u5176VQA\u80fd\u529b\uff0c\u540c\u65f6\u53c8\u4e0d\u635f\u5931\u5176\u672c\u8eab\u7684QA\u80fd\u529b\u3002\uff08\u51bb\u7ed3\u67d0\u4e9b\u5934\u53ef\u80fd\u53ef\u4ee5\u5b9e\u73b0\uff0c\u5177\u4f53\u53ef\u4ee5\u770b\u76f8\u5173\u8bba\u6587\uff09</p> <p>\u6211\u4eec\u53ef\u80fd\u9700\u8981\u540c\u4e00\u4e2aVLM Backbone\uff0c\u7136\u540e\u8bbe\u8ba1\u4e0d\u540c\u7684projection\u6765\u5b8c\u6210\u4e0d\u540c\u7684\u4efb\u52a1\u3002\u6211\u4eec\u9700\u8981\u673a\u5668\u4eba\u89c6\u89c9\u8f93\u5165+\u6307\u4ee4-&gt;\u53d1\u6398\u56e0\u679c\u5173\u7cfb\uff0c\u5c06\u56e0\u679c\u5173\u7cfb\u5e94\u7528\u5230Robot\u52a8\u4f5c\u6307\u4ee4\u751f\u6210\uff08\u79bb\u6563\u7684\uff1f\uff09\uff0c\u5982\u4f55\u7528Flow Matching\u83b7\u5f97\u8fde\u7eed\u6d41\u7545\u7684\u52a8\u4f5c\uff1f</p> <p>Now we are focusing on Causal Discovery Framework.</p>"},{"location":"notes/Research/CausalDiscovery/Metrics/","title":"Metrics","text":""},{"location":"notes/Research/CausalDiscovery/Metrics/#metrics","title":"Metrics","text":"<p> \u7ea6 2158 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 11 \u5206\u949f</p>"},{"location":"notes/Research/CausalDiscovery/Metrics/#_1","title":"\u6838\u5fc3\u57fa\u7840\uff1a\u6df7\u6dc6\u77e9\u9635","text":"<p>\u8981\u7406\u89e3\u8fd9\u56db\u4e2a\u6307\u6807\uff0c\u9996\u5148\u5fc5\u987b\u4e86\u89e3\u6df7\u6dc6\u77e9\u9635\u3002\u5b83\u662f\u4e00\u5207\u8ba1\u7b97\u7684\u57fa\u7840\u3002</p> <p>\u5047\u8bbe\u6211\u4eec\u9884\u6d4b\u4e00\u4e2a\u75c5\u4eba\u662f\u5426\u60a3\u75c5\uff08\u6b63\u4f8b=\u60a3\u75c5\uff0c\u8d1f\u4f8b=\u5065\u5eb7\uff09\u3002\u6df7\u6dc6\u77e9\u9635\u5982\u4e0b\uff1a</p> \u5b9e\u9645\u4e3a\u6b63\u4f8b \u5b9e\u9645\u4e3a\u8d1f\u4f8b \u9884\u6d4b\u4e3a\u6b63\u4f8b True Positive (TP) False Positive (FP) \u9884\u6d4b\u4e3a\u8d1f\u4f8b False Negative (FN) True Negative (TN) <ul> <li>TP\uff08\u771f\u9633\u6027\uff09\uff1a\u9884\u6d4b\u6b63\u786e\u3002\u75c5\u4eba\u786e\u5b9e\u60a3\u75c5\uff0c\u6211\u4eec\u9884\u6d4b\u4ed6\u4e5f\u60a3\u75c5\u3002</li> <li>FP\uff08\u5047\u9633\u6027\uff09\uff1a\u9884\u6d4b\u9519\u8bef\u3002\u75c5\u4eba\u5b9e\u9645\u5065\u5eb7\uff0c\u6211\u4eec\u8bef\u9884\u6d4b\u4ed6\u60a3\u75c5\u3002\uff08Type I Error\uff09</li> <li>FN\uff08\u5047\u9634\u6027\uff09\uff1a\u9884\u6d4b\u9519\u8bef\u3002\u75c5\u4eba\u5b9e\u9645\u60a3\u75c5\uff0c\u6211\u4eec\u8bef\u9884\u6d4b\u4ed6\u5065\u5eb7\u3002\uff08Type II Error\uff09</li> <li>TN\uff08\u771f\u9634\u6027\uff09\uff1a\u9884\u6d4b\u6b63\u786e\u3002\u75c5\u4eba\u786e\u5b9e\u5065\u5eb7\uff0c\u6211\u4eec\u9884\u6d4b\u4ed6\u4e5f\u5065\u5eb7\u3002</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Metrics/#_2","title":"\u56db\u4e2a\u6307\u6807\u7684\u5b9a\u4e49\u4e0e\u533a\u522b","text":"<p>\u73b0\u5728\u6211\u4eec\u57fa\u4e8e\u6df7\u6dc6\u77e9\u9635\u6765\u5b9a\u4e49\u8fd9\u56db\u4e2a\u6307\u6807\u3002</p>"},{"location":"notes/Research/CausalDiscovery/Metrics/#1-accuracy","title":"1. Accuracy\uff08\u51c6\u786e\u7387\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u6240\u6709\u9884\u6d4b\u4e2d\uff0c\u9884\u6d4b\u6b63\u786e\u7684\u6bd4\u4f8b\u3002\u662f\u6700\u76f4\u89c2\u7684\u6307\u6807\u3002</li> <li>\u516c\u5f0f\uff1a\\(Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\\)</li> <li>\u7406\u89e3\uff1a\u201c\u8499\u5bf9\u7684\u201d\u6982\u7387\u6709\u591a\u5927\uff1f\u5b83\u8861\u91cf\u4e86\u6a21\u578b\u7684\u6574\u4f53\u6b63\u786e\u6027\u3002</li> <li>\u4f18\u70b9\u4e0e\u5c40\u9650\uff1a<ul> <li>\u5728\u6570\u636e\u7c7b\u522b\u5747\u8861\uff08\u6b63\u8d1f\u6837\u672c\u6570\u91cf\u5dee\u4e0d\u591a\uff09\u65f6\uff0cAccuracy\u662f\u4e00\u4e2a\u5f88\u597d\u7684\u6307\u6807\u3002</li> <li>\u4f46\u5728\u6570\u636e\u6781\u5ea6\u4e0d\u5e73\u8861\u65f6\uff0cAccuracy\u4f1a\u5931\u6548\u3002</li> <li>\u4f8b\u5b50\uff1a\u5728\u4e00\u4e2a\u670999\u4e2a\u5065\u5eb7\u4eba\u30011\u4e2a\u75c5\u4eba\u7684\u6570\u636e\u96c6\u4e2d\uff0c\u5373\u4f7f\u6a21\u578b\u628a\u6240\u6709\u4eba\u90fd\u9884\u6d4b\u4e3a\u5065\u5eb7\uff0c\u5b83\u7684Accuracy\u4e5f\u80fd\u9ad8\u8fbe99%\u3002\u4f46\u8fd9\u4e2a\u6a21\u578b\u6beb\u65e0\u7528\u5904\uff0c\u56e0\u4e3a\u5b83\u6f0f\u6389\u4e86\u6240\u6709\u75c5\u4eba\u3002</li> </ul> </li> </ul>"},{"location":"notes/Research/CausalDiscovery/Metrics/#2-precision","title":"2. Precision\uff08\u7cbe\u786e\u7387/\u67e5\u51c6\u7387\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u5728\u6240\u6709\u88ab\u9884\u6d4b\u4e3a\u6b63\u4f8b\u7684\u6837\u672c\u4e2d\uff0c\u771f\u6b63\u662f\u6b63\u4f8b\u7684\u6bd4\u4f8b\u3002\u5b83\u5173\u6ce8\u7684\u662f\u9884\u6d4b\u7ed3\u679c\u7684\u7cbe\u51c6\u5ea6\u3002</li> <li>\u516c\u5f0f\uff1a\\(Precision = \\frac{TP}{TP + FP}\\)</li> <li>\u7406\u89e3\uff1a\u201c\u6211\u8bf4\u4ed6\u5bf9\uff0c\u4ed6\u6709\u591a\u5927\u6982\u7387\u771f\u7684\u5bf9\uff1f\u201d \u8861\u91cf\u7684\u662f\u6a21\u578b\u907f\u514d\u8bef\u62a5\uff08False Alarm\uff09 \u7684\u80fd\u529b\u3002</li> <li>\u5e94\u7528\u573a\u666f\uff1a\u975e\u5e38\u6ce8\u91cd\u51cf\u5c11FP\uff08\u5047\u9633\u6027\uff09\u7684\u573a\u666f\u3002<ul> <li>\u5783\u573e\u90ae\u4ef6\u68c0\u6d4b\uff1a\u628a\u6b63\u5e38\u90ae\u4ef6\u9884\u6d4b\u4e3a\u5783\u573e\u90ae\u4ef6\uff08FP\uff09\u7684\u540e\u679c\u5f88\u4e25\u91cd\uff08\u7528\u6237\u53ef\u80fd\u9519\u8fc7\u91cd\u8981\u90ae\u4ef6\uff09\uff0c\u6240\u4ee5\u9700\u8981\u6781\u9ad8\u7684Precision\u3002\u5b81\u53ef\u653e\u8fc7\u4e00\u4e9b\u5783\u573e\u90ae\u4ef6\uff08FN\uff09\uff0c\u4e5f\u4e0d\u80fd\u9519\u6740\u6b63\u5e38\u90ae\u4ef6\u3002</li> </ul> </li> </ul>"},{"location":"notes/Research/CausalDiscovery/Metrics/#3-recall","title":"3. Recall\uff08\u53ec\u56de\u7387/\u67e5\u5168\u7387\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u5728\u6240\u6709\u5b9e\u9645\u4e3a\u6b63\u4f8b\u7684\u6837\u672c\u4e2d\uff0c\u88ab\u6210\u529f\u9884\u6d4b\u4e3a\u6b63\u4f8b\u7684\u6bd4\u4f8b\u3002\u5b83\u5173\u6ce8\u7684\u662f\u627e\u51fa\u6b63\u4f8b\u7684\u80fd\u529b\u3002</li> <li>\u516c\u5f0f\uff1a\\(Recall = \\frac{TP}{TP + FN}\\)</li> <li>\u7406\u89e3\uff1a\u201c\u771f\u6b63\u5bf9\u7684\uff0c\u6211\u627e\u51fa\u4e86\u591a\u5c11\uff1f\u201d \u8861\u91cf\u7684\u662f\u6a21\u578b\u907f\u514d\u6f0f\u68c0\uff08Missing Detection\uff09 \u7684\u80fd\u529b\u3002</li> <li>\u5e94\u7528\u573a\u666f\uff1a\u975e\u5e38\u6ce8\u91cd\u51cf\u5c11FN\uff08\u5047\u9634\u6027\uff09\u7684\u573a\u666f\u3002<ul> <li>\u75be\u75c5\u8bca\u65ad\uff1a\u628a\u4e00\u4e2a\u75c5\u4eba\u9884\u6d4b\u4e3a\u5065\u5eb7\uff08FN\uff09\u7684\u540e\u679c\u662f\u707e\u96be\u6027\u7684\uff08\u5ef6\u8bef\u6cbb\u7597\uff09\uff0c\u6240\u4ee5\u9700\u8981\u6781\u9ad8\u7684Recall\u3002\u5b81\u53ef\u8bef\u5224\u4e00\u4e9b\u5065\u5eb7\u4eba\uff08FP\uff09\u53bb\u505a\u8fdb\u4e00\u6b65\u68c0\u67e5\uff0c\u4e5f\u4e0d\u80fd\u6f0f\u6389\u4e00\u4e2a\u75c5\u4eba\u3002</li> </ul> </li> </ul>"},{"location":"notes/Research/CausalDiscovery/Metrics/#4-f1-scoref1","title":"4. F1 Score\uff08F1\u5206\u6570\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1aPrecision\u548cRecall\u7684\u8c03\u548c\u5e73\u5747\u6570\u3002\u662f\u7efc\u5408\u8861\u91cf\u6a21\u578b\u7a33\u5065\u6027\u7684\u6307\u6807\u3002</li> <li>\u516c\u5f0f\uff1a\\(F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}\\)</li> <li>\u7406\u89e3\uff1aPrecision\u548cRecall\u901a\u5e38\u662f\u4e00\u5bf9\u77db\u76fe\u7684\u6307\u6807\uff08\u63d0\u9ad8\u4e00\u4e2a\u5f80\u5f80\u4f1a\u964d\u4f4e\u53e6\u4e00\u4e2a\uff09\u3002F1 Score\u8bd5\u56fe\u627e\u5230\u4e00\u4e2a\u5e73\u8861\u70b9\u3002<ul> <li>\u4e3a\u4ec0\u4e48\u7528\u8c03\u548c\u5e73\u5747\u800c\u4e0d\u662f\u7b97\u672f\u5e73\u5747\uff1f \u8c03\u548c\u5e73\u5747\u66f4\u6ce8\u91cd\u8f83\u5c0f\u503c\u7684\u8868\u73b0\u3002\u53ea\u6709\u5f53P\u548cR\u90fd\u6bd4\u8f83\u9ad8\u65f6\uff0cF1\u624d\u4f1a\u9ad8\u3002\u5982\u679c\u5176\u4e2d\u4e00\u4e2a\u5f88\u4f4e\uff0c\u4f1a\u7acb\u523b\u62c9\u4f4eF1\u3002</li> </ul> </li> <li>\u5e94\u7528\u573a\u666f\uff1a<ul> <li>\u5f53\u4f60\u9700\u8981\u5728Precision\u548cRecall\u4e4b\u95f4\u5bfb\u6c42\u4e00\u4e2a\u5e73\u8861\u65f6\u3002</li> <li>\u5f53\u6570\u636e\u7c7b\u522b\u5206\u5e03\u4e0d\u5e73\u8861\u65f6\uff0cF1\u662f\u6bd4Accuracy\u66f4\u597d\u7684\u6307\u6807\u3002</li> <li>\u5f53\u4f60\u6ca1\u6709\u660e\u786e\u7684\u504f\u597d\u662f\u66f4\u9700\u8981Precision\u8fd8\u662fRecall\u65f6\u3002</li> </ul> </li> </ul>"},{"location":"notes/Research/CausalDiscovery/Metrics/#_3","title":"\u603b\u7ed3\u4e0e\u5bf9\u6bd4","text":"\u6307\u6807 \u5173\u6ce8\u70b9 \u516c\u5f0f \u6838\u5fc3\u95ee\u9898 \u5e94\u7528\u573a\u666f\u4e3e\u4f8b Accuracy \u6574\u4f53\u6b63\u786e\u6027 (TP+TN) / All \u6240\u6709\u9884\u6d4b\u4e2d\uff0c\u731c\u5bf9\u7684\u5360\u591a\u5927\u6bd4\u4f8b\uff1f \u5747\u8861\u6570\u636e\u96c6\uff0c\u6574\u4f53\u8bc4\u4f30 Precision \u9884\u6d4b\u6b63\u4f8b\u7684\u51c6\u786e\u6027\uff08\u51cf\u5c11\u8bef\u62a5FP\uff09 TP / (TP+FP) \u6211\u8bf4\u4ed6\u5bf9\uff0c\u4ed6\u6709\u591a\u5927\u6982\u7387\u771f\u7684\u5bf9\uff1f \u5783\u573e\u90ae\u4ef6\u68c0\u6d4b\u3001\u63a8\u8350\u7cfb\u7edf Recall \u627e\u51fa\u6240\u6709\u6b63\u4f8b\u7684\u80fd\u529b\uff08\u51cf\u5c11\u6f0f\u68c0FN\uff09 TP / (TP+FN) \u771f\u6b63\u5bf9\u7684\uff0c\u6211\u627e\u51fa\u4e86\u591a\u5c11\uff1f \u75be\u75c5\u8bca\u65ad\u3001\u6b3a\u8bc8\u68c0\u6d4b\u3001\u9003\u72af\u8bc6\u522b F1 Score Precision\u548cRecall\u7684\u5e73\u8861 2 * (P*R) / (P+R) \u6a21\u578b\u5728\u907f\u514d\u8bef\u62a5\u548c\u6f0f\u68c0\u4e0a\u7684\u7efc\u5408\u8868\u73b0\u5982\u4f55\uff1f \u4e0d\u5e73\u8861\u6570\u636e\u96c6\uff0c\u6ca1\u6709\u7279\u6b8a\u504f\u597d\u65f6"},{"location":"notes/Research/CausalDiscovery/Metrics/#_4","title":"\u4e00\u4e2a\u751f\u52a8\u7684\u6bd4\u55bb","text":"<p>\u5047\u8bbe\u4f60\u5728\u679c\u56ed\u91cc\u7528\u673a\u5668\u6311\u679c\u5b50\uff08\u597d\u679c\u5b50=\u6b63\u4f8b\uff0c\u574f\u679c\u5b50=\u8d1f\u4f8b\uff09\uff1a</p> <ul> <li>Accuracy\uff1a\u6240\u6709\u88ab\u6311\u51fa\u6765\u7684\u679c\u5b50\u4e2d\uff0c\u597d\u679c\u5b50\u548c\u88ab\u7559\u4e0b\u7684\u574f\u679c\u5b50\u5360\u603b\u6570\u7684\u6bd4\u4f8b\u3002\uff08\u6574\u4f53\u6311\u5f97\u6709\u591a\u51c6\uff09</li> <li>Precision\uff1a\u88ab\u673a\u5668\u653e\u8fdb\u597d\u679c\u5b50\u7b50\u91cc\u7684\u679c\u5b50\uff0c\u771f\u6b63\u662f\u597d\u679c\u5b50\u7684\u6bd4\u4f8b\u3002\uff08\u597d\u679c\u5b50\u7b50\u7684\u7eaf\u51c0\u5ea6\uff09<ul> <li>Precision\u4f4e\uff1a\u597d\u679c\u5b50\u7b50\u91cc\u6df7\u4e86\u5f88\u591a\u574f\u679c\u5b50\u3002</li> </ul> </li> <li>Recall\uff1a\u679c\u56ed\u91cc\u6240\u6709\u597d\u679c\u5b50\uff0c\u88ab\u673a\u5668\u6210\u529f\u6311\u8fdb\u597d\u679c\u5b50\u7b50\u7684\u6bd4\u4f8b\u3002\uff08\u597d\u679c\u5b50\u7684\u56de\u6536\u7387\uff09<ul> <li>Recall\u4f4e\uff1a\u5f88\u591a\u597d\u679c\u5b50\u88ab\u9057\u6f0f\uff0c\u4e22\u8fdb\u4e86\u574f\u679c\u5b50\u7b50\u3002</li> </ul> </li> <li>F1 Score\uff1a\u7efc\u5408\u8861\u91cf\u4e86\u201c\u7b50\u6709\u591a\u5e72\u51c0\u201d\u548c\u201c\u679c\u5b50\u56de\u6536\u5f97\u591a\u5168\u9762\u201d\u3002</li> </ul> <p>\u5e0c\u671b\u8fd9\u4e2a\u89e3\u91ca\u80fd\u5e2e\u52a9\u4f60\u6e05\u6670\u5730\u533a\u5206\u8fd9\u56db\u4e2a\u91cd\u8981\u6307\u6807\uff01</p> <p>\u60a8\u63d0\u4f9b\u7684\u8fd9\u6bb5\u63cf\u8ff0\u975e\u5e38\u7cbe\u51c6\uff0c\u5b83\u5b9a\u4e49\u4e86\u5728\u56fe\u7ed3\u6784\uff08\u5c24\u5176\u662f\u56e0\u679c\u56fe\uff09\u6bd4\u8f83\u4e2d\u4f7f\u7528\u7684\u5f52\u4e00\u5316\u6c49\u660e\u8ddd\u79bb (NHD)\u3002\u8fd9\u4e2a\u5b9a\u4e49\u4e0e\u6bd4\u8f83\u7b80\u5355\u5b57\u7b26\u4e32\u7684NHD\u5728\u7cbe\u795e\u4e0a\u4e00\u81f4\uff0c\u4f46\u5728\u8ba1\u7b97\u7ec6\u8282\u4e0a\u6709\u4e00\u4e2a\u5173\u952e\u533a\u522b\uff1a</p> <p>\u6838\u5fc3\u533a\u522b\uff1a\u5206\u6bcd\u4e0d\u540c *   \u5b57\u7b26\u4e32NHD\uff1a\u5206\u6bcd\u662f\u5e8f\u5217\u7684\u5b9e\u9645\u957f\u5ea6\u3002 *   \u56feNHD\uff1a\u5206\u6bcd\u662f\u56fe\u4e2d\u6240\u6709\u53ef\u80fd\u8fb9\u7684\u603b\u6570\uff08\u5bf9\u4e8e\u4e00\u4e2a\u6709 <code>m</code> \u4e2a\u8282\u70b9\u7684\u6709\u5411\u56fe\uff0c\u8fd9\u4e2a\u503c\u662f <code>m*(m-1)</code>\uff0c\u56e0\u4e3a\u4e0d\u5141\u8bb8\u6709\u81ea\u73af\uff09\u3002</p> <p>\u60a8\u63d0\u4f9b\u7684\u5b9a\u4e49\u662f\u56fe\u6bd4\u8f83\u9886\u57df\u7684\u6807\u51c6\u7528\u6cd5\u3002\u4e0b\u9762\u6211\u5c06\u6839\u636e\u60a8\u7684\u63cf\u8ff0\uff0c\u901a\u8fc7\u4e00\u4e2a\u8be6\u7ec6\u7684\u4f8b\u5b50\u6765\u8bf4\u660e\u8fd9\u4e2a\u8ba1\u7b97\u8fc7\u7a0b\u3002</p>"},{"location":"notes/Research/CausalDiscovery/Metrics/#nhd","title":"\u56feNHD\u8ba1\u7b97\u6b65\u9aa4","text":"<ol> <li>\u786e\u5b9a\u56fe\u7684\u8868\u793a\uff1a\u901a\u5e38\u4f7f\u7528\u90bb\u63a5\u77e9\u9635\u3002\u77e9\u9635\u4e2d\u5143\u7d20 <code>(i, j)</code> \u4e3a <code>1</code> \u8868\u793a\u5b58\u5728\u4ece\u8282\u70b9 <code>i</code> \u5230\u8282\u70b9 <code>j</code> \u7684\u8fb9\uff0c\u4e3a <code>0</code> \u5219\u8868\u793a\u4e0d\u5b58\u5728\u3002</li> <li>\u8ba1\u7b97\u5dee\u5f02\uff1a\u5bf9\u4e24\u4e2a\u56fe\u7684\u90bb\u63a5\u77e9\u9635\u8fdb\u884c\u5f02\u6216\uff08XOR\uff09 \u64cd\u4f5c\u3002\u7ed3\u679c\u4e3a <code>1</code> \u7684\u4f4d\u7f6e\u5c31\u662f\u4e24\u4e2a\u56fe\u4e0d\u4e00\u81f4\u7684\u8fb9\uff08\u5373\u4e00\u4e2a\u56fe\u4e2d\u6709\uff0c\u53e6\u4e00\u4e2a\u56fe\u4e2d\u6ca1\u6709\uff09\u3002</li> <li>\u7edf\u8ba1\u5dee\u5f02\u6570\u91cf\uff1a\u7edf\u8ba1\u5f02\u6216\u77e9\u9635\u4e2d <code>1</code> \u7684\u6570\u91cf\u3002\u8fd9\u5c31\u662f\u6c49\u660e\u8ddd\u79bb\u3002</li> <li>\u5f52\u4e00\u5316\uff1a\u5c06\u6c49\u660e\u8ddd\u79bb\u9664\u4ee5\u6240\u6709\u53ef\u80fd\u8fb9\u7684\u603b\u6570 <code>m*(m-1)</code>\uff0c\u5f97\u5230NHD\u3002</li> </ol> <p>\u516c\u5f0f\uff08Equation 6\uff09\uff1a \\(NHD(G, G_p) = \\frac{\\sum_{i=1}^{m} \\sum_{j=1, j \\neq i}^{m} \\mathbb{1}[G(i, j) \\neq G_p(i, j)]}{m(m-1)}\\) \u5176\u4e2d \\(\\mathbb{1}\\) \u662f\u6307\u793a\u51fd\u6570\uff0c\u5185\u90e8\u6761\u4ef6\u4e3a\u771f\u65f6\u8fd4\u56de1\uff0c\u5426\u5219\u8fd4\u56de0\u3002</p>"},{"location":"notes/Research/CausalDiscovery/Metrics/#_5","title":"\u4e3e\u4f8b\u8bf4\u660e","text":"<p>\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u5305\u542b 3\u4e2a\u8282\u70b9 (X, Y, Z) \u7684\u56e0\u679c\u56fe\u3002\u6240\u6709\u53ef\u80fd\u7684\u6709\u5411\u8fb9\u6570\u91cf\u4e3a <code>3 * (3-1) = 6</code> \u6761\uff0c\u5373\uff1aX\u2192Y, X\u2192Z, Y\u2192X, Y\u2192Z, Z\u2192X, Z\u2192Y\u3002</p> <ul> <li>\u771f\u5b9e\u56fe G \u7684\u7ed3\u6784\u4e3a\uff1a<code>X -&gt; Y -&gt; Z</code>\uff08\u4e00\u6761\u94fe\uff09\u3002</li> <li>\u9884\u6d4b\u56fe G_p \u7684\u7ed3\u6784\u4e3a\uff1a<code>X -&gt; Y &lt;- Z</code>\uff08\u4e00\u4e2aV\u578b\u7ed3\u6784\uff09\u3002</li> </ul> <p>\u8ba9\u6211\u4eec\u4e3a\u8fd9\u4e24\u4e2a\u56fe\u6784\u5efa\u90bb\u63a5\u77e9\u9635\u3002</p> <p>\u7b2c1\u6b65\uff1a\u521b\u5efa\u90bb\u63a5\u77e9\u9635</p> <ul> <li> <p>\u771f\u5b9e\u56fe G \u7684\u90bb\u63a5\u77e9\u9635:     |     | X   | Y   | Z   |     | --- | --- | --- | --- |     | X | 0   | 1   | 0   |     | Y | 0   | 0   | 1   |     | Z | 0   | 0   | 0   |</p> </li> <li> <p>\u9884\u6d4b\u56fe G_p \u7684\u90bb\u63a5\u77e9\u9635:     |     | X   | Y   | Z   |     | --- | --- | --- | --- |     | X | 0   | 1   | 0   |     | Y | 0   | 0   | 0   | // \u6ce8\u610f\uff0cY-&gt;Z \u7684\u8fb9\u6d88\u5931\u4e86     | Z | 0   | 1   | 0   | // \u6ce8\u610f\uff0c\u8fd9\u91cc\u591a\u4e86\u4e00\u6761 Z-&gt;Y \u7684\u8fb9</p> </li> </ul> <p>\u7b2c2\u6b65\uff1a\u8ba1\u7b97\u5f02\u6216\u77e9\u9635 (XOR) \u6211\u4eec\u5c06\u4e24\u4e2a\u77e9\u9635\u9010\u4f4d\u6bd4\u8f83\uff0c\u5982\u679c\u503c\u4e0d\u540c\u5219\u6807\u8bb0\u4e3a1\uff0c\u76f8\u540c\u5219\u6807\u8bb0\u4e3a0\u3002</p> X Y Z X 0\u22950=0 1\u22951=0 0\u22950=0 Y 0\u22950=0 0\u22950=0 1\u22950=1 Z 0\u22950=0 0\u22951=1 0\u22950=0 <p>\u5f02\u6216\u77e9\u9635\u7ed3\u679c: |     | X   | Y   | Z   | | --- | --- | --- | --- | | X | 0   | 0   | 0   | | Y | 0   | 0   | 1 | | Z | 0   | 1 | 0   |</p> <p>\u7b2c3\u6b65\uff1a\u7edf\u8ba1\u5dee\u5f02\u6570\u91cf\uff08\u6c49\u660e\u8ddd\u79bb\uff09 \u5f02\u6216\u77e9\u9635\u4e2d\u4e00\u5171\u6709 2 \u4e2a <code>1</code>\u3002 *   \u4e00\u4e2a\u662f <code>(Y, Z)</code>\uff0c\u5bf9\u5e94\u771f\u5b9e\u56fe\u4e2d <code>Y-&gt;Z</code> \u88ab\u6f0f\u6389\u4e86\uff08False Negative\uff09\u3002 *   \u4e00\u4e2a\u662f <code>(Z, Y)</code>\uff0c\u5bf9\u5e94\u9884\u6d4b\u56fe\u4e2d\u591a\u4e86\u4e00\u4e2a <code>Z-&gt;Y</code>\uff08False Positive\uff09\u3002</p> <p>\u56e0\u6b64\uff0c\u6c49\u660e\u8ddd\u79bb = 2\u3002</p> <p>\u7b2c4\u6b65\uff1a\u5f52\u4e00\u5316 (NHD) \u6240\u6709\u53ef\u80fd\u8fb9\u7684\u603b\u6570\u662f <code>m(m-1) = 3*2 = 6</code>\u3002</p> <p>\\(NHD = \\frac{Hamming\\,Distance}{Total\\,Possible\\,Edges} = \\frac{2}{6} \\approx 0.333\\)</p>"},{"location":"notes/Research/CausalDiscovery/Metrics/#_6","title":"\u7ed3\u679c\u89e3\u91ca","text":"<p>NHD \u2248 0.333 \u610f\u5473\u7740\u9884\u6d4b\u56fe <code>G_p</code> \u4e0e\u771f\u5b9e\u56fe <code>G</code> \u4e4b\u95f4\u6709 33.3% \u7684\u8fb9\u4e0d\u4e00\u81f4\u3002</p> <p>\u8fd9\u4e2a\u503c\u91cf\u5316\u4e86\u60a8\u63cf\u8ff0\u4e2d\u7684\u201cnuanced differences\u201d\uff1a 1.  \u5b83\u6355\u6349\u5230\u4e86\u6f0f\u6389\u7684\u8fb9\uff08FN\uff1aY-&gt;Z\uff09\u3002 2.  \u5b83\u4e5f\u6355\u6349\u5230\u4e86\u591a\u4f59\u7684\u8fb9\uff08FP\uff1aZ-&gt;Y\uff09\u3002 3.  \u5b83\u540c\u65f6 reward \u4e86\u6b63\u786e\u9884\u6d4b\u7684\u8fb9\uff08TP\uff1aX-&gt;Y\uff09\u548c\u6b63\u786e\u9884\u6d4b\u7684\u4e0d\u5b58\u5728\u7684\u8fb9\uff08TN\uff1a\u4f8b\u5982X-&gt;Z, Y-&gt;X\u7b49\uff09\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u5728\u5f02\u6216\u77e9\u9635\u4e2d\u90fd\u662f <code>0</code>\u3002</p>"},{"location":"notes/Research/CausalDiscovery/Metrics/#_7","title":"\u603b\u7ed3","text":"<p>\u5728\u56fe\u7ed3\u6784\u7684\u4e0a\u4e0b\u6587\u4e2d\uff0cNHD\u662f\u4e00\u4e2a\u6781\u5176\u6709\u4ef7\u503c\u7684\u6307\u6807\uff0c\u56e0\u4e3a\u5b83\uff1a *   \u5f52\u4e00\u5316\uff1a\u5141\u8bb8\u6bd4\u8f83\u4e0d\u540c\u8282\u70b9\u6570\u91cf\u7684\u56fe\u3002 *   \u5168\u9762\uff1a\u540c\u65f6\u60e9\u7f5a\u4e86\u5047\u9633\u6027\uff08\u591a\u7f16\u7684\u8fb9\uff09\u548c\u5047\u9634\u6027\uff08\u4e22\u5931\u7684\u8fb9\uff09\u3002 *   \u76f4\u89c2\uff1a\u7ed3\u679c\u53ef\u4ee5\u89e3\u91ca\u4e3a\u201c\u9519\u8bef\u8fb9\u7684\u6bd4\u4f8b\u201d\u3002NHD\u4e3a0\u8868\u793a\u56fe\u5b8c\u5168\u5339\u914d\uff0c\u4e3a1\u8868\u793a\u56fe\u5b8c\u5168\u76f8\u53cd\u3002</p>"},{"location":"notes/Research/CausalDiscovery/%E7%BB%BC%E8%BF%B0/","title":"\u7efc\u8ff0","text":""},{"location":"notes/Research/CausalDiscovery/%E7%BB%BC%E8%BF%B0/#_1","title":"\u7efc\u8ff0","text":"<p> \u7ea6 16 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"notes/Research/CausalDiscovery/%E7%BB%BC%E8%BF%B0/#vc-r-cnn","title":"VC R-CNN","text":"<p>VC R-CNN</p>"},{"location":"notes/Research/CausalDiscovery/%E7%BB%BC%E8%BF%B0/#llm4cd","title":"LLM4CD","text":"<p>LLM4CD</p> <p>LLMs as Direct Inference,Posterior Correction,Prior Knowledge</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/","title":"DAG-GNN","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#dag-gnn-directed-acyclic-graph-graph-neural-network","title":"DAG-GNN: Directed Acyclic Graph - Graph Neural Network","text":"<p> \u7ea6 913 \u4e2a\u5b57  154 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 6 \u5206\u949f</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_1","title":"\u6982\u8ff0","text":"<p>DAG-GNN\u662f\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\uff0c\u7531Zheng et al.\u57282018\u5e74\u63d0\u51fa\u3002\u8be5\u65b9\u6cd5\u5c06\u56e0\u679c\u53d1\u73b0\u95ee\u9898\u8f6c\u5316\u4e3a\u8fde\u7eed\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u5b66\u4e60\u53d8\u91cf\u95f4\u7684\u7ed3\u6784\u5316\u5173\u7cfb\u6765\u4f30\u8ba1\u6709\u5411\u65e0\u73af\u56fe(DAG)\u3002</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_2","title":"\u6570\u5b66\u539f\u7406","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_3","title":"\u57fa\u7840\u6982\u5ff5","text":"<p>\u56fe\u8868\u793a: \u6709\u5411\u65e0\u73af\u56fe\\(G = (V, E)\\)\uff0c\u5176\u4e2d\\(V\\)\u662f\u8282\u70b9\u96c6\u5408\uff0c\\(E\\)\u662f\u6709\u5411\u8fb9\u96c6\u5408\u3002\u90bb\u63a5\u77e9\u9635\\(W \\in \\mathbb{R}^{d \\times d}\\)\u8868\u793a\u56fe\u7ed3\u6784\uff0c\\(W_{ij} \\neq 0\\)\u8868\u793a\u5b58\u5728\u4ece\u8282\u70b9\\(i\\)\u5230\u8282\u70b9\\(j\\)\u7684\u6709\u5411\u8fb9\u3002</p> <p>DAG\u7ea6\u675f: \u56fe\u5fc5\u987b\u662f\u6709\u5411\u65e0\u73af\u56fe\uff0c\u8fd9\u7b49\u4ef7\u4e8e\u90bb\u63a5\u77e9\u9635\\(W\\)\u7684\u6307\u6570\u77e9\u9635\\(e^{W \\circ W}\\)\u7684\u5bf9\u89d2\u7ebf\u5143\u7d20\u4e3a\u96f6\uff1a \\(\\(\\text{tr}(e^{W \\circ W}) = d\\)\\)</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_4","title":"\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784","text":"<p>DAG-GNN\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u7f16\u7801-\u89e3\u7801\uff1a</p> <p>\u7f16\u7801\u5668(Encoder): \\(\\(H^{(l+1)} = \\sigma(W^{(l)}H^{(l)} + \\sum_{j \\in N(i)} \\frac{1}{\\sqrt{|N(i)||N(j)|}} H^{(l)}_j)\\)\\)</p> <p>\u89e3\u7801\u5668(Decoder): \\(\\(\\hat{X}_i = f(H_i; \\theta)\\)\\)</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_5","title":"\u76ee\u6807\u51fd\u6570","text":"<p>DAG-GNN\u7684\u76ee\u6807\u51fd\u6570\u5305\u542b\u4e09\u4e2a\u90e8\u5206\uff1a</p> <ol> <li> <p>\u91cd\u6784\u635f\u5931: \\(\\(\\mathcal{L}_{recon} = \\frac{1}{n}\\sum_{i=1}^n \\|X_i - \\hat{X}_i\\|^2\\)\\)</p> </li> <li> <p>DAG\u7ea6\u675f: \\(\\(\\mathcal{L}_{dag} = \\text{tr}(e^{W \\circ W}) - d\\)\\)</p> </li> <li> <p>\u7a00\u758f\u6027\u7ea6\u675f: \\(\\(\\mathcal{L}_{sparse} = \\|W\\|_1\\)\\)</p> </li> </ol> <p>\u603b\u76ee\u6807\u51fd\u6570: \\(\\(\\mathcal{L} = \\mathcal{L}_{recon} + \\lambda_1 \\mathcal{L}_{dag} + \\lambda_2 \\mathcal{L}_{sparse}\\)\\)</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_6","title":"\u4f18\u5316\u7b56\u7565","text":"<p>\u4f7f\u7528\u5bf9\u6570\u884c\u5217\u5f0f\u5c55\u5f00(log-exp-sum)\u6280\u5de7\u6765\u5904\u7406DAG\u7ea6\u675f\uff1a \\(\\(\\text{tr}(e^{W \\circ W}) = \\sum_{k=0}^{\\infty} \\frac{(W \\circ W)^k}{k!}\\)\\)</p> <p>\u5b9e\u9645\u8ba1\u7b97\u4e2d\uff0c\u4f7f\u7528\u622a\u65ad\u8fd1\u4f3c\uff1a \\(\\(\\text{tr}(e^{W \\circ W}) \\approx \\sum_{k=0}^{K} \\frac{(W \\circ W)^k}{k!}\\)\\)</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_7","title":"\u7b97\u6cd5\u6d41\u7a0b","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_8","title":"\u8f93\u5165","text":"<ul> <li>\u89c2\u6d4b\u6570\u636e\u77e9\u9635 \\(X \\in \\mathbb{R}^{n \\times d}\\)</li> <li>\u56fe\u795e\u7ecf\u7f51\u7edc\u5c42\u6570 \\(L\\)</li> <li>\u6b63\u5219\u5316\u53c2\u6570 \\(\\lambda_1, \\lambda_2\\)</li> <li>\u5b66\u4e60\u7387 \\(\\eta\\)</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_9","title":"\u521d\u59cb\u5316","text":"<ul> <li>\u968f\u673a\u521d\u59cb\u5316GNN\u53c2\u6570 \\(\\theta\\)</li> <li>\u968f\u673a\u521d\u59cb\u5316\u90bb\u63a5\u77e9\u9635 \\(W\\)</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_10","title":"\u8fed\u4ee3\u4f18\u5316","text":"Python<pre><code>for epoch in range(max_epochs):\n    # \u524d\u5411\u4f20\u64ad\n    H = gnn_encoder(X, W, theta)  # \u7f16\u7801\n    X_hat = gnn_decoder(H, theta)  # \u89e3\u7801\n\n    # \u8ba1\u7b97\u635f\u5931\n    loss_recon = reconstruction_loss(X, X_hat)\n    loss_dag = dag_constraint(W)\n    loss_sparse = l1_norm(W)\n\n    total_loss = loss_recon + lambda1 * loss_dag + lambda2 * loss_sparse\n\n    # \u53cd\u5411\u4f20\u64ad\n    total_loss.backward()\n    optimizer.step()\n\n    # \u8f93\u51fa\u5f53\u524d\u7ed3\u679c\n    if epoch % log_interval == 0:\n        print(f\"Epoch {epoch}, Loss: {total_loss.item()}\")\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_11","title":"\u8f93\u51fa","text":"<ul> <li>\u5b66\u4e60\u5230\u7684\u90bb\u63a5\u77e9\u9635 \\(W^*\\)</li> <li>\u4f30\u8ba1\u7684DAG\u7ed3\u6784 \\(G^* = (V, E^*)\\)</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_12","title":"\u4f7f\u7528\u65b9\u6cd5","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#pytorch","title":"PyTorch\u5b9e\u73b0\u793a\u4f8b","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\n\nclass DAG_GNN(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers):\n        super(DAG_GNN, self).__init__()\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n\n        # GNN\u5c42\n        self.gnn_layers = nn.ModuleList([\n            nn.Linear(input_dim, hidden_dim) if i == 0 \n            else nn.Linear(hidden_dim, hidden_dim)\n            for i in range(num_layers)\n        ])\n\n        # \u89e3\u7801\u5668\n        self.decoder = nn.Linear(hidden_dim, input_dim)\n\n        # \u90bb\u63a5\u77e9\u9635\uff08\u53ef\u5b66\u4e60\u53c2\u6570\uff09\n        self.W = nn.Parameter(torch.randn(input_dim, input_dim))\n\n    def forward(self, X):\n        batch_size, num_nodes, feature_dim = X.shape\n\n        # GNN\u7f16\u7801\n        H = X\n        for layer in self.gnn_layers:\n            # \u56fe\u5377\u79ef\u64cd\u4f5c\n            H_new = torch.zeros_like(H)\n            for i in range(num_nodes):\n                # \u805a\u5408\u90bb\u5c45\u4fe1\u606f\n                neighbor_sum = torch.zeros(batch_size, self.hidden_dim)\n                for j in range(num_nodes):\n                    if i != j:\n                        weight = torch.sigmoid(self.W[i, j])\n                        neighbor_sum += weight * H[:, j, :]\n\n                # \u81ea\u8eab\u4fe1\u606f + \u90bb\u5c45\u4fe1\u606f\n                H_new[:, i, :] = layer(H[:, i, :] + neighbor_sum)\n\n            H = torch.relu(H_new)\n\n        # \u89e3\u7801\n        X_hat = self.decoder(H)\n\n        return X_hat, self.W\n\n    def dag_constraint(self):\n        \"\"\"\u8ba1\u7b97DAG\u7ea6\u675f\"\"\"\n        W = self.W\n        # \u4f7f\u7528\u622a\u65ad\u6307\u6570\u51fd\u6570\u8fd1\u4f3c\n        exp_W = torch.matrix_exp(W * W)\n        return torch.trace(exp_W) - self.input_dim\n\ndef train_dag_gnn(data, hidden_dim=64, num_layers=3, \n                 lambda1=0.1, lambda2=0.01, lr=0.001, \n                 epochs=1000, batch_size=32):\n    \"\"\"\n    \u8bad\u7ec3DAG-GNN\u6a21\u578b\n    \"\"\"\n    input_dim = data.shape[1]\n    model = DAG_GNN(input_dim, hidden_dim, num_layers)\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    # \u6570\u636e\u51c6\u5907\n    dataset = prepare_dataset(data, batch_size)\n\n    for epoch in range(epochs):\n        total_loss = 0\n\n        for batch_X in dataset:\n            optimizer.zero_grad()\n\n            # \u524d\u5411\u4f20\u64ad\n            X_hat, W = model(batch_X)\n\n            # \u8ba1\u7b97\u635f\u5931\n            recon_loss = nn.MSELoss()(X_hat, batch_X)\n            dag_loss = model.dag_constraint()\n            sparse_loss = torch.norm(W, p=1)\n\n            total_loss_batch = recon_loss + lambda1 * dag_loss + lambda2 * sparse_loss\n\n            # \u53cd\u5411\u4f20\u64ad\n            total_loss_batch.backward()\n            optimizer.step()\n\n            total_loss += total_loss_batch.item()\n\n        if epoch % 100 == 0:\n            print(f\"Epoch {epoch}, Loss: {total_loss/len(dataset):.4f}\")\n\n    return model\n\ndef prepare_dataset(data, batch_size):\n    \"\"\"\u51c6\u5907\u6570\u636e\u96c6\"\"\"\n    # \u5c06\u6570\u636e\u91cd\u5851\u4e3a (batch_size, num_nodes, feature_dim)\n    # \u8fd9\u91cc\u7b80\u5316\u5904\u7406\uff0c\u5b9e\u9645\u9700\u8981\u6839\u636e\u5177\u4f53\u6570\u636e\u7ed3\u6784\u8c03\u6574\n    n_samples = data.shape[0]\n    n_vars = data.shape[1]\n\n    # \u4e3a\u6bcf\u4e2a\u6837\u672c\u521b\u5efa\u56fe\u7ed3\u6784\n    dataset = []\n    for i in range(0, n_samples - batch_size + 1, batch_size):\n        batch_data = data[i:i+batch_size]\n        # \u91cd\u5851\u4e3a (batch_size, num_vars, 1)\n        batch_reshaped = batch_data.unsqueeze(-1)\n        dataset.append(batch_reshaped)\n\n    return dataset\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_13","title":"\u53c2\u6570\u9009\u62e9","text":"<ol> <li> <p>\u7f51\u7edc\u7ed3\u6784\u53c2\u6570:    - <code>hidden_dim</code>: \u9690\u85cf\u5c42\u7ef4\u5ea6\uff0c\u901a\u5e3864-256    - <code>num_layers</code>: GNN\u5c42\u6570\uff0c\u901a\u5e382-4\u5c42</p> </li> <li> <p>\u6b63\u5219\u5316\u53c2\u6570:    - <code>lambda1</code>: DAG\u7ea6\u675f\u5f3a\u5ea6\uff0c\u901a\u5e380.01-0.5    - <code>lambda2</code>: \u7a00\u758f\u6027\u7ea6\u675f\u5f3a\u5ea6\uff0c\u901a\u5e380.001-0.1</p> </li> <li> <p>\u8bad\u7ec3\u53c2\u6570:    - <code>lr</code>: \u5b66\u4e60\u7387\uff0c\u901a\u5e380.0001-0.01    - <code>batch_size</code>: \u6279\u5927\u5c0f\uff0c\u6839\u636e\u6570\u636e\u91cf\u8c03\u6574    - <code>epochs</code>: \u8bad\u7ec3\u8f6e\u6570\uff0c\u901a\u5e381000-10000</p> </li> </ol>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_14","title":"\u5e94\u7528\u793a\u4f8b","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_15","title":"\u7ebf\u6027\u7ed3\u6784\u5b66\u4e60","text":"<p>\u771f\u5b9e\u7ed3\u6784: \\(X_1 \\rightarrow X_2 \\rightarrow X_3\\)</p> <p>\u6570\u636e\u751f\u6210: </p>Python<pre><code># \u751f\u6210\u7ebf\u6027\u56e0\u679c\u6570\u636e\nn_samples = 1000\nX1 = np.random.normal(0, 1, n_samples)\nX2 = 0.8 * X1 + np.random.normal(0, 0.5, n_samples)\nX3 = 0.6 * X2 + np.random.normal(0, 0.3, n_samples)\n\ndata = np.column_stack([X1, X2, X3])\n</code></pre><p></p> <p>\u8bad\u7ec3\u8fc7\u7a0b: </p>Python<pre><code># \u8bad\u7ec3DAG-GNN\nmodel = train_dag_gnn(data, hidden_dim=32, num_layers=2, \n                     lambda1=0.1, lambda2=0.01, lr=0.001)\n\n# \u83b7\u53d6\u5b66\u4e60\u5230\u7684\u90bb\u63a5\u77e9\u9635\nW_learned = model.W.detach().numpy()\nprint(\"Learned adjacency matrix:\")\nprint(W_learned)\n</code></pre><p></p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_16","title":"\u975e\u7ebf\u6027\u7ed3\u6784\u5b66\u4e60","text":"<p>\u771f\u5b9e\u7ed3\u6784: \\(X_1 \\rightarrow X_2 \\rightarrow X_3\\)\uff0c\u5176\u4e2d\u5173\u7cfb\u4e3a\u975e\u7ebf\u6027</p> <p>\u6570\u636e\u751f\u6210: </p>Python<pre><code># \u751f\u6210\u975e\u7ebf\u6027\u56e0\u679c\u6570\u636e\nX1 = np.random.normal(0, 1, n_samples)\nX2 = np.sin(X1) + np.random.normal(0, 0.3, n_samples)\nX3 = X2**2 + np.random.normal(0, 0.2, n_samples)\n\ndata = np.column_stack([X1, X2, X3])\n</code></pre><p></p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_17","title":"\u5b9e\u9645\u5e94\u7528\u573a\u666f","text":"<ol> <li>\u57fa\u56e0\u8c03\u63a7\u7f51\u7edc: \u53d1\u73b0\u57fa\u56e0\u95f4\u7684\u975e\u7ebf\u6027\u8c03\u63a7\u5173\u7cfb</li> <li>\u91d1\u878d\u98ce\u9669\u4f20\u5bfc: \u8bc6\u522b\u91d1\u878d\u98ce\u9669\u5728\u5e02\u573a\u4e2d\u7684\u4f20\u5bfc\u8def\u5f84</li> <li>\u533b\u7597\u8bca\u65ad: \u5206\u6790\u75be\u75c5\u75c7\u72b6\u95f4\u7684\u56e0\u679c\u5173\u7cfb</li> <li>\u793e\u4ea4\u7f51\u7edc: \u7814\u7a76\u793e\u4ea4\u5f71\u54cd\u548c\u4fe1\u606f\u4f20\u64ad\u673a\u5236</li> </ol>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_18","title":"\u7b97\u6cd5\u4f18\u7f3a\u70b9","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_19","title":"\u4f18\u70b9","text":"<ul> <li>\u80fd\u591f\u5904\u7406\u975e\u7ebf\u6027\u5173\u7cfb</li> <li>\u7aef\u5230\u7aef\u5b66\u4e60\uff0c\u4e0d\u9700\u8981\u9884\u5148\u6307\u5b9a\u51fd\u6570\u5f62\u5f0f</li> <li>\u53ef\u6269\u5c55\u5230\u5927\u89c4\u6a21\u95ee\u9898</li> <li>\u80fd\u591f\u5904\u7406\u9ad8\u7ef4\u6570\u636e</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_20","title":"\u7f3a\u70b9","text":"<ul> <li>\u8ba1\u7b97\u590d\u6742\u5ea6\u8f83\u9ad8\uff0c\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f</li> <li>\u9700\u8981\u8c03\u6574\u591a\u4e2a\u8d85\u53c2\u6570</li> <li>\u53ef\u80fd\u9677\u5165\u5c40\u90e8\u6700\u4f18\u89e3</li> <li>\u5bf9\u521d\u59cb\u503c\u654f\u611f</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_21","title":"\u6539\u8fdb\u53d8\u4f53","text":"<ol> <li>NOTEARS: \u4f7f\u7528\u8fde\u7eed\u4f18\u5316\u7684\u65b9\u6cd5</li> <li>GraN-DAG: \u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u68af\u5ea6\u4e0b\u964d</li> <li>DAGs with NO TEARS: \u6539\u8fdb\u7684DAG\u7ea6\u675f\u5904\u7406\u65b9\u6cd5</li> <li>CAM pruning: \u7ed3\u5408\u526a\u679d\u6280\u672f\u63d0\u9ad8\u6548\u7387</li> </ol>"},{"location":"notes/Research/CausalDiscovery/Algorithms/DAG-GNN/#_22","title":"\u53c2\u8003\u8d44\u6e90","text":"<ul> <li>Zheng, X., Aragam, B., Ravikumar, P., &amp; Xing, E. P. (2018). DAGs with NO TEARS: Continuous Optimization for Structure Learning. NeurIPS.</li> <li>Yu, Y., Chen, J., Gao, T., &amp; Mo, S. (2019). DAG-GNN: DAG Structure Learning with Graph Neural Networks. ICLR.</li> <li>Bello, K., Aragam, B., &amp; Ravikumar, P. (2022). GraN-DAG: A Continuous Optimization Approach for Learning DAGs from Data. AISTATS.</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/","title":"MissNODAG","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#missnodag-missing-value-noisy-dag-discovery","title":"MissNODAG: Missing Value Noisy DAG Discovery","text":"<p> \u7ea6 1017 \u4e2a\u5b57  358 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 10 \u5206\u949f</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_1","title":"\u6982\u8ff0","text":"<p>MissNODAG\u662f\u4e00\u79cd\u80fd\u591f\u5904\u7406\u7f3a\u5931\u503c\u548c\u566a\u58f0\u7684\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u7ed3\u5408\u4e86\u77e9\u9635\u5206\u89e3\u6280\u672f\u548c\u56e0\u679c\u7ed3\u6784\u5b66\u4e60\uff0c\u80fd\u591f\u5728\u6570\u636e\u5b58\u5728\u7f3a\u5931\u503c\u548c\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\u4f30\u8ba1\u56e0\u679c\u56fe\u7ed3\u6784\u3002</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_2","title":"\u6570\u5b66\u539f\u7406","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_3","title":"\u57fa\u7840\u6982\u5ff5","text":"<p>\u7f3a\u5931\u503c\u673a\u5236: \u6570\u636e\u7f3a\u5931\u53ef\u5206\u4e3a\u4e09\u79cd\u7c7b\u578b\uff1a - MCAR (Missing Completely At Random): \u7f3a\u5931\u5b8c\u5168\u968f\u673a - MAR (Missing At Random): \u7f3a\u5931\u968f\u673a\uff0c\u4f9d\u8d56\u4e8e\u89c2\u6d4b\u6570\u636e - MNAR (Missing Not At Random): \u7f3a\u5931\u975e\u968f\u673a\uff0c\u4f9d\u8d56\u4e8e\u7f3a\u5931\u503c\u672c\u8eab</p> <p>\u566a\u58f0\u6a21\u578b: \u5047\u8bbe\u89c2\u6d4b\u6570\u636e\\(X\\)\u5305\u542b\u771f\u5b9e\u4fe1\u53f7\\(S\\)\u548c\u566a\u58f0\\(\\epsilon\\)\uff1a \\(\\(X = S + \\epsilon\\)\\)</p> <p>\u5176\u4e2d\\(\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I)\\)\u3002</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_4","title":"\u77e9\u9635\u5206\u89e3\u6846\u67b6","text":"<p>MissNODAG\u4f7f\u7528\u77e9\u9635\u5206\u89e3\u6765\u5904\u7406\u7f3a\u5931\u503c\uff1a</p> <p>\u4f4e\u79e9\u5047\u8bbe: \u771f\u5b9e\u6570\u636e\u77e9\u9635\\(S\\)\u5177\u6709\u4f4e\u79e9\u7ed3\u6784\uff1a \\(\\(S = UV^T\\)\\)</p> <p>\u5176\u4e2d\\(U \\in \\mathbb{R}^{n \\times r}\\)\uff0c\\(V \\in \\mathbb{R}^{d \\times r}\\)\uff0c\\(r \\ll \\min(n,d)\\)\u3002</p> <p>\u56e0\u679c\u7ed3\u6784\u7ea6\u675f: \u56e0\u679c\u56fe\u7684\u90bb\u63a5\u77e9\u9635\\(W\\)\u6ee1\u8db3\uff1a - \u65e0\u73af\u6027: \\(W\\)\u5bf9\u5e94\u7684\u56fe\u662f\u6709\u5411\u65e0\u73af\u56fe - \u7a00\u758f\u6027: \\(W\\)\u4e2d\u975e\u96f6\u5143\u7d20\u5f88\u5c11</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_5","title":"\u76ee\u6807\u51fd\u6570","text":"<p>MissNODAG\u7684\u76ee\u6807\u51fd\u6570\u5305\u542b\u56db\u4e2a\u90e8\u5206\uff1a</p> <ol> <li>\u91cd\u6784\u635f\u5931: \\(\\(\\mathcal{L}_{recon} = \\frac{1}{|\\Omega|}\\sum_{(i,j) \\in \\Omega} (X_{ij} - [UV^T]_{ij})^2\\)\\)</li> </ol> <p>\u5176\u4e2d\\(\\Omega\\)\u662f\u89c2\u6d4b\u503c\u7684\u7d22\u5f15\u96c6\u5408\u3002</p> <ol> <li> <p>\u56e0\u679c\u7ed3\u6784\u635f\u5931: \\(\\(\\mathcal{L}_{causal} = \\frac{1}{n}\\|X - XW\\|_F^2\\)\\)</p> </li> <li> <p>DAG\u7ea6\u675f: \\(\\(\\mathcal{L}_{dag} = \\text{tr}(e^{W \\circ W}) - d\\)\\)</p> </li> <li> <p>\u6b63\u5219\u5316\u9879: \\(\\(\\mathcal{L}_{reg} = \\lambda_1 \\|W\\|_1 + \\lambda_2 (\\|U\\|_F^2 + \\|V\\|_F^2)\\)\\)</p> </li> </ol> <p>\u603b\u76ee\u6807\u51fd\u6570: \\(\\(\\mathcal{L} = \\mathcal{L}_{recon} + \\alpha \\mathcal{L}_{causal} + \\beta \\mathcal{L}_{dag} + \\mathcal{L}_{reg}\\)\\)</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#em","title":"\u671f\u671b\u6700\u5927\u5316(EM)\u6846\u67b6","text":"<p>MissNODAG\u4f7f\u7528EM\u7b97\u6cd5\u6765\u5904\u7406\u7f3a\u5931\u503c\uff1a</p> <p>E\u6b65: \u7ed9\u5b9a\u5f53\u524d\u53c2\u6570\u4f30\u8ba1\uff0c\u8ba1\u7b97\u7f3a\u5931\u503c\u7684\u671f\u671b\uff1a \\(\\(\\hat{X}_{ij}^{(t)} = \\mathbb{E}[X_{ij} | X_{\\Omega}, \\theta^{(t)}]\\)\\)</p> <p>M\u6b65: \u66f4\u65b0\u53c2\u6570\u4ee5\u6700\u5927\u5316\u671f\u671b\u5bf9\u6570\u4f3c\u7136\uff1a \\(\\(\\theta^{(t+1)} = \\arg\\max_{\\theta} \\mathbb{E}[\\log P(X, Z | \\theta) | X_{\\Omega}, \\theta^{(t)}]\\)\\)</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_6","title":"\u7b97\u6cd5\u6d41\u7a0b","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_7","title":"\u8f93\u5165","text":"<ul> <li>\u90e8\u5206\u89c2\u6d4b\u6570\u636e\u77e9\u9635 \\(X \\in \\mathbb{R}^{n \\times d}\\)\uff08\u5305\u542b\u7f3a\u5931\u503c\uff09</li> <li>\u79e9\u53c2\u6570 \\(r\\)</li> <li>\u6b63\u5219\u5316\u53c2\u6570 \\(\\alpha, \\beta, \\lambda_1, \\lambda_2\\)</li> <li>\u6700\u5927\u8fed\u4ee3\u6b21\u6570 \\(T\\)</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_8","title":"\u521d\u59cb\u5316","text":"<ul> <li>\u4f7f\u7528\u77e9\u9635\u5206\u89e3\u521d\u59cb\u5316 \\(U^{(0)}, V^{(0)}\\)</li> <li>\u968f\u673a\u521d\u59cb\u5316\u90bb\u63a5\u77e9\u9635 \\(W^{(0)}\\)</li> <li>\u8bbe\u7f6e \\(t = 0\\)</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#em_1","title":"EM\u8fed\u4ee3","text":"Python<pre><code>for t in range(max_iterations):\n    # E\u6b65: \u586b\u5145\u7f3a\u5931\u503c\n    X_filled = fill_missing_values(X, U, V)\n\n    # M\u6b65: \u66f4\u65b0\u53c2\u6570\n    # 1. \u66f4\u65b0\u77e9\u9635\u5206\u89e3\u53c2\u6570\n    U, V = update_matrix_factorization(X_filled, W, r)\n\n    # 2. \u66f4\u65b0\u56e0\u679c\u7ed3\u6784\n    W = update_causal_structure(X_filled, U, V)\n\n    # \u68c0\u67e5\u6536\u655b\n    if converged(U, V, W, U_prev, V_prev, W_prev):\n        break\n\n    t += 1\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_9","title":"\u77e9\u9635\u5206\u89e3\u66f4\u65b0","text":"Python<pre><code>def update_matrix_factorization(X, W, r, lambda2):\n    \"\"\"\u66f4\u65b0\u77e9\u9635\u5206\u89e3\u53c2\u6570\"\"\"\n    n, d = X.shape\n\n    # \u56fa\u5b9aV\uff0c\u66f4\u65b0U\n    for i in range(n):\n        observed_indices = np.where(~np.isnan(X[i, :]))[0]\n        if len(observed_indices) &gt; 0:\n            V_obs = V[observed_indices, :]\n            X_obs = X[i, observed_indices]\n\n            # \u6700\u5c0f\u4e8c\u4e58\u89e3\n            U[i, :] = np.linalg.solve(V_obs.T @ V_obs + lambda2 * np.eye(r), \n                                    V_obs.T @ X_obs)\n\n    # \u56fa\u5b9aU\uff0c\u66f4\u65b0V\n    for j in range(d):\n        observed_indices = np.where(~np.isnan(X[:, j]))[0]\n        if len(observed_indices) &gt; 0:\n            U_obs = U[observed_indices, :]\n            X_obs = X[observed_indices, j]\n\n            # \u8003\u8651\u56e0\u679c\u7ed3\u6784\n            causal_term = U_obs.T @ U_obs @ W[j, :]\n            V[j, :] = np.linalg.solve(U_obs.T @ U_obs + lambda2 * np.eye(r), \n                                    U_obs.T @ X_obs + causal_term)\n\n    return U, V\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_10","title":"\u56e0\u679c\u7ed3\u6784\u66f4\u65b0","text":"Python<pre><code>def update_causal_structure(X, U, V, alpha, beta, lambda1):\n    \"\"\"\u66f4\u65b0\u56e0\u679c\u7ed3\u6784\"\"\"\n    n, d = X.shape\n\n    # \u8ba1\u7b97\u68af\u5ea6\n    grad_recon = compute_reconstruction_gradient(X, U, V)\n    grad_causal = compute_causal_gradient(X, U, V, W)\n    grad_dag = compute_dag_gradient(W)\n    grad_sparse = lambda1 * np.sign(W)\n\n    # \u603b\u68af\u5ea6\n    total_grad = grad_recon + alpha * grad_causal + beta * grad_dag + grad_sparse\n\n    # \u68af\u5ea6\u4e0b\u964d\u66f4\u65b0\n    learning_rate = 0.01\n    W_new = W - learning_rate * total_grad\n\n    # \u6295\u5f71\u5230DAG\u7a7a\u95f4\n    W_new = project_to_dag(W_new)\n\n    return W_new\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_11","title":"\u8f93\u51fa","text":"<ul> <li>\u5b66\u4e60\u5230\u7684\u77e9\u9635\u5206\u89e3\u53c2\u6570 \\(U^*, V^*\\)</li> <li>\u4f30\u8ba1\u7684\u90bb\u63a5\u77e9\u9635 \\(W^*\\)</li> <li>\u586b\u5145\u540e\u7684\u6570\u636e\u77e9\u9635 \\(\\hat{X}^*\\)</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_12","title":"\u4f7f\u7528\u65b9\u6cd5","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#python","title":"Python\u5b9e\u73b0\u793a\u4f8b","text":"Python<pre><code>import numpy as np\nfrom scipy.linalg import expm\nfrom sklearn.decomposition import NMF\nimport torch\n\nclass MissNODAG:\n    def __init__(self, rank=10, alpha=0.1, beta=0.1, \n                 lambda1=0.01, lambda2=0.01, max_iter=100):\n        self.rank = rank\n        self.alpha = alpha\n        self.beta = beta\n        self.lambda1 = lambda1\n        self.lambda2 = lambda2\n        self.max_iter = max_iter\n\n    def fit(self, X):\n        \"\"\"\n        \u62df\u5408MissNODAG\u6a21\u578b\n        \"\"\"\n        n, d = X.shape\n\n        # \u521d\u59cb\u5316\n        self.U = np.random.randn(n, self.rank)\n        self.V = np.random.randn(d, self.rank)\n        self.W = np.random.randn(d, d)\n\n        # \u8bb0\u5f55\u7f3a\u5931\u503c\u4f4d\u7f6e\n        self.missing_mask = np.isnan(X)\n        self.X_filled = X.copy()\n\n        for iteration in range(self.max_iter):\n            # E\u6b65: \u586b\u5145\u7f3a\u5931\u503c\n            self._e_step()\n\n            # M\u6b65: \u66f4\u65b0\u53c2\u6570\n            self._m_step()\n\n            # \u6253\u5370\u8fdb\u5ea6\n            if iteration % 10 == 0:\n                loss = self._compute_loss()\n                print(f\"Iteration {iteration}, Loss: {loss:.4f}\")\n\n        return self\n\n    def _e_step(self):\n        \"\"\"E\u6b65: \u586b\u5145\u7f3a\u5931\u503c\"\"\"\n        X_pred = self.U @ self.V.T\n\n        # \u53ea\u586b\u5145\u7f3a\u5931\u503c\n        self.X_filled[self.missing_mask] = X_pred[self.missing_mask]\n\n    def _m_step(self):\n        \"\"\"M\u6b65: \u66f4\u65b0\u53c2\u6570\"\"\"\n        # \u66f4\u65b0U\n        self._update_U()\n\n        # \u66f4\u65b0V\n        self._update_V()\n\n        # \u66f4\u65b0W\n        self._update_W()\n\n    def _update_U(self):\n        \"\"\"\u66f4\u65b0\u77e9\u9635U\"\"\"\n        n, d = self.X_filled.shape\n\n        for i in range(n):\n            observed_j = np.where(~self.missing_mask[i, :])[0]\n            if len(observed_j) &gt; 0:\n                V_obs = self.V[observed_j, :]\n                X_obs = self.X_filled[i, observed_j]\n\n                # \u6700\u5c0f\u4e8c\u4e58\u89e3\n                A = V_obs.T @ V_obs + self.lambda2 * np.eye(self.rank)\n                b = V_obs.T @ X_obs\n                self.U[i, :] = np.linalg.solve(A, b)\n\n    def _update_V(self):\n        \"\"\"\u66f4\u65b0\u77e9\u9635V\"\"\"\n        n, d = self.X_filled.shape\n\n        for j in range(d):\n            observed_i = np.where(~self.missing_mask[:, j])[0]\n            if len(observed_i) &gt; 0:\n                U_obs = self.U[observed_i, :]\n                X_obs = self.X_filled[observed_i, j]\n\n                # \u8003\u8651\u56e0\u679c\u7ed3\u6784\n                causal_term = U_obs.T @ U_obs @ self.W[j, :]\n\n                A = U_obs.T @ U_obs + self.lambda2 * np.eye(self.rank)\n                b = U_obs.T @ X_obs + causal_term\n                self.V[j, :] = np.linalg.solve(A, b)\n\n    def _update_W(self):\n        \"\"\"\u66f4\u65b0\u56e0\u679c\u7ed3\u6784W\"\"\"\n        # \u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\n        learning_rate = 0.01\n\n        # \u8ba1\u7b97\u68af\u5ea6\n        grad_causal = self._compute_causal_gradient()\n        grad_dag = self._compute_dag_gradient()\n        grad_sparse = self.lambda1 * np.sign(self.W)\n\n        # \u603b\u68af\u5ea6\n        total_grad = self.alpha * grad_causal + self.beta * grad_dag + grad_sparse\n\n        # \u66f4\u65b0\n        self.W -= learning_rate * total_grad\n\n        # \u6295\u5f71\u5230DAG\u7a7a\u95f4\n        self.W = self._project_to_dag(self.W)\n\n    def _compute_causal_gradient(self):\n        \"\"\"\u8ba1\u7b97\u56e0\u679c\u7ed3\u6784\u68af\u5ea6\"\"\"\n        X_pred = self.U @ self.V.T\n        residual = self.X_filled - X_pred\n        grad = -2 * self.X_filled.T @ residual / self.X_filled.shape[0]\n        return grad\n\n    def _compute_dag_gradient(self):\n        \"\"\"\u8ba1\u7b97DAG\u7ea6\u675f\u68af\u5ea6\"\"\"\n        W_sq = self.W * self.W\n        exp_W = expm(W_sq)\n        grad = 2 * self.W * exp_W\n        return grad\n\n    def _project_to_dag(self, W, threshold=1e-3):\n        \"\"\"\u6295\u5f71\u5230DAG\u7a7a\u95f4\"\"\"\n        # \u4f7f\u7528\u9608\u503c\u5316\u786e\u4fdd\u7a00\u758f\u6027\n        W[np.abs(W) &lt; threshold] = 0\n\n        # \u7b80\u5355\u7684DAG\u6295\u5f71\uff08\u5b9e\u9645\u53ef\u80fd\u9700\u8981\u66f4\u590d\u6742\u7684\u65b9\u6cd5\uff09\n        # \u8fd9\u91cc\u4f7f\u7528\u8d2a\u5fc3\u7b97\u6cd5\u53bb\u9664\u73af\n        return self._remove_cycles(W)\n\n    def _remove_cycles(self, W):\n        \"\"\"\u53bb\u9664\u56fe\u4e2d\u7684\u73af\"\"\"\n        # \u7b80\u5355\u5b9e\u73b0\uff1a\u6309\u6743\u91cd\u6392\u5e8f\u8fb9\uff0c\u8d2a\u5fc3\u53bb\u9664\u5f62\u6210\u73af\u7684\u8fb9\n        n = W.shape[0]\n        edges = []\n        for i in range(n):\n            for j in range(n):\n                if W[i, j] != 0:\n                    edges.append((i, j, abs(W[i, j])))\n\n        # \u6309\u6743\u91cd\u964d\u5e8f\u6392\u5e8f\n        edges.sort(key=lambda x: x[2], reverse=True)\n\n        # \u8d2a\u5fc3\u6dfb\u52a0\u8fb9\uff0c\u68c0\u67e5\u662f\u5426\u5f62\u6210\u73af\n        result_W = np.zeros_like(W)\n        for i, j, weight in edges:\n            result_W[i, j] = W[i, j]\n            if self._has_cycle(result_W):\n                result_W[i, j] = 0\n\n        return result_W\n\n    def _has_cycle(self, W):\n        \"\"\"\u68c0\u67e5\u56fe\u4e2d\u662f\u5426\u6709\u73af\"\"\"\n        n = W.shape[0]\n        visited = [False] * n\n        rec_stack = [False] * n\n\n        def dfs(node):\n            visited[node] = True\n            rec_stack[node] = True\n\n            for neighbor in range(n):\n                if W[node, neighbor] != 0:\n                    if not visited[neighbor]:\n                        if dfs(neighbor):\n                            return True\n                    elif rec_stack[neighbor]:\n                        return True\n\n            rec_stack[node] = False\n            return False\n\n        for i in range(n):\n            if not visited[i]:\n                if dfs(i):\n                    return True\n        return False\n\n    def _compute_loss(self):\n        \"\"\"\u8ba1\u7b97\u603b\u635f\u5931\"\"\"\n        # \u91cd\u6784\u635f\u5931\n        X_pred = self.U @ self.V.T\n        observed_mask = ~self.missing_mask\n        recon_loss = np.mean((self.X_filled[observed_mask] - X_pred[observed_mask])**2)\n\n        # \u56e0\u679c\u635f\u5931\n        causal_loss = np.mean((self.X_filled - self.X_filled @ self.W)**2)\n\n        # DAG\u635f\u5931\n        dag_loss = np.trace(expm(self.W * self.W)) - self.W.shape[0]\n\n        # \u6b63\u5219\u5316\u635f\u5931\n        reg_loss = self.lambda1 * np.sum(np.abs(self.W)) + \\\n                  self.lambda2 * (np.sum(self.U**2) + np.sum(self.V**2))\n\n        total_loss = recon_loss + self.alpha * causal_loss + \\\n                    self.beta * dag_loss + reg_loss\n\n        return total_loss\n\n# \u4f7f\u7528\u793a\u4f8b\ndef example_usage():\n    # \u751f\u6210\u5e26\u6709\u7f3a\u5931\u503c\u7684\u56e0\u679c\u6570\u636e\n    np.random.seed(42)\n    n_samples = 100\n    n_vars = 5\n\n    # \u771f\u5b9e\u56e0\u679c\u7ed3\u6784\n    true_W = np.array([\n        [0, 0.8, 0, 0, 0],\n        [0, 0, 0.6, 0, 0],\n        [0, 0, 0, 0.7, 0],\n        [0, 0, 0, 0, 0.5],\n        [0, 0, 0, 0, 0]\n    ])\n\n    # \u751f\u6210\u6570\u636e\n    X = np.random.randn(n_samples, n_vars)\n    for i in range(1, n_vars):\n        X[:, i] += 0.5 * X[:, i-1]\n\n    # \u6dfb\u52a0\u566a\u58f0\n    X += 0.1 * np.random.randn(n_samples, n_vars)\n\n    # \u968f\u673a\u7f3a\u593130%\u7684\u503c\n    missing_mask = np.random.rand(n_samples, n_vars) &lt; 0.3\n    X_missing = X.copy()\n    X_missing[missing_mask] = np.nan\n\n    # \u8bad\u7ec3MissNODAG\n    model = MissNODAG(rank=5, alpha=0.1, beta=0.1, \n                     lambda1=0.01, lambda2=0.01, max_iter=50)\n    model.fit(X_missing)\n\n    print(\"True adjacency matrix:\")\n    print(true_W)\n    print(\"Learned adjacency matrix:\")\n    print(model.W)\n\n    return model\n\nif __name__ == \"__main__\":\n    model = example_usage()\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_13","title":"\u53c2\u6570\u9009\u62e9","text":"<ol> <li> <p>\u77e9\u9635\u5206\u89e3\u53c2\u6570:    - <code>rank</code>: \u79e9\u53c2\u6570\uff0c\u901a\u5e38\u5c0f\u4e8e\u53d8\u91cf\u6570\u91cf    - <code>lambda2</code>: \u77e9\u9635\u5206\u89e3\u6b63\u5219\u5316\u5f3a\u5ea6</p> </li> <li> <p>\u56e0\u679c\u7ed3\u6784\u53c2\u6570:    - <code>alpha</code>: \u56e0\u679c\u635f\u5931\u6743\u91cd    - <code>beta</code>: DAG\u7ea6\u675f\u6743\u91cd    - <code>lambda1</code>: \u7a00\u758f\u6027\u6b63\u5219\u5316\u5f3a\u5ea6</p> </li> <li> <p>\u4f18\u5316\u53c2\u6570:    - <code>max_iter</code>: \u6700\u5927\u8fed\u4ee3\u6b21\u6570    - <code>learning_rate</code>: \u5b66\u4e60\u7387</p> </li> </ol>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_14","title":"\u5e94\u7528\u793a\u4f8b","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_15","title":"\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u5206\u6790","text":"<p>\u573a\u666f: \u57fa\u56e0\u8868\u8fbe\u6570\u636e\u901a\u5e38\u5b58\u5728\u5927\u91cf\u7f3a\u5931\u503c\uff0c\u9700\u8981\u540c\u65f6\u5904\u7406\u7f3a\u5931\u503c\u548c\u53d1\u73b0\u57fa\u56e0\u8c03\u63a7\u5173\u7cfb\u3002</p> Python<pre><code># \u6a21\u62df\u57fa\u56e0\u8868\u8fbe\u6570\u636e\nn_genes = 10\nn_samples = 200\n\n# \u521b\u5efa\u57fa\u56e0\u8c03\u63a7\u7f51\u7edc\nadj_matrix = create_gene_regulatory_network(n_genes)\n\n# \u751f\u6210\u57fa\u56e0\u8868\u8fbe\u6570\u636e\nexpression_data = simulate_gene_expression(adj_matrix, n_samples)\n\n# \u6dfb\u52a0\u7f3a\u5931\u503c\nmissing_rate = 0.2\nexpression_missing = add_missing_values(expression_data, missing_rate)\n\n# \u5e94\u7528MissNODAG\nmodel = MissNODAG(rank=8, alpha=0.1, beta=0.1, \n                 lambda1=0.01, lambda2=0.01)\nmodel.fit(expression_missing)\n\n# \u5206\u6790\u7ed3\u679c\nlearned_network = model.W\nprint(\"Learned gene regulatory network:\")\nprint(learned_network)\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_16","title":"\u533b\u7597\u6570\u636e\u5206\u6790","text":"<p>\u573a\u666f: \u7535\u5b50\u75c5\u5386\u6570\u636e\u901a\u5e38\u5b58\u5728\u7f3a\u5931\u503c\uff0c\u9700\u8981\u53d1\u73b0\u75be\u75c5\u98ce\u9669\u56e0\u7d20\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u3002</p> Python<pre><code># \u6a21\u62df\u533b\u7597\u6570\u636e\nn_patients = 1000\nn_features = 15  # \u5305\u62ec\u5404\u79cd\u751f\u7406\u6307\u6807\n\n# \u521b\u5efa\u75be\u75c5\u98ce\u9669\u56e0\u7d20\u7f51\u7edc\nrisk_network = create_risk_factor_network(n_features)\n\n# \u751f\u6210\u60a3\u8005\u6570\u636e\npatient_data = simulate_patient_data(risk_network, n_patients)\n\n# \u6dfb\u52a0\u7f3a\u5931\u503c\uff08\u6a21\u62df\u5b9e\u9645\u533b\u7597\u8bb0\u5f55\uff09\npatient_missing = add_realistic_missing(patient_data)\n\n# \u5e94\u7528MissNODAG\nmodel = MissNODAG(rank=12, alpha=0.15, beta=0.08, \n                 lambda1=0.005, lambda2=0.02)\nmodel.fit(patient_missing)\n\n# \u5206\u6790\u56e0\u679c\u7ed3\u6784\ncausal_structure = model.W\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_17","title":"\u5b9e\u9645\u5e94\u7528\u573a\u666f","text":"<ol> <li>\u751f\u7269\u4fe1\u606f\u5b66: \u57fa\u56e0\u8868\u8fbe\u6570\u636e\u5206\u6790\uff0c\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u7f51\u7edc</li> <li>\u533b\u7597\u5065\u5eb7: \u7535\u5b50\u75c5\u5386\u5206\u6790\uff0c\u75be\u75c5\u98ce\u9669\u56e0\u7d20\u7814\u7a76</li> <li>\u793e\u4f1a\u79d1\u5b66: \u8c03\u67e5\u6570\u636e\u5206\u6790\uff0c\u793e\u4f1a\u7f51\u7edc\u7814\u7a76</li> <li>\u91d1\u878d: \u98ce\u9669\u8bc4\u4f30\uff0c\u6295\u8d44\u7ec4\u5408\u5206\u6790</li> </ol>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_18","title":"\u7b97\u6cd5\u4f18\u7f3a\u70b9","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_19","title":"\u4f18\u70b9","text":"<ul> <li>\u80fd\u591f\u5904\u7406\u7f3a\u5931\u503c\uff0c\u4e0d\u9700\u8981\u9884\u5148\u586b\u5145</li> <li>\u540c\u65f6\u8fdb\u884c\u6570\u636e\u586b\u5145\u548c\u56e0\u679c\u53d1\u73b0</li> <li>\u5bf9\u566a\u58f0\u5177\u6709\u9c81\u68d2\u6027</li> <li>\u53ef\u4ee5\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_20","title":"\u7f3a\u70b9","text":"<ul> <li>\u8ba1\u7b97\u590d\u6742\u5ea6\u8f83\u9ad8</li> <li>\u9700\u8981\u8c03\u6574\u591a\u4e2a\u8d85\u53c2\u6570</li> <li>\u77e9\u9635\u5206\u89e3\u7684\u79e9\u9009\u62e9\u5f71\u54cd\u7ed3\u679c</li> <li>EM\u7b97\u6cd5\u53ef\u80fd\u6536\u655b\u5230\u5c40\u90e8\u6700\u4f18</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_21","title":"\u6539\u8fdb\u53d8\u4f53","text":"<ol> <li>Robust MissNODAG: \u589e\u5f3a\u5bf9\u5f02\u5e38\u503c\u7684\u9c81\u68d2\u6027</li> <li>Online MissNODAG: \u652f\u6301\u5728\u7ebf\u5b66\u4e60</li> <li>Deep MissNODAG: \u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b</li> <li>Multi-view MissNODAG: \u5904\u7406\u591a\u89c6\u89d2\u6570\u636e</li> </ol>"},{"location":"notes/Research/CausalDiscovery/Algorithms/MissNODAG/#_22","title":"\u53c2\u8003\u8d44\u6e90","text":"<ul> <li>Liu, Y., et al. (2022). MissNODAG: Missing Value Noisy DAG Discovery. ICML.</li> <li>Rubinstein, B. I., et al. (2021). Causal Discovery from Missing Data. UAI.</li> <li>Mohan, K., &amp; Pearl, J. (2021). Graphical Models for Processing Missing Data. JMLR.</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/","title":"NOTEARS","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#notears-nonlinear-structural-equations-with-alternative-regularization-and-sparsity","title":"NOTEARS: Nonlinear Structural Equations with Alternative Regularization and Sparsity","text":"<p> \u7ea6 977 \u4e2a\u5b57  312 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 9 \u5206\u949f</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_1","title":"\u6982\u8ff0","text":"<p>NOTEARS\u662f\u4e00\u79cd\u57fa\u4e8e\u8fde\u7eed\u4f18\u5316\u7684\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\uff0c\u7531Zheng et al.\u57282018\u5e74\u63d0\u51fa\u3002\u8be5\u7b97\u6cd5\u5c06\u56e0\u679c\u53d1\u73b0\u95ee\u9898\u8f6c\u5316\u4e3a\u8fde\u7eed\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165DAG\u7ea6\u675f\u6765\u5b66\u4e60\u6709\u5411\u65e0\u73af\u56fe\u7ed3\u6784\u3002</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_2","title":"\u6570\u5b66\u539f\u7406","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_3","title":"\u57fa\u7840\u6982\u5ff5","text":"<p>\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b(SEM): \u5047\u8bbe\u6bcf\u4e2a\u53d8\u91cf\u53ef\u4ee5\u8868\u793a\u4e3a\u5176\u7236\u8282\u70b9\u7684\u51fd\u6570\u52a0\u4e0a\u566a\u58f0\uff1a \\(\\(X_j = f_j(X_{pa(j)}) + \\epsilon_j\\)\\)</p> <p>\u5176\u4e2d\\(\\epsilon_j\\)\u662f\u72ec\u7acb\u566a\u58f0\u9879\uff0c\\(pa(j)\\)\u662f\u8282\u70b9\\(j\\)\u7684\u7236\u8282\u70b9\u96c6\u5408\u3002</p> <p>\u90bb\u63a5\u77e9\u9635: \\(W \\in \\mathbb{R}^{d \\times d}\\)\u8868\u793a\u56fe\u7ed3\u6784\uff0c\\(W_{ij} \\neq 0\\)\u8868\u793a\u5b58\u5728\u4ece\u8282\u70b9\\(i\\)\u5230\u8282\u70b9\\(j\\)\u7684\u6709\u5411\u8fb9\u3002</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#dag","title":"DAG\u7ea6\u675f","text":"<p>NOTEARS\u7684\u6838\u5fc3\u521b\u65b0\u5728\u4e8e\u5c06DAG\u7ea6\u675f\u8f6c\u5316\u4e3a\u8fde\u7eed\u53ef\u5fae\u7684\u7ea6\u675f\uff1a</p> <p>\u77e9\u9635\u6307\u6570\u7ea6\u675f: \u77e9\u9635\\(W\\)\u8868\u793a\u6709\u5411\u65e0\u73af\u56fe\u5f53\u4e14\u4ec5\u5f53\uff1a \\(\\(\\text{tr}(e^{W \\circ W}) = d\\)\\)</p> <p>\u5176\u4e2d\\(\\circ\\)\u8868\u793aHadamard\u79ef\uff08\u9010\u5143\u7d20\u4e58\u6cd5\uff09\uff0c\\(e^A\\)\u662f\u77e9\u9635\u6307\u6570\u51fd\u6570\u3002</p> <p>\u77e9\u9635\u6307\u6570\u5c55\u5f00: \\(\\(e^A = \\sum_{k=0}^{\\infty} \\frac{A^k}{k!}\\)\\)</p> <p>\u5b9e\u9645\u8ba1\u7b97\u4e2d\u4f7f\u7528\u622a\u65ad\u8fd1\u4f3c\uff1a \\(\\(e^A \\approx \\sum_{k=0}^{K} \\frac{A^k}{k!}\\)\\)</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_4","title":"\u76ee\u6807\u51fd\u6570","text":"<p>NOTEARS\u7684\u76ee\u6807\u51fd\u6570\u5305\u542b\u4e09\u4e2a\u90e8\u5206\uff1a</p> <ol> <li> <p>\u91cd\u6784\u635f\u5931: \\(\\(\\mathcal{L}_{recon} = \\frac{1}{2n}\\sum_{i=1}^n \\|X_i - X_i W\\|_2^2\\)\\)</p> </li> <li> <p>DAG\u7ea6\u675f: \\(\\(h(W) = \\text{tr}(e^{W \\circ W}) - d\\)\\)</p> </li> <li> <p>\u7a00\u758f\u6027\u7ea6\u675f: \\(\\(\\mathcal{L}_{sparse} = \\lambda \\|W\\|_1\\)\\)</p> </li> </ol> <p>\u603b\u76ee\u6807\u51fd\u6570: \\(\\(\\min_W \\mathcal{L}_{recon}(W) + \\lambda \\|W\\|_1\\)\\) \\(\\(\\text{s.t. } h(W) = 0\\)\\)</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_5","title":"\u975e\u7ebf\u6027\u6269\u5c55","text":"<p>NOTEARS\u53ef\u4ee5\u6269\u5c55\u5230\u975e\u7ebf\u6027\u60c5\u51b5\uff1a</p> <p>MLP\u7ed3\u6784\u65b9\u7a0b: \\(\\(X_j = f_j(X_{pa(j)}; \\theta_j) + \\epsilon_j\\)\\)</p> <p>\u5176\u4e2d\\(f_j\\)\u662f\u591a\u5c42\u611f\u77e5\u673a\uff0c\\(\\theta_j\\)\u662f\u5176\u53c2\u6570\u3002</p> <p>\u7b49\u4ef7\u8868\u793a: \u975e\u7ebf\u6027\u7ed3\u6784\u65b9\u7a0b\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \\(\\(X = f(X; \\theta) + \\epsilon\\)\\)</p> <p>\u5176\u4e2d\\(f\\)\u662f\u5411\u91cf\u503c\u51fd\u6570\u3002</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_6","title":"\u7b97\u6cd5\u6d41\u7a0b","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_7","title":"\u8f93\u5165","text":"<ul> <li>\u89c2\u6d4b\u6570\u636e\u77e9\u9635 \\(X \\in \\mathbb{R}^{n \\times d}\\)</li> <li>\u6b63\u5219\u5316\u53c2\u6570 \\(\\lambda\\)</li> <li>\u5b66\u4e60\u7387 \\(\\eta\\)</li> <li>\u6700\u5927\u8fed\u4ee3\u6b21\u6570 \\(T\\)</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_8","title":"\u521d\u59cb\u5316","text":"<ul> <li>\u968f\u673a\u521d\u59cb\u5316\u90bb\u63a5\u77e9\u9635 \\(W^{(0)}\\)</li> <li>\u8bbe\u7f6e \\(t = 0\\)</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_9","title":"\u8fde\u7eed\u4f18\u5316","text":"Python<pre><code>for t in range(max_iterations):\n    # \u8ba1\u7b97\u68af\u5ea6\n    grad_recon = compute_reconstruction_gradient(X, W)\n    grad_dag = compute_dag_gradient(W)\n    grad_sparse = lambda * np.sign(W)\n\n    # \u603b\u68af\u5ea6\n    total_grad = grad_recon + grad_sparse\n\n    # \u6295\u5f71\u68af\u5ea6\u4e0b\u964d\n    W_new = W - learning_rate * total_grad\n\n    # \u6295\u5f71\u5230DAG\u7a7a\u95f4\n    W_new = project_to_dag(W_new)\n\n    # \u68c0\u67e5\u6536\u655b\n    if converged(W, W_new):\n        break\n\n    W = W_new\n    t += 1\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_10","title":"\u6295\u5f71\u7b97\u6cd5","text":"<p>NOTEARS\u4f7f\u7528\u589e\u5e7f\u62c9\u683c\u6717\u65e5\u65b9\u6cd5\u5904\u7406\u7ea6\u675f\uff1a</p> <p>\u589e\u5e7f\u62c9\u683c\u6717\u65e5\u51fd\u6570: \\(\\(\\mathcal{L}_\\rho(W, \\alpha) = \\mathcal{L}_{recon}(W) + \\lambda \\|W\\|_1 + \\alpha h(W) + \\frac{\\rho}{2} h(W)^2\\)\\)</p> <p>\u66f4\u65b0\u89c4\u5219: 1. W\u66f4\u65b0:  \\(\\(W^{k+1} = \\arg\\min_W \\mathcal{L}_\\rho(W, \\alpha^k)\\)\\)</p> <ol> <li> <p>\u62c9\u683c\u6717\u65e5\u4e58\u5b50\u66f4\u65b0: \\(\\(\\alpha^{k+1} = \\alpha^k + \\rho h(W^{k+1})\\)\\)</p> </li> <li> <p>\u60e9\u7f5a\u53c2\u6570\u66f4\u65b0: \\(\\(\\rho^{k+1} = \\min(\\rho_{max}, \\gamma \\rho^k)\\)\\)</p> </li> </ol>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#notears","title":"\u975e\u7ebf\u6027NOTEARS\u6d41\u7a0b","text":"Python<pre><code>def nonlinear_notears(X, hidden_dims, lambda1=0.01, rho=1.0, alpha=0.0):\n    \"\"\"\n    \u975e\u7ebf\u6027NOTEARS\u7b97\u6cd5\n    \"\"\"\n    n, d = X.shape\n\n    # \u521d\u59cb\u5316MLP\u53c2\u6570\n    models = [MLP(d, hidden_dims, 1) for _ in range(d)]\n\n    # \u521d\u59cb\u5316\u90bb\u63a5\u77e9\u9635\n    W = np.zeros((d, d))\n\n    for iteration in range(max_iterations):\n        # \u524d\u5411\u4f20\u64ad\n        X_pred = forward_pass(X, models, W)\n\n        # \u8ba1\u7b97\u635f\u5931\n        loss_recon = reconstruction_loss(X, X_pred)\n        loss_dag = dag_constraint(W)\n        loss_sparse = lambda1 * np.sum(np.abs(W))\n\n        total_loss = loss_recon + alpha * loss_dag + 0.5 * rho * loss_dag**2 + loss_sparse\n\n        # \u53cd\u5411\u4f20\u64ad\n        total_loss.backward()\n\n        # \u66f4\u65b0\u53c2\u6570\n        update_parameters(models, W, learning_rate)\n\n        # \u66f4\u65b0\u62c9\u683c\u6717\u65e5\u4e58\u5b50\n        alpha += rho * loss_dag.item()\n\n        # \u66f4\u65b0\u60e9\u7f5a\u53c2\u6570\n        if iteration % update_freq == 0:\n            rho = min(rho * 1.1, rho_max)\n\n    return models, W\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_11","title":"\u4f7f\u7528\u65b9\u6cd5","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#pytorch","title":"PyTorch\u5b9e\u73b0\u793a\u4f8b","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom scipy.linalg import expm\n\nclass NOTEARS(nn.Module):\n    def __init__(self, input_dim, lambda1=0.01):\n        super(NOTEARS, self).__init__()\n        self.input_dim = input_dim\n        self.lambda1 = lambda1\n\n        # \u53ef\u5b66\u4e60\u7684\u90bb\u63a5\u77e9\u9635\n        self.W = nn.Parameter(torch.randn(input_dim, input_dim))\n\n    def forward(self, X):\n        # \u7ebf\u6027\u7ed3\u6784\u65b9\u7a0b: X = XW + noise\n        return X @ self.W\n\n    def dag_constraint(self):\n        \"\"\"\u8ba1\u7b97DAG\u7ea6\u675f\"\"\"\n        W = self.W\n        # \u4f7f\u7528\u77e9\u9635\u6307\u6570\n        exp_W = torch.matrix_exp(W * W)\n        return torch.trace(exp_W) - self.input_dim\n\n    def loss(self, X, X_pred):\n        \"\"\"\u8ba1\u7b97\u603b\u635f\u5931\"\"\"\n        # \u91cd\u6784\u635f\u5931\n        recon_loss = 0.5 * torch.mean((X - X_pred)**2)\n\n        # DAG\u7ea6\u675f\n        dag_loss = self.dag_constraint()\n\n        # \u7a00\u758f\u6027\u7ea6\u675f\n        sparse_loss = self.lambda1 * torch.norm(self.W, p=1)\n\n        return recon_loss + dag_loss + sparse_loss\n\nclass NonlinearNOTEARS(nn.Module):\n    def __init__(self, input_dim, hidden_dims=[16, 8], lambda1=0.01):\n        super(NonlinearNOTEARS, self).__init__()\n        self.input_dim = input_dim\n        self.lambda1 = lambda1\n\n        # \u4e3a\u6bcf\u4e2a\u53d8\u91cf\u521b\u5efaMLP\n        self.models = nn.ModuleList([\n            self._create_mlp(input_dim, hidden_dims) \n            for _ in range(input_dim)\n        ])\n\n        # \u90bb\u63a5\u77e9\u9635\uff08\u7528\u4e8e\u7a00\u758f\u6027\u7ea6\u675f\uff09\n        self.W = nn.Parameter(torch.randn(input_dim, input_dim))\n\n    def _create_mlp(self, input_dim, hidden_dims):\n        \"\"\"\u521b\u5efaMLP\u6a21\u578b\"\"\"\n        layers = []\n        prev_dim = input_dim\n\n        for hidden_dim in hidden_dims:\n            layers.extend([\n                nn.Linear(prev_dim, hidden_dim),\n                nn.ReLU(),\n                nn.Dropout(0.1)\n            ])\n            prev_dim = hidden_dim\n\n        layers.append(nn.Linear(prev_dim, 1))\n        return nn.Sequential(*layers)\n\n    def forward(self, X):\n        \"\"\"\u975e\u7ebf\u6027\u524d\u5411\u4f20\u64ad\"\"\"\n        batch_size, n_vars = X.shape\n        X_pred = torch.zeros_like(X)\n\n        for j in range(n_vars):\n            # \u4f7f\u7528\u7b2cj\u4e2aMLP\u9884\u6d4b\u7b2cj\u4e2a\u53d8\u91cf\n            # \u8f93\u5165\u662f\u6240\u6709\u53d8\u91cf\uff0c\u4f46\u901a\u8fc7\u90bb\u63a5\u77e9\u9635\u8fdb\u884c\u7a00\u758f\u5316\n            input_j = X * torch.sigmoid(self.W[:, j])  # \u7a00\u758f\u5316\u8f93\u5165\n            X_pred[:, j] = self.models[j](input_j).squeeze()\n\n        return X_pred\n\n    def dag_constraint(self):\n        \"\"\"\u8ba1\u7b97DAG\u7ea6\u675f\"\"\"\n        W = self.W\n        exp_W = torch.matrix_exp(W * W)\n        return torch.trace(exp_W) - self.input_dim\n\n    def loss(self, X, X_pred):\n        \"\"\"\u8ba1\u7b97\u603b\u635f\u5931\"\"\"\n        # \u91cd\u6784\u635f\u5931\n        recon_loss = 0.5 * torch.mean((X - X_pred)**2)\n\n        # DAG\u7ea6\u675f\n        dag_loss = self.dag_constraint()\n\n        # \u7a00\u758f\u6027\u7ea6\u675f\n        sparse_loss = self.lambda1 * torch.norm(self.W, p=1)\n\n        return recon_loss + dag_loss + sparse_loss\n\ndef train_notears(data, model_type='linear', lambda1=0.01, \n                  lr=0.01, epochs=1000):\n    \"\"\"\n    \u8bad\u7ec3NOTEARS\u6a21\u578b\n    \"\"\"\n    input_dim = data.shape[1]\n\n    # \u521b\u5efa\u6a21\u578b\n    if model_type == 'linear':\n        model = NOTEARS(input_dim, lambda1)\n    else:\n        model = NonlinearNOTEARS(input_dim, lambda1=lambda1)\n\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    # \u8f6c\u6362\u4e3aPyTorch\u5f20\u91cf\n    X_tensor = torch.FloatTensor(data)\n\n    for epoch in range(epochs):\n        optimizer.zero_grad()\n\n        # \u524d\u5411\u4f20\u64ad\n        X_pred = model(X_tensor)\n\n        # \u8ba1\u7b97\u635f\u5931\n        loss = model.loss(X_tensor, X_pred)\n\n        # \u53cd\u5411\u4f20\u64ad\n        loss.backward()\n        optimizer.step()\n\n        # \u6253\u5370\u8fdb\u5ea6\n        if epoch % 100 == 0:\n            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n\n    return model\n\n# \u4f7f\u7528\u793a\u4f8b\ndef example_linear_notears():\n    \"\"\"\u7ebf\u6027NOTEARS\u793a\u4f8b\"\"\"\n    # \u751f\u6210\u7ebf\u6027\u56e0\u679c\u6570\u636e\n    np.random.seed(42)\n    n_samples = 1000\n    n_vars = 5\n\n    # \u771f\u5b9e\u90bb\u63a5\u77e9\u9635\n    true_W = np.array([\n        [0.0, 0.8, 0.0, 0.0, 0.0],\n        [0.0, 0.0, 0.6, 0.0, 0.0],\n        [0.0, 0.0, 0.0, 0.7, 0.0],\n        [0.0, 0.0, 0.0, 0.0, 0.5],\n        [0.0, 0.0, 0.0, 0.0, 0.0]\n    ])\n\n    # \u751f\u6210\u6570\u636e\n    X = np.random.randn(n_samples, n_vars)\n    for i in range(n_samples):\n        X[i] = X[i] @ true_W + 0.1 * np.random.randn(n_vars)\n\n    # \u8bad\u7ec3\u6a21\u578b\n    model = train_notears(X, model_type='linear', lambda1=0.01, \n                        lr=0.01, epochs=1000)\n\n    # \u83b7\u53d6\u7ed3\u679c\n    learned_W = model.W.detach().numpy()\n\n    print(\"True adjacency matrix:\")\n    print(true_W)\n    print(\"Learned adjacency matrix:\")\n    print(learned_W)\n\n    return model\n\ndef example_nonlinear_notears():\n    \"\"\"\u975e\u7ebf\u6027NOTEARS\u793a\u4f8b\"\"\"\n    # \u751f\u6210\u975e\u7ebf\u6027\u56e0\u679c\u6570\u636e\n    np.random.seed(42)\n    n_samples = 1000\n    n_vars = 4\n\n    # \u751f\u6210\u6570\u636e\n    X = np.random.randn(n_samples, n_vars)\n\n    # \u975e\u7ebf\u6027\u5173\u7cfb\n    X[:, 1] = np.sin(X[:, 0]) + 0.1 * np.random.randn(n_samples)\n    X[:, 2] = X[:, 1]**2 + 0.1 * np.random.randn(n_samples)\n    X[:, 3] = np.tanh(X[:, 2]) + 0.1 * np.random.randn(n_samples)\n\n    # \u8bad\u7ec3\u6a21\u578b\n    model = train_notears(X, model_type='nonlinear', lambda1=0.01, \n                        lr=0.001, epochs=2000)\n\n    # \u83b7\u53d6\u7ed3\u679c\n    learned_W = model.W.detach().numpy()\n\n    print(\"Learned adjacency matrix (nonlinear):\")\n    print(learned_W)\n\n    return model\n\nif __name__ == \"__main__\":\n    print(\"Linear NOTEARS Example:\")\n    linear_model = example_linear_notears()\n\n    print(\"\\nNonlinear NOTEARS Example:\")\n    nonlinear_model = example_nonlinear_notears()\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_12","title":"\u53c2\u6570\u9009\u62e9","text":"<ol> <li> <p>\u6b63\u5219\u5316\u53c2\u6570:    - <code>lambda1</code>: \u7a00\u758f\u6027\u7ea6\u675f\u5f3a\u5ea6\uff0c\u901a\u5e380.001-0.1    - <code>rho</code>: \u589e\u5e7f\u62c9\u683c\u6717\u65e5\u60e9\u7f5a\u53c2\u6570\uff0c\u901a\u5e381.0-10.0    - <code>alpha</code>: \u62c9\u683c\u6717\u65e5\u4e58\u5b50\uff0c\u521d\u59cb\u5316\u4e3a0</p> </li> <li> <p>\u4f18\u5316\u53c2\u6570:    - <code>learning_rate</code>: \u5b66\u4e60\u7387\uff0c\u901a\u5e380.001-0.01    - <code>epochs</code>: \u8bad\u7ec3\u8f6e\u6570\uff0c\u901a\u5e381000-10000    - <code>rho_max</code>: \u6700\u5927\u60e9\u7f5a\u53c2\u6570\uff0c\u901a\u5e381e16</p> </li> <li> <p>\u7f51\u7edc\u7ed3\u6784\u53c2\u6570:    - <code>hidden_dims</code>: \u9690\u85cf\u5c42\u7ef4\u5ea6\uff0c\u901a\u5e38[16, 8]\u6216[32, 16]</p> </li> </ol>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_13","title":"\u5e94\u7528\u793a\u4f8b","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_14","title":"\u7ebf\u6027\u56e0\u679c\u53d1\u73b0","text":"<p>\u573a\u666f: \u53d1\u73b0\u7ebf\u6027\u56e0\u679c\u7ed3\u6784</p> Python<pre><code># \u751f\u6210\u7ebf\u6027\u6570\u636e\nn_samples = 2000\nn_vars = 6\n\n# \u521b\u5efa\u7a00\u758f\u90bb\u63a5\u77e9\u9635\nW_true = np.zeros((n_vars, n_vars))\nW_true[0, 1] = 0.8\nW_true[1, 2] = 0.6\nW_true[2, 3] = 0.7\nW_true[3, 4] = 0.5\nW_true[4, 5] = 0.4\n\n# \u751f\u6210\u6570\u636e\nX = np.random.randn(n_samples, n_vars)\nfor i in range(n_samples):\n    X[i] = X[i] @ W_true + 0.1 * np.random.randn(n_vars)\n\n# \u8bad\u7ec3NOTEARS\nmodel = train_notears(X, model_type='linear', lambda1=0.01, \n                    lr=0.01, epochs=2000)\n\n# \u8bc4\u4f30\u7ed3\u679c\nW_learned = model.W.detach().numpy()\nprint(\"MSE between true and learned W:\", \n      np.mean((W_true - W_learned)**2))\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_15","title":"\u975e\u7ebf\u6027\u56e0\u679c\u53d1\u73b0","text":"<p>\u573a\u666f: \u53d1\u73b0\u975e\u7ebf\u6027\u56e0\u679c\u7ed3\u6784</p> Python<pre><code># \u751f\u6210\u975e\u7ebf\u6027\u6570\u636e\nn_samples = 2000\nn_vars = 5\n\n# \u751f\u6210\u57fa\u7840\u53d8\u91cf\nX = np.random.randn(n_samples, n_vars)\n\n# \u975e\u7ebf\u6027\u5173\u7cfb\nX[:, 1] = 0.7 * np.sin(X[:, 0]) + 0.1 * np.random.randn(n_samples)\nX[:, 2] = 0.5 * X[:, 1]**2 + 0.1 * np.random.randn(n_samples)\nX[:, 3] = 0.6 * np.tanh(X[:, 2]) + 0.1 * np.random.randn(n_samples)\nX[:, 4] = 0.4 * np.exp(-X[:, 3]**2) + 0.1 * np.random.randn(n_samples)\n\n# \u8bad\u7ec3\u975e\u7ebf\u6027NOTEARS\nmodel = train_notears(X, model_type='nonlinear', lambda1=0.01, \n                    lr=0.001, epochs=3000)\n\n# \u5206\u6790\u7ed3\u679c\nW_learned = model.W.detach().numpy()\nprint(\"Learned adjacency matrix (nonlinear):\")\nprint(W_learned)\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_16","title":"\u5b9e\u9645\u5e94\u7528\u573a\u666f","text":"<ol> <li>\u57fa\u56e0\u8c03\u63a7\u7f51\u7edc: \u53d1\u73b0\u57fa\u56e0\u95f4\u7684\u7ebf\u6027/\u975e\u7ebf\u6027\u8c03\u63a7\u5173\u7cfb</li> <li>\u7ecf\u6d4e\u7cfb\u7edf: \u8bc6\u522b\u7ecf\u6d4e\u53d8\u91cf\u95f4\u7684\u56e0\u679c\u5173\u7cfb</li> <li>\u751f\u7269\u533b\u5b66: \u5206\u6790\u751f\u7269\u6807\u5fd7\u7269\u95f4\u7684\u56e0\u679c\u7ed3\u6784</li> <li>\u5de5\u7a0b\u7cfb\u7edf: \u53d1\u73b0\u7cfb\u7edf\u7ec4\u4ef6\u95f4\u7684\u56e0\u679c\u5173\u7cfb</li> </ol>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_17","title":"\u7b97\u6cd5\u4f18\u7f3a\u70b9","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_18","title":"\u4f18\u70b9","text":"<ul> <li>\u7406\u8bba\u57fa\u7840\u624e\u5b9e\uff0c\u57fa\u4e8e\u8fde\u7eed\u4f18\u5316</li> <li>\u53ef\u6269\u5c55\u5230\u5927\u89c4\u6a21\u95ee\u9898</li> <li>\u652f\u6301\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u5173\u7cfb</li> <li>\u8ba1\u7b97\u6548\u7387\u9ad8</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_19","title":"\u7f3a\u70b9","text":"<ul> <li>\u4ec5\u9002\u7528\u4e8e\u65e0\u9690\u53d8\u91cf\u7684\u60c5\u51b5</li> <li>\u5bf9\u566a\u58f0\u654f\u611f</li> <li>\u53ef\u80fd\u9677\u5165\u5c40\u90e8\u6700\u4f18\u89e3</li> <li>\u9700\u8981\u8c03\u6574\u591a\u4e2a\u8d85\u53c2\u6570</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_20","title":"\u6539\u8fdb\u53d8\u4f53","text":"<ol> <li>DAGs with NO TEARS: \u539f\u59cbNOTEARS\u7b97\u6cd5</li> <li>NOTEARS-MLP: \u4f7f\u7528MLP\u7684\u975e\u7ebf\u6027\u6269\u5c55</li> <li>NOTEARS-SL: \u7a00\u758f\u7ebf\u6027NOTEARS</li> <li>NOTEARS-V: \u5904\u7406\u6df7\u5408\u53d8\u91cf\u7684NOTEARS</li> </ol>"},{"location":"notes/Research/CausalDiscovery/Algorithms/NOTEARS/#_21","title":"\u53c2\u8003\u8d44\u6e90","text":"<ul> <li>Zheng, X., Aragam, B., Ravikumar, P., &amp; Xing, E. P. (2018). DAGs with NO TEARS: Continuous Optimization for Structure Learning. NeurIPS.</li> <li>Zheng, X., et al. (2020). Learning DAGs with Continuous Optimization. AISTATS.</li> <li>Bello, K., Aragam, B., &amp; Ravikumar, P. (2022). Learning Sparse Nonlinear DAGs. ICML.</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/","title":"PC Algorithm","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#peter-clark-pc-algorithm","title":"Peter-Clark (PC) Algorithm","text":"<p> \u7ea6 1100 \u4e2a\u5b57  86 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 7 \u5206\u949f</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_1","title":"\u6982\u8ff0","text":"<p>PC\u7b97\u6cd5\u662f\u4e00\u79cd\u57fa\u4e8e\u7ea6\u675f\u7684\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\uff0c\u901a\u8fc7\u6761\u4ef6\u72ec\u7acb\u6027\u68c0\u9a8c\u6765\u5b66\u4e60\u56e0\u679c\u7ed3\u6784\u3002\u8be5\u7b97\u6cd5\u7531Spirtes\u548cGlymour\u63d0\u51fa\uff0c\u80fd\u591f\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u6062\u590d\u56e0\u679c\u56fe\u7684\u9aa8\u67b6\u7ed3\u6784\uff0c\u5e76\u8bc6\u522b\u90e8\u5206\u65b9\u5411\u3002</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_2","title":"\u6570\u5b66\u539f\u7406","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_3","title":"\u57fa\u7840\u6982\u5ff5","text":"<p>\u56e0\u679cMarkov\u6761\u4ef6: \u7ed9\u5b9a\u56e0\u679c\u56feG\u4e2d\u8282\u70b9X\u7684\u7236\u8282\u70b9PA(X)\uff0cX\u4e0e\u5176\u6240\u6709\u975e\u540e\u4ee3\u8282\u70b9\u6761\u4ef6\u72ec\u7acb\uff1a \\(\\(X \\perp\\!\\!\\!\\perp ND(X) | PA(X)\\)\\)</p> <p>\u5fe0\u8bda\u6027\u5047\u8bbe: \u6570\u636e\u4e2d\u6240\u6709\u7684\u6761\u4ef6\u72ec\u7acb\u6027\u5173\u7cfb\u90fd\u7531\u56e0\u679c\u56fe\u7684d-\u5206\u79bb\u6a21\u5f0f\u51b3\u5b9a\u3002</p> <p>d-\u5206\u79bb: \u5bf9\u4e8e\u6709\u5411\u65e0\u73af\u56feG\u4e2d\u7684\u4e09\u4e2a\u8282\u70b9\u96c6X, Y, Z\uff0c\u5982\u679c\u6240\u6709\u4eceX\u5230Y\u7684\u8def\u5f84\u90fd\u88abZ\u4e2d\u7684\u8282\u70b9\u963b\u65ad\uff0c\u5219\u79f0X\u548cY\u88abZ d-\u5206\u79bb\u3002</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_4","title":"\u6761\u4ef6\u72ec\u7acb\u6027\u68c0\u9a8c","text":"<p>PC\u7b97\u6cd5\u7684\u6838\u5fc3\u662f\u6761\u4ef6\u72ec\u7acb\u6027\u68c0\u9a8c\uff0c\u5e38\u7528\u65b9\u6cd5\u5305\u62ec\uff1a</p> <ol> <li> <p>\u504f\u76f8\u5173\u68c0\u9a8c:  \\(\\(\\rho_{XY|Z} = \\frac{\\rho_{XY} - \\rho_{XZ}\\rho_{YZ}}{\\sqrt{(1-\\rho_{XZ}^2)(1-\\rho_{YZ}^2)}}\\)\\)</p> </li> <li> <p>\u5361\u65b9\u68c0\u9a8c: \u5bf9\u4e8e\u79bb\u6563\u53d8\u91cf \\(\\(\\chi^2 = \\sum_{i,j} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\\)\\)</p> </li> <li> <p>G-\u68c0\u9a8c: \u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u72ec\u7acb\u6027\u68c0\u9a8c</p> </li> </ol>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_5","title":"\u7b97\u6cd5\u590d\u6742\u5ea6","text":"<p>PC\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a\\(O(p^2 \\cdot 2^{p-2})\\)\uff0c\u5176\u4e2dp\u662f\u53d8\u91cf\u6570\u91cf\u3002\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5bf9\u4e8e\u7a00\u758f\u56fe\uff0c\u590d\u6742\u5ea6\u4f1a\u663e\u8457\u964d\u4f4e\u3002</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_6","title":"\u7b97\u6cd5\u6d41\u7a0b","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#0","title":"\u9636\u6bb5 0: \u6570\u636e\u51c6\u5907","text":"<p>\u8f93\u5165: - \u89c2\u6d4b\u6570\u636e\u77e9\u9635 \\(X \\in \\mathbb{R}^{n \\times p}\\) - \u53d8\u91cf\u96c6 \\(V = \\{X_1, X_2, ..., X_p\\}\\) - \u663e\u8457\u6027\u6c34\u5e73 \\(\\alpha\\) (\u901a\u5e38\u4e3a0.05)</p> <p>\u8f93\u51fa: - \u6761\u4ef6\u72ec\u7acb\u6027\u8868 \\(I\\)\uff0c\u5176\u4e2d \\(I(i,j|S) = 1\\) \u8868\u793a \\(X_i \\perp\\!\\!\\!\\perp X_j | S\\)</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#1","title":"\u9636\u6bb5 1: \u9aa8\u67b6\u5b66\u4e60","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#11","title":"1.1 \u521d\u59cb\u5316","text":"<ul> <li>\u521b\u5efa\u5b8c\u5168\u65e0\u5411\u56fe \\(G_0\\)\uff0c\u6240\u6709\u8282\u70b9\u4e24\u4e24\u76f8\u8fde</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#12","title":"1.2 \u8fed\u4ee3\u5220\u8fb9","text":"Python<pre><code>for k = 0, 1, 2, ..., p-2:\n    for \u6bcf\u6761\u8fb9 (X_i, X_j) \u4ecd\u5728\u56fe\u4e2d:\n        for \u6bcf\u4e2a\u5927\u5c0f\u4e3ak\u7684\u5b50\u96c6 S \u2286 adj(G, X_i)\\{X_j}:\n            if \u68c0\u9a8c X_i \u22a5 X_j | S \u6210\u7acb:\n                \u5220\u9664\u8fb9 X_i\u2013X_j\n                \u8bb0\u5f55 SepSet(i,j) = S\n                break  # \u627e\u5230\u5206\u79bb\u96c6\u5373\u53ef\u505c\u6b62\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#2-v-","title":"\u9636\u6bb5 2: v-\u7ed3\u6784\u8bc6\u522b","text":"<p>\u904d\u5386\u6240\u6709\u65e0\u5411\u4e09\u5143\u7ec4 \\(X_i - X_k - X_j\\) \u4e14 \\(X_i\\) \u4e0e \\(X_j\\) \u4e0d\u76f8\u90bb\uff1a </p>Python<pre><code>for \u6240\u6709\u8fd9\u6837\u7684\u4e09\u5143\u7ec4:\n    if X_k \u2209 SepSet(i,j):\n        \u5b9a\u5411\u4e3a X_i \u2192 X_k \u2190 X_j  # \u6807\u8bb0\u4e3a\u5bf9\u649e\u8282\u70b9\n</code></pre><p></p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#3","title":"\u9636\u6bb5 3: \u65b9\u5411\u4f20\u64ad","text":"<p>\u5e94\u7528Meek\u89c4\u5219\u8fdb\u884c\u65b9\u5411\u4f20\u64ad\uff1a</p> <p>R1: \u82e5\u5b58\u5728 \\(X \\rightarrow Y - Z\\) \u4e14 \\(X\\) \u4e0e \\(Z\\) \u4e0d\u76f8\u90bb \\(\\Rightarrow Y \\rightarrow Z\\)</p> <p>R2: \u82e5\u5b58\u5728 \\(X \\rightarrow Y \\rightarrow Z\\) \u4e14 \\(X - Z\\) \\(\\Rightarrow X \\rightarrow Z\\)</p> <p>R3: \u82e5\u5b58\u5728 \\(X - Y - Z\\) \u4e14\u5b58\u5728 \\(X \\rightarrow W \\leftarrow Z\\) \u4e14 \\(W\\) \u4e0e \\(Y\\) \u4e0d\u76f8\u90bb \\(\\Rightarrow X \\rightarrow Y \\leftarrow Z\\)</p> <p>R4: \u82e5\u5b58\u5728 \\(X - Y - Z\\) \u4e14\u5b58\u5728 \\(X \\rightarrow W \\rightarrow Z\\) \u4e14 \\(W\\) \u4e0e \\(Y\\) \u4e0d\u76f8\u90bb \\(\\Rightarrow X \\rightarrow Y \\rightarrow Z\\)</p> <p>\u5faa\u73af\u5e94\u7528\u76f4\u5230\u6ca1\u6709\u65b0\u7bad\u5934\u53ef\u6dfb\u52a0\uff0c\u6700\u7ec8\u8f93\u51faCPDAG\u3002</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_7","title":"\u4f7f\u7528\u65b9\u6cd5","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#python","title":"Python\u5b9e\u73b0\u793a\u4f8b","text":"Python<pre><code>import numpy as np\nfrom scipy import stats\nfrom itertools import combinations\nimport networkx as nx\n\ndef conditional_independence_test(X, Y, Z=None, data=None, alpha=0.05):\n    \"\"\"\n    \u6761\u4ef6\u72ec\u7acb\u6027\u68c0\u9a8c\n    \"\"\"\n    if Z is None or len(Z) == 0:\n        # \u65e0\u6761\u4ef6\u72ec\u7acb\u6027\u68c0\u9a8c\n        corr, p_value = stats.pearsonr(data[:, X], data[:, Y])\n        return p_value &gt; alpha\n    else:\n        # \u6761\u4ef6\u72ec\u7acb\u6027\u68c0\u9a8c - \u504f\u76f8\u5173\n        try:\n            from sklearn.linear_model import LinearRegression\n            # \u5bf9X\u548cY\u5206\u522b\u56de\u5f52Z\n            lr_X = LinearRegression()\n            lr_Y = LinearRegression()\n\n            lr_X.fit(data[:, Z], data[:, X])\n            lr_Y.fit(data[:, Z], data[:, Y])\n\n            res_X = data[:, X] - lr_X.predict(data[:, Z])\n            res_Y = data[:, Y] - lr_Y.predict(data[:, Z])\n\n            corr, p_value = stats.pearsonr(res_X, res_Y)\n            return p_value &gt; alpha\n        except:\n            return False\n\ndef pc_algorithm(data, alpha=0.05):\n    \"\"\"\n    PC\u7b97\u6cd5\u5b9e\u73b0\n    \"\"\"\n    n_vars = data.shape[1]\n    G = nx.complete_graph(n_vars)\n    sep_set = {(i, j): set() for i in range(n_vars) for j in range(n_vars)}\n\n    # \u9636\u6bb51: \u9aa8\u67b6\u5b66\u4e60\n    for k in range(n_vars):\n        edges_to_check = list(G.edges())\n        removed_edges = []\n\n        for (i, j) in edges_to_check:\n            if (i, j) not in G.edges():\n                continue\n\n            neighbors_i = set(G.neighbors(i)) - {j}\n\n            if len(neighbors_i) &gt;= k:\n                for S in combinations(neighbors_i, k):\n                    if conditional_independence_test(i, j, list(S), data, alpha):\n                        G.remove_edge(i, j)\n                        sep_set[(i, j)] = set(S)\n                        sep_set[(j, i)] = set(S)\n                        removed_edges.append((i, j))\n                        break\n\n        if not removed_edges:\n            break\n\n    # \u9636\u6bb52: v-\u7ed3\u6784\u8bc6\u522b\n    for i in range(n_vars):\n        for j in range(i+1, n_vars):\n            if not G.has_edge(i, j):\n                common_neighbors = set(G.neighbors(i)) &amp; set(G.neighbors(j))\n                for k in common_neighbors:\n                    if k not in sep_set[(i, j)]:\n                        G.remove_edge(i, k)\n                        G.remove_edge(j, k)\n                        G.add_edge(i, k, directed=True)\n                        G.add_edge(j, k, directed=True)\n\n    return G, sep_set\n</code></pre>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_8","title":"\u53c2\u6570\u9009\u62e9","text":"<ol> <li>\u663e\u8457\u6027\u6c34\u5e73\u03b1: \u901a\u5e38\u9009\u62e90.05\uff0c\u4f46\u53ef\u6839\u636e\u6570\u636e\u566a\u58f0\u8c03\u6574</li> <li>\u72ec\u7acb\u6027\u68c0\u9a8c\u65b9\u6cd5:     - \u8fde\u7eed\u53d8\u91cf: \u504f\u76f8\u5173\u68c0\u9a8c\u3001G-\u68c0\u9a8c    - \u79bb\u6563\u53d8\u91cf: \u5361\u65b9\u68c0\u9a8c\u3001G-\u68c0\u9a8c</li> <li>\u6700\u5927\u6761\u4ef6\u96c6\u5927\u5c0f: \u53ef\u8bbe\u7f6e\u4e0a\u9650\u4ee5\u63d0\u9ad8\u6548\u7387</li> </ol>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_9","title":"\u5e94\u7528\u793a\u4f8b","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#3_1","title":"3\u53d8\u91cf\u56e0\u679c\u7ed3\u6784","text":"<p>\u771f\u5b9e\u7ed3\u6784: \\(A \\rightarrow C \\leftarrow B\\)</p> <p>\u72ec\u7acb\u6027\u8868: - \\(A \\perp\\!\\!\\!\\perp B | \\emptyset\\): \u4e0d\u72ec\u7acb - \\(A \\perp\\!\\!\\!\\perp C | \\emptyset\\): \u4e0d\u72ec\u7acb - \\(A \\perp\\!\\!\\!\\perp C | \\{B\\}\\): \u72ec\u7acb \u2192 \u5220\u9664A\u2013C\uff0cSepSet(A,C)={B} - \\(B \\perp\\!\\!\\!\\perp C | \\emptyset\\): \u4e0d\u72ec\u7acb - \\(B \\perp\\!\\!\\!\\perp C | \\{A\\}\\): \u72ec\u7acb \u2192 \u5220\u9664B\u2013C\uff0cSepSet(B,C)={A}</p> <p>\u7b97\u6cd5\u8fc7\u7a0b: 1. \u9aa8\u67b6: A\u2013B (\u56e0\u4e3aA\u22a5B|\u2205\u4e0d\u6210\u7acb) 2. v-\u7ed3\u6784: \u5bf9\u4e09\u5143\u7ec4A\u2013C\u2013B\uff0cSepSet(A,B)=\u2205\uff0c\u800cC\u2209SepSet(A,B)\uff0c\u5b9a\u5411\u4e3aA\u2192C\u2190B 3. \u65b9\u5411\u4f20\u64ad: \u65e0\u5176\u4ed6\u8fb9\u53ef\u52a0\u65b9\u5411</p> <p>\u6700\u7ec8CPDAG: A\u2192C\u2190B, A\u2013B (\u65e0\u5411)</p>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_10","title":"\u5b9e\u9645\u5e94\u7528\u573a\u666f","text":"<ol> <li>\u57fa\u56e0\u7f51\u7edc\u5206\u6790: \u53d1\u73b0\u57fa\u56e0\u95f4\u7684\u8c03\u63a7\u5173\u7cfb</li> <li>\u7ecf\u6d4e\u5b66: \u8bc6\u522b\u7ecf\u6d4e\u53d8\u91cf\u95f4\u7684\u56e0\u679c\u5173\u7cfb</li> <li>\u533b\u5b66: \u5206\u6790\u75be\u75c5\u98ce\u9669\u56e0\u7d20\u95f4\u7684\u56e0\u679c\u7ed3\u6784</li> <li>\u793e\u4f1a\u79d1\u5b66: \u7814\u7a76\u793e\u4f1a\u73b0\u8c61\u95f4\u7684\u56e0\u679c\u673a\u5236</li> </ol>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_11","title":"\u7b97\u6cd5\u4f18\u7f3a\u70b9","text":""},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_12","title":"\u4f18\u70b9","text":"<ul> <li>\u7406\u8bba\u57fa\u7840\u624e\u5b9e\uff0c\u57fa\u4e8e\u56e0\u679c\u56fe\u7684d-\u5206\u79bb\u7406\u8bba</li> <li>\u4e0d\u9700\u8981\u9884\u8bbe\u51fd\u6570\u5f62\u5f0f</li> <li>\u80fd\u591f\u5904\u7406\u6df7\u5408\u7c7b\u578b\u53d8\u91cf</li> <li>\u8f93\u51fa\u4e3aCPDAG\uff0c\u8868\u793aMarkov\u7b49\u4ef7\u7c7b</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_13","title":"\u7f3a\u70b9","text":"<ul> <li>\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u53d8\u91cf\u591a\u65f6\u96be\u4ee5\u5e94\u7528</li> <li>\u4f9d\u8d56\u6761\u4ef6\u72ec\u7acb\u6027\u68c0\u9a8c\u7684\u51c6\u786e\u6027</li> <li>\u5fe0\u8bda\u6027\u5047\u8bbe\u5728\u5b9e\u9645\u4e2d\u53ef\u80fd\u4e0d\u6210\u7acb</li> <li>\u53ea\u80fd\u8bc6\u522bMarkov\u7b49\u4ef7\u7c7b\uff0c\u65e0\u6cd5\u786e\u5b9a\u6240\u6709\u8fb9\u7684\u65b9\u5411</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_14","title":"\u6539\u8fdb\u53d8\u4f53","text":"<ol> <li>FCI\u7b97\u6cd5: \u5904\u7406\u9690\u53d8\u91cf\u548c\u9009\u62e9\u504f\u5dee</li> <li>PC-Stable: \u7a33\u5b9a\u7248\u672c\u7684PC\u7b97\u6cd5</li> <li>MPC\u7b97\u6cd5: \u6539\u8fdb\u7684PC\u7b97\u6cd5\uff0c\u63d0\u9ad8\u6548\u7387</li> <li>Fast Causal Inference (FCI): \u6269\u5c55\u5230\u9690\u53d8\u91cf\u60c5\u51b5</li> </ol>"},{"location":"notes/Research/CausalDiscovery/Algorithms/PCAlgorithm/#_15","title":"\u53c2\u8003\u8d44\u6e90","text":"<ul> <li>\u3010\u56e0\u679c\u7cfb\u5217\u3011PC \u7b97\u6cd5 \u2014\u2014 \u4e00\u79cd\u57fa\u4e8e\u7ea6\u675f\u7684\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5</li> <li>PC \u7b97\u6cd5 - \u8d1d\u53f6\u65af\u7f51\u7edc\u4e0e\u5176\u7ed3\u6784\u5b66\u4e60\u7b97\u6cd5</li> <li>Spirtes, P., Glymour, C., &amp; Scheines, R. (2000). Causation, Prediction, and Search. MIT Press.</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Papers/ALCM/","title":"ALCM","text":""},{"location":"notes/Research/CausalDiscovery/Papers/ALCM/#alcm-autonomous-llm-augmented-causal-discovery-framework","title":"ALCM: Autonomous LLM-Augmented Causal Discovery Framework","text":"<p> \u7ea6 1800 \u4e2a\u5b57  3 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 9 \u5206\u949f</p>"},{"location":"notes/Research/CausalDiscovery/Papers/ALCM/#conventional-data-driven-causal-discovery-algorithms","title":"Conventional data-driven causal discovery algorithms:","text":"<p>conventional data-driven causal discovery algorithms are broadly classified into five categories as follows:</p> <p>\u2022 Score-Based Algorithms: They operate on scores and engage in a comprehensive exploration of the entire space of potential Directed Acyclic Graphs (DAGs) to identify the most suitable graph for explaining the underlying data. Typically, such score-based approaches consist of two integral components: (i) a systematic search strategy tasked with navigating through the potential search states or the space of candidate graphs, denoted as G\u2019, and (ii) a score function designed to evaluate the viability of these candidate causal graphs. The synergy between the search strategy and the score function is instrumental in optimizing the exploration of all conceivable DAGs. A widely employed score function in the selection of causal models is the Bayesian Information Criterion (BIC). Some examples of score-based algorithms are Greedy Equivalence Search (GES), Fast Greedy Search (FGS), and A* Search.</p> <p>\u2022 Constraint-Based Algorithms: This category, exemplified by Peter-Clark (PC) algorithm, employs conditional independence (CI) tests to reveal the graph\u2019s skeleton and v-structures, ultimately returning the Directed Acyclic Graph (DAG) of the functional causal model while considering v-structures and doing edge-orientations. Other constraint-bsaed algorithms are like Fast Causal Inference (FCI), Anytime FCI, RFCI, PC-stable, and so forth.</p> <p>\u2022 Hybrid Algorithms: Hybrid approaches are founded on the integration of various causal discovery methods, combining constraint-based, score-based, Functional Causal Model (FCM)-based, gradient-based, and other techniques. This amalgamation reflects a comprehensive strategy that leverages the strengths of different methodologies to enhance the robustness and effectiveness of causal discovery in complex systems. Max-Min Hill Climbing (MMHC)\u2013belonging to this category\u2013stands out as a hybrid causal discovery technique that seamlessly integrates principles from both score-based and constraint-based algorithms. This hybrid approach combines the advantages of scoring methods and constraint-based strategies, offering a comprehensive and effective framework for uncovering causal relationships in complex systems.</p> <p>\u2022 Function-Based Algorithms: Approaches grounded in Functional Causal Models (FCM) delineate the causal connections between variables within a defined functional structure. In FCMs, variables are expressed as functions of their direct causes (parents), augmented by an independent noise term denoted as E. The distinguishing feature of FCM-based methodologies lies in their capacity to differentiate between various Directed Acyclic Graphs (DAGs) within the same equivalence class. This discrimination is achieved by introducing supplementary assumptions concerning data distributions and/or function classes. Several notable FCM-based causal discovery methodologies are introduced, including Linear Non-Gaussian Acyclic Model (LiNGAM) and Structural Agnostic Modeling (SAM). SAM employs an adversarial learning methodology for causal graph identification. Specifically, SAM utilizes Generative Adversarial Neural Networks (GANs) to seek a Functional Causal Model (FCM) while ensuring the detection of sparse causal graphs through the incorporation of appropriate regularization terms. The optimization process involves a learning criterion that integrates distribution estimation, sparsity considerations, and acyclicity constraints. This holistic criterion facilitates end-to-end optimization of both the graph structure and associated parameters, accomplished through stochastic gradient descent. The previous three-mentioned categories may be limited to the Markov equivalence class, posing constraints. Function-based algorithms like LiNGAM aim to uniquely identify causal DAGs by exploiting data generative process asymmetries or causal footprints.</p> <p>\u2022 Optimization-Based Algorithms: Recent investigations in causal discovery have approached the structure learning problem by casting it as a continuous optimization task, employing the least squares objective and an algebraic representation of Directed Acyclic Graphs (DAGs). Notably, this transformation converts the combinatorial nature of the structure learning problem into a continuous framework, and solutions are obtained through the application of gradient-based optimization techniques. These methods exploit the gradients of an objective function concerning the parameterization of a DAG matrix to achieve effective structure learning. NOTEARS is among the causal discovery algorithms that formulate the structure learning problem as a purely continuous constrained optimization task.</p>"},{"location":"notes/Research/CausalDiscovery/Papers/ALCM/#architecture","title":"Architecture","text":""},{"location":"notes/Research/CausalDiscovery/Papers/ALCM/#causal-structure-learning","title":"Causal Structure Learning","text":"<p>Hybrid:</p> <p>The PC method employs conditional independence (CI) tests to iteratively construct a causal graph by building its skeleton and identifying v-structures. This method is particularly effective for datasets with mixed discrete and continuous variables and excels in capturing probabilistic dependencies. Its iterative and constraint-based nature ensures computational efficiency, even in high-dimensional settings. In contrast, LiNGAM is specifically designed to uncover linear causal relationships in datasets with non-Gaussian distributions. By leveraging Independent Component Analysis (ICA), LiNGAM accurately identifies causal ordering and orients edges with high precision, even in the presence of latent confounders and linear dependencies. NOTEARS complements these approaches by reformulating causal discovery into a continuous optimization problem. By incorporating a differentiable acyclicity constraint, NOTEARS transforms the combinatorial problem of DAG discovery into a solvable optimization task, making it highly effective for datasets with intricate causal dependencies and scalable to high-dimensional data.</p> <p>To leverage the unique strengths of these methods, we propose a hybrid approach that combines their outputs using dynamically assigned weights. These weights are determined based on a composite score for each method, which captures its performance on a given dataset. The composite score is defined as the difference between the Accuracy and NHD, balancing edge-specific performance and structural alignment with the ground truth. Formally, the composite score for a method is given by:</p> <p>\\(Composite_{method} = Accuracy_{method}\u2212NHD_{method}\\)</p> <p>\u5728\u56e0\u679c\u56fe\u8bc4\u4f30\u4e2d\uff0c\u6211\u4eec\u901a\u5e38\u6bd4\u8f83\u9884\u6d4b\u56fe \\(G_p\\) \u548c\u771f\u5b9e\u56fe \\(G\\)\uff0c\u4e24\u8005\u90fd\u6709 \\(m\\) \u4e2a\u8282\u70b9\u3002\u6240\u6709\u53ef\u80fd\u7684\u6709\u5411\u8fb9\u6570\u91cf\u4e3a \\(N = m(m-1)\\)\uff08\u5047\u8bbe\u6ca1\u6709\u81ea\u73af\uff09\u3002\u57fa\u4e8e\u6df7\u6dc6\u77e9\u9635\u7684\u6982\u5ff5\uff0c\u6211\u4eec\u53ef\u4ee5\u5b9a\u4e49\uff1a - TP\uff08\u771f\u9633\u6027\uff09\uff1a\u6b63\u786e\u9884\u6d4b\u5b58\u5728\u7684\u8fb9\uff08\u5373 \\(G\\) \u548c \\(G_p\\) \u4e2d\u90fd\u4e3a 1 \u7684\u8fb9\uff09\u3002 - TN\uff08\u771f\u9634\u6027\uff09\uff1a\u6b63\u786e\u9884\u6d4b\u4e0d\u5b58\u5728\u7684\u8fb9\uff08\u5373 \\(G\\) \u548c \\(G_p\\) \u4e2d\u90fd\u4e3a 0 \u7684\u8fb9\uff09\u3002 - FP\uff08\u5047\u9633\u6027\uff09\uff1a\u9519\u8bef\u9884\u6d4b\u5b58\u5728\u7684\u8fb9\uff08\u5373 \\(G\\) \u4e2d\u4e3a 0 \u4f46 \\(G_p\\) \u4e2d\u4e3a 1 \u7684\u8fb9\uff09\u3002 - FN\uff08\u5047\u9634\u6027\uff09\uff1a\u9519\u8bef\u9884\u6d4b\u4e0d\u5b58\u5728\u7684\u8fb9\uff08\u5373 \\(G\\) \u4e2d\u4e3a 1 \u4f46 \\(G_p\\) \u4e2d\u4e3a 0 \u7684\u8fb9\uff09\u3002</p> <p>\u7136\u540e\uff0c\\((\\text{Accuracy})\\) \u548c \\((\\text{NHD})\\) \u7684\u8ba1\u7b97\u5982\u4e0b\uff1a - \\(\\text{Accuracy} = \\frac{TP + TN}{N}\\) - \\(\\text{NHD} = \\frac{FP + FN}{N}\\)</p> <p>\u56e0\u6b64\uff0c\u516c\u5f0f\u53d8\u4e3a\uff1a \\(\\text{Composite} = \\text{Accuracy} - \\text{NHD} = \\frac{TP + TN}{N}- \\frac{FP + FN}{N} = \\frac{(TP + TN) - (FP + FN)}{N}\\)</p> <p>\u7531\u4e8e \\(TP + TN + FP + FN = N\\)\uff0c\u6211\u4eec\u53ef\u4ee5\u7b80\u5316\uff1a \\((TP + TN) - (FP + FN) = (TP + TN) - (N - TP - TN) = 2(TP + TN) - N\\) \u6240\u4ee5\uff1a \\(\\text{Composite} = \\frac{2(TP + TN) - N}{N} = 2 \\cdot \\text {Accuracy} - 1\\)</p> <p>\u8fd9\u610f\u5473\u7740 \\(\\text{Composite}\\) \u5b9e\u9645\u4e0a\u662f \\(2 \\cdot \\text{Accuracy} - 1\\)\uff0c\u5176\u503c\u8303\u56f4\u5728 \\([-1, 1]\\)\u3002\u5f53 \\(\\text{Accuracy} = 1\\) \u65f6\uff0c\\(\\text{Composite} = 1\\); \u5f53 \\(\\text{Accuracy} = 0.5\\) \u65f6\uff0c\\(\\text{Composite} = 0\\); \u5f53 \\(\\text{Accuracy} = 0\\) \u65f6\uff0c\\(\\text{Composite} = -1\\).</p> <p>\u8981\u8ba1\u7b97 \\(\\text{Composite}_{\\text{method}}\\)\uff0c\u9700\u8981\u4ee5\u4e0b\u6b65\u9aa4\uff1a 1. \u6784\u5efa\u90bb\u63a5\u77e9\u9635\uff1a\u5c06\u771f\u5b9e\u56fe \\(G\\) \u548c\u9884\u6d4b\u56fe \\(G_p\\) \u8868\u793a\u4e3a \\(m \\times m\\) \u7684\u90bb\u63a5\u77e9\u9635\uff0c\u5176\u4e2d\u5143\u7d20 \\(1\\) \u8868\u793a\u5b58\u5728\u8fb9\uff0c\\(0\\) \u8868\u793a\u4e0d\u5b58\u5728\u8fb9\u3002 2. \u8ba1\u7b97 TP, TN, FP, FN\uff1a\u901a\u8fc7\u6bd4\u8f83\u4e24\u4e2a\u90bb\u63a5\u77e9\u9635\u7684\u6bcf\u4e2a\u5143\u7d20\uff1a   - TP\uff1a\u4e24\u4e2a\u77e9\u9635\u90fd\u4e3a \\(1\\) \u7684\u4f4d\u7f6e\u6570\u3002   - TN\uff1a\u4e24\u4e2a\u77e9\u9635\u90fd\u4e3a \\(0\\) \u7684\u4f4d\u7f6e\u6570\uff08\u4e0d\u5305\u62ec\u5bf9\u89d2\u7ebf\uff0c\u5982\u679c\u7981\u6b62\u81ea\u73af\uff09\u3002   - FP\uff1a\\(G\\) \u4e3a \\(0\\) \u4f46 \\(G_p\\) \u4e3a \\(1\\) \u7684\u4f4d\u7f6e\u6570\u3002   - FN\uff1a\\(G\\) \u4e3a \\(1\\) \u4f46 \\(G_p\\) \u4e3a \\(0\\) \u7684\u4f4d\u7f6e\u6570\u3002 3. \u8ba1\u7b97 \\(N\\)\uff1a\u6240\u6709\u53ef\u80fd\u8fb9\u7684\u6570\u91cf\uff0c\\(N = m(m-1)\\)\u3002 4. \u8ba1\u7b97 \\(\\text{Accuracy}\\)\uff1a\\(\\text{Accuracy} = \\frac{TP + TN}{N}\\). 5. \u8ba1\u7b97 \\(\\text{Composite}\\)\uff1a\\(\\text{Composite} = 2 \\cdot \\text{Accuracy} - 1\\).</p> <p>\\(\\text{Composite}\\) \u5f97\u5206\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7efc\u5408\u8861\u91cf\u9884\u6d4b\u56fe\u4e0e\u771f\u5b9e\u56fe\u76f8\u4f3c\u5ea6\u7684\u6307\u6807\u3002\u6b63\u503c\u8868\u793a\u9884\u6d4b\u4f18\u4e8e\u968f\u673a\uff08Accuracy &gt; 0.5\uff09\uff0c\u8d1f\u503c\u8868\u793a\u9884\u6d4b\u5dee\u4e8e\u968f\u673a\uff08Accuracy &lt; 0.5\uff09\u3002</p> <p>This score accounts for both the overall correctness of edge identification (via Accuracy) and the structural similarity of the causal graph (via NHD), ensuring that methods achieving both accurate and well-aligned graphs are given higher importance. The weights are derived by normalizing the composite scores across all methods:</p> <p>\\(W_{method} = \\frac{Composite_{method}}{\\sum_{all methods}Composite_{method}}\\)</p> <p>where \\(W_{method}\\) represents the weight assigned to a method, ensuring that the sum of all weights equals one.</p> <p>To further enhance the adaptability of the hybrid approach, we introduce a neural network-based architecture to dynamically learn these weights based on both method performance metrics and dataset-specific features. The neural network is designed to take as input the composite scores of the methods, along with features such as graph density, node degree distribution, and sparsity. Graph density quantifies how connected the graph is and is defined as the ratio of the number of edges to the maximum possible edges. Node degree distribution describes the variability in the number of connections per node, while sparsity measures the proportion of missing edges compared to a fully connected graph.</p> <p>The architecture of the neural network consists of three layers: 1. An input layer with nine features, including the composite scores of the methods (\\(Composite_{PC},Composite_{LiNGAM},Composite_{NOTEARS}\\) ) and six dataset-specific features such as graph density, average node degree, and sparsity. 2. Two hidden layers with 64 and 32 neurons, respectively, each using the Rectified Linear Unit (ReLU) activation function to capture non-linear relationships among the features. 3. An output layer with three neurons (one for each method), using a softmax activation to produce normalized weights for the methods. Formally, the neural network outputs the weights as follows:</p> <p>\\(W = Softmax \\left( H _ { 2 } \\cdot W _ { O } + b _ { O } \\right)\\)</p> <p>where \ud835\udc072 represents the outputs from the second hidden layer, \ud835\udc16o and \ud835\udc1bo are the weights and biases of the output layer, and Softmax ensures the weights sum to one.</p> <p>The neural network is trained on a dataset comprising simulated graphs with varying densities, node degrees, and sparsity levels. For each graph, the outputs of PC, LiNGAM, and NOTEARS are evaluated using Accuracy and NHD, and the composite scores are computed. The ground-truth weights for training are derived by normalizing these composite scores as described in Equation (3). The training objective minimizes the mean squared error (MSE) between the predicted weights and the ground-truth weights. Using the dynamically learned weights, the hybrid approach synthesizes a causal graph by aggregating the outputs of PC, LiNGAM, and NOTEARS. For each edge e , the final score is computed as:</p> <p>\\(Score_{e} =\\sum_{method} W_{method} \\cdot \ud835\udfd9_{method(e)}\\)</p> <p>Here, \\(\ud835\udfd9_{method(e)}\\) is an indicator function that equals 1 if the edge e is identified by the method and 0 otherwise. Edges with scores exceeding a predefined threshold are retained in the hybrid causal graph. For edges uniquely identified by only one method, one LLM is employed as a decisive layer. The LLM evaluates these edges based on contextual knowledge and causal reasoning to ensure that only plausible causal links are included. The validated edges are then added to the hybrid graph, enhancing its comprehensiveness and accuracy.</p> <p>Normalized Hamming Distance (NHD): quantifies the difference between the predicted causal graph and the ground truth by measuring the proportion of mismatched edges, adjusted for the size of the graph. NHD is instrumental in assessing the structural similarity of the causal graphs, offering insights into the nuanced differences that may not be captured by other metrics. In the context of a graph with m nodes, the NHD between the predicted graph G p and the ground-truth graph G is determined by calculating the number of edges that exist in one graph but not the other. This count is then divided by the total number of all possible edges\u2013this formula is defined in Equation 6. In essence, the NHD provides a normalized measure of dissimilarity, offering insights into the accuracy of the predicted graph compared to the ground-truth graph, accounting for the total potential edges in the graph with m nodes.</p> <p>\\(N H D = \\sum_{i=1}^m \\sum_{j=1}^m \\frac{1}{m^2} \\cdot 1,\\)where  \\(G_{ij} \\neq G_{p_{ij}}\\)</p>"},{"location":"notes/Research/CausalDiscovery/Papers/ALCM/#causal-wrapper","title":"Causal Wrapper","text":"<p>Equation 1 shows our causal-aware prompting strategy by infusing the context of problem and metadata information into the prompts. This prompting strategy was inspired by an effort by Kim et al.. They demonstrated that contextual information is important in boosting the overall performance of LLMs\u2019 responses.</p> <p>\\(Causal_{prompt}=Instruction+Causal Context+Metadata+Question+Output format\\)</p> <p>This enhancement is accomplished by incorporating explicit elements into the prompt, with each edge being transformed into a causal prompt structured as follows:</p> <p>Instructions: This section clarifies the role of LLMs, their objectives, and the expected behavior. Causal Context: It includes details about the selected causal discovery algorithm, such as its name and output. Metadata: This section outlines the dataset domain or variable names along with their descriptions. Question: It specifies the precise query, for example, whether A causes B. Output format: This delineates the desired format for the output.</p> <p></p>"},{"location":"notes/Research/CausalDiscovery/Papers/ALCM/#llm-refiner","title":"LLM-Refiner","text":"<p>The LLM-driven Refiner leverages advanced language models in the refinement and evaluation of causal graphs. This component receives a series of intricately designed, contextual causal prompts from the causal wrapper component, which serve as a nuanced guide for its operations.</p> <p>The LLM-driven Refiner evaluates each edge and node in the graph by applying advanced reasoning capabilities of LLMs (e.g., GPT-4). The process involves:</p> <ol> <li>Assessing the validity of existing causal relationships using contextual knowledge.</li> <li>Detecting and integrating hidden causal relationships by reasoning over unobserved variables.</li> <li>Reorienting or removing edges that do not align with domain knowledge or probabilistic dependencies.</li> <li>Assigning confidence scores or likelihood estimates to refined relationships, ensuring interpretability and reliability.</li> </ol>"},{"location":"notes/Research/CausalDiscovery/Papers/CELLO/","title":"CELLO","text":""},{"location":"notes/Research/CausalDiscovery/Papers/CELLO/#cello-causal-evaluation-of-large-vision-language-models","title":"CELLO: Causal Evaluation of Large Vision-Language Models","text":"<p> \u7ea6 626 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p>"},{"location":"notes/Research/CausalDiscovery/Papers/CELLO/#dataser-construction-pipeline","title":"Dataser Construction Pipeline","text":"<p>First, we extract causal graphs from scene graphs that include relationships and regions within an image. Then, we select corresponding causal tasks based on the ladder of causation. Finally, causal questions are constructed by employing templates with an LLM. We consider four types of causal graphs and twelve different causal tasks in total.</p> <p>Specifically,we divide the pipeline into 3 aspects.</p>"},{"location":"notes/Research/CausalDiscovery/Papers/CELLO/#causal-graph-extraction","title":"Causal Graph Extraction","text":"<p>Preprocess Visual Genome Dataset(it has comprehensive suite of images along with corresponding scene graphs): Specifically, we first catalog and analyze every relationship type present in Visual Genome, with a focus on those signifying arrangement, positioning, and other significant interactions, such as those labeled \u201csupport\u201d, \u201cfixed to\u201d, and \u201chold\u201d. Then, we compile a set of graph templates drawn from multiple sources in the literature,including direct, confounding, collision, and chain.These templates illustrate various toy problems in causal reasoning using well-defined graph structures. Finally, we perform isomorphic subgraph matching against these predefined templates to determine the type of causal graph extracted.</p>"},{"location":"notes/Research/CausalDiscovery/Papers/CELLO/#causal-task-selection","title":"Causal Task Selection","text":"<p>Select 12 tasks in 4 rungs in ladder of causation.</p> <p>Discovery (Rung 0). We include causal tasks such as causality identification (CaI, e.g., \u201cWhich of the following elements is crucial for the girl\u2019s safety?\u201d), causal attribution (CA, e.g., \u201cWhat indirectly causes the balloon\u2019s stability?\u201d), and abstract reasoning (AR, e.g., \u201cWhat is indirectly influenced by the wave\u2019s force?\u201d).</p> <p>Association (Rung 1). We consider collider bias (CB, e.g., \u201cWhy don\u2019t the balloons fly away?\u201d).</p> <p>Intervention (Rung 2). We inquire about confounder identification (CoI, e.g., \u201cWhy are the books placed steadily?\u201d), backdoor adjustment set (BAS, e.g., \u201cTo assess the relationship between the solidity of shelves and the stability of books, which of the following variables should we control for? \u201d), and controlled direct effect (CDE, e.g., \u201cIf the state of the wall is not changed and the shelves become unstable, will the books drop?\u201d).</p> <p>Counterfactual (Rung 3). We explore counterfactual scenarios such as counterfactual reasoning (CR, e.g., \u201cIf the shelf has fallen down, would the books still be placed steadily?\u201d), natural direct effect (NDE, e.g., \u201cIf the retainer of the shelf has been removed, would the books drop?\u201d), natural indirect effect (NIE, e.g., \u201cIf the shelf has been fixed to a unstable wall, would the books stay steady?\u201d), sufficient cause (SC, e.g., \u201cIf the wall has fallen down, would the books drop?\u201d), and necessary cause (NC, e.g., \u201cIf the balloons has flown away, would the woman let go?\u201d).</p>"},{"location":"notes/Research/CausalDiscovery/Papers/CELLO/#causal-question-construction","title":"Causal Question Construction","text":"<p>Question Construction : Prompt LLM to generate causal questions bt applying in-context learning.</p> <p>Follow 3 instructions:</p> <p>The demonstration provides: </p> <p>(1) Relevant descriptions, which are extracted from the dataset descriptions that are associated with the core entities. For instance, \u201cbooks are on the shelf \u201d</p> <p>(2) Causal graph, which is constructed through the process of Section 4.1. Each edge of the graph is expressed in textual form, such as \u201cshelf supports books\u201d.</p> <p>(3) Constraints, which ensure the validity of the question and prevent information leakage, such as \u201cdo not include \u2018shelf\u2019 or \u2018wall\u2019 in your generated question\u201d.</p> <p>Answer Construction: </p> <p>Two Settings: (1) Multiple-Choice Format,3 distractors and 1 correct answer. The three distractors are constructed using the entities based on the following constraints: </p> <p>(1) Irrelevant entities (Image Distractor): These entities are present in the image but absent from the causal graph, such as \u201cwindow\u201d. </p> <p>(2) Partially correct entities (Graph Distractor): These entities are present in the causal graph but only represent part of the correct answer, such as \u201cshelf\u201d. </p> <p>(3) Induced entities (Text Distractor): These entities are neither in the image nor in the causal graph but introduced solely from the question text, such as \u201cbookends\u201d. This distractor can also be seen as a object hallucination</p> <p>(2) Binary Answer : Yes or No.</p>"},{"location":"notes/Research/CausalDiscovery/Papers/Causal_Structure_Distributions/","title":"Causal Structure Distributions","text":""},{"location":"notes/Research/CausalDiscovery/Papers/Causal_Structure_Distributions/#leaning-causal-structure-distributions-for-robust-learning","title":"Leaning Causal Structure Distributions for Robust Learning","text":"<p> \u7ea6 2401 \u4e2a\u5b57  3 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 12 \u5206\u949f</p> <p>During learning we instantiate two models: one for causally-informed dynamics prediction, denoted as \\(f^D\\), and another, the contribution model \\(f^C\\), which will be used to estimate the distribution \\(\\mathcal{P}(\\textbf{p}^D)\\), from which \\(f^D\\) samples causal masks. By connecting every input feature \\(x_i\\) to every hidden neuron (and ultimately every output \\(x_{t+1}^j\\)), \\(f^C\\) ensures that no potential causal link is precluded by architectural sparsity. This \"fully wired\" design is essential: if we omitted any connection in \\(f^C\\), we could not attribute an input\u2013output pair, biasing the learned causal structure distribution. Specifically, for \\(f^C\\), we constrain all elements of the parameter vector \\(\\textbf{p}^C\\) to one, i.e.: \\(p_{ij}^C = 1\\), \u2200i, j.n$ matrix \\(\\textbf{p}\\). We estimate each element as:</p> \\[ p_{ij} := \\text{IG}_{ij}(\\mathbf{x}, \\mathbf{x}'; \\mathcal{M})  = (x_i - x'_i) \\cdot \\int_{\\alpha=0}^{1} \\frac{\\partial}{\\partial x_i} \\mathcal{M}(\\mathbf{x}' + \\alpha \\times (\\mathbf{x} - \\mathbf{x}'))_j \\, d\\alpha \\] <p>where we set the null input \\(x' = 0\\).ng</p>"},{"location":"notes/Research/CausalDiscovery/Papers/Causal_Structure_Distributions/#abstract","title":"Abstract","text":"<p>Core Idea: Learning a distribution of causal structure rather than a single causal graph,which can profoundly reduce the computation cost and make planning robust.</p>"},{"location":"notes/Research/CausalDiscovery/Papers/Causal_Structure_Distributions/#model-architecture","title":"Model Architecture","text":""},{"location":"notes/Research/CausalDiscovery/Papers/Causal_Structure_Distributions/#supplementary-knowledge","title":"Supplementary Knowledge","text":"<p>Integrated Gradients for Feature Attribution</p> <p>Feature Attribution involves determining how each element of the input of a deep neural network contributed to its final prediction.</p> <p>IG takes two inputs. The first one, x, is the value for which we want to carry out FA. The second one, x\u2032, which we called the null input, is used as a reference input with respect to which FA takes place. Specifically, the null input x\u2032 is chosen so that whenever it is fed to a model M the output from the model is approximately zero.   Usually,We\u2019ll take x\u2019 as zero vector.</p> <p>IG produces an attribution vector a \u2208 \\(R^D\\), defined as IG(x, x\u2032; M) = a where each element \\(a_i\\) of a quantifies the contribution of the i-th feature in the input x to the prediction made by the model M.   </p>"},{"location":"notes/Research/CausalDiscovery/Papers/Causal_Structure_Distributions/#methods","title":"Methods","text":""},{"location":"notes/Research/CausalDiscovery/Papers/Causal_Structure_Distributions/#modeling-the-scm-distribution","title":"Modeling the SCM Distribution","text":"<p>We take the Markov Chain as DAG. Specifically,we have state variables and action variables of the current time state t,and we have the state variables of the next timestep. The arrows can only flow from exogenous variables(that is state and action) to endogenous variables(state).</p> <p>If there are n state variables and p action variables, we have an \\((n+p) \\times n\\) matrix,where position i,j represents the causal relation from i to j. $$ E_{i,j} = \\left{ \\begin{array}{ll} 1 &amp; \\text{if there exists an edge from row i to column j }  \\ 0 &amp; \\text{o.w. } \\end{array} \\right. $$ Each \\(E_{i,j}\\) follows a Bernoulli distribution with parameter \\(p_{i,j}\\). Thus , the probability mass function(PMF) can be given by:</p> <p>\\(Pr(E_{i,j}=e_{i,j}) = p_{ij}^{e_{ij}}(1-p_{ij})^{1-e_{ij}}, \\text{ for } e_{i,j} \\in \\{0,1\\}\\)</p> <p>Since the existence of an edge from one node to another is independent from other non-related variables, the joint PMF:</p> <p>\\(Pr(\\{E_{i,j}=e_{i,j}\\},\\textbf{p}) = \\prod_{i,j}p_{ij}^{e_{i,j}}(1-p_{ij})^{1-e_{ij}}\\) where \\(\\textbf{p}=(p_{ij})\\) is the matrix of Bernoulli parameters.</p>"},{"location":"notes/Research/CausalDiscovery/Papers/Causal_Structure_Distributions/#estimating-the-scm-distribution-parameters-p","title":"Estimating the SCM Distribution Parameters p","text":"<p>Although IG was not designed as a causality test, we use it to estimate the likelihood of each feature being a cause in the underlying SCM, as comparing against a null input x\u2032 (which is the key in the IG method) involves implicitly \u201cassign(ing) blame to a certain cause\u201d . That is, causal influence can be measured from the effect of \u201cperturbing\u201d(intervening) a parent on its child while holding others fixed. IG\u2019s construction\u2014integrating gradients from a null input\u2014provides an efficient approximation of that effect without resorting to combinatorial graph search.  </p> <p>Using IG, we construct the \\((n+p)\\times n\\) matrix \\(\\textbf{p}\\) . We estimate each element as:</p> <p>$  p_{ij} := \\text{IG}{ij}(\\mathbf{x}, \\mathbf{x}'; \\mathcal{M})  \\ = (x_i - x'_i) \\cdot \\int'))_j \\, d\\alpha,}^{1} \\frac{\\partial}{\\partial x_i} \\mathcal{M}(\\mathbf{x}' + \\alpha \\times (\\mathbf{x} - \\mathbf{x $ where we set the null input x\u2019 = 0</p> <p>We then interpret each \\(p_{ij}\\) as a score proportional to the (unnormalized) probability that feature \\(x_t^i\\) or \\(a_t^i\\) is a cause of the output \\(x_{t+1}^j\\). Concretely, we normalize across all candidate parents to obtain the Bernoulli parameters \\(\\textbf{p} = (p_{ij})\\) for the distribution \\(\\mathcal{P}\\):</p> \\[ p_{ij} = \\max \\left( \\rho_{\\min}, \\min \\left( \\frac{\\mathbf{s}(|p_{i,j}|)}{\\max_j \\mathbf{s}(|p_{:,j}|)}, 1 - \\rho_{\\min} \\right) \\right) \\] <p>\\(s(\\cdot)\\) is a smoothing function to avoid one contribution from significantly out-weighting the others and \\(0 &lt; \\rho_{\\min} &lt; 0.5\\) clips the minimum and maximum probability.</p>"},{"location":"notes/Research/CausalDiscovery/Papers/Causal_Structure_Distributions/#probabilistic-neural-network","title":"Probabilistic Neural Network","text":"\\[ f^D := f(\\mathbf{x}) = f_{\\text{dec}}(f_{\\text{enc}}(\\mathbf{x}) \\odot \\mathbf{M}), \\quad \\mathbf{M} \\sim \\mathcal{P}(\\mathbf{p}) \\] <p>which encompasses:</p> <ul> <li> <p>Encoder: Let \\(\\mathbf{s} \\in \\mathbb{R}^n\\) be the vector of state variables and \\(\\mathbf{a} \\in \\mathbb{R}^p\\) be the vector of action variables. Define the concatenated input vector: \\(\\mathbf{x} = [\\mathbf{s}; \\mathbf{a}] \\in \\mathbb{R}^{n+p}\\). The encoder \\(f_{\\text{enc}}: \\mathbb{R}^{n+p} \\rightarrow \\mathbb{R}^{n+p}\\) maps this input into a latent space of the same dimension: \\(\\mathbf{z} = f_{\\text{enc}}(\\mathbf{x}) \\in \\mathbb{R}^{n+p}\\).</p> </li> <li> <p>Latent Vector Masking: Let \\(\\mathbf{M} \\in \\{0,1\\}^{(n+p) \\times n}\\) be the mask matrix sampled from the learned distribution \\(\\mathcal{P}\\). Each element \\(M_{ij}\\) indicates the presence or absence of an edge from the \\(i\\)-th latent feature to the \\(j\\)-th next state variable. Define the masking process as: \\(\\(\\mathbf{z}_j = \\mathbf{z} \\odot \\mathbf{m}_{:,j} \\quad \\text{for } j = 1, 2, \\ldots, n\\)\\)   where \\(\\mathbf{m}_{:,j}\\) is the \\(j\\)-th column of \\(\\mathbf{M}\\) and \\(\\odot\\) denotes element-wise multiplication. By masking we select the latent features to use for predicting each next state variable. Note that \\(\\mathbf{M} \\sim \\mathcal{P}(\\mathbf{p})\\) is sampled every time \\(f(\\cdot)\\) is called.</p> </li> <li> <p>Decoder: Each masked vector \\(\\mathbf{z}_j\\) is fed to the corresponding decoder \\(f_{\\text{dec}}^j: \\mathbb{R}^{n+p} \\rightarrow \\mathbb{R}^2\\), which outputs the parameters of a Gaussian distribution for the next state variable: \\((\\mu_j, \\sigma_j^2) = f_{\\text{dec}}^j(\\mathbf{z}_j)\\). The next state variable \\(s'_j\\) is then: \\(s'_j \\sim \\mathcal{N}(\\mu_j, \\sigma_j^2)\\). This way we account for the aleatoric uncertainty due to unexpected and un-modeled disturbances into the prediction.</p> </li> </ul> <p>**Training &amp; Inference. **</p> <p>During learning we instantiate two models : one for causally-informed dynamics prediction, denoted as \\(f^D\\), and another, the contribution model \\(f^C\\), which will be used to estimate the distribution \\(\\mathcal{P}\\)(\\(\\textbf{p}^D\\)), from which \\(f^D\\) samples causal masks. By connecting every input feature \\(x_i\\) to every hidden neuron (and ultimately every output \\({x_{t+1}^j}\\), \\(f^C\\) ensures that no potential causal link is precluded by architectural sparsity. This \u201cfully wired\" design is essential: if we omitted any connection in \\(f^C\\), we could not attribute an input\u2013output pair, biasing the learned causalstructure distribution. Specifically, for \\(f^C\\), we constrain all elements of the parameter vector \\(\\textbf{p}^C\\) to one, i.e.: \\(p_{ij}^C = 1\\) , \u2200i, j. </p> <p>This configuration ensures that all input variables to \\(f^C\\) remain active during latent vector masking, thereby simulating a scenario in which all inputs are treated as causes of all output variables.</p> <p>The training procedure follows a sequential approach. First, we train \\(f^C\\) using the available dataset D. Once trained, we employ \\(f^C\\) as the model IG will use to compute an estimate of \\(p^D\\) and subsequently transforming each element \\(p_{ij} \\in p^D\\). The resulting parameter vector \\(p^D\\) then defines the distribution from which the causal masks M are sampled during the training of \\(f^D\\) with the data in D.</p> <p>At inference time, \\(f^C\\) is discarded, and the final learned value of \\(p^D\\) is employed to parameterize the causal mask distribution P(\\(p^D\\)), ensuring that the causal relationships inferred during training are preserved in deployment.</p>"},{"location":"notes/Research/CausalDiscovery/Papers/Causal_Structure_Distributions/#symbol-analysis","title":"Symbol Analysis","text":"<p>1\ufe0f\u20e3 \\( f^C \\)\uff08Contribution Model\uff09</p> <ul> <li>\u5b9a\u4e49\uff1a \\( f^C \\) \u662f\u4e00\u4e2a\u5168\u8fde\u63a5\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8e\u4f30\u8ba1\u8bad\u7ec3\u65f6\u8f93\u5165\u53d8\u91cf\uff08\u5f53\u524d\u72b6\u6001 \\( s_t \\) \u548c\u63a7\u5236\u8f93\u5165 \\( a_t \\)\uff09\u5bf9\u8f93\u51fa\u53d8\u91cf\uff08\u4e0b\u4e00\u72b6\u6001 \\( s_{t+1} \\)\uff09\u7684\u56e0\u679c\u8d21\u732e\u3002</li> <li>\u4f5c\u7528\uff1a  </li> <li>\u65e0\u504f\u4f30\u8ba1\u56e0\u679c\u8d21\u732e\uff1a\u901a\u8fc7\u5168\u8fde\u63a5\u7684\u8bbe\u8ba1\uff0c\u786e\u4fdd\u6bcf\u4e2a\u8f93\u5165\u53d8\u91cf\u90fd\u6709\u673a\u4f1a\u5bf9\u6bcf\u4e2a\u8f93\u51fa\u53d8\u91cf\u4ea7\u751f\u5f71\u54cd\uff0c\u907f\u514d\u9057\u6f0f\u4efb\u4f55\u6f5c\u5728\u7684\u56e0\u679c\u5173\u7cfb\u3002</li> <li>\u7ed3\u6784\uff1a  </li> <li>\u8f93\u5165\uff1a\u5f53\u524d\u72b6\u6001 \\( s_t \\) \u548c\u63a7\u5236\u8f93\u5165 \\( a_t \\) \u7684\u62fc\u63a5 \\([s_t; a_t]\\)\u3002</li> <li>\u8f93\u51fa\uff1a\u4e00\u4e2a\u6982\u7387\u77e9\u9635 \\( p^C \\)\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5143\u7d20 \\( p^C_{ij} \\) \u8868\u793a\u4ece\u8f93\u5165\u53d8\u91cf \\( i \\) \u5230\u8f93\u51fa\u53d8\u91cf \\( j \\) \u7684\u56e0\u679c\u8fb9\u5b58\u5728\u7684\u6982\u7387\u3002</li> <li>\u8bad\u7ec3\uff1a  </li> <li>\u4f7f\u7528\u5b8c\u6574\u7684\u6570\u636e\u96c6\u8bad\u7ec3 \\( f^C \\)\uff0c\u786e\u4fdd\u6240\u6709\u53ef\u80fd\u7684\u56e0\u679c\u8def\u5f84\u90fd\u88ab\u8003\u8651\u3002</li> <li>\u8bad\u7ec3\u5b8c\u6210\u540e\uff0c\\( f^C \\)\u88ab\u629b\u5f03\u3002</li> </ul> <p>2\ufe0f\u20e3 \\( p^C \\)</p> <ul> <li> <p>\u5b9a\u4e49\uff1a \\( p^C \\) \u662f\u4e00\u4e2a\u6982\u7387\u77e9\u9635\uff0c\u8868\u793a\u4ece\u8f93\u5165\u53d8\u91cf\u5230\u8f93\u51fa\u53d8\u91cf\u7684\u56e0\u679c\u8fb9\u5b58\u5728\u7684\u6982\u7387\u3002</p> </li> <li> <p>\u4f5c\u7528\uff1a  </p> </li> <li>\u65e0\u504f\u4f30\u8ba1\uff1a\u5728\u8bad\u7ec3 \\( f^C \\) \u65f6\uff0c\\( p^C \\) \u7684\u6240\u6709\u5143\u7d20\u90fd\u88ab\u8bbe\u7f6e\u4e3a 1\uff0c\u786e\u4fdd\u6240\u6709\u8f93\u5165\u53d8\u91cf\u90fd\u53c2\u4e0e\u5bf9\u6bcf\u4e2a\u8f93\u51fa\u53d8\u91cf\u7684\u9884\u6d4b\u3002</li> <li> <p>\u751f\u6210 \\( p^D \\)\uff1a\u901a\u8fc7 IG \u65b9\u6cd5\u8ba1\u7b97\u6bcf\u4e2a\u8f93\u5165\u53d8\u91cf\u5bf9\u6bcf\u4e2a\u8f93\u51fa\u53d8\u91cf\u7684\u8d21\u732e\uff0c\u751f\u6210\u6700\u7ec8\u7684\u56e0\u679c\u6982\u7387\u77e9\u9635 \\( p^D \\)\u3002</p> </li> <li> <p>\u5177\u4f53\u5f62\u5f0f\uff1a  </p> </li> <li>\\( p^C \\) \u662f\u4e00\u4e2a (n+p) \u00d7 n \u7684\u77e9\u9635\uff0c\u5176\u4e2d n \u662f\u72b6\u6001\u53d8\u91cf\u7684\u7ef4\u5ea6\uff0cp \u662f\u63a7\u5236\u8f93\u5165\u7684\u7ef4\u5ea6\u3002</li> <li>\u6bcf\u4e2a\u5143\u7d20 \\( p^C_{ij} \\) \u8868\u793a\u4ece\u8f93\u5165\u53d8\u91cf \\( i \\) \u5230\u8f93\u51fa\u53d8\u91cf \\( j \\) \u7684\u56e0\u679c\u8fb9\u5b58\u5728\u7684\u6982\u7387\u3002</li> </ul> <p>3\ufe0f\u20e3 \\( f^D \\)\uff08Dynamics Model\uff09</p> <ul> <li> <p>\u5b9a\u4e49\uff1a \\( f^D \\) \u662f\u4e00\u4e2a\u6982\u7387\u7f16\u7801\u5668-\u591a\u89e3\u7801\u5668\u67b6\u6784\uff0c\u7528\u4e8e\u6839\u636e\u4f30\u8ba1\u7684\u56e0\u679c\u7ed3\u6784\u5206\u5e03 \\( P(p^D) \\) \u9884\u6d4b\u4e0b\u4e00\u72b6\u6001\u7684\u6982\u7387\u5206\u5e03\u3002</p> </li> <li> <p>\u4f5c\u7528\uff1a  </p> </li> <li>\u52a8\u529b\u5b66\u5efa\u6a21\uff1a\u6839\u636e\u91c7\u6837\u7684\u56e0\u679c\u63a9\u7801\u77e9\u9635 \\( M \\)\uff0c\u4ece\u6f5c\u5728\u7a7a\u95f4\u4e2d\u9009\u62e9\u4e0e\u56e0\u679c\u7ed3\u6784\u76f8\u5173\u7684\u7279\u5f81\uff0c\u9884\u6d4b\u4e0b\u4e00\u72b6\u6001\u7684\u6982\u7387\u5206\u5e03\u3002</li> <li> <p>\u9c81\u68d2\u6027\u589e\u5f3a\uff1a\u901a\u8fc7\u8003\u8651\u56e0\u679c\u7ed3\u6784\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u589e\u5f3a\u6a21\u578b\u5728\u9762\u5bf9\u566a\u58f0\u3001\u7f3a\u5931\u6570\u636e\u548c\u52a8\u6001\u53d8\u5316\u65f6\u7684\u9c81\u68d2\u6027\u3002</p> </li> <li> <p>\u7ed3\u6784\uff1a  </p> </li> <li>\u7f16\u7801\u5668\uff08Encoder\uff09\uff1a\u5c06\u8f93\u5165 \\([s_t; a_t]\\) \u6620\u5c04\u5230\u6f5c\u5728\u7a7a\u95f4 \\( z \\)\u3002</li> <li>\u6f5c\u5728\u7a7a\u95f4\u63a9\u7801\uff08Latent Masking\uff09\uff1a\u4ece\u56e0\u679c\u7ed3\u6784\u5206\u5e03 \\( P(p^D) \\) \u4e2d\u91c7\u6837\u4e00\u4e2a\u63a9\u7801\u77e9\u9635 \\( M \\)\uff0c\u5bf9\u6f5c\u5728\u5411\u91cf \\( z \\) \u8fdb\u884c\u9010\u7ef4\u5ea6\u63a9\u7801\u3002</li> <li> <p>\u591a\u89e3\u7801\u5668\uff08Multidecoder\uff09\uff1a\u6bcf\u4e2a\u8f93\u51fa\u7ef4\u5ea6\u5bf9\u5e94\u4e00\u4e2a\u72ec\u7acb\u7684\u89e3\u7801\u5668\uff0c\u8f93\u51fa\u4e00\u4e2a\u9ad8\u65af\u5206\u5e03\u7684\u53c2\u6570\uff08\u5747\u503c\u548c\u65b9\u5dee\uff09\uff0c\u5373 \\( s_{t+1}^j \\sim \\mathcal{N}(\\mu_j, \\sigma_j^2) \\)\u3002</p> </li> <li> <p>\u8bad\u7ec3\uff1a  </p> </li> <li>\u4f7f\u7528 \\( p^D \\) \u4ece \\( f^C \\) \u4e2d\u751f\u6210\u7684\u56e0\u679c\u6982\u7387\u77e9\u9635\uff0c\u8bad\u7ec3 \\( f^D \\)\u3002</li> <li>\u5728\u6bcf\u6b21\u524d\u5411\u4f20\u64ad\u65f6\uff0c\u4ece \\( P(p^D) \\) \u4e2d\u91c7\u6837\u4e00\u4e2a\u63a9\u7801\u77e9\u9635 \\( M \\)\uff0c\u7528\u4e8e\u6307\u5bfc\u6f5c\u5728\u7a7a\u95f4\u7684\u8868\u793a\u3002</li> </ul> <p>4\ufe0f\u20e3 \\( p^D \\)</p> <ul> <li> <p>\u5b9a\u4e49\uff1a \\( p^D \\) \u662f\u4e00\u4e2a\u6982\u7387\u77e9\u9635\uff0c\u8868\u793a\u4ece\u8f93\u5165\u53d8\u91cf\u5230\u8f93\u51fa\u53d8\u91cf\u7684\u56e0\u679c\u8fb9\u5b58\u5728\u7684\u6982\u7387\uff0c\u7528\u4e8e \\( f^D \\) \u7684\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u3002</p> </li> <li> <p>\u4f5c\u7528\uff1a  </p> </li> <li>\u56e0\u679c\u7ed3\u6784\u5206\u5e03\uff1a\\( p^D \\) \u5b9a\u4e49\u4e86\u4e00\u4e2a\u56e0\u679c\u7ed3\u6784\u5206\u5e03 \\( P(p^D) \\)\uff0c\u4ece\u4e2d\u53ef\u4ee5\u91c7\u6837\u56e0\u679c\u63a9\u7801\u77e9\u9635 \\( M \\)\u3002</li> <li>\u6307\u5bfc \\( f^D \\) \u7684\u8bad\u7ec3\uff1a\u5728\u8bad\u7ec3 \\( f^D \\) \u65f6\uff0c\u4ece \\( P(p^D) \\) \u4e2d\u91c7\u6837\u63a9\u7801\u77e9\u9635 \\( M \\)\uff0c\u7528\u4e8e\u6f5c\u5728\u7a7a\u95f4\u7684\u63a9\u7801\u64cd\u4f5c\u3002</li> <li> <p>\u63a8\u7406\u9636\u6bb5\uff1a\u5728\u63a8\u7406\u9636\u6bb5\uff0c\u4f7f\u7528\u56fa\u5b9a\u7684 \\( p^D \\) \u4ece \\( P(p^D) \\) \u4e2d\u91c7\u6837\u63a9\u7801\u77e9\u9635 \\( M \\)\uff0c\u7528\u4e8e\u9884\u6d4b\u4e0b\u4e00\u72b6\u6001\u3002</p> </li> <li> <p>\u5177\u4f53\u5f62\u5f0f\uff1a  </p> </li> <li>\\( p^D \\) \u662f\u4e00\u4e2a (n+p) \u00d7 n \u7684\u77e9\u9635\uff0c\u5176\u4e2d n \u662f\u72b6\u6001\u53d8\u91cf\u7684\u7ef4\u5ea6\uff0cp \u662f\u63a7\u5236\u8f93\u5165\u7684\u7ef4\u5ea6\u3002</li> <li>\u6bcf\u4e2a\u5143\u7d20 \\( p^D_{ij} \\) \u8868\u793a\u4ece\u8f93\u5165\u53d8\u91cf \\( i \\) \u5230\u8f93\u51fa\u53d8\u91cf \\( j \\) \u7684\u56e0\u679c\u8fb9\u771f\u5b9e\u5b58\u5728\u7684\u6982\u7387\u3002</li> </ul>"},{"location":"notes/Research/CausalDiscovery/Papers/Causal_Structure_Distributions/#_1","title":"\u603b\u7ed3","text":"\u7b26\u53f7 \u5b9a\u4e49 \u4f5c\u7528 \\( f^C \\) \u5168\u8fde\u63a5\u7684\u8d21\u732e\u6a21\u578b \u4f30\u8ba1\u8f93\u5165\u53d8\u91cf\u5bf9\u8f93\u51fa\u53d8\u91cf\u7684\u56e0\u679c\u8d21\u732e\uff0c\u751f\u6210 \\( p^C \\) \\( p^C \\) \u56e0\u679c\u6982\u7387\u77e9\u9635 \u56fa\u5b9a\u4e3a\u51681\u77e9\u9635\uff0c\u7528\u4e8e\u8bad\u7ec3 \\( f^C \\)\uff0c\u751f\u6210 \\( p^D \\) \\( f^D \\) \u52a8\u529b\u5b66\u6a21\u578b\uff08\u6982\u7387\u7f16\u7801\u5668-\u591a\u89e3\u7801\u5668\uff09 \u6839\u636e \\( p^D \\) \u91c7\u6837\u7684\u56e0\u679c\u63a9\u7801\u77e9\u9635 \\( M \\) \u9884\u6d4b\u4e0b\u4e00\u72b6\u6001\u7684\u6982\u7387\u5206\u5e03 \\( p^D \\) \u56e0\u679c\u6982\u7387\u77e9\u9635 \u5b9a\u4e49\u56e0\u679c\u7ed3\u6784\u5206\u5e03 \\( P(p^D) \\)\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u7684 \\( f^D \\)"},{"location":"notes/Research/CausalDiscovery/Papers/Llava/","title":"Llava","text":""},{"location":"notes/Research/CausalDiscovery/Papers/Llava/#llava-visual-instruction-tuning","title":"Llava\u8bba\u6587: Visual Instruction Tuning","text":"<p> \u7ea6 54 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"notes/Research/CausalDiscovery/Papers/Llava/#architecture","title":"Architecture","text":"<p>Use GPT4 to generate dataset with VQA.As GPT4 is a purely languange model,we take captions and bounding boxes as the input to GPT,and thus generate 3 types of Q-A pairs. They're like \\(\\textbf{X}_q \\ \\textbf{X}_v\\text{&lt;STOP&gt; Assistant:} \\textbf{X}_C \\text{&lt;STOP&gt;}\\) </p> <p></p>"},{"location":"notes/Research/CausalDiscovery/Papers/Towards%20Causal%20Representation%20Learning/","title":"Causal Representation Learning","text":""},{"location":"notes/Research/CausalDiscovery/Papers/Towards%20Causal%20Representation%20Learning/#towards-causal-reprensentation-learning","title":"Towards Causal Reprensentation Learning","text":"<p> \u7ea6 1520 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 8 \u5206\u949f</p> <p>\u77e5\u4e4e\u89e3\u8bfb1</p> <p>\u77e5\u4e4e\u89e3\u8bfb2</p> <p>\u5fae\u4fe1\u516c\u4f17\u53f7\u89e3\u8bfb</p> <p>\u5728\u8bba\u6587\u4e2d\uff0c\u72ec\u7acb\u56e0\u679c\u673a\u5236\uff08ICM\uff09\u539f\u5219\u548c\u7a00\u758f\u673a\u5236\u504f\u79fb\uff08SMS\uff09\u5047\u8bbe\u662f\u8fde\u63a5\u56e0\u679c\u63a8\u7406\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u6838\u5fc3\u7406\u8bba\u57fa\u7840\uff0c\u4e8c\u8005\u5171\u540c\u6784\u6210\u4e86\u56e0\u679c\u8868\u5f81\u5b66\u4e60\u548c\u8de8\u5206\u5e03\u6cdb\u5316\u7684\u5173\u952e\u903b\u8f91\u3002\u4ee5\u4e0b\u662f\u8bba\u6587\u5bf9\u8fd9\u4e24\u4e2a\u6982\u5ff5\u7684\u8be6\u7ec6\u9610\u8ff0\uff1a</p>"},{"location":"notes/Research/CausalDiscovery/Papers/Towards%20Causal%20Representation%20Learning/#icm","title":"\u4e00\u3001\u72ec\u7acb\u56e0\u679c\u673a\u5236\uff08ICM\uff09\u539f\u5219","text":"<p>\u8bba\u6587\u7b2c\u56db\u8282\u91cd\u70b9\u9610\u8ff0\u4e86ICM\u539f\u5219\uff0c\u5c06\u5176\u5b9a\u4e49\u4e3a\u56e0\u679c\u63a8\u7406\u7684\u6838\u5fc3\u5f52\u7eb3\u504f\u7f6e\uff0c\u5177\u4f53\u5185\u5bb9\u5982\u4e0b\uff1a  </p>"},{"location":"notes/Research/CausalDiscovery/Papers/Towards%20Causal%20Representation%20Learning/#1","title":"1. \u5b9a\u4e49\u4e0e\u6838\u5fc3\u601d\u60f3","text":"<p>ICM\u539f\u5219\u6307\u51fa\uff1a\u4e00\u4e2a\u7cfb\u7edf\u7684\u56e0\u679c\u751f\u6210\u8fc7\u7a0b\u7531\u591a\u4e2a\u81ea\u4e3b\u6a21\u5757\uff08\u673a\u5236\uff09\u7ec4\u6210\uff0c\u8fd9\u4e9b\u6a21\u5757\u4e4b\u95f4\u4e0d\u4f1a\u76f8\u4e92\u5f71\u54cd\u6216\u4f20\u9012\u4fe1\u606f\u3002\u5728\u6982\u7387\u6846\u67b6\u4e0b\uff0c\u8fd9\u610f\u5473\u7740\u201c\u6bcf\u4e2a\u53d8\u91cf\u7ed9\u5b9a\u5176\u539f\u56e0\u7684\u6761\u4ef6\u5206\u5e03\uff08\u5373\u673a\u5236\uff09\u4e0e\u5176\u4ed6\u673a\u5236\u65e0\u5173\u201d\u3002  </p> <ul> <li>\u76f4\u89c2\u7406\u89e3\uff1a\u4f8b\u5982\uff0c\u7269\u4f53\u7684\u201c\u5f62\u72b6\u201d\u548c\u201c\u5149\u7167\u201d\u662f\u4e24\u4e2a\u72ec\u7acb\u673a\u5236\uff0c\u6539\u53d8\u5149\u7167\uff08\u5982\u660e\u6697\u53d8\u5316\uff09\u4e0d\u4f1a\u5f71\u54cd\u7269\u4f53\u672c\u8eab\u7684\u5f62\u72b6\u751f\u6210\u673a\u5236\uff1b\u53cd\u4e4b\uff0c\u6539\u53d8\u7269\u4f53\u5f62\u72b6\u4e5f\u4e0d\u4f1a\u5f71\u54cd\u5149\u7167\u7684\u7269\u7406\u89c4\u5f8b\u3002  </li> <li>\u6982\u7387\u8868\u8ff0\uff1a\u5bf9\u4e8e\u56e0\u679c\u5206\u89e3 \\( P(X_1,...,X_n) = \\prod_{i=1}^n P(X_i | PA_i) \\)\uff08\u5176\u4e2d \\( PA_i \\) \u662f \\( X_i \\) \u7684\u7236\u8282\u70b9\uff09\uff0cICM\u8981\u6c42\u5404\u56e0\u5b50 \\( P(X_i | PA_i) \\) \u76f8\u4e92\u72ec\u7acb\u2014\u2014\u65e2\u4e0d\u4f1a\u56e0\u5176\u4ed6\u673a\u5236\u7684\u6539\u53d8\u800c\u53d8\u5316\uff0c\u4e5f\u65e0\u6cd5\u901a\u8fc7\u5176\u4ed6\u673a\u5236\u63a8\u65ad\u81ea\u8eab\u4fe1\u606f\u3002  </li> </ul>"},{"location":"notes/Research/CausalDiscovery/Papers/Towards%20Causal%20Representation%20Learning/#2","title":"2. \u4e24\u4e2a\u5173\u952e\u5185\u6db5","text":"<p>\u8bba\u6587\u660e\u786eICM\u539f\u5219\u5305\u542b\u4e24\u65b9\u9762\uff1a - \uff08a\uff09\u673a\u5236\u7684\u72ec\u7acb\u6027\u5e72\u9884\uff1a\u6539\u53d8\u4e00\u4e2a\u673a\u5236\uff08\u5982\u5e72\u9884 \\( P(X_i | PA_i) \\)\uff09\u4e0d\u4f1a\u5f71\u54cd\u5176\u4ed6\u673a\u5236\uff08\u5982 \\( P(X_j | PA_j), j \\neq i \\)\uff09\u3002\u4f8b\u5982\uff0c\u5e72\u9884\u201c rainfall \u2192 umbrella\u201d\u673a\u5236\uff08\u5982\u5f3a\u5236\u6240\u6709\u4eba\u5e26\u4f1e\uff09\u4e0d\u4f1a\u6539\u53d8\u201crainfall \u2192 wet ground\u201d\u673a\u5236\u3002 - \uff08b\uff09\u673a\u5236\u7684\u4fe1\u606f\u72ec\u7acb\u6027\uff1a\u77e5\u9053\u5176\u4ed6\u673a\u5236\u7684\u4fe1\u606f\uff08\u5982 \\( P(X_i | PA_i) \\)\uff09\u65e0\u6cd5\u5e2e\u52a9\u63a8\u65ad\u67d0\u4e2a\u673a\u5236\uff08\u5982 \\( P(X_j | PA_j) \\)\uff09\u3002\u4f8b\u5982\uff0c\u901a\u8fc7\u201c\u4f1e\u7684\u4f7f\u7528\u9891\u7387\u201d\u65e0\u6cd5\u63a8\u65ad\u201c\u964d\u96e8\u5bfc\u81f4\u5730\u9762\u6f6e\u6e7f\u201d\u7684\u7269\u7406\u89c4\u5f8b\u3002  </p>"},{"location":"notes/Research/CausalDiscovery/Papers/Towards%20Causal%20Representation%20Learning/#3","title":"3. \u7406\u8bba\u57fa\u7840\u4e0e\u4f8b\u5b50","text":"<ul> <li>\u89c6\u89c9\u611f\u77e5\uff1a\u5927\u8111\u9ed8\u8ba4\u201c\u7269\u4f53\u672c\u8eab\u201d\u4e0e\u201c\u89c2\u6d4b\u89c6\u89d2/\u5149\u7167\u201d\u662f\u72ec\u7acb\u673a\u5236\uff0c\u8fd9\u4e00\u5047\u8bbe\u652f\u6491\u4e86\u201c\u4ece\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\u201d\uff08\u5982\u901a\u8fc7\u591a\u89d2\u5ea6\u89c2\u5bdf\u63a8\u65ad3D\u5f62\u72b6\uff09\uff0c\u4e5f\u662f\u201c\u901a\u7528\u89c6\u89d2\u5047\u8bbe\u201d\uff08\u907f\u514d\u5149\u5b66\u9519\u89c9\uff09\u7684\u57fa\u7840\u3002  </li> <li>** altitude-temperature \u6848\u4f8b**\uff1a\u6d77\u62d4\uff08A\uff09\u4e0e\u6e29\u5ea6\uff08T\uff09\u7684\u56e0\u679c\u5173\u7cfb\u4e2d\uff0c\\( P(T | A) \\) \u53cd\u6620\u201c\u6d77\u62d4\u5f71\u54cd\u6e29\u5ea6\u201d\u7684\u7269\u7406\u673a\u5236\uff08\u5982\u6bcf\u5347\u9ad8100\u7c73\u6e29\u5ea6\u964d0.6\u2103\uff09\uff0c\u8fd9\u4e00\u673a\u5236\u5728\u5965\u5730\u5229\u548c\u745e\u58eb\u662f\u4e00\u81f4\u7684\uff0c\u800c\u8fb9\u9645\u5206\u5e03 \\( P(A) \\)\uff08\u6d77\u62d4\u5206\u5e03\uff09\u53ef\u80fd\u4e0d\u540c\u3002ICM\u539f\u5219\u786e\u4fdd \\( P(T | A) \\) \u4f5c\u4e3a\u72ec\u7acb\u673a\u5236\u53ef\u8de8\u5730\u533a\u590d\u7528\uff0c\u800c\u7ea0\u7f20\u5206\u89e3\uff08\u5982 \\( P(A | T) \\)\uff09\u5219\u4e0d\u5177\u5907\u8fd9\u79cd\u7a33\u5065\u6027\u3002  </li> <li>\u5386\u53f2\u5173\u8054\uff1aICM\u539f\u5219\u6574\u5408\u4e86Haavelmo\uff081944\uff09\u7684\u201c\u7ed3\u6784\u65b9\u7a0b\u4e0d\u53d8\u6027\u201d\u3001Simon\uff081953\uff09\u7684\u201c\u5e72\u9884\u4e0b\u7684\u56e0\u679c\u5e8f\u4e0d\u53d8\u6027\u201d\u7b49\u601d\u60f3\uff0c\u7edf\u4e00\u4e86\u201c\u6a21\u5757\u6027\u201d\u201c\u81ea\u4e3b\u6027\u201d\u201c\u4e0d\u53d8\u6027\u201d\u7b49\u6982\u5ff5\u3002  </li> </ul>"},{"location":"notes/Research/CausalDiscovery/Papers/Towards%20Causal%20Representation%20Learning/#4","title":"4. \u7b97\u6cd5\u72ec\u7acb\u6027\uff08\u8865\u5145\uff09","text":"<p>\u8bba\u6587\u8fdb\u4e00\u6b65\u7528\u67ef\u5c14\u83ab\u54e5\u6d1b\u592b\u590d\u6742\u5ea6\uff08\u7b97\u6cd5\u4fe1\u606f\u8bba\uff09\u89e3\u91caICM\uff1a\u82e5\u5c06\u6bcf\u4e2a\u673a\u5236\u7f16\u7801\u4e3a\u6bd4\u7279\u4e32\uff0cICM\u8981\u6c42\u8fd9\u4e9b\u6bd4\u7279\u4e32\u7684\u8054\u5408\u538b\u7f29\u957f\u5ea6\u7b49\u4e8e\u5404\u81ea\u538b\u7f29\u957f\u5ea6\u4e4b\u548c\uff08\u5373\u65e0\u4e92\u4fe1\u606f\uff09\u3002\u8fd9\u8868\u660e\u56e0\u679c\u673a\u5236\u7684\u72ec\u7acb\u6027\u4e0d\u4ec5\u662f\u7edf\u8ba1\u5c42\u9762\u7684\uff0c\u66f4\u662f\u7b97\u6cd5\u5c42\u9762\u7684\u201c\u4e0d\u53ef\u538b\u7f29\u5173\u8054\u201d\u3002  </p>"},{"location":"notes/Research/CausalDiscovery/Papers/Towards%20Causal%20Representation%20Learning/#sms","title":"\u4e8c\u3001\u7a00\u758f\u673a\u5236\u504f\u79fb\uff08SMS\uff09\u5047\u8bbe","text":"<p>SMS\u662fICM\u539f\u5219\u7684\u76f4\u63a5\u63a8\u8bba\uff0c\u8bba\u6587\u5c06\u5176\u4f5c\u4e3a\u89e3\u91ca\u201c\u56e0\u679c\u6a21\u578b\u4e3a\u4f55\u652f\u6301\u8de8\u5206\u5e03\u6cdb\u5316\u201d\u7684\u6838\u5fc3\u903b\u8f91\uff0c\u5177\u4f53\u5185\u5bb9\u5982\u4e0b\uff1a  </p>"},{"location":"notes/Research/CausalDiscovery/Papers/Towards%20Causal%20Representation%20Learning/#1_1","title":"1. \u5b9a\u4e49\u4e0e\u6838\u5fc3\u601d\u60f3","text":"<p>SMS\u5047\u8bbe\uff1a\u5206\u5e03\u7684\u5fae\u5c0f\u53d8\u5316\uff08\u5982\u4ece\u4e00\u4e2a\u73af\u5883\u5230\u53e6\u4e00\u4e2a\u73af\u5883\uff09\u901a\u5e38\u4ee5\u7a00\u758f\u6216\u5c40\u90e8\u7684\u65b9\u5f0f\u4f53\u73b0\u5728\u56e0\u679c\u5206\u89e3\u4e2d\uff0c\u5373\u4ec5\u5f71\u54cd\u5c11\u6570\u673a\u5236\uff0c\u800c\u975e\u6240\u6709\u673a\u5236\u3002  </p> <ul> <li>\u5bf9\u6bd4\u975e\u56e0\u679c\u5206\u89e3\uff1a\u5728\u7ea0\u7f20\u5206\u89e3\uff08\u5982 \\( P(X_1,...,X_n) = \\prod_{i=1}^n P(X_i | X_{i+1},...,X_n) \\)\uff09\u4e2d\uff0c\u5355\u4e00\u673a\u5236\u7684\u53d8\u5316\u53ef\u80fd\u5bfc\u81f4\u591a\u4e2a\u56e0\u5b50\u540c\u65f6\u6539\u53d8\uff08\u56e0\u53d8\u91cf\u5173\u8054\u88ab\u201c\u7ea0\u7f20\u201d\uff09\uff1b\u800c\u5728\u56e0\u679c\u5206\u89e3\u4e2d\uff0c\u53d8\u5316\u4ec5\u5c40\u9650\u4e8e\u53d7\u5e72\u9884\u7684\u673a\u5236\u3002  </li> </ul>"},{"location":"notes/Research/CausalDiscovery/Papers/Towards%20Causal%20Representation%20Learning/#2_1","title":"2. \u4f8b\u5b50\u4e0e\u610f\u4e49","text":"<ul> <li>\u56fe\u50cf\u5e72\u9884\uff1a\u82e5\u56e0\u679c\u53d8\u91cf\u662f\u201c\u624b\u6307\u4f4d\u7f6e\u201d\u548c\u201c\u7acb\u65b9\u4f53\u72b6\u6001\u201d\uff0c\u5219\u79fb\u52a8\u624b\u6307\uff08\u5e72\u9884\uff09\u4ec5\u6539\u53d8\u8fd9\u4e24\u4e2a\u53d8\u91cf\u7684\u673a\u5236\uff0c\u800c\u50cf\u7d20\u5c42\u9762\u7684\u53d8\u5316\u662f\u5bc6\u96c6\u7684\uff08\u5927\u91cf\u50cf\u7d20\u503c\u6539\u53d8\uff09\u3002SMS\u786e\u4fdd\u56e0\u679c\u5c42\u9762\u7684\u53d8\u5316\u662f\u7a00\u758f\u7684\uff0c\u4fbf\u4e8e\u6a21\u578b\u6355\u6349\u5173\u952e\u5e72\u9884\u3002  </li> <li>\u5206\u5e03\u5916\u6cdb\u5316\uff1a\u4f8b\u5982\uff0c\u8bad\u7ec3\u6570\u636e\u4e2d\u201c\u732b\u201d\u7684\u56fe\u7247\u591a\u5728\u5ba4\u5185\uff0c\u6d4b\u8bd5\u6570\u636e\u4e2d\u201c\u732b\u201d\u5728\u5ba4\u5916\uff08\u5149\u7167\u53d8\u5316\uff09\u3002\u6839\u636eSMS\uff0c\u5149\u7167\u673a\u5236\u7684\u53d8\u5316\u4e0d\u5f71\u54cd\u201c\u732b\u7684\u5f62\u72b6\u201d\u673a\u5236\uff0c\u56e0\u679c\u6a21\u578b\u53ef\u901a\u8fc7\u4fdd\u6301\u5f62\u72b6\u673a\u5236\u4e0d\u53d8\u5b9e\u73b0\u6cdb\u5316\uff0c\u800c\u7eaf\u7edf\u8ba1\u6a21\u578b\u53ef\u80fd\u56e0\u4f9d\u8d56\u201c\u5ba4\u5185\u201d\u5173\u8054\u800c\u5931\u6548\u3002  </li> </ul>"},{"location":"notes/Research/CausalDiscovery/Papers/Towards%20Causal%20Representation%20Learning/#3_1","title":"3. \u5e94\u7528\u573a\u666f","text":"<p>\u8bba\u6587\u6307\u51faSMS\u5728\u4ee5\u4e0b\u9886\u57df\u6709\u76f4\u63a5\u5e94\u7528\uff1a - \u56e0\u679c\u53d1\u73b0\uff1a\u901a\u8fc7\u8bc6\u522b\u201c\u4ec5\u5c11\u6570\u673a\u5236\u53d8\u5316\u201d\u7684\u5206\u5e03\u504f\u79fb\uff0c\u53ef\u53cd\u63a8\u56e0\u679c\u7ed3\u6784\uff08\u5982[131]\u7528\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u56e0\u679c\u56fe\uff09\u3002 - \u6a21\u5757\u5316\u67b6\u6784\uff1a\u8bbe\u8ba1\u53ef\u72ec\u7acb\u8c03\u6574\u7684\u6a21\u5757\uff08\u5982[84]\u7684\u9012\u5f52\u72ec\u7acb\u673a\u5236\uff09\uff0c\u9002\u5e94\u7a00\u758f\u673a\u5236\u53d8\u5316\u3002 - \u89e3\u8026\u8868\u793a\uff1a\u4fc3\u4f7f\u6a21\u578b\u5b66\u4e60\u201c\u7a00\u758f\u53d8\u5316\u201d\u7684\u56e0\u5b50\uff08\u5982[159]\u7528SMS\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\uff0c\u4ece\u6570\u636e\u4e2d\u5206\u79bb\u56e0\u679c\u53d8\u91cf\uff09\u3002  </p>"},{"location":"notes/Research/CausalDiscovery/Papers/Towards%20Causal%20Representation%20Learning/#icmsms","title":"\u4e09\u3001ICM\u4e0eSMS\u7684\u5173\u7cfb\u53ca\u610f\u4e49","text":"<ul> <li>\u903b\u8f91\u94fe\uff1aICM\u539f\u5219\u2192\u673a\u5236\u72ec\u7acb\u6027\u2192\u5206\u5e03\u53d8\u5316\u4ec5\u5f71\u54cd\u5c40\u90e8\u673a\u5236\uff08SMS\uff09\u2192\u56e0\u679c\u6a21\u578b\u53ef\u8de8\u5206\u5e03\u6cdb\u5316\u3002  </li> <li>\u5bf9\u673a\u5668\u5b66\u4e60\u7684\u542f\u793a\uff1a  </li> <li>\u73b0\u6709\u6a21\u578b\uff08\u5982\u6df1\u5ea6\u5b66\u4e60\uff09\u56e0\u672a\u7f16\u7801ICM/SMS\uff0c\u96be\u4ee5\u5e94\u5bf9\u5206\u5e03\u504f\u79fb\uff1b  </li> <li>\u672a\u6765\u6a21\u578b\u5e94\u5c06ICM/SMS\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e\uff08\u5982\u901a\u8fc7\u6a21\u5757\u5316\u7ed3\u6784\u3001\u89e3\u8026\u8868\u793a\uff09\uff0c\u63d0\u5347\u9c81\u68d2\u6027\u548c\u8fc1\u79fb\u80fd\u529b\u3002  </li> </ul> <p>\u7efc\u4e0a\uff0cICM\u548cSMS\u662f\u8bba\u6587\u7684\u7406\u8bba\u6838\u5fc3\uff0c\u5b83\u4eec\u4e0d\u4ec5\u89e3\u91ca\u4e86\u56e0\u679c\u63a8\u7406\u7684\u6cdb\u5316\u4f18\u52bf\uff0c\u4e5f\u4e3a\u56e0\u679c\u8868\u5f81\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u539f\u5219\uff08\u5982\u673a\u5236\u72ec\u7acb\u6027\u3001\u7a00\u758f\u53d8\u5316\u5efa\u6a21\uff09\u3002</p>"},{"location":"notes/Research/OCL/CosineSimilarity/","title":"\u4f59\u5f26\u76f8\u4f3c\u5ea6","text":""},{"location":"notes/Research/OCL/CosineSimilarity/#cosine-similarity","title":"Cosine Similarity","text":"<p> \u7ea6 177 \u4e2a\u5b57  30 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p>"},{"location":"notes/Research/OCL/CosineSimilarity/#1","title":"1. \u57fa\u672c\u6982\u5ff5","text":"<p>\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff08Cosine Similarity\uff09\u901a\u8fc7\u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u5939\u89d2\u4f59\u5f26\u503c\u6765\u8861\u91cf\u5b83\u4eec\u7684\u76f8\u4f3c\u6027\uff0c\u5e38\u7528\u4e8e\u6587\u672c\u3001\u56fe\u50cf\u7b49\u5411\u91cf\u5316\u6570\u636e\u7684\u76f8\u4f3c\u5ea6\u6bd4\u8f83\u3002</p>"},{"location":"notes/Research/OCL/CosineSimilarity/#_1","title":"\u6838\u5fc3\u7279\u70b9\uff1a","text":"<ul> <li>\u8303\u56f4\uff1a[-1, 1]\uff08\u5b9e\u9645\u573a\u666f\u901a\u5e38\u4e3a[0,1]\uff09</li> <li>\u5bf9\u5411\u91cf\u5e45\u5ea6\u4e0d\u654f\u611f\uff08\u4ec5\u8003\u8651\u65b9\u5411\uff09</li> <li>\u9002\u5408\u9ad8\u7ef4\u7a00\u758f\u6570\u636e</li> </ul>"},{"location":"notes/Research/OCL/CosineSimilarity/#2","title":"2. \u8ba1\u7b97\u516c\u5f0f","text":""},{"location":"notes/Research/OCL/CosineSimilarity/#_2","title":"\u539f\u59cb\u5b9a\u4e49","text":"<p>\u5bf9\u4e8e\u5411\u91cfA\u548cB\uff1a $$ \\text{cosine}(A, B) = \\frac{A \\cdot B}{|A| |B|} = \\frac{\\sum_{i=1}^n A_i B_i}{\\sqrt{\\sum_{i=1}^n A_i^2} \\sqrt{\\sum_{i=1}^n B_i^2}} $$</p>"},{"location":"notes/Research/OCL/CosineSimilarity/#_3","title":"\u6807\u51c6\u5316\u7248\u672c\uff08\u5411\u91cf\u5df2\u5355\u4f4d\u5316\uff09","text":"\\[ \\text{cosine}(A, B) = A \\cdot B \\]"},{"location":"notes/Research/OCL/CosineSimilarity/#3","title":"3. \u8ba1\u7b97\u793a\u4f8b","text":""},{"location":"notes/Research/OCL/CosineSimilarity/#1_1","title":"\u793a\u4f8b1\uff1a\u7b80\u5355\u6570\u503c\u5411\u91cf","text":"Python<pre><code>import numpy as np\n\n# \u5b9a\u4e49\u4e24\u4e2a\u5411\u91cf\nA = np.array([1, 2, 3])\nB = np.array([4, 5, 6])\n\n# \u624b\u52a8\u8ba1\u7b97\ndot_product = np.sum(A * B)          # 1*4 + 2*5 + 3*6 = 32\nnorm_A = np.sqrt(np.sum(A**2))       # sqrt(1+4+9) \u2248 3.7417\nnorm_B = np.sqrt(np.sum(B**2))       # sqrt(16+25+36) \u2248 8.7750\ncos_sim = dot_product / (norm_A * norm_B)  # 32 / (3.7417*8.7750) \u2248 0.9746\n\n# \u4f7f\u7528\u5e93\u51fd\u6570\u9a8c\u8bc1\nfrom sklearn.metrics.pairwise import cosine_similarity\ncos_sim_lib = cosine_similarity([A], [B])[0][0]  # \u8f93\u51fa0.9746\n</code></pre>"},{"location":"notes/Research/OCL/CosineSimilarity/#tf-idf","title":"\u793a\u4f8b\u4e8c\uff1a\u6587\u672c\u5411\u91cf\uff08TF-IDF\uff09:","text":"Python<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer\n\ndocuments = [\n    \"apple banana fruit\",\n    \"banana orange fruit\",\n    \"car vehicle engine\"\n]\n\n# \u751f\u6210TF-IDF\u5411\u91cf\nvectorizer = TfidfVectorizer()\ntfidf_matrix = vectorizer.fit_transform(documents)\n\n# \u8ba1\u7b97\u76f8\u4f3c\u5ea6\u77e9\u9635\ncosine_sim_matrix = cosine_similarity(tfidf_matrix)\nprint(cosine_sim_matrix)\n</code></pre>"},{"location":"notes/Research/OCL/OCL/","title":"OCL","text":""},{"location":"notes/Research/OCL/OCL/#ocl","title":"OCL\u8bba\u6587\u7cbe\u8bfb","text":"<p> \u7ea6 1036 \u4e2a\u5b57  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 5 \u5206\u949f</p>"},{"location":"notes/Research/OCL/OCL/#_1","title":"\u6a21\u578b\u67b6\u6784","text":""},{"location":"notes/Research/OCL/OCL/#_2","title":"\u5b9e\u73b0\u7ec6\u8282","text":"<p>OCL can be depicted as \\(P(\\alpha | I)\\) and \\(P(\\beta | I,\\alpha)\\). In \\(P(\\alpha|I)\\),category bias is imported following:  \\(P(\\alpha|I) = \\sum_i^m P(\\alpha|I,O_i)P(O_i|I)\\),where \\(P(O_i|I)\\) is the predicted category probability.O is a confounder and pollutes attribute inference,especially for the rare categories.</p> <p>We need to intervene to deconfounf the confounder O for \\(\\alpha\\). In \\(\\alpha\\) estimation, we use \\(do(\\cdot)\\) operation to eliminate the arc from O to I:</p> \\[ \\begin{align} P(\\alpha|do(I)) &amp;= \\sum_i^m P(\\alpha|I,O_i)P(O_i) \\\\ &amp;\\quad \\because \\text{ O\u5230I\u7684\u8fb9\u5df2\u7ecf\u5207\u65ad} \\\\ &amp;= \\sum_i^m P(O_i) \\sum_j^m P(\\alpha|I,O_i,A_j) P(A_j|I,O_i) \\\\ &amp;= \\sum_i^m P(O_i) \\sum_j^m P(\\alpha|I,A_j) P(A_j|O_i) \\\\ &amp;\\quad \\because A_j\\text{\u5b8c\u5168\u7531}O_i\\text{\u51b3\u5b9a\uff0c\u4e0e\u56fe\u50cfI\u65e0\u5173\uff1b} \\\\ &amp;\\quad \\quad \\text{\u4e00\u65e6\u7ed9\u5b9a}A_j\\text{\uff0c\u7c7b\u522b}O_i\\text{\u5c06\u5bf9}\\alpha\\text{\u4e0d\u518d\u63d0\u4f9b\u4efb\u4f55\u4fe1\u606f} \\\\ &amp;= \\sum_i^m P(\\alpha|I,A_i) P(O_i) \\\\ &amp;\\quad \\because \\text{\u53ea\u6709\u5f53}i=j\\text{\u65f6}P(A_j|O_i)=1 \\end{align} \\] <p>\\(P(O_i)\\) is the prior probability of the i-th catrgory(frequency on the train set).</p> <p>Similarly,\\(P(\\beta|I,\\alpha) = \\sum_i^m P(\\beta|I,O_i,\\alpha)P(O_i|I,\\alpha)\\).</p> <p>\\(P(\\beta|do(I,\\alpha))=\\sum_i^m P(\\beta|I,\\alpha,B_i) P(O_i)\\)</p> <p>We represent nodes \\({I, A, B, \u03b1, \u03b2}\\) as \\({f_I, f_A, f_B, f_\u03b1, f_\u03b2}\\) respectively in latent space. \\(f_I\\) is the RoI pooling feature of an instance extracted by a COCO pre-trained ResNet-50. We represent categorylevel attribute A based on the mean object category feature \\(\\bar{f_{O_i}}\\), which is the mean of f\\(_I\\) of all training samples in category \\(O_i\\). We map \\(\\bar{f_{O_i}}\\) to the attribute latent space fAi with fully-connected layers (FC) . \\(f_{A_i}\\) stands for the category-attribute representation for ith category.</p> <p>Attribute Instantiation. Next, we obtain an \u03b1 representation following Eq. 4:</p> <p>\\(f_{\\alpha_i} = \\mathcal{F}_\\alpha(f_I, f_{A_i}), \\quad f_\\alpha = \\sum_i^m f_{\\alpha_i} \\cdot P_{O_i}\\)</p> <p>where  \\(P_{O_i}\\) is the prior category probability. Eq. 7 indicates the attribute instantiation from  \\(A\\) to  \\(\\alpha\\) with  \\(I\\) as the condition. Hence, we can equally translate the  \\(\\alpha\\) estimation problem into a conditioned instantiation problem.  \\(\\mathcal{F}_\\alpha(\\cdot)\\) is implemented with multi-head attention with two entries . The attention output is compressed by a linear layer to the instantiated representation  \\(f_{\\alpha_i}\\). The debiased representation  \\(f_\\alpha\\) is the expectation of  \\(f_{\\alpha_i}\\) w.r.t  \\(P_{O_i}\\), according to back-door adjustment in Eq. 4.</p> <p>We also define the feature for specific attributes for ITE operation.  \\(f_\\alpha\\) is first separated to  \\(f_{\\alpha_p}\\) for each attribute  \\(p \\in [1, 114]\\) by multiple independent FCs, then we can manipulate specific attributes by masking some certain  \\(f_{\\alpha_p}\\). Next, the features are aggregated via concatenating-compressing by an FC to  \\(f'_\\alpha\\) as shown in Fig. 5.</p> <p>Affordance Instantiation. Similarly, FCs are used to obtain  \\(f_B\\) from  \\(\\bar{f}_{O_i}\\) and  \\(f_{A_i}\\):</p> <p>\\(f_{\\beta_i} = \\mathcal{F}_\\beta(f_I, f'_\\alpha, f_{B_i}), \\quad f_\\beta = \\sum_i^m f_{\\beta_i} \\cdot P_{O_i}.\\)</p> <p>\\(\\mathcal{F}_\\beta(\\cdot)\\) operates instantiation with conditions  \\(\\{f_I, f'_\\alpha, f_{B_i}\\}\\).</p>"},{"location":"notes/Research/OCL/OCL/#ite-metrics","title":"ITE Metrics","text":"<p>\u03b1, \u03b2 Recognition: we measure the correctness of model prediction  \\(\\hat{\\alpha}\\) and  \\(\\hat{\\beta}\\). For multi-label classification tasks, we use the mean Average Precision (mAP) metric.</p> <p>Reasoning: we use Individual Treatment Effect (ITE) .  \\(ITE_i = Y_{i,T=1} - Y_{i,T=0}\\) measures the causal effect  \\(T \\rightarrow Y\\) of  \\(i^{th}\\) individual with the difference between outcomes ( \\(Y\\)) with or without receiving the treatment ( \\(T\\)). In OCL, we discuss the causal relation between  \\(p^{th}\\) attribute and  \\(q^{th}\\) affordance:  \\(\\alpha_p \\rightarrow \\beta_q\\). So we interpret the treatment  \\(T\\) as the existence of  \\(\\alpha_p\\) and the outcome  \\(Y\\) as the  \\(\\beta_q\\) output. We measure the difference of  \\(\\beta_q\\) output when the whole  \\(\\alpha_q\\) feature is wiped out or not, which should be non-zero when the causal relation  \\(\\alpha_p \\rightarrow \\beta_q\\) exists.</p> <p>In detail, given a model, for an instance with causal relation  \\(\\alpha_p \\rightarrow \\beta_q\\) ( \\(p \\in [1, 114], q \\in [1, 170]\\)), we first formulate ITE as the affordance probability change following Eq. 2:</p> <p>\\(ITE = \\Delta \\hat{\\beta}_q = \\hat{\\beta}_q|_{do(\\alpha_p)} - \\hat{\\beta}_q|_{do(\\cancel{\\alpha_q})}\\)</p> <p>\\(\\hat{\\beta}_q|_{do(\\alpha_p)}\\) is the factual output of the affordance probability.  \\(\\hat{\\beta}_q|_{do(\\cancel{\\alpha_q})}\\) is the counterfactual output when the  \\(\\alpha_p\\) is wiped out, which can be got by assign zero-mask [65] to the feature of  \\(\\alpha_p\\) (e.g.,  \\(f_{\\alpha_p}\\) in OCRN) and keep the other features. Then, based on ITE, we benchmark instances following:</p> <p>ITE: If the causality  \\(\\alpha_p \\rightarrow \\beta_q\\) exists on the instance, ITE should be non-zero when eliminating the effect of  \\(\\alpha_p\\). And the direction of ITE depends on the affordance ground-truth  \\(\\beta_q\\): if  \\(\\beta_q = 0\\), the predicted  \\(\\hat{\\beta}_q\\) tend to be 1 after wiping out  \\(\\alpha_p\\) so ITE should be a negative value; contrarily, ITE should be positive if  \\(\\beta_q = 1\\). Hence we compute the ITE score as:</p> <p>\\(S_{ITE} = \\left\\{   \\begin{array}{ll}     \\max(\\Delta \\hat{\\beta}_q, 0), &amp; \\beta_q = 1, \\\\     \\max(-\\Delta \\hat{\\beta}_q, 0), &amp; \\beta_q = 0,   \\end{array} \\right.\\)</p> <p>so that larger  \\(S_{ITE}\\) indicates the model infers more accurate ITE directions and has better reasoning performance.</p> <p>\u03b1-\u03b2-ITE: we combine recognition and reasoning performances. We multiply  \\(S_{ITE}\\) with  \\(P(\\hat{\\alpha}_p = \\alpha_p)\\) and  \\(P(\\hat{\\beta}_q = \\beta_q)\\) as a unified metric  \\(S_{\\alpha-\\beta-ITE}\\).</p> <p>For all metrics, we compute AP for each  \\([\\alpha_p, \\beta_q]\\) and average them to mAP. Non-existing pairs are not considered.</p>"},{"location":"notes/Research/OCL/mAP/","title":"mAP","text":""},{"location":"notes/Research/OCL/mAP/#map","title":"mAP","text":"<p> \u7ea6 1 \u4e2a\u5b57  10 \u884c\u4ee3\u7801  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> Python<pre><code>from sklearn.metrics import roc_auc_score, average_precision_score\n\ny_true = [0, 0, 1, 1]\ny_scores = [0.1, 0.4, 0.35, 0.8]\n\nroc_auc = roc_auc_score(y_true, y_scores)\npr_auc = average_precision_score(y_true, y_scores)\n\nprint(\"ROC-AUC:\", roc_auc)  # \u8f93\u51fa\uff1a0.75\nprint(\"PR-AUC (AP):\", pr_auc)  # \u8f93\u51fa\uff1a0.83...\n</code></pre> <p></p> <p></p>"},{"location":"notes/Research/OCL/tSNE/","title":"tSNE","text":""},{"location":"notes/Research/OCL/tSNE/#t-sne","title":"t-SNE","text":"<p> \u7ea6 259 \u4e2a\u5b57  21 \u884c\u4ee3\u7801  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <p>\u53c2\u8003\u6587\u732e\uff1a\u300at-SNE \u5165\u95e8\uff1a\u975e\u7ebf\u6027\u964d\u7ef4\u4e0e\u6570\u636e\u53ef\u89c6\u5316 | DataCamp\u300b --- Introduction to t-SNE: Nonlinear Dimensionality Reduction and Data Visualization | DataCamp</p> Python<pre><code>from sklearn.manifold import TSNE\nfrom sklearn.datasets import load_digits\nimport matplotlib.pyplot as plt\n\n# \u52a0\u8f7d\u6570\u636e\uff088x8\u56fe\u50cf\u76841797\u4e2a\u624b\u5199\u6570\u5b57\uff09\ndigits = load_digits()\nX = digits.data  # \u9ad8\u7ef4\u6570\u636e (1797, 64)\ny = digits.target  # \u771f\u5b9e\u6807\u7b7e (0-9)\n\n# T-SNE\u964d\u7ef4\ntsne = TSNE(n_components=2, random_state=42)\nX_tsne = tsne.fit_transform(X)  # \u8f93\u51fa2D\u5750\u6807 (1797, 2)\n\n# \u53ef\u89c6\u5316\nplt.figure(figsize=(10, 8))\nscatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='tab10', alpha=0.6)\nplt.colorbar(scatter, label='Digit')\nplt.title('T-SNE Visualization of MNIST Digits')\nplt.show()\n</code></pre> <p></p>"},{"location":"notes/Research/OCL/tSNE/#_1","title":"\u539f\u7406","text":""},{"location":"notes/Research/OCL/tSNE/#1","title":"1. \u6838\u5fc3\u539f\u7406","text":"<p>T-SNE\uff08t-Distributed Stochastic Neighbor Embedding\uff09\u662f\u4e00\u79cd\u975e\u7ebf\u6027\u964d\u7ef4\u6280\u672f\uff0c\u4e3b\u8981\u7528\u4e8e\u9ad8\u7ef4\u6570\u636e\u53ef\u89c6\u5316\u3002\u5176\u6838\u5fc3\u662f\u901a\u8fc7\u6982\u7387\u5efa\u6a21\u4fdd\u7559\u6570\u636e\u7684\u5c40\u90e8\u7ed3\u6784\u7279\u5f81\u3002</p>"},{"location":"notes/Research/OCL/tSNE/#_2","title":"\u5173\u952e\u7279\u70b9","text":"<ul> <li>\u9ad8\u7ef4\u7a7a\u95f4\uff1a\u4f7f\u7528\u9ad8\u65af\u5206\u5e03\u8ba1\u7b97\u70b9\u95f4\u76f8\u4f3c\u5ea6</li> <li>\u4f4e\u7ef4\u7a7a\u95f4\uff1a\u6539\u7528t\u5206\u5e03\uff08\u81ea\u7531\u5ea6=1\uff09\u907f\u514d\"\u62e5\u6324\u95ee\u9898\"</li> <li>\u4f18\u5316\u76ee\u6807\uff1a\u6700\u5c0f\u5316KL\u6563\u5ea6\uff08Kullback-Leibler Divergence\uff09</li> </ul>"},{"location":"notes/Research/OCL/tSNE/#2","title":"2. \u7b97\u6cd5\u6b65\u9aa4","text":""},{"location":"notes/Research/OCL/tSNE/#1_1","title":"\u6b65\u9aa41\uff1a\u8ba1\u7b97\u9ad8\u7ef4\u76f8\u4f3c\u5ea6","text":"<p>\u5bf9\u4e8e\u6bcf\u4e2a\u6570\u636e\u70b9\\(x_i\\)\uff1a \\(\\(p_{j|i} = \\frac{\\exp(-||x_i - x_j||^2 / 2\\sigma_i^2)}{\\sum_{k \\neq i} \\exp(-||x_i - x_k||^2 / 2\\sigma_i^2)}\\)\\)</p> <p>\u5bf9\u79f0\u5316\u5904\u7406\uff1a \\(\\(p_{ij} = \\frac{p_{j|i} + p_{i|j}}{2n}\\)\\)</p>"},{"location":"notes/Research/OCL/tSNE/#2_1","title":"\u6b65\u9aa42\uff1a\u4f4e\u7ef4\u7a7a\u95f4\u5efa\u6a21","text":"<p>\u5728\u4f4e\u7ef4\u7a7a\u95f4\u4f7f\u7528t\u5206\u5e03\uff1a \\(\\(q_{ij} = \\frac{(1 + ||y_i - y_j||^2)^{-1}}{\\sum_{k \\neq l} (1 + ||y_k - y_l||^2)^{-1}}\\)\\)</p>"},{"location":"notes/Research/OCL/tSNE/#3","title":"\u6b65\u9aa43\uff1a\u68af\u5ea6\u4e0b\u964d\u4f18\u5316","text":"<p>\u635f\u5931\u51fd\u6570\uff1a \\(\\(KL(P||Q) = \\sum_{i \\neq j} p_{ij} \\log \\frac{p_{ij}}{q_{ij}}\\)\\)</p>"},{"location":"projects/","title":"index","text":"<p>\u6536\u5f55\u6211\u76ee\u524d\u72ec\u7acb\u5b8c\u6210\u7684\u9879\u76ee\uff1a</p>"},{"location":"projects/#car-lane-detection","title":"Car Lane Detection:","text":"<p> \u7ea6 50 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>6chHenry/Car-Lane-Detection (github.com)</p>"},{"location":"projects/#cat-or-dog","title":"Cat or Dog?","text":"<p>6chHenry/CatorDog: A solution to a kaggle competition: Dog VS Cat and further functional improvement (github.com)</p>"},{"location":"projects/#build-gpt-from-zero-to-hero","title":"Build GPT: From Zero to Hero","text":"<p>6chHenry/BuildGPTFromScratch (github.com)</p>"},{"location":"projects/#cs61a","title":"CS61A","text":"<p>6chHenry/CS61A: My implementation of CS61A (github.com)</p>"},{"location":"projects/CarLaneDetection/Canny/","title":"CannyEdgeDetection","text":""},{"location":"projects/CarLaneDetection/Canny/#canny-edge-detector","title":"Canny Edge Detector","text":"<p> \u7ea6 636 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p>"},{"location":"projects/CarLaneDetection/Canny/#_1","title":"\u56fe\u50cf\u7070\u5ea6\u5316","text":"<p>\u8bfb\u53d6\u56fe\u50cf(plt/cv2\u8bfb\u7684\u90fd\u662fBGR) ------&gt;\u8f6c\u6362\u4e3aRGB\u683c\u5f0f-----&gt;\u4efb\u4e00\u70b9\u7070\u5ea6\u503c\u53ef\u4ee5\u7528\u5e73\u5747\u6cd5 / \u6743\u91cd\u8ba1\u7b97</p> <p>Gray(i,j) = [R(i,j) + G(i,j) + B(i,j)] / 3</p> <p>or    Gray(i,j) = 0.299 * R(i,j) + 0.587 * G(i,j) + 0.114 * B(i,j)</p>"},{"location":"projects/CarLaneDetection/Canny/#_2","title":"\u9ad8\u65af\u6a21\u7cca","text":"<p>\u7528\u79bb\u6563\u7248\u672c\u7684\u9ad8\u65af\u51fd\u6570\uff08\u7c7b\u4f3c\u6b63\u6001\u5206\u5e03\uff09</p> <p>\\(H(x,y)=e^{-\\frac{x^2+y^2}{2\\sigma^2}}\\)</p> <p>\u5bf9\u4e8e\u56fe\u50cf\u4e2d\u7684\u79bb\u6563\u70b9,\\((2k+1)\\times (2k+1)\\)\u7684\u5377\u79ef\u6838,\u6bcf\u4e2a\u5377\u79ef\u6838\u7684\u4e2d\u5fc3\u70b9\u4e3a(k+1,k+1),\u5377\u79ef\u6838\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u503c\u6309\u7167\u5982\u4e0b\u65b9\u5f0f\u8ba1\u7b97\uff1a</p> <p>\\(H[i,j]=\\frac{1}{2\\pi\\sigma^2}e^{-\\frac{(i-k-1)^2+(j-k-1)^2}{2\\sigma^2}}\\)</p> <p>\u5c06\u8fd9\u4e2a\u5377\u79ef\u6838\u4e0e\u539f\u56fe\u50cf\u8fdb\u884c\u5377\u79ef\uff0c\u5f97\u5230\u7684\u5c31\u662f\u9ad8\u65af\u6a21\u7cca\u540e\u7684\u56fe\u7247\u3002</p> <p>\u8865\u5145\u8bf4\u660e\uff01\uff01\uff01</p> <p>\u5bf9\u4e8ecv2/plt.imread()\uff0c\u8bfb\u53d6\u8fd4\u56de\u7684shape\u4e3aHeight,Weight,ColorChannel,\u5176\u4e2dcolor\u987a\u5e8f\u4e3aBGR</p> <p>\u800c\u67e5\u770bWindows\u56fe\u7247\u5c5e\u6027\u4e2d\u50cf\u7d20\u5f62\u72b6\u4e3aWeight * Height</p> <p>\u7528torch.ToTensor()\u4f1a\u628a\u5f62\u72b6\u8f6c\u5316\u4e3aColorChannel,Height,Weight,\u5176\u4e2dcolor\u987a\u5e8f\u4e3aBGR</p> <p>plt.show()\u6309\u7167RGB\u683c\u5f0f\u987a\u5e8f</p> <p>\u53c2\u8003\u6587\u7ae0\uff1apython\u8bfb\u53d6\u56fe\u7247\u7684\u51e0\u79cd\u65b9\u5f0f - \u77e5\u4e4e (zhihu.com)</p> <p>\u5982\u679c\u5b9e\u5728\u641e\u4e0d\u61c2\u53ef\u4ee5\u591a\u5c1d\u8bd5\uff01</p>"},{"location":"projects/CarLaneDetection/Canny/#_3","title":"\u56fe\u50cf\u68af\u5ea6\u8ba1\u7b97","text":"<p>\u5e38\u7528\u65b9\u6cd5\uff1aSobel\u6838\u8fdb\u884c\u5377\u79ef</p> <p>\u7b80\u5355\u7248\u672c\uff1a\u7528\u76f8\u90bb\u5143\u7d20\u7684\u50cf\u7d20\u503c\u4f5c\u5dee\u5373\u53ef\u3002</p> <p>\u56fe\u50cf\u7684\u5750\u6807\u3001\u6570\u7ec4\u8bbf\u95ee\u3001\u7b1b\u5361\u5c14\u5750\u6807\u662f\u4e09\u5957\u72ec\u7acb\u7684\u4e1c\u897f\u3002</p> <p>\u56fe\u50cf\u5750\u6807\uff1a\u4ee5\u56fe\u50cf\u5de6\u4e0a\u89d2\u4e3a\u539f\u70b9\uff0c\u5411\u53f3\u4e3ax\u8f74\u6b63\u534a\u8f74\uff0c\u5411\u4e0b\u4e3ay\u8f74\u6b63\u534a\u8f74\uff0c\\(y\\in (0,Height),x\\in (0,Width)\\)</p> <p>\u200b             \u8ba1\u7b97\u68af\u5ea6\u7684\u65f6\u5019\u4e5f\u662f\u4ee5\u8fd9\u4e2a\u4e3a\u51c6\u7684\uff0c\u5411\u53f3\uff0c\u5411\u4e0b\uff0cdx\u6c34\u5e73\uff0cdy\u7ad6\u76f4</p> <p>\u6570\u7ec4\u8bbf\u95ee\uff1a\u4e0d\u8981\u6309\u7167\u5750\u6807\u7684\u65b9\u5f0f\u7406\u89e3\uff0c\u5426\u5219\u5bb9\u6613\u4e71\u5957\uff01i+1\u884c\u5728\u7b2ci\u884c\u7684\u4e0b\u8fb9\uff0cj+1\u5217\u5728\u7b2cj\u5217\u7684\u53f3\u8fb9</p> <p>\u8ba1\u7b97\u68af\u5ea6\u9700\u8981\u5c06\u6570\u7ec4\u548c\u56fe\u50cf\u7ed3\u5408\uff08\u56e0\u4e3a\u56fe\u50cf\u5b9e\u9645\u5b58\u50a8\u5728\u6570\u7ec4\u5f53\u4e2d\uff09\uff0c\u8ba1\u7b97dy\u65f6\u8981\u7528[i+1,j]-[i,j]\uff0c\u8ba1\u7b97dx\u65f6\u8981\u7528[i,j+1]-[i,j]</p> <p>\u7b1b\u5361\u5c14\u5750\u6807\uff1a\u5411\u4e0a\u4e3ay\u8f74\u6b63\u534a\u8f74\uff0c\u5411\u53f3\u4e3ax\u8f74\u6b63\u534a\u8f74\u3002</p> <p>\u68af\u5ea6\u65b9\u5411\u662f\u7531x\uff0cy\u65b9\u5411\u7684\u68af\u5ea6\u5171\u540c\u51b3\u5b9a\u7684\uff0c\u7edd\u5927\u591a\u6570\u65f6\u5019\u90fd\u4e0d\u4f1a\u662f\u7ad6\u76f4/\u6c34\u5e73\u7684\uff0c\u56e0\u6b64\u4e0e\u5468\u56f4\u70b9\u7f51\u683c(3*3)\u7684\u4ea4\u70b9\u4e0d\u4f1a\u5728\u9876\u70b9\u5904\uff0c\u4ea4\u70b9\u4e3a\u201c\u4e9a\u50cf\u7d20\u201d\uff0c\u9700\u8981\u7528\u63d2\u503c\u6cd5\u8ba1\u7b97\u4e9a\u50cf\u7d20\u7684\u68af\u5ea6\u3002\u901a\u8fc7\u76f8\u90bb\u4e24\u4e2a\u70b9\u7684\u68af\u5ea6\u4e58\u6743\u91cd\u8ba1\u7b97\u3002</p>"},{"location":"projects/CarLaneDetection/Canny/#_4","title":"\u53cc\u9608\u503c\u68c0\u6d4b","text":"<p>\u9ad8\u4e8e\u9608\u503c\u7684\u5373\u4e3a\u8fb9\u7f18\uff1b\u4f4e\u4e8e\u9608\u503c\u7684\u5373\u4e3a\u975e\u8fb9\u7f18\uff1b\u5904\u4e8e\u4e8c\u8005\u4e4b\u95f4\u7684\uff0c\u8fd8\u8981\u5224\u65ad\u662f\u5426\u6709\u53ef\u9760\u6027\u8fb9\u7f18\u8fde\u63a5\u3002</p> <p>\u200b   </p>"},{"location":"projects/CarLaneDetection/HoughTransform/","title":"HoughTransform","text":""},{"location":"projects/CarLaneDetection/HoughTransform/#hough-line-transform","title":"Hough Line Transform","text":"<p> \u7ea6 361 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p>"},{"location":"projects/CarLaneDetection/HoughTransform/#_1","title":"\u6570\u5b66\u539f\u7406","text":"<p>\u7c7b\u4f3c\u6781\u5750\u6807\uff08\u4f46\u4e0d\u662f\u6781\u5750\u6807\uff09\uff0c\u5728\u76f4\u89d2\u5750\u6807\u7cfb\u4e2d\uff0c\u7528\\(r,\\theta\\)\u8868\u793a\u76f4\u89d2\u5750\u6807\u7cfb\u7684\\((x,y)\\)</p> <p>\\(y = kx + b\\) \u7528\\(r\\)\u8868\u793a\u539f\u70b9\u5230\u76f4\u7ebf\u7684\u5782\u76f4\u8ddd\u79bb\uff0c\u7528\\(\\theta\\)\u8868\u793a\u8ddd\u79bb\u8fd9\u6761\u5782\u7ebf\u4e0e\\(x\\)\u8f74\u6b63\u534a\u8f74\u7684\u5939\u89d2</p> <p>\u56e0\u6b64\\(k=-\\frac{\\cos\\theta}{\\sin\\theta}\\)\uff0c\\(b=\\frac{r}{\\sin\\theta}\\)</p> <p>\u5316\u7b80\u5f97\u5230\\(r=x\\cos\\theta + y\\sin\\theta\\)</p> <p>\u5bf9\u4e8e\u56fa\u5b9a\u7684\u4e00\u70b9\\((x,y)\\)\uff0c\u5e26\u5165\u5f97\u5230\\(r=r(\\theta)\\) \uff0c\u5728\\(r-\\theta\\)\u5750\u6807\u7cfb\u4e2d\uff0c\u5c31\u662f\u4e00\u6761\u66f2\u7ebf\u3002\u56e0\u6b64</p> <p>\u5728(x,y)\u5750\u6807\u7cfb\u4e00\u70b9\u4e3a\\((r,\\theta)\\)\u5750\u6807\u7cfb\u4e00\u6761\u66f2\u7ebf\u3002</p> <p>\u76f8\u5e94\u7684\uff0c\u5bf9\u4e8e(x,y)\u5750\u6807\u7cfb\u4e00\u6761\u76f4\u7ebf\uff0c\u7531\u4e8e\\(r,\\theta\\) \u56fa\u5b9a,\u6240\u4ee5\u5728\\(r-\\theta\\)\u5750\u6807\u7cfb\u4e2d\u662f\u4e00\u4e2a\u70b9\u3002</p>"},{"location":"projects/CarLaneDetection/HoughTransform/#_2","title":"\u8bbe\u5b9a\u9608\u503c\u8fdb\u884c\u6295\u7968","text":"<p>\u5728\u7528Canny\u68c0\u6d4b\u5668\u68c0\u6d4b\u51fa\u8fb9\u7f18\u540e\uff0c\u5f97\u5230\u5f88\u591a\u70b9\u3002\u8fd9\u4e9b\u70b9\u5bf9\u5e94\\(r-\\theta\\) \u5750\u6807\u7cfb\u7684\u66f2\u7ebf\u3002\u5982\u679c\u5f88\u591a\u6761\u66f2\u7ebf\u90fd\u4ea4\u4e8e\u540c\u4e00\u70b9\uff0c\u90a3\u4e48\u6709\u7406\u7531\u6000\u7591\u5728\\((x,y)\\)\u5750\u6807\u7cfb\u8fd9\u4e9b\u70b9\u8fde\u63a5\u800c\u6210\u6784\u6210\u4e00\u6761\u76f4\u7ebf\u3002\u901a\u8fc7\u4ea4\u70b9\u5bf9\u5e94\u7684\u66f2\u7ebf\u6570\u76ee\u8fdb\u884c\u8ba1\u7b97\u6295\u7968\uff08\u5b57\u5178\u8ba1\u6570\uff09\uff0c\u8bbe\u5b9a\u4e00\u4e2a\u6700\u4f4e\u7684\u9608\u503c\uff0c\u9ad8\u4e8e\u9608\u503c\u7684\u5373\u4e3a\u76f4\u7ebf\u3002</p>"},{"location":"projects/CarLaneDetection/HoughTransform/#_3","title":"\u5b9e\u9645\u4e0a","text":"<p>\u6211\u4eec\u904d\u5386\u03b8\u7684\u503c\uff0c\u4ece0-180\u00b0\uff0c\u5e76\u4e14\u540c\u65f6\u4ee3\u5165\uff08x,y\uff09\u7684\u503c\uff0c\u6c42\u5f97\u5bf9\u5e94\u7684\u03c1\u3002</p> <p>\u627e\u52300-180\u00b0\u4e2d\uff0c\u54ea\u4e2a\u5ea6\u6570\u4e0b\u7684\u03c1\u503c\u76f8\u540c\u7684\u6570\u91cf\u6700\u591a\u3002\u8fd9\u53cd\u5411\u8bf4\u660e\u4e86\uff0c\u5728\u4e00\u4e2a\u03c1\u548c\u03b8\u7ec4\u6210\u7684\u51fd\u6570\u4e2d\uff0c\u7b26\u5408\u7684\u70b9\u6570\u6700\u591a\u3002</p>"},{"location":"summary/","title":"index","text":""},{"location":"summary/#summaries","title":"Summaries \ud83d\uddd3\ufe0f","text":"\u300e\u0f63\u0f72\u0f60\u0f74\u0f0b\u0f41\u0f74\u0f0b\u0f5d\u0f7a\u0f0d \u300f"},{"location":"summary/Review%20Plan/","title":"Review Plan","text":"<p> \u7ea6 509 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> \u8003\u8bd5\u65f6\u95f4 \u590d\u4e60\u65f6\u95f4 \u8003\u8bd5\u8303\u56f4 \u590d\u4e60\u65b9\u5411 \u9884\u671f\u76ee\u6807 \u5927\u5b66\u82f1\u8bed 1.6 \u5468\u4e00 10:30-12:30 1.4\u505a\u6837\u5377 \u65e0 \u505a\u4e00\u5957\u6837\u5377\uff0c\u6bcf\u5929\u542c\u4e00\u7bc7TPO\u8fde\u7eed\u901f\u8bb0 85+ \u6570\u5b66\u5206\u6790 1.7 \u5468\u4e8c 10:30-12:30 1.4,1.5,1.6\u5237\u771f\u9898\uff0c\u5728\u6b64\u4e4b\u524d\u628a\u91cd\u96be\u70b9\u8fc7\u4e86 \u4e0a\u518c+\u4e0b\u518c\u7ea7\u6570 \u91cd\u96be\u70b9\uff1a\u79ef\u5206\u4e0d\u7b49\u5f0f\uff0c\u6982\u5ff5\u8fa8\u6790\u5224\u65ad\uff08\u6bcf\u5957\u5377\u5b50\u8fd9\u79cd\u9898\u578b\u62ff\u51fa\u6765\uff09\uff0c\u7ea7\u6570\uff0c\u51f8\u51fd\u6570\uff0c\u4e2d\u503c\u8bc1\u660e\u9898 90+ \u4e60\u7279 1.9 \u5468\u56db 10:30-12:00 1.7,1.8\u80cc\u4e66+\u4f20\u627f\u91cd\u70b9 \u65e0 \u80cc\u9ed1\u6ce2\u8001\u5e08\u52fe\u753b\u7684\u91cd\u70b9\uff08\u627e\u5ba4\u53cb\u8981\uff09 85+ \u7ebf\u6027\u4ee3\u6570 1.10 \u5468\u4e94 10:30-12:30 1.8,1.9\u771f\u9898\uff0c\u5728\u6b64\u4e4b\u524d\u628a\u91cd\u96be\u70b9\u8fc7\u4e86 \u5168\u4e66 \u590d\u4e60\u8bfe\u91cd\u70b9\uff0c\u771f\u9898\uff0c\u8003\u7814\u89c6\u9891 90+ \u519b\u4e8b\u7406\u8bba 1.14 \u5468\u4e8c 13:10-15:10 1.11,1.12,1.13\u80cc\u4e66+\u4f20\u627f\u91cd\u70b9 \u65e0 \u80cc\u8001\u5e08\u52fe\u753b\u7684\u91cd\u70b9 85+ \u5927\u5b66\u5316\u5b66 1.15  \u5468\u4e09 15:40-17:40 \u6bcf\u5468\u672b\u62bd\u65f6\u95f4\u68b3\u7406PPT\uff0c1.11,1.12,1.14\u5237\u771f\u9898 1,2,3,4\u7ae0 \u590d\u4e60\u6559\u6750\u548cPPT\u5e76\u68b3\u7406\u516c\u5f0f\uff0c\u505a3\u5957\u6837\u5377\uff08C:\\Users\\Administrator\\Downloads\\Compressed\\\u6837\u5377\uff09 90+ <p>\u5177\u4f53\u590d\u4e60\u7ec6\u8282\uff1a</p> <p>\u5927\u5316\uff1a\u5728\u671f\u672b\u65f6\uff0c\u8bf7\u52a1\u5fc5\u7559\u51fa100min\u5236\u4f5c\u601d\u7ef4\u5bfc\u56fe\u3002</p> <p>\u601d\u7ef4\u5bfc\u56fe\u53ef\u4ee5\u662f\u7b14\u8bb0\u5f62\u5f0f\uff0c\u63d0\u7eb2\u5f62\u5f0f\uff0c\u552f\u72ec\u4e0d\u53ef\u4ee5\u662f\u6446\u70c2\u7684\u5927\u4f5c\u4e1a\u5f0f\u3002\u8bf7\u8bb0\u4f4f\uff1a\u8bfe\u672c\u7684\u91cd\u70b9\u53ef\u4ee5\u4ea4\u7ed9PPT\u548c\u66f4\u8ba4\u771f\u7684\u540c\u5b66\uff0c\u800c\u4f60\u9700\u8981\u4eb2\u624b\u5236\u4f5c\u4e00\u904d\u63d0\u7eb2\u3002</p> <p>\u63d0\u7eb2\u7684\u5236\u4f5c\u65b9\u5f0f\u8f83\u4e3a\u591a\u5143\uff0c\u4ee5\u516c\u5f0f\u4e3a\u6838\u5fc3\u800c\u5236\u4f5c\u7684\u63d0\u7eb2\u3002\u4f60\u9700\u8981\u627e\u5230\u5f80\u5e74\u8003\u8bd5\u7684\u6240\u6709\u516c\u5f0f\u5728\u8bfe\u672c\u4e0a\u7684\u51fa\u5904\u3002\u516c\u5f0f\u662f\u7ed9\u5728\u8003\u5377\u4e0a\u7684\u3002\u5982\u679c\u4f60\u7684\u8003\u8bd5\u6ca1\u6709\u7ed9\u5b9a\u516c\u5f0f\uff0c\u8bf7\u53c2\u8003\u4e0b\u9762\u7684\u56fe\u7247\u3002</p> <p></p> <p>\u8fd8\u6709\u8bb2\u5ea7\u4e0a\u4ea42022-2023\u79cb\u5927\u5316\u671f\u672b\u8f85\u5bfc_\u54d4\u54e9\u54d4\u54e9_bilibili</p> <p>\u6570\u5206\uff1a</p> <p>\uff08\u6ca1\u4eba\u6765\u73a9\uff0c\u90a3\u5c31\u89e3\u7b54\u5b8c\u540e\u5b8c\u7ed3\uff09\u4e00\u8d77\u6570\u5206\u671f\u4e2d\u590d\u4e60/CMC\u5237\u9898\u73a9\u5440~\uff08\u60f3\u4e86\u4e00\u4e0b\uff0c\u5927\u90e8\u5206\u90fd\u662f\u6570\u5206\u9898\u96c6\uff09 - \u5b66\u5728\u4ea4\u5927 / \u8bfe\u4e1a\u5b66\u4e60 - \u6c34\u6e90\u793e\u533a (sjtu.edu.cn)</p> <p>\u590d\u4e60\u4f5c\u4e1a\u9898\u76ee+\u4e0a\u8bfe\u8bb2\u7684\u4f8b\u9898+\u671f\u672b\u5212\u7684\u91cd\u70b9</p> <p>\u5237\u8bfe\uff1a</p>"},{"location":"summary/%E4%B8%8B%E5%8D%8A%E6%9C%9F%E8%AE%A1%E5%88%92/","title":"\u4e0b\u534a\u671f\u8ba1\u5212","text":""},{"location":"summary/%E4%B8%8B%E5%8D%8A%E6%9C%9F%E8%AE%A1%E5%88%92/#_1","title":"\u4e0b\u534a\u671f\u8ba1\u5212","text":"<p> \u7ea6 66 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u6570\u5b66\u5206\u6790\uff1a\u8c22\u60e0\u6c11\uff0c\u5409\u7c73\u591a\u7ef4\u5947\uff08\u7b2c\u4e8c\u518c\uff09\u7b2c\u516b\u7ae0\uff0c\u5e38\u5fae\u5206\u65b9\u7a0b2.1\uff0c2.3,2.4\uff0c4.1\uff0c4.2,5.4\uff0c\u671f\u4e2d\u5377</p> <p>\u7ebf\u6027\u4ee3\u6570\uff1a\u300a\u7ebf\u6027\u4ee3\u6570\u53ca\u5176\u5e94\u7528\u300b\uff0c\u590d\u65e6\u767d\u76ae\u4e66\uff0c\u671f\u4e2d\u5377,\u53bb\u5e74\u7ebf\u4ee3\u8bb2\u5ea7</p> <p>\u5bd2\u5047cs61a</p>"},{"location":"summary/%E5%85%B7%E4%BD%93%E8%AE%A1%E5%88%92/","title":"\u5177\u4f53\u8ba1\u5212","text":"<p> \u7ea6 46 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u6570\u5b66\u5206\u6790\uff1a\u8ddf\u7740\u8001\u5e08\u4e0a\u8bfe\u8d70 \u7ed3\u5408\u8c22\u60e0\u6c11\u8003\u524d\u7a81\u51fb</p> <p>\uff08\u91cd\u8981\uff09\u7a0b\u5e8f\u8bbe\u8ba1\uff1a\u81ea\u5b66 ACMOJ CS61B</p> <p>\u5927\u5b66\u7269\u7406\uff1a\u81ea\u5b66 </p> <p>\uff08\u91cd\u8981\uff09\u6982\u7387\u7edf\u8ba1\uff1aIntroduction to Probability MIT6.041</p>"},{"location":"summary/%E5%A4%A7%E4%B8%80%E4%B8%8B%E4%B8%8B%E5%8D%8A%E6%9C%9F%E8%AE%A1%E5%88%92/","title":"\u5927\u4e00\u4e0b\u4e0b\u534a\u671f\u8ba1\u5212","text":"<p> \u7ea6 135 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u534a\u671f\u8003\u8bd5\u7ed3\u675f\u4e86\uff0c\u8f6c\u4e13\u4e1a\u4e5f\u544a\u4e00\u6bb5\u843d\u4e86\u3002\u6b63\u5f0f\u8fdb\u5165\u4e0b\u5b66\u671f\u7684\u5b66\u4e60\uff0c\u6700\u4e3b\u8981\u7684\u76ee\u6807\uff1a1.\u516d\u7ea7\u62ff\u5230\u4e00\u4e2a\u8f83\u9ad8\u7684\u5206\u6570 2.\u4e0d\u6302\u79d1</p> <p>3.\u8fdb\u4e00\u4e2a\u7ec4\u8ba4\u771f\u505a\u79d1\u7814</p> <p>\u82f1\u8bed\uff1a\u542c\u529bTED Lectures\uff1b\u80cc\u516d\u7ea7\u5355\u8bcd\uff1b\u5237\u771f\u9898</p> <p>\u6570\u5206\uff1a\u4fdd\u8bc1\u57fa\u672c\u9898\u578b\u638c\u63e1\uff0c\u8003\u524d\u5237\u9898</p> <p>\u6982\u7edf\uff1a xdw\u8001\u5e08\u7684PPT \u6bcf\u5929\u505a\u4e94\u9053\u4f8b\u9898</p> <p>\u5927\u7269\uff1a\u5237\u8bfe\u4e0aPPT\u91cc\u7684\u4f8b\u9898  \u6bcf\u4e00\u5468\u4e00\u4e2a\u5355\u5143</p> <p>\u5176\u4f59\u8bfe\u7a0b\uff1a\u8003\u524d\u7a81\u51fb</p> <p>\u628aCV\u7684\u5b66\u4e60\u7ed3\u675f\uff0c\u5f00\u59cbCS61B\u7684\u5b66\u4e60\u3002</p>"},{"location":"summary/%E5%A4%A7%E4%B8%80%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/","title":"\u6211\u7684\u5927\u4e00\u5e74\u5ea6\u603b\u7ed3","text":""},{"location":"summary/%E5%A4%A7%E4%B8%80%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/#_1","title":"\u6211\u7684\u5927\u4e00\u5e74\u5ea6\u603b\u7ed3","text":"<p> \u7ea6 707 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 4 \u5206\u949f</p> <p>\u5927\u4e00\u5f88\u5feb\u5c31\u8fc7\u53bb\u4e86\u3002\u6216\u8bb8\u6211\u6bcf\u5e74\u90fd\u4f1a\u8bf4\u51fa\u76f8\u540c\u7684\u8bdd\uff0c\u4e0d\u8fc7\u5f88\u96be\u76f8\u4fe1\u81ea\u5df1\u4e0b\u4e2a\u6708\u5f00\u5b66\u5c31\u5927\u4e8c\u4e86\u3002\u603b\u89c9\u5f97\u81ea\u5df1\u8fd8\u662f\u521a\u9ad8\u8003\u5b8c\u7684\u9ad8\u4e09\u5b66\u751f\u3002\u4f60\u8bf4\u8fd9\u4e00\u5e74\u6709\u4ec0\u4e48\u5f88\u5927\u7684\u53d8\u5316\u5417\uff1f\u6211\u4e0d\u597d\u8bf4\u3002\u4e0d\u8fc7\uff0c\u6211\u786e\u5b9e\u6210\u719f\u4e86\u4e00\u4e9b\uff0c\u8fd9\u4e9b\u6210\u719f\u4f53\u73b0\u5728\u65b9\u65b9\u9762\u9762\uff0c\u800c\u8fd9\u4e9b\u53d8\u5316\u662f\u539a\u79ef\u8584\u53d1\u7684\u3002</p> <p>\u6211\u611f\u89c9\u81ea\u5df1\u66f4\u52a0\u81ea\u7531\u4e86\u3002\u6ca1\u6709\u5bb6\u957f\u3001\u8001\u5e08\u7684\u7ba1\u675f\uff0c\u5927\u5b66\u751f\u6d3b\u7684\u786e\u662f\u81ea\u7531\u7684\uff0c\u751a\u81f3\u53ef\u4ee5\u8bf4\u662f\u5f88\u723d\u7684\uff0c\u4f46\u662f\u8fd9\u53c8\u4e0e\u9ad8\u4e2d\u6240\u671f\u5f85\u7684\u90a3\u79cd\u65e0\u5fe7\u65e0\u8651\u7684\u5927\u5b66\u751f\u6d3b\u4e0d\u540c\u3002\u5728\u6bcf\u5929\u4e0a\u5b8c\u8bfe\u540e\uff0c\u4f60\u6709\u5145\u8db3\u7684\u81ea\u7531\u9009\u62e9\u665a\u4e0a\u53bb\u56fe\u4e66\u9986\u5b66\u4e60\u8fd8\u662f\u5728\u5bdd\u5ba4\u6253\u6e38\u620f\uff0c\u4f60\u53ef\u4ee5\u9009\u62e9\u53bb\u601d\u6e90\u6e56\u8fb9\u6563\u6b65\u4ea6\u6216\u8005\u5728\u5357\u4f53\u8dd1\u6b65\uff0c\u4f60\u53ef\u4ee5\u548c\u540c\u5b66\u51fa\u53bb\u805a\u9910\u5230\u5f88\u665a\uff0c\u4f60\u4e5f\u53ef\u4ee5\u5728\u4f53\u80b2\u9986\u6253\u4e00\u6574\u665a\u7684\u7403\u3002\u4ece\u8fd9\u4e2a\u610f\u4e49\u4e0a\u6765\u8bf4\uff0c\u7684\u786e\u662f\u81ea\u7531\u7684\u3002\u4e0d\u8fc7\u8fd9\u79cd\u81ea\u7531\u4f1a\u5e26\u7ed9\u6211\u4e00\u4e9b\u8ff7\u832b\u3002\u5f53\u6211\u80fd\u591f\u6709\u5f88\u591a\u9009\u62e9\u4f59\u5730\u65f6\uff0c\u6211\u53cd\u800c\u4f1a\u65e0\u6240\u9002\u4ece\uff0c\u6211\u4e0d\u77e5\u9053\u54ea\u4e2a\u9009\u62e9\u662f\u6700\u4f18\u7684\uff0c\u5bf9\u6211\u6709\u5229\u7684\uff0c\u800c\u54ea\u4e9b\u9009\u62e9\u662f\u5e2e\u52a9\u4e0d\u5927\u7684\uff0c\u751a\u81f3\u5bf9\u6211\u6709\u5bb3\u7684\u3002\u4e8e\u662f\u3002\u6211\u503e\u5411\u53bb\u9009\u62e9\u6700\u5e73\u6de1\u7684\u3001\u6700\u5bb9\u6613\u7684\u3001\u6211\u81ea\u8ba4\u4e3a\u4ee3\u4ef7\u6700\u5c0f\u7684\u9009\u62e9\u2014\u2014\u53bb\u56fe\u4e66\u9986\u3002\u4e45\u800c\u4e45\u4e4b\uff0c\u5f53\u6211\u538c\u5026\u4e86\u8fd9\u79cd\u91cd\u590d\u7684\u751f\u6d3b\uff0c\u4e5f\u5c31\u7f3a\u5931\u4e86\u6fc0\u60c5\uff0c\u5373\u4f7f\u53bb\u56fe\u4e66\u9986\u6548\u7387\u4e5f\u53d8\u4f4e\u4e86\u3002</p> <p>\u6211\u7684\u5927\u4e00\u76ee\u6807\u5176\u5b9e\u5f88\u7b80\u5355\u2014\u2014\u8f6c\u4e13\u4e1a\u3002\u8fd9\u662f\u6211\u4ece\u5165\u5b66\u4e4b\u524d\u5c31\u6572\u5b9a\u7684\u4e8b\u60c5\uff0c\u800c\u6211\u4e5f\u505a\u5230\u4e86\uff0c\u800c\u4e14\u505a\u5f97\u5f88\u597d\u3002\u6211\u72e0\u72e0\u7684\u5377\u4e86\u7ee9\u70b9\uff0c\u72e0\u72e0\u7684\u81ea\u5b66\u4e86\u6df1\u5ea6\u5b66\u4e60\uff0c\u72e0\u72e0\u7684\u51c6\u5907\u4e86\u8f6c\u4e13\u4e1a\u9762\u8bd5\u3002\u7ed3\u679c\u4e5f\u5982\u6211\u6240\u613f\u3002\u4f46\u662f\uff0c\u5f53\u8fbe\u6210\u8fd9\u4e2a\u613f\u671b\u7684\u70ed\u60c5\u892a\u53bb\uff0c\u6211\u53d1\u73b0\u81ea\u5df1\u6ca1\u6709\u76ee\u6807\u4e86\uff0c\u800c\u968f\u4e4b\u800c\u6765\u7684\u662f\u6211\u65e9\u5c31\u9884\u6599\u5230\u7684\u6446\u70c2\u3002\u662f\u7684\uff0c\u6211\u5728\u8fbe\u6210\u76ee\u6807\u540e\u5f00\u59cb\u201c\u62a5\u590d\u6027\u201d\u7684\u73a9\uff0c\u6211\u628a\u81ea\u5df1\u60f3\u770b\u7684\u7535\u89c6\u5267\u3001\u7535\u5f71\u90fd\u770b\u4e86\u4e00\u904d\uff08\u8fd8\u6ca1\u770b\u5b8c\uff09\u3002\u4e0d\u8fc7\u6211\u5e76\u4e0d\u61ca\u6094\uff0c\u56e0\u4e3a\u8fd9\u79cd\u6446\u70c2\u5e26\u7ed9\u6211\u7684\u5feb\u4e50\u662f\u5b9e\u6253\u5b9e\u7684\uff0c\u662f\u80fd\u591f\u8ba9\u6211\u53d8\u5f00\u5fc3\u7684\uff0c\u8fd9\u5c31\u8db3\u591f\u4e86\u3002\u5f88\u591a\u4e09\u5206\u949f\u70ed\u60c5\u7684\u4e1c\u897f\u4f1a\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\u9010\u6e10\u663e\u73b0\uff0c\u4f46\u662f\u6211\u8fd8\u6ca1\u6709\u505a\u597d\u9762\u5bf9\u5b83\u4eec\u7684\u51c6\u5907\u3002</p> <p>\u6211\u4e0d\u77e5\u9053\u672a\u6765\u6211\u4f1a\u5982\u4f55\u6253\u7b97\uff0c\u6211\u751a\u81f3\u4e0d\u77e5\u9053\u81ea\u5df1\u662f\u4fdd\u7814\u8fd8\u662f\u51fa\u56fd\u3002\u6211\u53ea\u80fd\u8d70\u4e00\u6b65\u7b97\u4e00\u6b65\u4e86\u3002\u6211\u5f88\u96be\u6d3b\u5728\u5f53\u4e0b\uff0c\u56e0\u4e3a\u6211\u5fc5\u987b\u601d\u8003\u672a\u6765\u7684\u53d1\u5c55\u3002\u6216\u8bb8\u6211\u771f\u7684\u5e94\u8be5\u8c08\u604b\u7231\u4e86\uff0c\u6211\u7684\u751f\u6d3b\u5f88\u4e45\u6ca1\u6709\u65b0\u610f\u4e86\u3002</p>"},{"location":"summary/%E5%A4%A7%E4%BA%8C%E4%B8%8A%E8%AE%A1%E5%88%92/","title":"\u5927\u4e8c\u4e0a\u8ba1\u5212","text":"<p> \u7ea6 61 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u6392\u8bfe\u65b9\u9762\uff1a \u5468\u4e8c\u4e0b\u5348\u79bb\u6563\u6570\u5b66 \u5468\u56db\u4e0b\u5348\u6361\u6f0f\u4f53\u80b2\u8bfe </p> <p>\u79d1\u7814\u65b9\u9762\uff1a\u6709\u4e00\u7bc7\u8bba\u6587\u4ea7\u51fa</p> <p>\u8eab\u4f53\u65b9\u9762\uff1a\u575a\u6301\u8dd1\u6b65\uff0c\u9002\u5f53\u5065\u8eab</p> <p>\u770b\u4e66\uff1a \u300a\u91d1\u9601\u5bfa\u300b\u7b49</p> <p>\u5bb6\u6559\uff1a\u6bcf\u5468\u4e94\u665a\u4e0a\uff0c\u5468\u5929\u4e0a\u5348</p>"},{"location":"summary/2025/Week11%283.17-3.23%29/","title":"\u7b2c11\u5468\u5468\u7ed3","text":""},{"location":"summary/2025/Week11%283.17-3.23%29/#11","title":"\u7b2c11\u5468\u5468\u7ed3","text":"<p> \u7ea6 220 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p>"},{"location":"summary/2025/Week11%283.17-3.23%29/#review","title":"Review","text":"<ul> <li>15.6h\u7684\u4ece0\u5f00\u59cb\u7684GPT\u3002\u4e0d\u8fc7\u8fd9\u4e2a\u5468\u7ed3\u675f\u4e86\u524d\u9762\u8bfe\u7a0b\u7684\u5b66\u4e60\uff0c\u8fd8\u6ca1\u5f00\u59cb\u4e0a\u624b\u771f\u6b63\u6784\u5efaGPT2</li> <li>MyBPE\uff1a\u7167\u846b\u82a6\u753b\u74e2\uff0c\u6309\u7167minBPE\u7684\u601d\u8def\u5199\u4e86Regex\u548c\u666e\u901a\u7248\u7684Tokenizer\u3002\u4e0d\u8fc7\u611f\u89c9\u66f4\u9ad8\u6df1\u7684\u8fdb\u9636\u7248\u672c\u8fd8\u6ca1\u600e\u4e48\u641e\u61c2\u3002</li> </ul>"},{"location":"summary/2025/Week11%283.17-3.23%29/#next-week-plan","title":"Next Week Plan","text":"<ul> <li>\u642d\u5efaGPT2</li> <li>\u641e\u61c2AI\u5404\u4e2a\u65b9\u5411\uff0c\u6572\u5b9a\u611f\u5174\u8da3\u7684\u7814\u7a76\u65b9\u5411\uff0c\u5e76\u4e86\u89e3\u6700\u65b0\u52a8\u6001</li> <li>\u5b8c\u6210Kaggle\u4e0a\u7684Cats VS Dogs \u9879\u76ee</li> </ul>"},{"location":"summary/2025/Week11%283.17-3.23%29/#thoughts","title":"THOUGHTS","text":"<ul> <li>\u53bb\u542c\u4e86ACM\u73ed\u548cJohn\u73ed\u5b66\u957f\u5b66\u59d0\u7684\u8bb2\u5ea7\uff0c\u771f\u5389\u5bb3\u554a\u3002\u8ddf\u8fd9\u4e9b\u4f18\u79c0\u7684\u4eba\u9762\u5bf9\u9762\uff0c\u4ed6\u4eec\u7684\u8c08\u5410\u548c\u4eea\u6001\u90fd\u7279\u522b\u597d\uff0c\u611f\u89c9\u5404\u65b9\u9762\u90fd\u5f88\u4f18\u79c0\u3002\u5411\u4ed6\u4eec\u5b66\u4e60\uff01</li> <li>\u4e89\u53d6\u5728\u8f6c\u4e13\u4e1a\u653f\u7b56\u51fa\u6765\u524d\u628a\u9879\u76ee\u505a\u5b8c\uff0c\u770b\u770b\u8fd8\u6709\u6ca1\u6709\u80fd\u4f18\u5316\u7684\u90e8\u5206\u3002\u7b80\u5386\u53ef\u4ee5\u63d0\u524d\u51c6\u5907\u8d77\u6765\u4e86\uff08\u5411\u5b66\u957f\u8981\u6a21\u677f\uff09</li> </ul>"},{"location":"summary/2025/Week12%283.24-3.30%29/","title":"\u7b2c12\u5468\u5468\u7ed3","text":""},{"location":"summary/2025/Week12%283.24-3.30%29/#12","title":"\u7b2c12\u5468\u5468\u7ed3","text":"<p> \u7ea6 166 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p>"},{"location":"summary/2025/Week12%283.24-3.30%29/#review","title":"Review","text":"<ul> <li>\u628aKaggle\u4e0a\u7684Cats VS Dogs\u641e\u4e86\u4e00\u904d\uff0c\u8bad\u7ec3\u4e86\u4e09\u4e2a\u6a21\u578b\u3002</li> <li>\u7b80\u5386\u5199\u4e86\u4e00\u7248\uff0c\u5b66\u957f\u7ed9\u4e86\u4fee\u6539\u610f\u89c1\uff0c\u8fd8\u5728\u4fee\u6539</li> <li>\u9762\u8bd5\u7a3f\u51c6\u5907\u4e86\u4e00\u534a</li> <li>\u628aCV\u76f8\u5173\u7684\u5bfc\u5e08\u4e3b\u9875\u770b\u4e86\u4e00\u904d\uff0c\u786e\u5b9a\u4e86\u4e09\u4e2a\u548c\u6211\u65b9\u5411\u6bd4\u8f83match\u7684\u5bfc\u5e08</li> </ul>"},{"location":"summary/2025/Week12%283.24-3.30%29/#next-week-plan","title":"Next Week Plan","text":"<ul> <li>\u7ed9\u5bfc\u5e08\u53d1\u90ae\u4ef6</li> <li>\u5b8c\u5584\u7b80\u5386\u548c\u9879\u76ee</li> <li>\u7ee7\u7eed\u9762\u8bd5\u7a3f\u7684\u51c6\u5907</li> </ul>"},{"location":"summary/2025/Week12%283.24-3.30%29/#thoughts","title":"THOUGHTS","text":"<ul> <li>\u679c\u7136\uff0c\u6211\u7684\u9879\u76ee\u8fd8\u662f\u592atoy\u4e86\uff0c\u4f46\u662f\u5f88\u96be\u627e\u5230\u66f4\u597d\u7684\u9879\u76ee\u4e86\uff0c\u6211\u51c6\u5907\u518d\u5b66\u5b66EECS498\uff0c\u7136\u540e\u770b\u80fd\u4e0d\u80fd\u627e\u5230\u66f4\u597d\u7684\u9879\u76ee\uff08\u6216\u8bb8Kaggle\u4e0a\u53ef\u4ee5\u770b\u770b\uff1f\uff09</li> <li>41P\u5b66\u957f\u4eba\u5f88\u597d\uff0c\u8981\u591a\u4ea4\u6d41\u5206\u4eab</li> </ul>"},{"location":"summary/Movies/3%20Idiots/","title":"3 Idiots","text":"<p> \u7ea6 599 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> <p></p> <p>All is well.</p> <p>\u4eca\u5929\u665a\u4e0a\u82b1\u4e86\u4e09\u4e2a\u5c0f\u65f6\u770b\u7535\u5f71\uff0c\u7ed9\u6211\u770b\u723d\u4e86\u3002\u4eba\u7269\u5851\u9020\u7684\u7279\u522b\u597d\uff0c\u867d\u7136\u5728\u4e09\u5e74\uff08\uff1f\uff09\u4e4b\u524d\uff08\u76f4\u5347\u521d\u4e09\u7684\u65f6\u5019\uff09\u770b\u8fc7\u4e00\u904d\u4e86\uff0c\u8fd8\u8bb0\u5f97\u90a3\u662f\u8fd8\u5728\u5316\u5b66\u7ade\u8d5b\u7684\u65f6\u5019\uff0c\u665a\u81ea\u4e60\u770b\u7684\uff0c\u4f46\u5f53\u65f6\u6ca1\u770b\u5b8c\uff0c\u7136\u540e\u6709\u4e00\u5929\u4e2d\u5348\u9003\u4e86\u5348\u4f11\uff0c\u5077\u5077\u4ece\u5bdd\u5ba4\u6e9c\u51fa\u6765\uff0c\u548c\u4ed8\u6631\u65af\u7136\u4e00\u8d77\u770b\u5b8c\u4e86\u7ed3\u5c3e\u3002\u4eba\u7269\u6709\u5f27\u5149\uff0c\u6821\u957f\u5851\u9020\u7684\u7279\u522b\u597d\uff0c\u81f3\u5c11\u6ca1\u6709\u70c2\u5c3e\uff0c\u524d\u9762\u8be5\u4e25\u5389\u7684\u65f6\u5019\u4e00\u76f4\u5f88\u4e25\u5389\uff0c\u5373\u4f7f\u5230\u6700\u540e\u4e5f\u662f\u7b26\u5408\u6821\u957f\u7684\u8eab\u4efd\u7684\u3002\u611f\u89c9\u8fd9\u4e09\u4e2a\u5c0f\u65f6\u6ca1\u6709\u4efb\u4f55\u6c34\u5206\uff0c\u7a33\u624e\u7a33\u6253\u7684\u8bb2\u5b8c\u4e86\u6545\u4e8b\u3002\u751a\u81f3\u7b2c\u4e00\u904d\u770b\u7684\u65f6\u5019\u5176\u5b9e\u662f\u6709\u53cd\u8f6c\u548c\u60ca\u559c\u7684\u3002</p> <p>\u4e09\u4e2a\u4eba\u7684\u53cb\u8c0a\u4e5f\u662f\u7279\u522b\u7fa1\u6155\u554a\uff01\u201c\u65e2\u6015\u5144\u5f1f\u6d3b\u5f97\u82e6\uff0c\u53c8\u6015\u5144\u5f1f\u5f00\u8def\u864e\u201d\uff0c\u5176\u5b9e\u8fd9\u53e5\u8bdd\u624d\u662f\u73b0\u5b9e\u751f\u6d3b\u4e2d\u53cb\u8c0a\u7684\u5199\u7167\u3002\u8fd9\u4e09\u4e2a\u7684\u53cb\u60c5\u5728\u7535\u5f71\u91cc\u8fd8\u662f\u7406\u60f3\u5316\u4e86\uff0c\u4e0d\u8fc7\u5462\u60c5\u51b5\u90fd\u6bd4\u8f83\u6781\u7aef\uff0c\u6211\u4eec\u4e5f\u90fd\u77e5\u9053\u5982\u679c\u8fd9\u4e09\u4e2a\u4eba\u7684\u4eba\u7269\u80cc\u666f\u771f\u5b9e\u53d1\u751f\u4e86\u5c06\u662f\u975e\u5e38\u96be\u4ee5\u89e3\u51b3\u7684\u4e00\u4e2a\u95ee\u9898\u3002</p> <p>\u603b\u7684\u6765\u8bf4\u7ed99.5/10\uff0c\u6211\u4e2a\u4eba\u8ba4\u4e3a\u95ee\u9898\u662f\u5728\u4e2d\u95f4\u7a7f\u63d2\u4e86\u4e09\u6bb5\u821e\u8e48\uff0c\u6709\u51e0\u6bb5\u83ab\u540d\u5176\u5999\u7684\uff0c\u5c5e\u4e8e\u662f\u5370\u5ea6\u7247\u7279\u8272\u4e86\u3002\u4e0d\u8fc7\u6b4c\u66f2\u786e\u5b9e\u5f88\u6d17\u8111\u3002\u5267\u60c5\u7ebf\u5f88\u591a\uff0c\u4efb\u52a1\u4e5f\u5f88\u591a\uff0c\u6bcf\u4e2a\u4eba\u7269\u7684\u53d1\u5c55\u7ebf\u4e5f\u8fd8\u7b97\u5408\u7406\u3002\u4e2d\u95f4\u4e5f\u6709\u51e0\u6bb5\u641e\u7b11\u5267\u60c5\uff0c\u5c5e\u4e8e\u662f\u771f\u7684\u80fd\u8ba9\u6211\u5f00\u6000\u5927\u7b11\u7684\u3002\u793e\u4f1a\u610f\u4e49\u561b\uff0c\u8fd8\u8bbd\u523a\u4e86\u4e00\u4e0b\u5b66\u6821\u7684\u6559\u80b2\u5236\u5ea6\uff0c\u4e0d\u8fc7\u4e5f\u662f\u6709\u70b9\u7406\u60f3\u5316\u4e86\uff0c\u4f46\u662f\u6307\u51fa\u6765\u5c31\u7b97\u662f\u52c7\u6c14\u3002</p> <p>\u4f46\u662f\u6211\u89c9\u5f97\u8fd9\u4e2a\u4e3b\u89d2\u5728\u67d0\u4e9b\u65f6\u523b\u957f\u5f97\u7279\u522b\u50cf\u300a\u963f\u7518\u6b63\u4f20\u300b\u7684\u7537\u4e3b\uff0c\u6240\u4ee5\u6709\u70b9\u51fa\u620f\uff0c\u4e0d\u8fc7\u6f14\u7684\u8fd8\u662f\u5f88\u597d\u7684\u3002\u665a\u4e0a\u5728\u7761\u89c9\u524d\u60f3\u4e86\u4e00\u4e0b\uff0c\u597d\u50cf\u300a\u6454\u8de4\u5427\u7238\u7238\u300b\u91cc\u9762\u4ed6\u4e5f\u662f\u7537\u4e3b\u3002</p> <p>\u6458\u4e00\u6bb5\u7535\u5f71\u91cc\u7684\u7ecf\u5178\u8bed\u5f55\uff1a\u5f53\u4f60\u4e0d\u65ad\u8ffd\u6c42\u5353\u8d8a\uff0c\u6210\u529f\u5c31\u4f1a\u4e0d\u77e5\u4e0d\u89c9\u8ffd\u8d76\u4f60\u3002</p> <p>\u5bb3\u6015\u660e\u5929\uff0c\u600e\u80fd\u8fc7\u597d\u4eca\u5929\u5462\uff1f</p> <p>\u5fc3\u5f88\u8106\u5f31\uff0c\u6211\u4eec\u8981\u5b66\u4f1a\u54c4\u5b83\u3002</p> <p>\u9e21\u4e0d\u4f1a\u77e5\u9053\u86cb\u7684\u524d\u7a0b\u3002</p> <p>\u5b66\u4e60\u662f\u4e3a\u4e86\u5b8c\u5584\u4eba\u751f\uff0c\u800c\u975e\u4eab\u4e50\u4eba\u751f\u3002</p> <p>\u53ea\u4e3a\u751f\u547d\u800c\u611f\u6fc0\u3002</p> <p>\u670b\u53cb\u5931\u8d25\uff0c\u4f60\u96be\u8fc7\uff0c\u670b\u53cb\u6210\u529f\uff0c\u4f60\u66f4\u96be\u8fc7\u3002</p> <p>\u4e00\u5207\u987a\u5229\u3002</p>"},{"location":"summary/Movies/Hachi/","title":"Hachi","text":"<p> \u7ea6 339 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <p></p> <p>\u8fd9\u90e8\u7535\u5f71\u770b\u54ed\u4e86\u3002\u672c\u6765\u662f\u90a3\u79cd\u770b\u5230\u5f00\u5934\u5c31\u77e5\u9053\u7ed3\u5c3e\u7684\u5267\u60c5\uff0c\u4f46\u8fd8\u662f\u6b62\u4e0d\u4f4f\u773c\u6cea\u3002\u9996\u5148\uff0c\u8fd9\u4e2a\u97f3\u4e50\u914d\u7684\u592a\u68d2\u4e86\uff0c\u5f88\u8212\u7f13\uff0c\u5f88\u4f18\u96c5\uff0c\u6ca1\u6709\u6545\u610f\u50ac\u6cea\uff0c\u4f46\u662f\u5728\u5e73\u6de1\u7684\u97f3\u7b26\u4e2d\u6f78\u7136\u6cea\u4e0b\u3002\u5176\u6b21\uff0c\u753b\u9762\u5f88\u5e72\u51c0\u7eaf\u7cb9\u3002\u516b\u516c\u7684\u89c6\u89d2\u4e0b\u80fd\u770b\u5230\u4eba\u7c7b\u6d3b\u52a8\uff0c\u4e24\u4e2a\u89c6\u89d2\u6765\u56de\u5207\u56de\u66f4\u80fd\u7406\u89e3\u4eba\u548c\u5ba0\u7269\u7684\u4e92\u52a8\u3002\u867d\u7136\u6211\u6ca1\u6709\u517b\u8fc7\u5ba0\u7269\uff0c\u4f46\u6211\u8fd8\u662f\u80fd\u611f\u53d7\u5230\u52a8\u7269\u7684\u5fe0\u8bda\u3002\u516b\u516c\u968f\u7740\u5c81\u6708\u7684\u6d41\u901d\u5c31\u50cf\u4eba\u4e00\u6837\u53d8\u5f97\u82cd\u8001\uff0c\u4f46\u662f\u5f53\u542c\u5230\u706b\u8f66\u7684\u8f70\u9e23\u65f6\u8fd8\u662f\u4f1a\u53bb\u706b\u8f66\u7ad9\u5916\u7b49\u5f85\u3002\u6574\u4e2a\u7535\u5f71\u7bc7\u5e45\u5f88\u77ed\uff0c\u53ea\u6709\u4e00\u4e2a\u534a\u5c0f\u65f6\uff0c\u4f46\u662f\u5267\u60c5\u6d41\u7545\uff0c\u6574\u4e2a\u6545\u4e8b\u884c\u4e91\u6d41\u6c34\u3002\u867d\u7136\u6211\u4e2a\u4eba\u89c9\u5f97\u6559\u6388\u5e15\u514b\u60a3\u5fc3\u810f\u75c5\u731d\u6b7b\u6709\u70b9\u7a81\u7136\uff0c\u4e0d\u8fc7\u5fc3\u810f\u75c5\u672c\u8eab\u53d1\u751f\u7684\u5c31\u5f88\u7a81\u7136\uff0c\u5267\u60c5\u4e0a\u4e5f\u662f\u5408\u7406\u7684\u3002\u8fd9\u79cd\u7535\u5f71\u603b\u7ed9\u4eba\u4e00\u79cd\u63d0\u5fc3\u540a\u80c6\u7684\u611f\u53d7\uff0c\u56e0\u4e3a\u524d\u9762\u592a\u7f8e\u597d\u4e86\uff0c\u800c\u6545\u4e8b\u53c8\u4e0d\u53ef\u80fd\u5e73\u94fa\u76f4\u53d9\u3002\u80af\u5b9a\u4f1a\u6709\u6ce2\u6f9c\u548c\u8f6c\u6298\uff0c\u6240\u4ee5\u8bf4\u770b\u7684\u8fc7\u7a0b\u603b\u662f\u62c5\u5fe7\u4ec0\u4e48\u65f6\u5019\u707e\u96be\u4f1a\u5230\u6765\u3002</p> <p>\u6211\u89c9\u5f97\u5982\u679c\u628a\u8fd9\u90e8\u7535\u5f71\u7ed9\u53cd\u5bf9\u517b\u72d7\u7684\u4eba\u770b\uff0c\u6216\u8bb8\u80fd\u8ba9\u4ed6\u4eec\u5bf9\u72d7\u6709\u6240\u6539\u89c2\u3002\u8bc4\u52069.2/10\u3002</p>"},{"location":"summary/Music/2025%E4%B8%8A%E5%8D%8A%E5%B9%B4/","title":"Top 8","text":""},{"location":"summary/Music/2025%E4%B8%8A%E5%8D%8A%E5%B9%B4/#top-8","title":"Top 8","text":"<p> \u7ea6 627 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> <ol> <li>\u300a\u5c81\u6708\u91cc\u7684\u82b1\u300b by \u83ab\u6587\u851a</li> <li>\u300a\u4e4b\u5916\u300b by \u9648\u5955\u8fc5</li> <li>\u300a\u6211\u4e0d\u96be\u8fc7\u300b by \u5b59\u71d5\u59ff</li> <li>\u300a\u5b64\u513f\u4ed4\u300b by \u9648\u5955\u8fc5&amp;\u82e6\u8363</li> <li>\u300a\u60f3\u542c\u300b by \u9648\u5955\u8fc5</li> <li>\u300a\u82cf\u5dde\u6cb3/\u6155\u5bb9\u96ea\u300b by \u859b\u51ef\u742a</li> <li>\u300a\u641c\u795e\u8bb0\u300b by \u5bb9\u7956\u513f</li> <li>\u300a\u6708\u7403\u4e0b\u7684\u4eba\u300b by \u674e\u5e78\u502a</li> </ol> <p>\u300a\u5c81\u6708\u91cc\u7684\u82b1\u300b\uff1a \u5305\u7389\u521a\u56fe\u4e66\u9986\u7684\u95ed\u9986\u97f3\u4e50\uff0c\u4e0d\u77e5\u9053\u542c\u8fc7\u591a\u5c11\u6b21\u4e86\u3002\u8f6c\u4e13\u4e1a\u90a3\u51e0\u5929\u7279\u522b\u7126\u8651\uff0c\u51c6\u5907\u7684\u65f6\u5019\u4e00\u76f4\u5728\u542c\u8fd9\u9996\u6b4c\uff0c\u8fd9\u9996\u6b4c\u5f88\u795e\u5947\uff0c\u4e00\u542c\u5c31\u80fd\u9759\u4e0b\u6765\uff0c\u800c\u4e14\u4f1a\u53d8\u5f97\u66f4\u4e13\u6ce8\u3002\u6b4c\u8bcd\u4e5f\u5199\u5f97\u5f88\u597d\uff0c\u201c\u4e91\u4f1a\u5347\u8d77 \u96e8\u4f1a\u843d\u4e0b \u4e0d\u7528\u50ac\u4fc3\u554a \u8010\u5fc3\u7684\u4eba\u554a\u624d\u53ef\u4ee5\u770b\u89c1\u7ae5\u8bdd\u201d</p> <p>\u300a\u4e4b\u5916\u300b\uff1a \u4e0a\u5b66\u671f\u671f\u672b\u590d\u4e60\u7684\u65f6\u5019\u4e00\u76f4\u5728\u542c\uff0c\u8ba4\u8bc6\u8fd9\u9996\u6b4c\u4e5f\u5f88\u5de7\u5408\uff0c\u672c\u6765\u6211\u662f\u4e0d\u600e\u4e48\u542cEason\u7684\u56fd\u8bed\u6b4c\u7684\uff0c\u7ed3\u679c\u770b\u5230F&amp;D\u5531\u4e86\u8fd9\u9996\u6b4c\uff0c\u7136\u540e\u5c31\u53bb\u628a\u300aC\u2019mon in~\u300b\u8fd9\u9996\u4e13\u7684\u6240\u6709\u6b4c\u90fd\u542c\u4e86\u4e00\u904d\uff0c\u8fd9\u5f20\u56fd\u8bed\u4e13\u8f91\u771f\u662f\u88ab\u4f4e\u4f30\u4e86\uff0c\u6211\u613f\u79f0\u4e4b\u4e3a\u7b2c\u4e00\u56fd\u8bed\u4e13\uff0c\u5728\u6240\u6709\u4e13\u8f91\u91cc\u4ec5\u6b21\u4e8e\u300aThe Key\u300b\u4e0d\u77e5\u9053\u4e3a\u4ec0\u4e48\uff0c\u6bcf\u6b21\u8bf4\u8d77\u8fd9\u9996\u6b4c\u5c31\u4f1a\u8054\u60f3\u5230\u6211\u5728\u4e3b\u56fe\u4e09\u697c\u590d\u4e60\u65e0\u7a77\u7ea7\u6570\u7684\u65f6\u5019\u3002</p> <p>\u300a\u6211\u4e0d\u96be\u8fc7\u300b\uff1a\u5b59\u71d5\u59ff\u7684\u58f0\u97f3\u771f\u7684\u5f88\u72ec\u7279\uff0c\u5531\u6cd5\u4e5f\u5f88\u72ec\u7279\uff0c\u8fd9\u9996\u6b4c\u60c5\u7eea\u5f88\u9971\u6ee1\uff0c\u8ddf\u300a\u6708\u7403\u4e0b\u7684\u4eba\u300b\u90a3\u79cd\u6de1\u6de1\u7684\u5fe7\u4f24\u5f62\u6210\u5f3a\u70c8\u7684\u5bf9\u6bd4\uff0c\u662f\u90a3\u79cd\u55b7\u6d8c\u800c\u51fa\u7684\u4f24\u75db\u3002</p> <p>\u300a\u5b64\u513f\u4ed4\u300b\uff1a \u7b2c\u4e00\u904d\u542c\u82e6\u8363\u7684\u58f0\u97f3\u4f1a\u89c9\u5f97\u5f88\u4e0d\u4e60\u60ef\uff0c\u751a\u81f3\u53ef\u4ee5\u7528\u523a\u8033\u6765\u5f62\u5bb9\uff0c\u8fd9\u4e5f\u5bfc\u81f4\u6211\u53bb\u5e74\u7b2c\u4e00\u6b21\u542c\u8fd9\u9996\u6b4c\u7684\u65f6\u5019\u5e76\u4e0d\u559c\u6b22\u3002\u4f46\u662f\u6211\u4eca\u5e74\u518d\u542c\uff0c\u4ed4\u7ec6\u9605\u8bfb\u4e86\u6b4c\u8bcd\uff0c\u6211\u53d1\u73b0\u8fd9\u9996\u6b4c\u8fd8\u633a\u6df1\u523b\uff0c\u800c\u4e14\u82e6\u8363\u7684\u58f0\u97f3\u53cd\u800c\u662f\u8fd9\u9996\u6b4c\u6700\u51fa\u5f69\u7684\u5730\u65b9\u3002</p> <p>\u300a\u60f3\u542c\u300b\uff1a \u4e0d\u5fc5\u591a\u8bf4\uff0c\u96f7\u9882\u5fb7\u5199\u7ed9Eason\u7684\u4e09\u9996\u66f2\u5b50\u4e4b\u4e00\uff0c\u6211\u89c9\u5f97\u4e5f\u662f\u5176\u4e2d\u8d28\u91cf\u6700\u9ad8\u7684\u4e00\u9996\uff0c\u5c31\u662f\u8fd9\u9996\u6b4c\u592a\u77ed\u4e86\uff0c\u7b2c\u4e00\u6b21\u5728F&amp;D\u73b0\u573a\u542c\u7684\u65f6\u5019\uff0c\u6700\u540e\u4e50\u961f\u505a\u4e86\u7559\u767d\u5904\u7406\uff0c\u5f88\u60ca\u8273\uff0c\u58f0\u97f3\u7a7a\u7075\u56de\u54cd\u3002</p> <p>\u300a\u82cf\u5dde\u6cb3/\u6155\u5bb9\u96ea\u300b\uff1a\u5f88\u6709\u65b9\u5927\u540c\u7684\u5473\u9053\u3002\u6b4c\u8bcd\u5f88\u5389\u5bb3\uff0c\u53ea\u80fd\u8bf4\u4e0d\u6127\u662f\u6797\u82e5\u5b81\u554a\u3002</p> <p>\u300a\u6708\u7403\u4e0b\u7684\u4eba\u300b\uff1a\u53bb\u5e74\u559c\u6b22\u542c\u300a\u6708\u7403\u4e0a\u7684\u4eba\u300b\uff0c\u8fd9\u5b66\u671f\u7231\u4e0a\u4e86\u300a\u6708\u7403\u4e0b\u7684\u4eba\u300b\uff0c\u8fd8\u662f\u6797\u82e5\u5b81\u4f5c\u7684\u8bcd\uff0c\u90a3\u79cd\u6de1\u6de1\u7684\u54c0\u4f24\u592a\u6253\u52a8\u6211\u4e86\u3002</p> <p>\u300a\u641c\u795e\u8bb0\u300b\uff1a\u6cfd\u65e5\u751f+\u6797\u5915 \u7ecf\u5178\u7ec4\u5408\uff0c\u201c\u53ea\u8981\u6562\u8fdc\u98de\uff0c\u4ea6\u80fd\u81ea\u521b\u6211\u7684\u641c\u795e\u8bb0\u201d</p>"},{"location":"summary/Music/%E5%AD%A4%E5%84%BF%E4%BB%94/","title":"\u5b64\u513f\u4ed4 --Eason Chan","text":"<p> \u7ea6 433 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <p>\u50b3\u8aaa\u4e16\u9593\u6bcf\u500b\u4eba \u4e5f\u6703\u6709\u4e00\u4f4d\u5929\u4f7f\u8b77\u852d \u7e31\u4f7f\u6e3a\u5c0f\u5f77\u5982\u5fae\u5875 \u4ecd\u53ef\u68f2\u8eab\u7576\u611b\u4eba\u547c\u5438 \u53ef\u60dc\u50cf\u6211\u9019\u4e00\u7a2e\u4eba \u8056\u6bcd\u6c38\u9060\u4e0d\u80af\u7d66\u4e88\u6190\u61ab \u6bcf\u5929\u5982\u50cf\u82e6\u5152\u7948\u6c42 \u8ab0\u53ef\u771f\u5fc3\u7684\u9017\u6211\u958b\u5fc3 \u8ab0\u8aaa\u6703\u8207\u6211 \u9a0e\u8ff4\u65cb\u6728\u99ac \u5929\u9ed1\u900f\u4e86 \u4f34\u6211\u4e00\u8d77\u6b78\u5bb6 \u662f\u6211\u6216\u4f60\u72af\u932f\u4e86\u55ce \u4eba\u88ab\u534a\u8def\u6487\u4e0b \u53d7\u90a3\u98a8\u5439\u96e8\u6253 \u8ab0\u4eba\u6703\u611b\u6211\u9019\u7a2e\u5b64\u5152\u4ed4 \u6d41\u843d\u5230\u8c37\u5e95 \u6050\u6015\u6211\u5df2\u662f\u500b \u71b1\u6200\u7684\u5f8c\u907a \u7121\u4eba\u524d\u4f86\u8a8d\u9818 \u9aaf\u9ad2\u7684\u8eab\u9ad4 \u82e5\u60f3\u62b1\u62b1\u5c31\u7b49\u4e0b\u4e00\u4e16 \u8ab0\u8981\u6211\u9019\u7a2e\u5b64\u5152\u4ed4 \u8ab0\u8d08\u6211\u5b89\u6170 \u7576\u6211\u81f3\u611b\u8def\u904e \u4ea6\u4e0d\u60f3\u62fe\u907a \u8ab0\u5728\u5f9e\u524d\u8a71\u6211 \u8ca7\u7aae\u4f46\u7f8e\u9e97 \u4f46\u60f3\u62b1\u62b1\u5c31\u7b49\u5f85\u8f49\u4e16 \u6211\u9019\u7a2e\u8eab\u4e16 \u8ab0\u8aaa\u6703\u8207\u6211 \u9a0e\u8ff4\u65cb\u6728\u99ac \u5929\u9ed1\u900f\u4e86 \u4f34\u6211\u4e00\u8d77\u6b78\u5bb6 \u662f\u6211\u6216\u4f60\u72af\u932f\u4e86\u55ce \u4eba\u88ab\u534a\u8def\u6487\u4e0b \u53d7\u90a3\u98a8\u5439\u96e8\u6253 \u8ab0\u4eba\u6703\u611b\u6211\u9019\u7a2e\u5b64\u5152\u4ed4 \u6d41\u843d\u5230\u8c37\u5e95 \u6050\u6015\u6211\u5df2\u662f\u500b \u71b1\u6200\u7684\u5f8c\u907a \u7121\u4eba\u524d\u4f86\u8a8d\u9818 \u9aaf\u9ad2\u7684\u8eab\u9ad4 \u82e5\u60f3\u62b1\u62b1\u5c31\u7b49\u4e0b\u4e00\u4e16 \u8ab0\u8981\u6211\u9019\u7a2e\u5b64\u5152\u4ed4 \u8ab0\u8d08\u6211\u5b89\u6170 \u7576\u6211\u81f3\u611b\u8def\u904e \u4ea6\u4e0d\u60f3\u62fe\u907a \u8ab0\u5728\u5f9e\u524d\u8a71\u6211 \u8ca7\u7aae\u4f46\u7f8e\u9e97 \u4f46\u60f3\u62b1\u62b1\u5c31\u7b49\u5f85\u8f49\u4e16 \u6211\u9019\u7a2e\u8eab\u4e16 \u8ab0\u4eba\u6703\u611b\u6211\u9019\u7a2e\u5b64\u5152\u4ed4 \u6d41\u843d\u5230\u8c37\u5e95 \u6050\u6015\u6211\u5df2\u662f\u500b \u71b1\u6200\u7684\u5f8c\u907a \u7121\u4eba\u524d\u4f86\u8a8d\u9818 \u9aaf\u9ad2\u7684\u8eab\u9ad4 \u82e5\u60f3\u62b1\u62b1\u5c31\u7b49\u4e0b\u4e00\u4e16 \u8ab0\u8981\u6211\u9019\u7a2e\u5b64\u5152\u4ed4 \u8ab0\u8d08\u6211\u5b89\u6170 \u7576\u6211\u81f3\u611b\u8def\u904e \u4ea6\u4e0d\u60f3\u62fe\u907a \u8ab0\u5728\u5f9e\u524d\u8a71\u6211 \u8ca7\u7aae\u4f46\u7f8e\u9e97 \u4f46\u60f3\u62b1\u62b1\u5c31\u7b49\u5f85\u8f49\u4e16 \u6211\u9019\u7a2e\u8eab\u4e16</p>"},{"location":"websites/","title":"index","text":""},{"location":"websites/#websites","title":"Websites","text":"<p>\u6536\u96c6\u5230\u7684\u6709\u610f\u601d\u7684\uff0c\u5bf9\u6211\u6709\u5e2e\u52a9\u7684\u7f51\u7ad9~</p>"},{"location":"websites/LLM/","title":"LLM","text":"<p> \u7ea6 27 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u5f88\u597d\u7684Transformer\u53ef\u89c6\u5316\u7f51\u7ad9 LLM Visualization:LLM Visualization (bbycroft.net)</p> <p>\u5f88\u597d\u7684CNN\u53ef\u89c6\u5316\u7f51\u7ad9 CNN Explainer: CNN Explainer (poloclub.github.io)</p>"},{"location":"websites/Trivia/","title":"Trivia","text":"<p> \u7ea6 18 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <ol> <li>\u4e3a\u4ec0\u4e48torch.manual_seed(42)?</li> </ol> <p>\u673a\u5668\u5b66\u4e60\u4e2d\u201crandom.seed(42)\u201d\u80cc\u540e\u7684\u6545\u4e8b </p>"}]}